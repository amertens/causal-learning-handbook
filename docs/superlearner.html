<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<<<<<<< HEAD

<title>Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</title>
=======
<meta name="description" content="A practical guide to the Causal Roadmap, Targeted Maximum Likelihood Estimation (TMLE), and Super Learner for modern causal inference in epidemiology, with emphasis on pharmacoepidemiology and clinical trial analysis.">

<title>10&nbsp; Chapter 2.4: SuperLearner and Machine Learning for Causal Inference – Causal Learning Handbook</title>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<<<<<<< HEAD
<script src="superlearner_files/libs/clipboard/clipboard.min.js"></script>
<script src="superlearner_files/libs/quarto-html/quarto.js"></script>
<script src="superlearner_files/libs/quarto-html/popper.min.js"></script>
<script src="superlearner_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="superlearner_files/libs/quarto-html/anchor.min.js"></script>
<link href="superlearner_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="superlearner_files/libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="superlearner_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="superlearner_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="superlearner_files/libs/bootstrap/bootstrap-1bc8a17f135ab3d594c857e9f48e611b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
=======
<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./03-03-longitudinal-case-study.html" rel="next">
<link href="./02-04-tmle-teaching-examples.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-b343bb23504f009ddf7b24643a6af19a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
>>>>>>> claude/tmle-teaching-examples-EP2Hd

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<<<<<<< HEAD
</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</h1>
=======
<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02-01-gcomputation.html">Part II: Estimation Methods</a></li><li class="breadcrumb-item"><a href="./superlearner.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Causal Learning Handbook</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/amertens/causal-learning-handbook" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Causal Learning Handbook</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Part I: Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-01-regression-vs-causal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Chapter 1.1: Limitations of Standard Regression Analyses</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-02-causal-roadmap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Chapter 1.2: The Causal Roadmap</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-03-identification-estimands.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./roadmap_tutorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Causal Roadmap for Real-world Evidence Generation: A Tutorial</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Part II: Estimation Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-01-gcomputation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Chapter 2.1: Outcome Modeling and Standardization (G-Computation)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-02-iptw.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Chapter 2.2: Inverse Probability of Treatment Weighting (IPTW)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-03-doubly-robust-tmle.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Chapter 2.3: Doubly Robust Estimators and Targeted Learning (AIPW + TMLE)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-04-tmle-teaching-examples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Chapter 2.4: From Question to Estimate — TMLE in Practice</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./superlearner.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Part III: Advanced Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-03-longitudinal-case-study.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chapter 3.3: Case Study – Real-World Application in Longitudinal Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-04-effect-modification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-05-advanced-diagnostics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-06-rwd-meets-rct-hybrid-designs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Chapter 3.6: When RWD Meets RCT – Hybrid Designs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-07-longitudinal-td-confounding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-08-tmle-clean-room.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-09-illustrated-ltmle.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">An Illustrated Guide to Longitudinal TMLE</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-10-tmle-mediation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">An Illustrated Guide to TMLE for Mediation Analysis</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./common-pitfalls.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Common Pitfalls and How to Avoid Them</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./anotated_bibliography.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Annotated Bibliography: Modern Causal Inference and Targeted Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./other_resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Resources</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#chapter-2.4-superlearner-and-machine-learning-for-causal-inference" id="toc-chapter-2.4-superlearner-and-machine-learning-for-causal-inference" class="nav-link active" data-scroll-target="#chapter-2.4-superlearner-and-machine-learning-for-causal-inference"><span class="header-section-number">11</span> Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</a>
  <ul class="collapse">
  <li><a href="#why-use-superlearner-in-causal-inference" id="toc-why-use-superlearner-in-causal-inference" class="nav-link" data-scroll-target="#why-use-superlearner-in-causal-inference"><span class="header-section-number">11.1</span> 1. Why Use SuperLearner in Causal Inference?</a></li>
  <li><a href="#conceptual-overview-of-superlearner" id="toc-conceptual-overview-of-superlearner" class="nav-link" data-scroll-target="#conceptual-overview-of-superlearner"><span class="header-section-number">11.2</span> 2. Conceptual Overview of SuperLearner</a></li>
  <li><a href="#a-minimal-working-example" id="toc-a-minimal-working-example" class="nav-link" data-scroll-target="#a-minimal-working-example"><span class="header-section-number">11.3</span> 3. A Minimal Working Example</a>
  <ul class="collapse">
  <li><a href="#simulated-data" id="toc-simulated-data" class="nav-link" data-scroll-target="#simulated-data"><span class="header-section-number">11.3.1</span> 3.1 Simulated data</a></li>
  </ul></li>
  <li><a href="#using-the-superlearner-package" id="toc-using-the-superlearner-package" class="nav-link" data-scroll-target="#using-the-superlearner-package"><span class="header-section-number">11.4</span> 4. Using the <code>SuperLearner</code> Package</a>
  <ul class="collapse">
  <li><a href="#basic-call" id="toc-basic-call" class="nav-link" data-scroll-target="#basic-call"><span class="header-section-number">11.4.1</span> 4.1 Basic call</a></li>
  </ul></li>
  <li><a href="#choosing-a-loss-function-mse-vs-log-likelihood-vs-auc" id="toc-choosing-a-loss-function-mse-vs-log-likelihood-vs-auc" class="nav-link" data-scroll-target="#choosing-a-loss-function-mse-vs-log-likelihood-vs-auc"><span class="header-section-number">11.5</span> 5. Choosing a Loss Function: MSE vs Log-Likelihood vs AUC</a>
  <ul class="collapse">
  <li><a href="#mean-squared-error-mse" id="toc-mean-squared-error-mse" class="nav-link" data-scroll-target="#mean-squared-error-mse"><span class="header-section-number">11.5.1</span> 5.1 Mean Squared Error (MSE)</a></li>
  <li><a href="#negative-log-likelihood-binomial-deviance" id="toc-negative-log-likelihood-binomial-deviance" class="nav-link" data-scroll-target="#negative-log-likelihood-binomial-deviance"><span class="header-section-number">11.5.2</span> 5.2 Negative Log-Likelihood (Binomial deviance)</a></li>
  <li><a href="#auc-rank-loss" id="toc-auc-rank-loss" class="nav-link" data-scroll-target="#auc-rank-loss"><span class="header-section-number">11.5.3</span> 5.3 AUC / Rank Loss</a></li>
  <li><a href="#which-loss-should-i-choose" id="toc-which-loss-should-i-choose" class="nav-link" data-scroll-target="#which-loss-should-i-choose"><span class="header-section-number">11.5.4</span> 5.4 Which loss should I choose?</a></li>
  </ul></li>
  <li><a href="#interpreting-cv-risk-and-coefficient-weights" id="toc-interpreting-cv-risk-and-coefficient-weights" class="nav-link" data-scroll-target="#interpreting-cv-risk-and-coefficient-weights"><span class="header-section-number">11.6</span> 6. Interpreting CV-Risk and Coefficient Weights</a></li>
  <li><a href="#customizing-the-library-and-tuning-learners" id="toc-customizing-the-library-and-tuning-learners" class="nav-link" data-scroll-target="#customizing-the-library-and-tuning-learners"><span class="header-section-number">11.7</span> 7. Customizing the Library and Tuning Learners</a>
  <ul class="collapse">
  <li><a href="#adding-tuned-versions-of-a-learner-e.g.-random-forest" id="toc-adding-tuned-versions-of-a-learner-e.g.-random-forest" class="nav-link" data-scroll-target="#adding-tuned-versions-of-a-learner-e.g.-random-forest"><span class="header-section-number">11.7.1</span> 7.1 Adding tuned versions of a learner (e.g., Random Forest)</a></li>
  </ul></li>
  <li><a href="#cross-validated-superlearner-cv.superlearner" id="toc-cross-validated-superlearner-cv.superlearner" class="nav-link" data-scroll-target="#cross-validated-superlearner-cv.superlearner"><span class="header-section-number">11.8</span> 8. Cross-Validated SuperLearner (<code>CV.SuperLearner</code>)</a></li>
  <li><a href="#integrating-superlearner-into-causal-inference" id="toc-integrating-superlearner-into-causal-inference" class="nav-link" data-scroll-target="#integrating-superlearner-into-causal-inference"><span class="header-section-number">11.9</span> 9. Integrating SuperLearner into Causal Inference</a></li>
  <li><a href="#practical-tips-for-using-superlearner" id="toc-practical-tips-for-using-superlearner" class="nav-link" data-scroll-target="#practical-tips-for-using-superlearner"><span class="header-section-number">11.10</span> 10. Practical Tips for Using SuperLearner</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">11.11</span> 11. Summary</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02-01-gcomputation.html">Part II: Estimation Methods</a></li><li class="breadcrumb-item"><a href="./superlearner.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<<<<<<< HEAD
<section id="chapter-2.4-superlearner-and-machine-learning-for-causal-inference" class="level1">
<h1>Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</h1>
=======
<section id="chapter-2.4-superlearner-and-machine-learning-for-causal-inference" class="level1" data-number="11">
<h1 data-number="11"><span class="header-section-number">11</span> Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</h1>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<p><em>Flexible prediction to strengthen causal effect estimation</em></p>
<p>Modern causal inference relies on estimating <strong>nuisance functions</strong> (outcome regressions and treatment / censoring mechanisms) that are as accurate as possible. If these models are mis-specified, even sophisticated causal estimators can be biased.</p>
<p>Rather than gambling on a single model (e.g., logistic regression), we can <strong>stack</strong> many candidate learners and let the data decide how to combine them. This is what <strong>SuperLearner</strong> does.</p>
<p>In this chapter you will learn:</p>
<ul>
<li>The intuition behind SuperLearner (SL) and stacking<br>
</li>
<li>How cross-validation is used to avoid overfitting<br>
</li>
<li>How to build and interpret SuperLearner models in R<br>
</li>
<li>When and why to choose different <strong>loss functions</strong> (MSE, log-likelihood, AUC)<br>
</li>
<li>How to customize SL libraries and tune algorithms<br>
</li>
<li>How SL integrates with TMLE and other causal estimators</li>
</ul>
<p>This chapter leans heavily on the excellent visual tutorial by Katherine Hoffman and the SuperLearner demo by David Benkeser (both provided as PDFs), and recasts them in a causal-inference focused Quarto format.</p>
<hr>
<<<<<<< HEAD
<section id="why-use-superlearner-in-causal-inference" class="level2">
<h2 class="anchored" data-anchor-id="why-use-superlearner-in-causal-inference">1. Why Use SuperLearner in Causal Inference?</h2>
=======
<section id="why-use-superlearner-in-causal-inference" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="why-use-superlearner-in-causal-inference"><span class="header-section-number">11.1</span> 1. Why Use SuperLearner in Causal Inference?</h2>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<p>Causal estimators such as g-computation, IPTW, AIPW, and TMLE rely on estimating:</p>
<ul>
<li><p>The <strong>outcome regression</strong>:<br>
( Q(W, A) = E[Y W, A] )</p></li>
<li><p>The <strong>treatment (or censoring) mechanism</strong>:<br>
( g(W) = P(A = 1 W) )</p></li>
</ul>
<p>In traditional practice, both are often modeled with simple GLMs. This is dangerous when:</p>
<ul>
<li>Relationships are nonlinear</li>
<li>Interactions are present</li>
<li>There are many covariates</li>
<li>We are unsure about which variables to include or in what functional form</li>
</ul>
<p>SuperLearner helps by:</p>
<ul>
<li>Combining multiple algorithms (GLM, random forests, LASSO, boosted trees, etc.)</li>
<li>Using <strong>K-fold cross-validation</strong> to evaluate and weight each algorithm</li>
<li>Producing an ensemble predictor with theoretical guarantees (an “oracle inequality”): asymptotically, SL performs nearly as well as the best algorithm in the library</li>
</ul>
<p>In causal inference, we rarely care about prediction for its own sake, but good prediction of nuisance functions leads to <strong>better causal effect estimation</strong>.</p>
<hr>
</section>
<<<<<<< HEAD
<section id="conceptual-overview-of-superlearner" class="level2">
<h2 class="anchored" data-anchor-id="conceptual-overview-of-superlearner">2. Conceptual Overview of SuperLearner</h2>
=======
<section id="conceptual-overview-of-superlearner" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="conceptual-overview-of-superlearner"><span class="header-section-number">11.2</span> 2. Conceptual Overview of SuperLearner</h2>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<p>At a high level, SuperLearner does the following:</p>
<ol type="1">
<li>Pick a <strong>set of candidate learners</strong> (the library).</li>
<li>Split the data into <strong>K folds</strong>.</li>
<li>For each learner:
<ul>
<li>Fit on K-1 folds (training data),</li>
<li>Predict on the held-out fold (validation data).</li>
</ul></li>
<li>Collect <strong>cross-validated predictions</strong> for every observation and every learner.</li>
<li>Fit a <strong>metalearner</strong> (often a linear regression) that finds the optimal weighted combination of the learners’ predictions to minimize a chosen <strong>loss function</strong> (e.g., mean squared error, negative log-likelihood).</li>
<li>Refit each base learner on the full dataset.</li>
<li>Use the metalearner and the refit base learners to form the final ensemble and obtain predictions for new data.</li>
</ol>
<p>This is exactly the workflow illustrated in the “VISUAL GUIDE TO SUPERLEARNING” figure in the KHstats tutorial.</p>
<hr>
</section>
<<<<<<< HEAD
<section id="a-minimal-working-example" class="level2">
<h2 class="anchored" data-anchor-id="a-minimal-working-example">3. A Minimal Working Example</h2>
<p>We’ll start with a simple prediction problem, then connect it back to causal inference later.</p>
<section id="simulated-data" class="level3">
<h3 class="anchored" data-anchor-id="simulated-data">3.1 Simulated data</h3>
=======
<section id="a-minimal-working-example" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="a-minimal-working-example"><span class="header-section-number">11.3</span> 3. A Minimal Working Example</h2>
<p>We’ll start with a simple prediction problem, then connect it back to causal inference later.</p>
<section id="simulated-data" class="level3" data-number="11.3.1">
<h3 data-number="11.3.1" class="anchored" data-anchor-id="simulated-data"><span class="header-section-number">11.3.1</span> 3.1 Simulated data</h3>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'ggplot2' was built under R version 4.4.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'stringr' was built under R version 4.4.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.6.0
✔ ggplot2   3.5.2     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.1
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(SuperLearner)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: nnls
Loading required package: gam
Loading required package: splines
Loading required package: foreach

Attaching package: 'foreach'

The following objects are masked from 'package:purrr':

    accumulate, when

Loaded gam 1.22-5

Super Learner
Version: 2.0-29
Package created on 2024-02-06</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">7</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">2000</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>obs <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">id =</span> <span class="dv">1</span><span class="sc">:</span>n,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="fu">rnorm</span>(n),</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">x2 =</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fu">plogis</span>(<span class="dv">10</span> <span class="sc">*</span> x1)),</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">x3 =</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fu">plogis</span>(x1 <span class="sc">*</span> x2 <span class="sc">+</span> <span class="fl">0.5</span> <span class="sc">*</span> x2)),</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">x4 =</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> x1 <span class="sc">*</span> x2, <span class="at">sd =</span> <span class="fl">0.5</span> <span class="sc">*</span> x3),</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">y  =</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x2 <span class="sc">*</span> x3 <span class="sc">+</span> <span class="fu">sin</span>(x4) <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> <span class="fl">0.2</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(obs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 2,000
Columns: 6
$ id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, …
$ x1 &lt;dbl&gt; 2.287247161, -1.196771682, -0.694292510, -0.412292951, -0.970673341…
$ x2 &lt;int&gt; 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1…
$ x3 &lt;int&gt; 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1…
$ x4 &lt;dbl&gt; 1.50283924, 0.04260947, 0.00000000, 0.00000000, 0.00000000, 1.07555…
$ y  &lt;dbl&gt; 5.03669124, -1.13306036, -0.38284042, -0.28671230, -0.87539307, -0.…</code></pre>
</div>
</div>
<p>The outcome <code>y</code> is a nonlinear function of the covariates, with interactions and a sine term. GLMs will struggle here.</p>
<hr>
</section>
</section>
<<<<<<< HEAD
<section id="using-the-superlearner-package" class="level2">
<h2 class="anchored" data-anchor-id="using-the-superlearner-package">4. Using the <code>SuperLearner</code> Package</h2>
<section id="basic-call" class="level3">
<h3 class="anchored" data-anchor-id="basic-call">4.1 Basic call</h3>
=======
<section id="using-the-superlearner-package" class="level2" data-number="11.4">
<h2 data-number="11.4" class="anchored" data-anchor-id="using-the-superlearner-package"><span class="header-section-number">11.4</span> 4. Using the <code>SuperLearner</code> Package</h2>
<section id="basic-call" class="level3" data-number="11.4.1">
<h3 data-number="11.4.1" class="anchored" data-anchor-id="basic-call"><span class="header-section-number">11.4.1</span> 4.1 Basic call</h3>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<p>We’ll start with a small library for illustration.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> obs <span class="sc">%&gt;%</span> <span class="fu">select</span>(x1<span class="sc">:</span>x4) <span class="sc">%&gt;%</span> <span class="fu">as.data.frame</span>()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> obs<span class="sc">$</span>y</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>SL.lib <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"SL.glm"</span>,      <span class="co"># simple GLM</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>            <span class="st">"SL.mean"</span>,     <span class="co"># intercept-only</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">"SL.earth"</span>,    <span class="co"># multivariate adaptive regression splines (MARS)</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>            <span class="st">"SL.ranger"</span>)   <span class="co"># random forest</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>sl_fit <span class="ot">&lt;-</span> <span class="fu">SuperLearner</span>(</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">Y =</span> Y,</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">X =</span> X,</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">newX =</span> <span class="cn">NULL</span>,</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">SL.library =</span> SL.lib,</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"method.NNLS"</span>,  <span class="co"># non-negative least squares metalearner</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">cvControl =</span> <span class="fu">list</span>(<span class="at">V =</span> <span class="dv">10</span>L)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required namespace: earth</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required namespace: ranger</code></pre>
</div>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>sl_fit</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:  
SuperLearner(Y = Y, X = X, newX = NULL, family = gaussian(), SL.library = SL.lib,  
    method = "method.NNLS", cvControl = list(V = 10L)) 

                    Risk      Coef
SL.glm_All    0.15038334 0.0000000
SL.mean_All   4.52716718 0.0000000
SL.earth_All  0.04408952 0.8593302
SL.ranger_All 0.05735981 0.1406698</code></pre>
</div>
</div>
<p>Key outputs:</p>
<ul>
<li><code>Risk</code>: cross-validated risk (e.g., MSE) for each learner</li>
<li><code>Coef</code>: weight given to each learner in the ensemble</li>
</ul>
<p>The learner with the smallest CV-risk often gets the largest weight, but SL can combine learners.</p>
<p>We can access the <strong>ensemble predictions</strong>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(sl_fit<span class="sc">$</span>SL.predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         [,1]
1  5.36960217
2 -1.15651994
3 -0.66557910
4 -0.39653932
5 -0.94879355
6 -0.04451723</code></pre>
</div>
</div>
<p>and predictions from individual learners:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(sl_fit<span class="sc">$</span>library.predict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  SL.glm_All SL.mean_All SL.earth_All SL.ranger_All
1  4.9119003    1.145784   5.44169210     4.9292158
2 -0.9619611    1.145784  -1.14585410    -1.2216759
3 -0.8907976    1.145784  -0.67326080    -0.6186528
4 -0.6300543    1.145784  -0.40211488    -0.3624791
5 -1.1463457    1.145784  -0.94947428    -0.9446351
6 -0.1673960    1.145784  -0.01723667    -0.2111701</code></pre>
</div>
</div>
<hr>
</section>
</section>
<<<<<<< HEAD
<section id="choosing-a-loss-function-mse-vs-log-likelihood-vs-auc" class="level2">
<h2 class="anchored" data-anchor-id="choosing-a-loss-function-mse-vs-log-likelihood-vs-auc">5. Choosing a Loss Function: MSE vs Log-Likelihood vs AUC</h2>
<p>SuperLearner allows different <strong>loss functions</strong>, which define what we mean by “best” prediction.</p>
<section id="mean-squared-error-mse" class="level3">
<h3 class="anchored" data-anchor-id="mean-squared-error-mse">5.1 Mean Squared Error (MSE)</h3>
=======
<section id="choosing-a-loss-function-mse-vs-log-likelihood-vs-auc" class="level2" data-number="11.5">
<h2 data-number="11.5" class="anchored" data-anchor-id="choosing-a-loss-function-mse-vs-log-likelihood-vs-auc"><span class="header-section-number">11.5</span> 5. Choosing a Loss Function: MSE vs Log-Likelihood vs AUC</h2>
<p>SuperLearner allows different <strong>loss functions</strong>, which define what we mean by “best” prediction.</p>
<section id="mean-squared-error-mse" class="level3" data-number="11.5.1">
<h3 data-number="11.5.1" class="anchored" data-anchor-id="mean-squared-error-mse"><span class="header-section-number">11.5.1</span> 5.1 Mean Squared Error (MSE)</h3>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<ul>
<li>Default for <code>family = gaussian()</code></li>
<li>Appropriate for <strong>continuous outcomes</strong> when we care about squared error: <span class="math display">\[ L(y, \hat{y}) = (y - \hat{y})^2 \]</span></li>
<li>Good when we want well-calibrated mean predictions</li>
</ul>
<p>Example (already used above): <code>method = "method.NNLS"</code> with <code>family = gaussian()</code></p>
</section>
<<<<<<< HEAD
<section id="negative-log-likelihood-binomial-deviance" class="level3">
<h3 class="anchored" data-anchor-id="negative-log-likelihood-binomial-deviance">5.2 Negative Log-Likelihood (Binomial deviance)</h3>
=======
<section id="negative-log-likelihood-binomial-deviance" class="level3" data-number="11.5.2">
<h3 data-number="11.5.2" class="anchored" data-anchor-id="negative-log-likelihood-binomial-deviance"><span class="header-section-number">11.5.2</span> 5.2 Negative Log-Likelihood (Binomial deviance)</h3>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<ul>
<li>Natural choice for <strong>binary outcomes</strong> when we care about probability calibration: <span class="math display">\[ L(y, \hat{p}) = -[y \log(\hat{p}) + (1-y) \log(1-\hat{p})] \]</span></li>
<li>Strongly penalizes confident but wrong predictions</li>
<li>Recommended for:
<ul>
<li>Outcome models (<code>Y</code> binary)</li>
<li>Treatment models (<code>A</code> binary) in causal inference</li>
</ul></li>
</ul>
<p>Use <code>method = "method.NNloglik"</code> with <code>family = binomial()</code>.</p>
<p>Example:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># suppose Y is binary</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>Y_bin <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fu">plogis</span>(X<span class="sc">$</span>x1 <span class="sc">+</span> X<span class="sc">$</span>x2))</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>sl_loglik <span class="ot">&lt;-</span> <span class="fu">SuperLearner</span>(</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">Y =</span> Y_bin,</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">X =</span> X,</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">binomial</span>(),</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">SL.library =</span> <span class="fu">c</span>(<span class="st">"SL.glm"</span>, <span class="st">"SL.mean"</span>, <span class="st">"SL.ranger"</span>),</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"method.NNloglik"</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>sl_loglik</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:  
SuperLearner(Y = Y_bin, X = X, family = binomial(), SL.library = c("SL.glm",  
    "SL.mean", "SL.ranger"), method = "method.NNloglik") 

                   Risk      Coef
SL.glm_All    0.5286216 0.8914129
SL.mean_All   0.6818619 0.0000000
SL.ranger_All 0.5537130 0.1085871</code></pre>
</div>
</div>
</section>
<<<<<<< HEAD
<section id="auc-rank-loss" class="level3">
<h3 class="anchored" data-anchor-id="auc-rank-loss">5.3 AUC / Rank Loss</h3>
=======
<section id="auc-rank-loss" class="level3" data-number="11.5.3">
<h3 data-number="11.5.3" class="anchored" data-anchor-id="auc-rank-loss"><span class="header-section-number">11.5.3</span> 5.3 AUC / Rank Loss</h3>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<ul>
<li>For classification problems where the <strong>ranking</strong> of probabilities matters more than calibration</li>
<li>Common when choosing a threshold later (e.g., risk stratification)</li>
<li>SuperLearner implementation: <code>method = "method.AUC"</code></li>
<li>Particularly useful when interested in discriminatory ability (e.g., disease risk scores)</li>
</ul>
<p>Example:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cvAUC)   <span class="co"># required by method.AUC</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>sl_auc <span class="ot">&lt;-</span> <span class="fu">SuperLearner</span>(</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">Y =</span> Y_bin,</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">X =</span> X,</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">binomial</span>(),</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">SL.library =</span> <span class="fu">c</span>(<span class="st">"SL.glm"</span>, <span class="st">"SL.mean"</span>, <span class="st">"SL.ranger"</span>),</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"method.AUC"</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames, :
optim didn't converge when estimating the super learner coefficients, reason
(see ?optim): 52 optim message: ERROR: ABNORMAL_TERMINATION_IN_LNSRCH</code></pre>
</div>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>sl_auc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:  
SuperLearner(Y = Y_bin, X = X, family = binomial(), SL.library = c("SL.glm",  
    "SL.mean", "SL.ranger"), method = "method.AUC") 

                   Risk         Coef
SL.glm_All    0.1938743 0.9988292700
SL.mean_All   0.5268196 0.0006672332
SL.ranger_All 0.2104779 0.0005034968</code></pre>
</div>
</div>
</section>
<<<<<<< HEAD
<section id="which-loss-should-i-choose" class="level3">
<h3 class="anchored" data-anchor-id="which-loss-should-i-choose">5.4 Which loss should I choose?</h3>
=======
<section id="which-loss-should-i-choose" class="level3" data-number="11.5.4">
<h3 data-number="11.5.4" class="anchored" data-anchor-id="which-loss-should-i-choose"><span class="header-section-number">11.5.4</span> 5.4 Which loss should I choose?</h3>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<ul>
<li><strong>For outcome models in TMLE/AIPW:</strong>
<ul>
<li>If binary → log-likelihood (binomial deviance)<br>
</li>
<li>If continuous → MSE or other appropriate distribution-based loss<br>
</li>
</ul></li>
<li><strong>For treatment / censoring models in causal inference:</strong>
<ul>
<li>Typically log-likelihood (because we want accurate estimates of <code>P(A | W)</code>)</li>
</ul></li>
<li><strong>For pure classification (no causal estimation):</strong>
<ul>
<li>Consider AUC loss (<code>method.AUC</code>) if ranking is the priority</li>
</ul></li>
</ul>
<hr>
</section>
</section>
<<<<<<< HEAD
<section id="interpreting-cv-risk-and-coefficient-weights" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-cv-risk-and-coefficient-weights">6. Interpreting CV-Risk and Coefficient Weights</h2>
=======
<section id="interpreting-cv-risk-and-coefficient-weights" class="level2" data-number="11.6">
<h2 data-number="11.6" class="anchored" data-anchor-id="interpreting-cv-risk-and-coefficient-weights"><span class="header-section-number">11.6</span> 6. Interpreting CV-Risk and Coefficient Weights</h2>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>sl_fit<span class="sc">$</span>cvRisk</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   SL.glm_All   SL.mean_All  SL.earth_All SL.ranger_All 
   0.15038334    4.52716718    0.04408952    0.05735981 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>sl_fit<span class="sc">$</span>coef</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   SL.glm_All   SL.mean_All  SL.earth_All SL.ranger_All 
    0.0000000     0.0000000     0.8593302     0.1406698 </code></pre>
</div>
</div>
<ul>
<li><code>cvRisk</code> shows cross-validated risk for each algorithm</li>
<li><code>coef</code> gives the ensemble weights (metalearner solution)</li>
</ul>
<p>An algorithm might have:</p>
<ul>
<li>Low risk → high weight<br>
</li>
<li>High risk → weight near zero (effectively excluded)</li>
</ul>
<p>This matches the demonstration in the Benkeser notes where GLM dominates mean-only models when predicting MI.</p>
<hr>
</section>
<<<<<<< HEAD
<section id="customizing-the-library-and-tuning-learners" class="level2">
<h2 class="anchored" data-anchor-id="customizing-the-library-and-tuning-learners">7. Customizing the Library and Tuning Learners</h2>
<section id="adding-tuned-versions-of-a-learner-e.g.-random-forest" class="level3">
<h3 class="anchored" data-anchor-id="adding-tuned-versions-of-a-learner-e.g.-random-forest">7.1 Adding tuned versions of a learner (e.g., Random Forest)</h3>
=======
<section id="customizing-the-library-and-tuning-learners" class="level2" data-number="11.7">
<h2 data-number="11.7" class="anchored" data-anchor-id="customizing-the-library-and-tuning-learners"><span class="header-section-number">11.7</span> 7. Customizing the Library and Tuning Learners</h2>
<section id="adding-tuned-versions-of-a-learner-e.g.-random-forest" class="level3" data-number="11.7.1">
<h3 data-number="11.7.1" class="anchored" data-anchor-id="adding-tuned-versions-of-a-learner-e.g.-random-forest"><span class="header-section-number">11.7.1</span> 7.1 Adding tuned versions of a learner (e.g., Random Forest)</h3>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<p>We can define bounded random forest variants with different hyperparameters.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>SL.ranger_mtry3 <span class="ot">&lt;-</span> <span class="cf">function</span>(..., <span class="at">mtry =</span> <span class="dv">3</span>){</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">SL.ranger</span>(..., <span class="at">mtry =</span> mtry)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>SL.ranger_mtry4 <span class="ot">&lt;-</span> <span class="cf">function</span>(..., <span class="at">mtry =</span> <span class="dv">4</span>){</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">SL.ranger</span>(..., <span class="at">mtry =</span> mtry)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>SL.lib_tuned <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"SL.glm"</span>,</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>                  <span class="st">"SL.earth"</span>,</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>                  <span class="st">"SL.ranger_mtry3"</span>,</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>                  <span class="st">"SL.ranger_mtry4"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then run:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>sl_tuned <span class="ot">&lt;-</span> <span class="fu">SuperLearner</span>(</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">Y =</span> Y,</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">X =</span> X,</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">SL.library =</span> SL.lib_tuned,</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"method.NNLS"</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>sl_tuned<span class="sc">$</span>cvRisk</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         SL.glm_All        SL.earth_All SL.ranger_mtry3_All SL.ranger_mtry4_All 
         0.15062184          0.04401740          0.05044671          0.05242569 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>sl_tuned<span class="sc">$</span>coef</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         SL.glm_All        SL.earth_All SL.ranger_mtry3_All SL.ranger_mtry4_All 
          0.0000000           0.7318382           0.2681618           0.0000000 </code></pre>
</div>
</div>
<p>SuperLearner automatically picks which tuned version (or combination) works best.</p>
<hr>
</section>
</section>
<<<<<<< HEAD
<section id="cross-validated-superlearner-cv.superlearner" class="level2">
<h2 class="anchored" data-anchor-id="cross-validated-superlearner-cv.superlearner">8. Cross-Validated SuperLearner (<code>CV.SuperLearner</code>)</h2>
=======
<section id="cross-validated-superlearner-cv.superlearner" class="level2" data-number="11.8">
<h2 data-number="11.8" class="anchored" data-anchor-id="cross-validated-superlearner-cv.superlearner"><span class="header-section-number">11.8</span> 8. Cross-Validated SuperLearner (<code>CV.SuperLearner</code>)</h2>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<p><code>CV.SuperLearner</code> adds an <strong>outer layer</strong> of cross-validation to evaluate SL versus its components objectively.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>cv_sl <span class="ot">&lt;-</span> <span class="fu">CV.SuperLearner</span>(</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">Y =</span> Y,</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">X =</span> X,</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">V =</span> <span class="dv">5</span>,</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="fu">gaussian</span>(),</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">SL.library =</span> SL.lib</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>cv_sl</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:  
CV.SuperLearner(Y = Y, X = X, V = 5, family = gaussian(), SL.library = SL.lib) 



Cross-validated predictions from the SuperLearner:  SL.predict 

Cross-validated predictions from the discrete super learner (cross-validation selector):  discreteSL.predict 

Which library algorithm was the discrete super learner:  whichDiscreteSL 

Cross-validated prediction for all algorithms in the library:  library.predict</code></pre>
</div>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv_sl)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="superlearner_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The plot shows:</p>
<ul>
<li>Cross-validated risks and confidence intervals for each learner</li>
<li>Performance of the discrete and continuous SuperLearner</li>
</ul>
<p>This step is particularly helpful when you want to justify using SL rather than a single, simpler algorithm.</p>
<hr>
</section>
<<<<<<< HEAD
<section id="integrating-superlearner-into-causal-inference" class="level2">
<h2 class="anchored" data-anchor-id="integrating-superlearner-into-causal-inference">9. Integrating SuperLearner into Causal Inference</h2>
=======
<section id="integrating-superlearner-into-causal-inference" class="level2" data-number="11.9">
<h2 data-number="11.9" class="anchored" data-anchor-id="integrating-superlearner-into-causal-inference"><span class="header-section-number">11.9</span> 9. Integrating SuperLearner into Causal Inference</h2>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<p>So far we focused on prediction. How does this relate to causal inference?</p>
<p>For a point-treatment ATE, a TMLE analysis might look like:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example skeleton (you will flesh this out later with your own data)</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tmle)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>tmle_fit <span class="ot">&lt;-</span> <span class="fu">tmle</span>(</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">Y =</span> Y_bin,          <span class="co"># binary outcome</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">A =</span> A,              <span class="co"># treatment</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">W =</span> X,              <span class="co"># covariates</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="st">"binomial"</span>,</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">Q.SL.library =</span> <span class="fu">c</span>(<span class="st">"SL.glm"</span>, <span class="st">"SL.ranger"</span>, <span class="st">"SL.earth"</span>),</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">g.SL.library =</span> <span class="fu">c</span>(<span class="st">"SL.glm"</span>, <span class="st">"SL.ranger"</span>, <span class="st">"SL.mean"</span>)</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>tmle_fit<span class="sc">$</span>estimates<span class="sc">$</span>ATE</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here:</p>
<ul>
<li><code>Q.SL.library</code> is used to estimate outcome regression <code>E[Y|A,W]</code></li>
<li><code>g.SL.library</code> is used to estimate propensity scores <code>P(A|W)</code></li>
<li>TMLE combines these with targeting to produce an efficient, doubly robust estimate</li>
</ul>
<p>Key advantages:</p>
<ul>
<li>You no longer need to guess the “right” model for Y or A<br>
</li>
<li>You can include many flexible learners without overfitting (thanks to SL + CV)<br>
</li>
<li>Your causal inference relies less on arbitrary parametric modeling choices</li>
</ul>
<hr>
</section>
<<<<<<< HEAD
<section id="practical-tips-for-using-superlearner" class="level2">
<h2 class="anchored" data-anchor-id="practical-tips-for-using-superlearner">10. Practical Tips for Using SuperLearner</h2>
=======
<section id="practical-tips-for-using-superlearner" class="level2" data-number="11.10">
<h2 data-number="11.10" class="anchored" data-anchor-id="practical-tips-for-using-superlearner"><span class="header-section-number">11.10</span> 10. Practical Tips for Using SuperLearner</h2>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<ol type="1">
<li><strong>Start with a modest but diverse library</strong>
<ul>
<li>GLM (<code>SL.glm</code>)<br>
</li>
<li>Random forest (<code>SL.ranger</code> or <code>SL.randomForest</code>)<br>
</li>
<li>MARS (<code>SL.earth</code>)<br>
</li>
<li>Penalized regression (<code>SL.glmnet</code>)</li>
</ul></li>
<li><strong>Pick loss functions that match your problem</strong>
<ul>
<li>Binary → log-likelihood (for calibration) or AUC (for ranking)<br>
</li>
<li>Continuous → MSE</li>
</ul></li>
<li><strong>Watch computation time</strong>
<ul>
<li>SL is more expensive than a single GLM, especially with many learners and CV folds.</li>
</ul></li>
<li><strong>Use SL primarily on nuisance functions</strong>
<ul>
<li>Don’t use SL to directly estimate the causal effect; instead, use SL to estimate <code>Q</code> and <code>g</code> and feed these into TMLE, AIPW, etc.</li>
</ul></li>
<li><strong>Inspect SL outputs</strong>
<ul>
<li>Which learners are getting weight?<br>
</li>
<li>Are any learners consistently poor performers?<br>
</li>
<li>Do you need to adjust your library?</li>
</ul></li>
</ol>
<hr>
</section>
<<<<<<< HEAD
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">11. Summary</h2>
=======
<section id="summary" class="level2" data-number="11.11">
<h2 data-number="11.11" class="anchored" data-anchor-id="summary"><span class="header-section-number">11.11</span> 11. Summary</h2>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<p>In this chapter you learned</p>
<ul>
<li>How SuperLearner combines multiple algorithms using cross-validation and a metalearner<br>
</li>
<li>The role of loss functions (MSE, log-likelihood, AUC) and when to choose each<br>
</li>
<li>How to implement SuperLearner in R, inspect CV-risk and weights, and customize the library<br>
</li>
<li>How SuperLearner supports reliable causal inference by improving nuisance function estimation and integrating seamlessly with TMLE and other estimators</li>
</ul>
<p>Next, we move to <strong>Module 3</strong>, where we tackle longitudinal data, dynamic treatment regimes, and modified treatment policies, often using SuperLearner as a core building block.</p>
<<<<<<< HEAD
</section>
</section>

</main>
<!-- /main column -->
=======


<!-- -->

</section>
</section>

</main> <!-- /main -->
>>>>>>> claude/tmle-teaching-examples-EP2Hd
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
<<<<<<< HEAD
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
=======
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/amertens\.github\.io\/causal-learning-handbook\/");
>>>>>>> claude/tmle-teaching-examples-EP2Hd
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<<<<<<< HEAD
=======
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./02-04-tmle-teaching-examples.html" class="pagination-link" aria-label="Chapter 2.4: From Question to Estimate — TMLE in Practice">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Chapter 2.4: From Question to Estimate — TMLE in Practice</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./03-03-longitudinal-case-study.html" class="pagination-link" aria-label="Chapter 3.3: Case Study – Real-World Application in Longitudinal Analysis">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chapter 3.3: Case Study – Real-World Application in Longitudinal Analysis</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb37" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Chapter 2.4: SuperLearner and Machine Learning for Causal Inference"</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> html</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="fu"># Chapter 2.4: SuperLearner and Machine Learning for Causal Inference  </span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>*Flexible prediction to strengthen causal effect estimation*</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>Modern causal inference relies on estimating **nuisance functions** (outcome regressions and treatment / censoring mechanisms) that are as accurate as possible. If these models are mis-specified, even sophisticated causal estimators can be biased.</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>Rather than gambling on a single model (e.g., logistic regression), we can **stack** many candidate learners and let the data decide how to combine them. This is what **SuperLearner** does.</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>In this chapter you will learn:</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The intuition behind SuperLearner (SL) and stacking  </span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>How cross-validation is used to avoid overfitting  </span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>How to build and interpret SuperLearner models in R  </span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>When and why to choose different **loss functions** (MSE, log-likelihood, AUC)  </span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>How to customize SL libraries and tune algorithms  </span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>How SL integrates with TMLE and other causal estimators  </span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>This chapter leans heavily on the excellent visual tutorial by Katherine Hoffman and the SuperLearner demo by David Benkeser (both provided as PDFs), and recasts them in a causal-inference focused Quarto format.</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a><span class="fu">## 1. Why Use SuperLearner in Causal Inference?</span></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a>Causal estimators such as g-computation, IPTW, AIPW, and TMLE rely on estimating:</span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The **outcome regression**:  </span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a>  <span class="sc">\(</span> Q(W, A) = E<span class="co">[</span><span class="ot">Y \mid W, A</span><span class="co">]</span> <span class="sc">\)</span></span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The **treatment (or censoring) mechanism**:  </span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a>  <span class="sc">\(</span> g(W) = P(A = 1 \mid W) <span class="sc">\)</span></span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true" tabindex="-1"></a>In traditional practice, both are often modeled with simple GLMs. This is dangerous when:</span>
<span id="cb37-37"><a href="#cb37-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-38"><a href="#cb37-38" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Relationships are nonlinear</span>
<span id="cb37-39"><a href="#cb37-39" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Interactions are present</span>
<span id="cb37-40"><a href="#cb37-40" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>There are many covariates</span>
<span id="cb37-41"><a href="#cb37-41" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We are unsure about which variables to include or in what functional form</span>
<span id="cb37-42"><a href="#cb37-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-43"><a href="#cb37-43" aria-hidden="true" tabindex="-1"></a>SuperLearner helps by:</span>
<span id="cb37-44"><a href="#cb37-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-45"><a href="#cb37-45" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Combining multiple algorithms (GLM, random forests, LASSO, boosted trees, etc.)</span>
<span id="cb37-46"><a href="#cb37-46" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Using **K-fold cross-validation** to evaluate and weight each algorithm</span>
<span id="cb37-47"><a href="#cb37-47" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Producing an ensemble predictor with theoretical guarantees (an “oracle inequality”): asymptotically, SL performs nearly as well as the best algorithm in the library</span>
<span id="cb37-48"><a href="#cb37-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-49"><a href="#cb37-49" aria-hidden="true" tabindex="-1"></a>In causal inference, we rarely care about prediction for its own sake, but good prediction of nuisance functions leads to **better causal effect estimation**.</span>
<span id="cb37-50"><a href="#cb37-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-51"><a href="#cb37-51" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb37-52"><a href="#cb37-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-53"><a href="#cb37-53" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2. Conceptual Overview of SuperLearner</span></span>
<span id="cb37-54"><a href="#cb37-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-55"><a href="#cb37-55" aria-hidden="true" tabindex="-1"></a>At a high level, SuperLearner does the following:</span>
<span id="cb37-56"><a href="#cb37-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-57"><a href="#cb37-57" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Pick a **set of candidate learners** (the library).</span>
<span id="cb37-58"><a href="#cb37-58" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Split the data into **K folds**.</span>
<span id="cb37-59"><a href="#cb37-59" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>For each learner:</span>
<span id="cb37-60"><a href="#cb37-60" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Fit on K-1 folds (training data),</span>
<span id="cb37-61"><a href="#cb37-61" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Predict on the held-out fold (validation data).</span>
<span id="cb37-62"><a href="#cb37-62" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Collect **cross-validated predictions** for every observation and every learner.</span>
<span id="cb37-63"><a href="#cb37-63" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Fit a **metalearner** (often a linear regression) that finds the optimal weighted combination of the learners’ predictions to minimize a chosen **loss function** (e.g., mean squared error, negative log-likelihood).</span>
<span id="cb37-64"><a href="#cb37-64" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>Refit each base learner on the full dataset.</span>
<span id="cb37-65"><a href="#cb37-65" aria-hidden="true" tabindex="-1"></a><span class="ss">7. </span>Use the metalearner and the refit base learners to form the final ensemble and obtain predictions for new data.</span>
<span id="cb37-66"><a href="#cb37-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-67"><a href="#cb37-67" aria-hidden="true" tabindex="-1"></a>This is exactly the workflow illustrated in the “VISUAL GUIDE TO SUPERLEARNING” figure in the KHstats tutorial.</span>
<span id="cb37-68"><a href="#cb37-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-69"><a href="#cb37-69" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb37-70"><a href="#cb37-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-71"><a href="#cb37-71" aria-hidden="true" tabindex="-1"></a><span class="fu">## 3. A Minimal Working Example</span></span>
<span id="cb37-72"><a href="#cb37-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-73"><a href="#cb37-73" aria-hidden="true" tabindex="-1"></a>We’ll start with a simple prediction problem, then connect it back to causal inference later.</span>
<span id="cb37-74"><a href="#cb37-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-75"><a href="#cb37-75" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.1 Simulated data</span></span>
<span id="cb37-76"><a href="#cb37-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-77"><a href="#cb37-77" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, cache=TRUE}</span></span>
<span id="cb37-78"><a href="#cb37-78" aria-hidden="true" tabindex="-1"></a><span class="in">library(tidyverse)</span></span>
<span id="cb37-79"><a href="#cb37-79" aria-hidden="true" tabindex="-1"></a><span class="in">library(SuperLearner)</span></span>
<span id="cb37-80"><a href="#cb37-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-81"><a href="#cb37-81" aria-hidden="true" tabindex="-1"></a><span class="in">set.seed(7)</span></span>
<span id="cb37-82"><a href="#cb37-82" aria-hidden="true" tabindex="-1"></a><span class="in">n &lt;- 2000</span></span>
<span id="cb37-83"><a href="#cb37-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-84"><a href="#cb37-84" aria-hidden="true" tabindex="-1"></a><span class="in">obs &lt;- tibble(</span></span>
<span id="cb37-85"><a href="#cb37-85" aria-hidden="true" tabindex="-1"></a><span class="in">  id = 1:n,</span></span>
<span id="cb37-86"><a href="#cb37-86" aria-hidden="true" tabindex="-1"></a><span class="in">  x1 = rnorm(n),</span></span>
<span id="cb37-87"><a href="#cb37-87" aria-hidden="true" tabindex="-1"></a><span class="in">  x2 = rbinom(n, 1, plogis(10 * x1)),</span></span>
<span id="cb37-88"><a href="#cb37-88" aria-hidden="true" tabindex="-1"></a><span class="in">  x3 = rbinom(n, 1, plogis(x1 * x2 + 0.5 * x2)),</span></span>
<span id="cb37-89"><a href="#cb37-89" aria-hidden="true" tabindex="-1"></a><span class="in">  x4 = rnorm(n, mean = x1 * x2, sd = 0.5 * x3),</span></span>
<span id="cb37-90"><a href="#cb37-90" aria-hidden="true" tabindex="-1"></a><span class="in">  y  = x1 + x2 + x2 * x3 + sin(x4) + rnorm(n, sd = 0.2)</span></span>
<span id="cb37-91"><a href="#cb37-91" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb37-92"><a href="#cb37-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-93"><a href="#cb37-93" aria-hidden="true" tabindex="-1"></a><span class="in">glimpse(obs)</span></span>
<span id="cb37-94"><a href="#cb37-94" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb37-95"><a href="#cb37-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-96"><a href="#cb37-96" aria-hidden="true" tabindex="-1"></a>The outcome <span class="in">`y`</span> is a nonlinear function of the covariates, with interactions and a sine term. GLMs will struggle here.</span>
<span id="cb37-97"><a href="#cb37-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-98"><a href="#cb37-98" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb37-99"><a href="#cb37-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-100"><a href="#cb37-100" aria-hidden="true" tabindex="-1"></a><span class="fu">## 4. Using the `SuperLearner` Package</span></span>
<span id="cb37-101"><a href="#cb37-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-102"><a href="#cb37-102" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.1 Basic call</span></span>
<span id="cb37-103"><a href="#cb37-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-104"><a href="#cb37-104" aria-hidden="true" tabindex="-1"></a>We’ll start with a small library for illustration.</span>
<span id="cb37-105"><a href="#cb37-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-106"><a href="#cb37-106" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, cache=TRUE}</span></span>
<span id="cb37-107"><a href="#cb37-107" aria-hidden="true" tabindex="-1"></a><span class="in">set.seed(1234)</span></span>
<span id="cb37-108"><a href="#cb37-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-109"><a href="#cb37-109" aria-hidden="true" tabindex="-1"></a><span class="in">X &lt;- obs %&gt;% select(x1:x4) %&gt;% as.data.frame()</span></span>
<span id="cb37-110"><a href="#cb37-110" aria-hidden="true" tabindex="-1"></a><span class="in">Y &lt;- obs$y</span></span>
<span id="cb37-111"><a href="#cb37-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-112"><a href="#cb37-112" aria-hidden="true" tabindex="-1"></a><span class="in">SL.lib &lt;- c("SL.glm",      # simple GLM</span></span>
<span id="cb37-113"><a href="#cb37-113" aria-hidden="true" tabindex="-1"></a><span class="in">            "SL.mean",     # intercept-only</span></span>
<span id="cb37-114"><a href="#cb37-114" aria-hidden="true" tabindex="-1"></a><span class="in">            "SL.earth",    # multivariate adaptive regression splines (MARS)</span></span>
<span id="cb37-115"><a href="#cb37-115" aria-hidden="true" tabindex="-1"></a><span class="in">            "SL.ranger")   # random forest</span></span>
<span id="cb37-116"><a href="#cb37-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-117"><a href="#cb37-117" aria-hidden="true" tabindex="-1"></a><span class="in">sl_fit &lt;- SuperLearner(</span></span>
<span id="cb37-118"><a href="#cb37-118" aria-hidden="true" tabindex="-1"></a><span class="in">  Y = Y,</span></span>
<span id="cb37-119"><a href="#cb37-119" aria-hidden="true" tabindex="-1"></a><span class="in">  X = X,</span></span>
<span id="cb37-120"><a href="#cb37-120" aria-hidden="true" tabindex="-1"></a><span class="in">  newX = NULL,</span></span>
<span id="cb37-121"><a href="#cb37-121" aria-hidden="true" tabindex="-1"></a><span class="in">  family = gaussian(),</span></span>
<span id="cb37-122"><a href="#cb37-122" aria-hidden="true" tabindex="-1"></a><span class="in">  SL.library = SL.lib,</span></span>
<span id="cb37-123"><a href="#cb37-123" aria-hidden="true" tabindex="-1"></a><span class="in">  method = "method.NNLS",  # non-negative least squares metalearner</span></span>
<span id="cb37-124"><a href="#cb37-124" aria-hidden="true" tabindex="-1"></a><span class="in">  cvControl = list(V = 10L)</span></span>
<span id="cb37-125"><a href="#cb37-125" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb37-126"><a href="#cb37-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-127"><a href="#cb37-127" aria-hidden="true" tabindex="-1"></a><span class="in">sl_fit</span></span>
<span id="cb37-128"><a href="#cb37-128" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb37-129"><a href="#cb37-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-130"><a href="#cb37-130" aria-hidden="true" tabindex="-1"></a>Key outputs:</span>
<span id="cb37-131"><a href="#cb37-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-132"><a href="#cb37-132" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`Risk`</span>: cross-validated risk (e.g., MSE) for each learner</span>
<span id="cb37-133"><a href="#cb37-133" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`Coef`</span>: weight given to each learner in the ensemble</span>
<span id="cb37-134"><a href="#cb37-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-135"><a href="#cb37-135" aria-hidden="true" tabindex="-1"></a>The learner with the smallest CV-risk often gets the largest weight, but SL can combine learners.</span>
<span id="cb37-136"><a href="#cb37-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-137"><a href="#cb37-137" aria-hidden="true" tabindex="-1"></a>We can access the **ensemble predictions**:</span>
<span id="cb37-138"><a href="#cb37-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-139"><a href="#cb37-139" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, cache=TRUE}</span></span>
<span id="cb37-140"><a href="#cb37-140" aria-hidden="true" tabindex="-1"></a><span class="in">head(sl_fit$SL.predict)</span></span>
<span id="cb37-141"><a href="#cb37-141" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb37-142"><a href="#cb37-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-143"><a href="#cb37-143" aria-hidden="true" tabindex="-1"></a>and predictions from individual learners:</span>
<span id="cb37-144"><a href="#cb37-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-145"><a href="#cb37-145" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, cache=TRUE}</span></span>
<span id="cb37-146"><a href="#cb37-146" aria-hidden="true" tabindex="-1"></a><span class="in">head(sl_fit$library.predict)</span></span>
<span id="cb37-147"><a href="#cb37-147" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb37-148"><a href="#cb37-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-149"><a href="#cb37-149" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb37-150"><a href="#cb37-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-151"><a href="#cb37-151" aria-hidden="true" tabindex="-1"></a><span class="fu">## 5. Choosing a Loss Function: MSE vs Log-Likelihood vs AUC</span></span>
<span id="cb37-152"><a href="#cb37-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-153"><a href="#cb37-153" aria-hidden="true" tabindex="-1"></a>SuperLearner allows different **loss functions**, which define what we mean by “best” prediction.</span>
<span id="cb37-154"><a href="#cb37-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-155"><a href="#cb37-155" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5.1 Mean Squared Error (MSE)</span></span>
<span id="cb37-156"><a href="#cb37-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-157"><a href="#cb37-157" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Default for <span class="in">`family = gaussian()`</span></span>
<span id="cb37-158"><a href="#cb37-158" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Appropriate for **continuous outcomes** when we care about squared error:</span>
<span id="cb37-159"><a href="#cb37-159" aria-hidden="true" tabindex="-1"></a>  $$ L(y, \hat{y}) = (y - \hat{y})^2 $$</span>
<span id="cb37-160"><a href="#cb37-160" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Good when we want well-calibrated mean predictions</span>
<span id="cb37-161"><a href="#cb37-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-162"><a href="#cb37-162" aria-hidden="true" tabindex="-1"></a>Example (already used above): <span class="in">`method = "method.NNLS"`</span> with <span class="in">`family = gaussian()`</span></span>
<span id="cb37-163"><a href="#cb37-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-164"><a href="#cb37-164" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5.2 Negative Log-Likelihood (Binomial deviance)</span></span>
<span id="cb37-165"><a href="#cb37-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-166"><a href="#cb37-166" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Natural choice for **binary outcomes** when we care about probability calibration:</span>
<span id="cb37-167"><a href="#cb37-167" aria-hidden="true" tabindex="-1"></a>  $$ L(y, \hat{p}) = -<span class="co">[</span><span class="ot">y \log(\hat{p}) + (1-y) \log(1-\hat{p})</span><span class="co">]</span> $$</span>
<span id="cb37-168"><a href="#cb37-168" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Strongly penalizes confident but wrong predictions</span>
<span id="cb37-169"><a href="#cb37-169" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Recommended for:</span>
<span id="cb37-170"><a href="#cb37-170" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Outcome models (<span class="in">`Y`</span> binary)</span>
<span id="cb37-171"><a href="#cb37-171" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Treatment models (<span class="in">`A`</span> binary) in causal inference</span>
<span id="cb37-172"><a href="#cb37-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-173"><a href="#cb37-173" aria-hidden="true" tabindex="-1"></a>Use <span class="in">`method = "method.NNloglik"`</span> with <span class="in">`family = binomial()`</span>.</span>
<span id="cb37-174"><a href="#cb37-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-175"><a href="#cb37-175" aria-hidden="true" tabindex="-1"></a>Example:</span>
<span id="cb37-176"><a href="#cb37-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-177"><a href="#cb37-177" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, cache=TRUE}</span></span>
<span id="cb37-178"><a href="#cb37-178" aria-hidden="true" tabindex="-1"></a><span class="in"># suppose Y is binary</span></span>
<span id="cb37-179"><a href="#cb37-179" aria-hidden="true" tabindex="-1"></a><span class="in">Y_bin &lt;- rbinom(n, 1, plogis(X$x1 + X$x2))</span></span>
<span id="cb37-180"><a href="#cb37-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-181"><a href="#cb37-181" aria-hidden="true" tabindex="-1"></a><span class="in">sl_loglik &lt;- SuperLearner(</span></span>
<span id="cb37-182"><a href="#cb37-182" aria-hidden="true" tabindex="-1"></a><span class="in">  Y = Y_bin,</span></span>
<span id="cb37-183"><a href="#cb37-183" aria-hidden="true" tabindex="-1"></a><span class="in">  X = X,</span></span>
<span id="cb37-184"><a href="#cb37-184" aria-hidden="true" tabindex="-1"></a><span class="in">  family = binomial(),</span></span>
<span id="cb37-185"><a href="#cb37-185" aria-hidden="true" tabindex="-1"></a><span class="in">  SL.library = c("SL.glm", "SL.mean", "SL.ranger"),</span></span>
<span id="cb37-186"><a href="#cb37-186" aria-hidden="true" tabindex="-1"></a><span class="in">  method = "method.NNloglik"</span></span>
<span id="cb37-187"><a href="#cb37-187" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb37-188"><a href="#cb37-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-189"><a href="#cb37-189" aria-hidden="true" tabindex="-1"></a><span class="in">sl_loglik</span></span>
<span id="cb37-190"><a href="#cb37-190" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb37-191"><a href="#cb37-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-192"><a href="#cb37-192" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5.3 AUC / Rank Loss</span></span>
<span id="cb37-193"><a href="#cb37-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-194"><a href="#cb37-194" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For classification problems where the **ranking** of probabilities matters more than calibration</span>
<span id="cb37-195"><a href="#cb37-195" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Common when choosing a threshold later (e.g., risk stratification)</span>
<span id="cb37-196"><a href="#cb37-196" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>SuperLearner implementation: <span class="in">`method = "method.AUC"`</span></span>
<span id="cb37-197"><a href="#cb37-197" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Particularly useful when interested in discriminatory ability (e.g., disease risk scores)</span>
<span id="cb37-198"><a href="#cb37-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-199"><a href="#cb37-199" aria-hidden="true" tabindex="-1"></a>Example:</span>
<span id="cb37-200"><a href="#cb37-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-201"><a href="#cb37-201" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, cache=TRUE}</span></span>
<span id="cb37-202"><a href="#cb37-202" aria-hidden="true" tabindex="-1"></a><span class="in">library(cvAUC)   # required by method.AUC</span></span>
<span id="cb37-203"><a href="#cb37-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-204"><a href="#cb37-204" aria-hidden="true" tabindex="-1"></a><span class="in">sl_auc &lt;- SuperLearner(</span></span>
<span id="cb37-205"><a href="#cb37-205" aria-hidden="true" tabindex="-1"></a><span class="in">  Y = Y_bin,</span></span>
<span id="cb37-206"><a href="#cb37-206" aria-hidden="true" tabindex="-1"></a><span class="in">  X = X,</span></span>
<span id="cb37-207"><a href="#cb37-207" aria-hidden="true" tabindex="-1"></a><span class="in">  family = binomial(),</span></span>
<span id="cb37-208"><a href="#cb37-208" aria-hidden="true" tabindex="-1"></a><span class="in">  SL.library = c("SL.glm", "SL.mean", "SL.ranger"),</span></span>
<span id="cb37-209"><a href="#cb37-209" aria-hidden="true" tabindex="-1"></a><span class="in">  method = "method.AUC"</span></span>
<span id="cb37-210"><a href="#cb37-210" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb37-211"><a href="#cb37-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-212"><a href="#cb37-212" aria-hidden="true" tabindex="-1"></a><span class="in">sl_auc</span></span>
<span id="cb37-213"><a href="#cb37-213" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb37-214"><a href="#cb37-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-215"><a href="#cb37-215" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5.4 Which loss should I choose?</span></span>
<span id="cb37-216"><a href="#cb37-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-217"><a href="#cb37-217" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**For outcome models in TMLE/AIPW:**  </span>
<span id="cb37-218"><a href="#cb37-218" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>If binary → log-likelihood (binomial deviance)  </span>
<span id="cb37-219"><a href="#cb37-219" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>If continuous → MSE or other appropriate distribution-based loss  </span>
<span id="cb37-220"><a href="#cb37-220" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**For treatment / censoring models in causal inference:**  </span>
<span id="cb37-221"><a href="#cb37-221" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Typically log-likelihood (because we want accurate estimates of <span class="in">`P(A | W)`</span>)</span>
<span id="cb37-222"><a href="#cb37-222" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**For pure classification (no causal estimation):**  </span>
<span id="cb37-223"><a href="#cb37-223" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Consider AUC loss (<span class="in">`method.AUC`</span>) if ranking is the priority</span>
<span id="cb37-224"><a href="#cb37-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-225"><a href="#cb37-225" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb37-226"><a href="#cb37-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-227"><a href="#cb37-227" aria-hidden="true" tabindex="-1"></a><span class="fu">## 6. Interpreting CV-Risk and Coefficient Weights</span></span>
<span id="cb37-228"><a href="#cb37-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-229"><a href="#cb37-229" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, cache=TRUE}</span></span>
<span id="cb37-230"><a href="#cb37-230" aria-hidden="true" tabindex="-1"></a><span class="in">sl_fit$cvRisk</span></span>
<span id="cb37-231"><a href="#cb37-231" aria-hidden="true" tabindex="-1"></a><span class="in">sl_fit$coef</span></span>
<span id="cb37-232"><a href="#cb37-232" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb37-233"><a href="#cb37-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-234"><a href="#cb37-234" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`cvRisk`</span> shows cross-validated risk for each algorithm</span>
<span id="cb37-235"><a href="#cb37-235" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`coef`</span> gives the ensemble weights (metalearner solution)</span>
<span id="cb37-236"><a href="#cb37-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-237"><a href="#cb37-237" aria-hidden="true" tabindex="-1"></a>An algorithm might have:</span>
<span id="cb37-238"><a href="#cb37-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-239"><a href="#cb37-239" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Low risk → high weight  </span>
<span id="cb37-240"><a href="#cb37-240" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>High risk → weight near zero (effectively excluded)</span>
<span id="cb37-241"><a href="#cb37-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-242"><a href="#cb37-242" aria-hidden="true" tabindex="-1"></a>This matches the demonstration in the Benkeser notes where GLM dominates mean-only models when predicting MI.  </span>
<span id="cb37-243"><a href="#cb37-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-244"><a href="#cb37-244" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb37-245"><a href="#cb37-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-246"><a href="#cb37-246" aria-hidden="true" tabindex="-1"></a><span class="fu">## 7. Customizing the Library and Tuning Learners</span></span>
<span id="cb37-247"><a href="#cb37-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-248"><a href="#cb37-248" aria-hidden="true" tabindex="-1"></a><span class="fu">### 7.1 Adding tuned versions of a learner (e.g., Random Forest)</span></span>
<span id="cb37-249"><a href="#cb37-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-250"><a href="#cb37-250" aria-hidden="true" tabindex="-1"></a>We can define bounded random forest variants with different hyperparameters.</span>
<span id="cb37-251"><a href="#cb37-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-252"><a href="#cb37-252" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, cache=TRUE}</span></span>
<span id="cb37-253"><a href="#cb37-253" aria-hidden="true" tabindex="-1"></a><span class="in">SL.ranger_mtry3 &lt;- function(..., mtry = 3){</span></span>
<span id="cb37-254"><a href="#cb37-254" aria-hidden="true" tabindex="-1"></a><span class="in">  SL.ranger(..., mtry = mtry)</span></span>
<span id="cb37-255"><a href="#cb37-255" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb37-256"><a href="#cb37-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-257"><a href="#cb37-257" aria-hidden="true" tabindex="-1"></a><span class="in">SL.ranger_mtry4 &lt;- function(..., mtry = 4){</span></span>
<span id="cb37-258"><a href="#cb37-258" aria-hidden="true" tabindex="-1"></a><span class="in">  SL.ranger(..., mtry = mtry)</span></span>
<span id="cb37-259"><a href="#cb37-259" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb37-260"><a href="#cb37-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-261"><a href="#cb37-261" aria-hidden="true" tabindex="-1"></a><span class="in">SL.lib_tuned &lt;- c("SL.glm",</span></span>
<span id="cb37-262"><a href="#cb37-262" aria-hidden="true" tabindex="-1"></a><span class="in">                  "SL.earth",</span></span>
<span id="cb37-263"><a href="#cb37-263" aria-hidden="true" tabindex="-1"></a><span class="in">                  "SL.ranger_mtry3",</span></span>
<span id="cb37-264"><a href="#cb37-264" aria-hidden="true" tabindex="-1"></a><span class="in">                  "SL.ranger_mtry4")</span></span>
<span id="cb37-265"><a href="#cb37-265" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb37-266"><a href="#cb37-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-267"><a href="#cb37-267" aria-hidden="true" tabindex="-1"></a>Then run:</span>
<span id="cb37-268"><a href="#cb37-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-269"><a href="#cb37-269" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, cache=TRUE}</span></span>
<span id="cb37-270"><a href="#cb37-270" aria-hidden="true" tabindex="-1"></a><span class="in">set.seed(123)</span></span>
<span id="cb37-271"><a href="#cb37-271" aria-hidden="true" tabindex="-1"></a><span class="in">sl_tuned &lt;- SuperLearner(</span></span>
<span id="cb37-272"><a href="#cb37-272" aria-hidden="true" tabindex="-1"></a><span class="in">  Y = Y,</span></span>
<span id="cb37-273"><a href="#cb37-273" aria-hidden="true" tabindex="-1"></a><span class="in">  X = X,</span></span>
<span id="cb37-274"><a href="#cb37-274" aria-hidden="true" tabindex="-1"></a><span class="in">  family = gaussian(),</span></span>
<span id="cb37-275"><a href="#cb37-275" aria-hidden="true" tabindex="-1"></a><span class="in">  SL.library = SL.lib_tuned,</span></span>
<span id="cb37-276"><a href="#cb37-276" aria-hidden="true" tabindex="-1"></a><span class="in">  method = "method.NNLS"</span></span>
<span id="cb37-277"><a href="#cb37-277" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb37-278"><a href="#cb37-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-279"><a href="#cb37-279" aria-hidden="true" tabindex="-1"></a><span class="in">sl_tuned$cvRisk</span></span>
<span id="cb37-280"><a href="#cb37-280" aria-hidden="true" tabindex="-1"></a><span class="in">sl_tuned$coef</span></span>
<span id="cb37-281"><a href="#cb37-281" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb37-282"><a href="#cb37-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-283"><a href="#cb37-283" aria-hidden="true" tabindex="-1"></a>SuperLearner automatically picks which tuned version (or combination) works best.</span>
<span id="cb37-284"><a href="#cb37-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-285"><a href="#cb37-285" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb37-286"><a href="#cb37-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-287"><a href="#cb37-287" aria-hidden="true" tabindex="-1"></a><span class="fu">## 8. Cross-Validated SuperLearner (`CV.SuperLearner`)</span></span>
<span id="cb37-288"><a href="#cb37-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-289"><a href="#cb37-289" aria-hidden="true" tabindex="-1"></a><span class="in">`CV.SuperLearner`</span> adds an **outer layer** of cross-validation to evaluate SL versus its components objectively.</span>
<span id="cb37-290"><a href="#cb37-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-291"><a href="#cb37-291" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, cache=TRUE}</span></span>
<span id="cb37-292"><a href="#cb37-292" aria-hidden="true" tabindex="-1"></a><span class="in">set.seed(123)</span></span>
<span id="cb37-293"><a href="#cb37-293" aria-hidden="true" tabindex="-1"></a><span class="in">cv_sl &lt;- CV.SuperLearner(</span></span>
<span id="cb37-294"><a href="#cb37-294" aria-hidden="true" tabindex="-1"></a><span class="in">  Y = Y,</span></span>
<span id="cb37-295"><a href="#cb37-295" aria-hidden="true" tabindex="-1"></a><span class="in">  X = X,</span></span>
<span id="cb37-296"><a href="#cb37-296" aria-hidden="true" tabindex="-1"></a><span class="in">  V = 5,</span></span>
<span id="cb37-297"><a href="#cb37-297" aria-hidden="true" tabindex="-1"></a><span class="in">  family = gaussian(),</span></span>
<span id="cb37-298"><a href="#cb37-298" aria-hidden="true" tabindex="-1"></a><span class="in">  SL.library = SL.lib</span></span>
<span id="cb37-299"><a href="#cb37-299" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb37-300"><a href="#cb37-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-301"><a href="#cb37-301" aria-hidden="true" tabindex="-1"></a><span class="in">cv_sl</span></span>
<span id="cb37-302"><a href="#cb37-302" aria-hidden="true" tabindex="-1"></a><span class="in">plot(cv_sl)</span></span>
<span id="cb37-303"><a href="#cb37-303" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb37-304"><a href="#cb37-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-305"><a href="#cb37-305" aria-hidden="true" tabindex="-1"></a>The plot shows:</span>
<span id="cb37-306"><a href="#cb37-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-307"><a href="#cb37-307" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Cross-validated risks and confidence intervals for each learner</span>
<span id="cb37-308"><a href="#cb37-308" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Performance of the discrete and continuous SuperLearner</span>
<span id="cb37-309"><a href="#cb37-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-310"><a href="#cb37-310" aria-hidden="true" tabindex="-1"></a>This step is particularly helpful when you want to justify using SL rather than a single, simpler algorithm.</span>
<span id="cb37-311"><a href="#cb37-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-312"><a href="#cb37-312" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb37-313"><a href="#cb37-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-314"><a href="#cb37-314" aria-hidden="true" tabindex="-1"></a><span class="fu">## 9. Integrating SuperLearner into Causal Inference</span></span>
<span id="cb37-315"><a href="#cb37-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-316"><a href="#cb37-316" aria-hidden="true" tabindex="-1"></a>So far we focused on prediction. How does this relate to causal inference?</span>
<span id="cb37-317"><a href="#cb37-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-318"><a href="#cb37-318" aria-hidden="true" tabindex="-1"></a>For a point-treatment ATE, a TMLE analysis might look like:</span>
<span id="cb37-319"><a href="#cb37-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-320"><a href="#cb37-320" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, cache=TRUE, eval=F}</span></span>
<span id="cb37-321"><a href="#cb37-321" aria-hidden="true" tabindex="-1"></a><span class="in"># Example skeleton (you will flesh this out later with your own data)</span></span>
<span id="cb37-322"><a href="#cb37-322" aria-hidden="true" tabindex="-1"></a><span class="in">library(tmle)</span></span>
<span id="cb37-323"><a href="#cb37-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-324"><a href="#cb37-324" aria-hidden="true" tabindex="-1"></a><span class="in">tmle_fit &lt;- tmle(</span></span>
<span id="cb37-325"><a href="#cb37-325" aria-hidden="true" tabindex="-1"></a><span class="in">  Y = Y_bin,          # binary outcome</span></span>
<span id="cb37-326"><a href="#cb37-326" aria-hidden="true" tabindex="-1"></a><span class="in">  A = A,              # treatment</span></span>
<span id="cb37-327"><a href="#cb37-327" aria-hidden="true" tabindex="-1"></a><span class="in">  W = X,              # covariates</span></span>
<span id="cb37-328"><a href="#cb37-328" aria-hidden="true" tabindex="-1"></a><span class="in">  family = "binomial",</span></span>
<span id="cb37-329"><a href="#cb37-329" aria-hidden="true" tabindex="-1"></a><span class="in">  Q.SL.library = c("SL.glm", "SL.ranger", "SL.earth"),</span></span>
<span id="cb37-330"><a href="#cb37-330" aria-hidden="true" tabindex="-1"></a><span class="in">  g.SL.library = c("SL.glm", "SL.ranger", "SL.mean")</span></span>
<span id="cb37-331"><a href="#cb37-331" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb37-332"><a href="#cb37-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-333"><a href="#cb37-333" aria-hidden="true" tabindex="-1"></a><span class="in">tmle_fit$estimates$ATE</span></span>
<span id="cb37-334"><a href="#cb37-334" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb37-335"><a href="#cb37-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-336"><a href="#cb37-336" aria-hidden="true" tabindex="-1"></a>Here:</span>
<span id="cb37-337"><a href="#cb37-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-338"><a href="#cb37-338" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`Q.SL.library`</span> is used to estimate outcome regression <span class="in">`E[Y|A,W]`</span></span>
<span id="cb37-339"><a href="#cb37-339" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`g.SL.library`</span> is used to estimate propensity scores <span class="in">`P(A|W)`</span></span>
<span id="cb37-340"><a href="#cb37-340" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>TMLE combines these with targeting to produce an efficient, doubly robust estimate</span>
<span id="cb37-341"><a href="#cb37-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-342"><a href="#cb37-342" aria-hidden="true" tabindex="-1"></a>Key advantages:</span>
<span id="cb37-343"><a href="#cb37-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-344"><a href="#cb37-344" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>You no longer need to guess the “right” model for Y or A  </span>
<span id="cb37-345"><a href="#cb37-345" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>You can include many flexible learners without overfitting (thanks to SL + CV)  </span>
<span id="cb37-346"><a href="#cb37-346" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Your causal inference relies less on arbitrary parametric modeling choices  </span>
<span id="cb37-347"><a href="#cb37-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-348"><a href="#cb37-348" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb37-349"><a href="#cb37-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-350"><a href="#cb37-350" aria-hidden="true" tabindex="-1"></a><span class="fu">## 10. Practical Tips for Using SuperLearner</span></span>
<span id="cb37-351"><a href="#cb37-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-352"><a href="#cb37-352" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Start with a modest but diverse library**  </span>
<span id="cb37-353"><a href="#cb37-353" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>GLM (<span class="in">`SL.glm`</span>)  </span>
<span id="cb37-354"><a href="#cb37-354" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Random forest (<span class="in">`SL.ranger`</span> or <span class="in">`SL.randomForest`</span>)  </span>
<span id="cb37-355"><a href="#cb37-355" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>MARS (<span class="in">`SL.earth`</span>)  </span>
<span id="cb37-356"><a href="#cb37-356" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Penalized regression (<span class="in">`SL.glmnet`</span>)  </span>
<span id="cb37-357"><a href="#cb37-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-358"><a href="#cb37-358" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Pick loss functions that match your problem**  </span>
<span id="cb37-359"><a href="#cb37-359" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Binary → log-likelihood (for calibration) or AUC (for ranking)  </span>
<span id="cb37-360"><a href="#cb37-360" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Continuous → MSE  </span>
<span id="cb37-361"><a href="#cb37-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-362"><a href="#cb37-362" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Watch computation time**  </span>
<span id="cb37-363"><a href="#cb37-363" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>SL is more expensive than a single GLM, especially with many learners and CV folds.</span>
<span id="cb37-364"><a href="#cb37-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-365"><a href="#cb37-365" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Use SL primarily on nuisance functions**  </span>
<span id="cb37-366"><a href="#cb37-366" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Don’t use SL to directly estimate the causal effect; instead, use SL to estimate <span class="in">`Q`</span> and <span class="in">`g`</span> and feed these into TMLE, AIPW, etc.</span>
<span id="cb37-367"><a href="#cb37-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-368"><a href="#cb37-368" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Inspect SL outputs**  </span>
<span id="cb37-369"><a href="#cb37-369" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Which learners are getting weight?  </span>
<span id="cb37-370"><a href="#cb37-370" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Are any learners consistently poor performers?  </span>
<span id="cb37-371"><a href="#cb37-371" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Do you need to adjust your library?  </span>
<span id="cb37-372"><a href="#cb37-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-373"><a href="#cb37-373" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb37-374"><a href="#cb37-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-375"><a href="#cb37-375" aria-hidden="true" tabindex="-1"></a><span class="fu">## 11. Summary</span></span>
<span id="cb37-376"><a href="#cb37-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-377"><a href="#cb37-377" aria-hidden="true" tabindex="-1"></a>In this chapter you learned</span>
<span id="cb37-378"><a href="#cb37-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-379"><a href="#cb37-379" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>How SuperLearner combines multiple algorithms using cross-validation and a metalearner  </span>
<span id="cb37-380"><a href="#cb37-380" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The role of loss functions (MSE, log-likelihood, AUC) and when to choose each  </span>
<span id="cb37-381"><a href="#cb37-381" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>How to implement SuperLearner in R, inspect CV-risk and weights, and customize the library  </span>
<span id="cb37-382"><a href="#cb37-382" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>How SuperLearner supports reliable causal inference by improving nuisance function estimation and integrating seamlessly with TMLE and other estimators  </span>
<span id="cb37-383"><a href="#cb37-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-384"><a href="#cb37-384" aria-hidden="true" tabindex="-1"></a>Next, we move to **Module 3**, where we tackle longitudinal data, dynamic treatment regimes, and modified treatment policies, often using SuperLearner as a core building block.</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
>>>>>>> claude/tmle-teaching-examples-EP2Hd
</div> <!-- /content -->




</body></html>