[
  {
    "objectID": "resources/index.html",
    "href": "resources/index.html",
    "title": "Resources",
    "section": "",
    "text": "(to do: add descriptions of each)\n\nBeyondTheATE.com\nTLverse handbook\nIntroduction to modern causal inference\nVisual guides to causal inference\n\n-https://vanderlaan-lab.org/ -https://ehsanx.github.io/TMLEworkshop/\n-2 workshops from Laura"
  },
  {
    "objectID": "cases/index.html",
    "href": "cases/index.html",
    "title": "Case study applications of the causal roadmap and targeted learning",
    "section": "",
    "text": "Note all data is simulated and estimates of drug effects are for teaching purposes only and do not reflect real-world efficacy.\n\nART adherence and HIV virologic suppression\n(Draft in progress) HIV adherence analysis plan and simulation results\nThis roadmap analysis plan defines a longitudinal causal estimand to evaluate how imperfect adherence to antiretroviral therapy affects HIV virologic suppression under realistic, observed treatment patterns. Using a structural equation model and directed acyclic graph, the plan formalizes the impact of intercurrent events such as treatment switching, disenrollment, and differential monitoring. An example analysis is implemented on HealthVerity claims data to estimate adherence–outcome relationships using longitudinal targeted maximum likelihood estimation (TMLE), adjusted for time-varying confounding and censoring. A simulation study then replicates key data-generating features—pharmacy fill patterns, lab engagement, and switching behavior—under varying degrees of adherence and confounding, to benchmark estimator performance and assess bias in standard Cox models versus TMLE under the causal roadmap framework\n\n\nCausal Roadmap case study of an acute kidney injury safety analysis\nhttps://bookdown.org/amertens/causal-roadmap-tutorial/"
  },
  {
    "objectID": "advanced/common-pitfalls.html",
    "href": "advanced/common-pitfalls.html",
    "title": "Chapter X: Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "A practical guide for avoiding frequent mistakes in causal inference and targeted learning\nEven with a solid understanding of the causal roadmap and modern estimators, it is remarkably easy to make analytic choices that lead to biased, unstable, or misleading results. In real-world evidence (RWE), the stakes are even higher: data are messy, treatment pathways are irregular, and clinical validity depends on careful execution.\nThis chapter catalogs the most common pitfalls analysts encounter in causal inference—especially in pharmacoepidemiologic and longitudinal RWE settings—and provides concrete strategies to avoid them.\n\n\n\n\n\n\nMistake:\nRunning multivariable regression and interpreting the treatment coefficient as a causal effect.\nWhy it matters:\nRegression coefficients estimate conditional associations, not causal contrasts. Unless the regression exactly corresponds to the identification formula and correctly specifies the functional forms, the estimate is biased.\nAvoid by:\n- Defining a precise causal question and estimand\n- Using G-computation, IPTW, AIPW, or TMLE instead of regression coefficients\n- Using flexible nuisance estimation (SuperLearner)\n\n\n\n\n\n\n\nMistake: Including variables measured after treatment assignment in regression or propensity score models.\nWhy it matters:\n- These variables often lie on causal pathways → adjusting blocks part of the effect\n- They may be colliders → inducing bias\n- Breaks the hypothetical intervention definition\nAvoid by:\n- Adjusting only for baseline confounders\n- Using LMTP/LTMLE when post-treatment confounding exists\n- Drawing DAGs to clarify temporal structure\n\n\n\n\n\n\n\nSymptoms:\n- Propensity scores near 0 or 1\n- Large IPTW weights\n- Extreme clever covariates in TMLE\nAvoid by:\n- Checking PS overlap\n- Truncating weights\n- Restricting to regions of support\n- Using stochastic interventions when static interventions are not feasible\n\n\n\n\n\n\n\nAvoid by:\n- Using SuperLearner\n- Evaluating cross-validated risk\n- Inspecting calibration\n\n\n\n\n\n\n\nAvoid by:\n- Always using cross-validation\n- Checking calibration and residual diagnostics\n- Using TMLE to protect inference from ML instability\n\n\n\n\n\nAvoid by:\n- Modeling censoring with SL\n- Using TMLE/LMTP with censoring nodes\n- Conducting sensitivity analyses\n\n\n\n\n\n\nAvoid by:\n- Prespecifying subgroups\n- Reporting uncertainty\n- Treating causal forest results as exploratory\n- Using TMLE-based variable-importance for confirmatory analyses\n\n\n\n\n\n\n\nAvoid by:\n- Targeting risk differences, risk ratios, survival curves, or RMST\n- Using LMTP/TMLE for causal survival analysis\n\n\n\n\n\n\n\nAvoid by:\n- Inspecting weight distributions\n- Checking clever covariate ranges\n- Examining influence curve stability\n- Running calibration checks for Q/g\n\n\n\n\n\n\n\nAvoid by:\n- E-values\n- Quantitative bias analysis\n- Negative control outcomes/exposures\n- Stochastic sensitivity analyses\n\n\n\n\n\nAvoid by:\n- Harmonizing definitions\n- Checking covariate balance across datasets\n- Applying ES-CV-TMLE or A-TMLE\n- Conducting negative controls in RWD\n\n\n\n\nAvoid by:\n- Including absolute risk estimates\n- Transparently stating assumptions\n- Discussing limitations and robustness\n- Framing the estimand in scientific terms\n\n\n\n\nCommon pitfalls arise from misalignment between analytic choices and scientific questions, misspecification, unchecked assumptions, and overinterpretation. Avoiding them requires:\n\nThe causal roadmap\n\nDiagnostics\n\nSensitivity analyses\n\nCareful communication\n\nThese principles yield causal evidence that is credible, reproducible, and actionable.\n\n\nCode\nsessionInfo()\n\n\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26200)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.2    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.4.2       htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10      \n [9] rmarkdown_2.29    knitr_1.49        jsonlite_2.0.0    xfun_0.49        \n[13] digest_0.6.37     rlang_1.1.6       evaluate_1.0.5"
  },
  {
    "objectID": "advanced/common-pitfalls.html#common-pitfalls-and-how-to-avoid-them",
    "href": "advanced/common-pitfalls.html#common-pitfalls-and-how-to-avoid-them",
    "title": "Chapter X: Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "A practical guide for avoiding frequent mistakes in causal inference and targeted learning\nEven with a solid understanding of the causal roadmap and modern estimators, it is remarkably easy to make analytic choices that lead to biased, unstable, or misleading results. In real-world evidence (RWE), the stakes are even higher: data are messy, treatment pathways are irregular, and clinical validity depends on careful execution.\nThis chapter catalogs the most common pitfalls analysts encounter in causal inference—especially in pharmacoepidemiologic and longitudinal RWE settings—and provides concrete strategies to avoid them."
  },
  {
    "objectID": "advanced/common-pitfalls.html#pitfall-confusing-association-with-causation",
    "href": "advanced/common-pitfalls.html#pitfall-confusing-association-with-causation",
    "title": "Chapter X: Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "Mistake:\nRunning multivariable regression and interpreting the treatment coefficient as a causal effect.\nWhy it matters:\nRegression coefficients estimate conditional associations, not causal contrasts. Unless the regression exactly corresponds to the identification formula and correctly specifies the functional forms, the estimate is biased.\nAvoid by:\n- Defining a precise causal question and estimand\n- Using G-computation, IPTW, AIPW, or TMLE instead of regression coefficients\n- Using flexible nuisance estimation (SuperLearner)"
  },
  {
    "objectID": "advanced/common-pitfalls.html#pitfall-adjusting-for-post-treatment-variables",
    "href": "advanced/common-pitfalls.html#pitfall-adjusting-for-post-treatment-variables",
    "title": "Chapter X: Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "Mistake: Including variables measured after treatment assignment in regression or propensity score models.\nWhy it matters:\n- These variables often lie on causal pathways → adjusting blocks part of the effect\n- They may be colliders → inducing bias\n- Breaks the hypothetical intervention definition\nAvoid by:\n- Adjusting only for baseline confounders\n- Using LMTP/LTMLE when post-treatment confounding exists\n- Drawing DAGs to clarify temporal structure"
  },
  {
    "objectID": "advanced/common-pitfalls.html#pitfall-violated-positivity-lack-of-overlap",
    "href": "advanced/common-pitfalls.html#pitfall-violated-positivity-lack-of-overlap",
    "title": "Chapter X: Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "Symptoms:\n- Propensity scores near 0 or 1\n- Large IPTW weights\n- Extreme clever covariates in TMLE\nAvoid by:\n- Checking PS overlap\n- Truncating weights\n- Restricting to regions of support\n- Using stochastic interventions when static interventions are not feasible"
  },
  {
    "objectID": "advanced/common-pitfalls.html#pitfall-misspecified-outcome-or-propensity-models",
    "href": "advanced/common-pitfalls.html#pitfall-misspecified-outcome-or-propensity-models",
    "title": "Chapter X: Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "Avoid by:\n- Using SuperLearner\n- Evaluating cross-validated risk\n- Inspecting calibration"
  },
  {
    "objectID": "advanced/common-pitfalls.html#pitfall-blindly-trusting-machine-learning",
    "href": "advanced/common-pitfalls.html#pitfall-blindly-trusting-machine-learning",
    "title": "Chapter X: Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "Avoid by:\n- Always using cross-validation\n- Checking calibration and residual diagnostics\n- Using TMLE to protect inference from ML instability"
  },
  {
    "objectID": "advanced/common-pitfalls.html#pitfall-ignoring-censoring-and-informative-dropout",
    "href": "advanced/common-pitfalls.html#pitfall-ignoring-censoring-and-informative-dropout",
    "title": "Chapter X: Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "Avoid by:\n- Modeling censoring with SL\n- Using TMLE/LMTP with censoring nodes\n- Conducting sensitivity analyses"
  },
  {
    "objectID": "advanced/common-pitfalls.html#pitfall-over-interpreting-heterogeneous-treatment-effects",
    "href": "advanced/common-pitfalls.html#pitfall-over-interpreting-heterogeneous-treatment-effects",
    "title": "Chapter X: Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "Avoid by:\n- Prespecifying subgroups\n- Reporting uncertainty\n- Treating causal forest results as exploratory\n- Using TMLE-based variable-importance for confirmatory analyses"
  },
  {
    "objectID": "advanced/common-pitfalls.html#pitfall-using-the-wrong-estimand",
    "href": "advanced/common-pitfalls.html#pitfall-using-the-wrong-estimand",
    "title": "Chapter X: Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "Avoid by:\n- Targeting risk differences, risk ratios, survival curves, or RMST\n- Using LMTP/TMLE for causal survival analysis"
  },
  {
    "objectID": "advanced/common-pitfalls.html#pitfall-not-performing-diagnostics",
    "href": "advanced/common-pitfalls.html#pitfall-not-performing-diagnostics",
    "title": "Chapter X: Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "Avoid by:\n- Inspecting weight distributions\n- Checking clever covariate ranges\n- Examining influence curve stability\n- Running calibration checks for Q/g"
  },
  {
    "objectID": "advanced/common-pitfalls.html#pitfall-neglecting-sensitivity-analyses",
    "href": "advanced/common-pitfalls.html#pitfall-neglecting-sensitivity-analyses",
    "title": "Chapter X: Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "Avoid by:\n- E-values\n- Quantitative bias analysis\n- Negative control outcomes/exposures\n- Stochastic sensitivity analyses"
  },
  {
    "objectID": "advanced/common-pitfalls.html#pitfall-poor-alignment-between-rct-and-rwd-in-hybrid-designs",
    "href": "advanced/common-pitfalls.html#pitfall-poor-alignment-between-rct-and-rwd-in-hybrid-designs",
    "title": "Chapter X: Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "Avoid by:\n- Harmonizing definitions\n- Checking covariate balance across datasets\n- Applying ES-CV-TMLE or A-TMLE\n- Conducting negative controls in RWD"
  },
  {
    "objectID": "advanced/common-pitfalls.html#pitfall-reporting-without-context-or-interpretation",
    "href": "advanced/common-pitfalls.html#pitfall-reporting-without-context-or-interpretation",
    "title": "Chapter X: Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "Avoid by:\n- Including absolute risk estimates\n- Transparently stating assumptions\n- Discussing limitations and robustness\n- Framing the estimand in scientific terms"
  },
  {
    "objectID": "advanced/common-pitfalls.html#summary",
    "href": "advanced/common-pitfalls.html#summary",
    "title": "Chapter X: Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "Common pitfalls arise from misalignment between analytic choices and scientific questions, misspecification, unchecked assumptions, and overinterpretation. Avoiding them requires:\n\nThe causal roadmap\n\nDiagnostics\n\nSensitivity analyses\n\nCareful communication\n\nThese principles yield causal evidence that is credible, reproducible, and actionable.\n\n\nCode\nsessionInfo()\n\n\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26200)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.2    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.4.2       htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10      \n [9] rmarkdown_2.29    knitr_1.49        jsonlite_2.0.0    xfun_0.49        \n[13] digest_0.6.37     rlang_1.1.6       evaluate_1.0.5"
  },
  {
    "objectID": "advanced/03-08-tmle-clean-room.html",
    "href": "advanced/03-08-tmle-clean-room.html",
    "title": "Chapter 3.8: TMLE in the Clean Room Framework for Pharmacoepidemiology",
    "section": "",
    "text": "This chapter demonstrates how to implement TMLE in a clean-room workflow using SuperLearner for g(A|W), evaluating balance using flexible diagnostics, and estimating effects robustly using tmle. It draws on the NSAIDs vs opioids AKI case study as a practical example."
  },
  {
    "objectID": "advanced/03-08-tmle-clean-room.html#tmle-in-the-clean-room-framework-for-pharmacoepidemiology",
    "href": "advanced/03-08-tmle-clean-room.html#tmle-in-the-clean-room-framework-for-pharmacoepidemiology",
    "title": "Chapter 3.8: TMLE in the Clean Room Framework for Pharmacoepidemiology",
    "section": "",
    "text": "This chapter demonstrates how to implement TMLE in a clean-room workflow using SuperLearner for g(A|W), evaluating balance using flexible diagnostics, and estimating effects robustly using tmle. It draws on the NSAIDs vs opioids AKI case study as a practical example."
  },
  {
    "objectID": "advanced/03-06-rwd-meets-rct-hybrid-designs.html",
    "href": "advanced/03-06-rwd-meets-rct-hybrid-designs.html",
    "title": "Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "",
    "text": "Combining randomized and observational data to improve precision and generalizability\nRandomized controlled trials (RCTs) are the gold standard for causal inference.\nBut they are:\n\nExpensive and slow\n\nOften underpowered for rare events and subgroup effects\n\nConducted in selective populations\n\nNot always feasible or ethical\n\nReal-world data (RWD) — registries, EHR, claims — provide:\n\nLarge, diverse populations\n\nNaturalistic treatment patterns\n\nLong-term safety follow-up\n\nHybrid RCT–RWD designs aim to combine:\n\nThe internal validity of RCTs\n\nThe external validity and scale of RWD\n\nThis chapter introduces:\n\nWhy hybrid designs are needed\n\nTypes of hybrid designs with external controls\n\nTransportability and generalizability concepts\n\nES-CV-TMLE (External Supervised Cross-Validated TMLE)\n\nA-TMLE (Adaptive TMLE) for integrating multiple data sources\n\nPractical considerations and diagnostics\n\n\n\n\n\n\n\nTrials may be underpowered for:\n\nRare safety endpoints\n\nImportant subgroups\n\nLong-term secondary endpoints\n\nExternal RWD can add information and boost precision without enrolling more randomized patients.\n\n\n\nRCT participants tend to:\n\nBe younger and healthier\n\nHave fewer comorbidities\n\nBe more adherent and monitored\n\nThus, trial results may not fully apply to routine-care populations.\n\n\n\nHybrid designs are useful when:\n\nPlacebo or standard randomized controls are unethical\n\nOnly a single-arm trial is feasible\n\nRapid evidence is needed (e.g., post-marketing surveillance, rare diseases)\n\n\n\n\n\n\nSeveral design patterns are commonly used.\n\n\n\nA single-arm trial (all patients get experimental treatment) may be compared against an external control arm from RWD.\nUse cases:\n\nOncology (historical controls)\n\nRare diseases\n\nWhen standard-of-care is well characterized\n\nChallenges:\n\nConfounding by indication\n\nDifferences in data capture, follow-up, eligibility\n\nTiming effects (calendar time, coding changes)\n\n\n\n\n\nAn RCT randomizes patients to:\n\nExperimental treatment vs trial control (e.g., 2:1 randomization)\n\nBut the trial control arm is augmented with external RWD controls to:\n\nImprove precision\n\nReduce required randomized control sample size\n\nSupport safety and rare-event evaluation\n\nBorrowing can be:\n\nFixed (pre-specified)\n\nDynamic / adaptive (data-driven)\n\n\n\n\n\nYou may have:\n\nAn RCT effect estimate in a selected population\n\nA target population in RWD\n\nGoal:\n\nTransport or generalize the trial effect to the RWD population.\n\nRequires:\n\nModeling the difference between trial and target populations\n\nAdjusting for “sampling bias” (who joins the trial)\n\nTechniques:\n\nInverse odds of sampling weights (IOSW)\n\nTransport / generalizability TMLE\n\nDoubly robust methods combining outcome and sampling models\n\n\n\n\n\n\nBeyond usual RCT assumptions, hybrid designs require:\n\n\nWithin the external data:\n\nTreatment–outcome confounding must be controlled using available covariates\n\nResidual confounding may bias the hybrid estimate\n\n\n\n\nThe joint covariate space of:\n\nRCT participants\n\nRWD patients\n\nmust overlap, especially when:\n\nUsing RWD to estimate control outcomes\n\nTransporting effects across populations\n\n\n\n\nMedical coding, endpoint definitions, and measurement schemes should be compatible (or harmonized).\n\n\n\n\n\nES-CV-TMLE (External Supervised Cross-Validated TMLE) is a targeted learning approach that:\n\nUses external data (RWD) to help train nuisance models (e.g., outcome regressions)\n\nValidates and selects among them using cross-validation in the RCT only\n\nEnsures external data do not degrade the validity of RCT-based estimation\n\n\n\nWe may have poor precision in the RCT alone for nuisance functions (Q) and (g).\nExternal data can improve the learning of these functions, but confounding in the RWD could distort:\n\nOutcome relationships\n\nTreatment assignment mechanisms\n\nES-CV-TMLE protects against this by:\n\nProposing multiple candidate nuisance models, some learned on:\n\nRCT only\n\nRWD only\n\nCombined data\n\nUsing cross-validation on the RCT to evaluate each model’s performance (e.g., via log-likelihood loss).\n\nChoosing the best-performing nuisance model (or an ensemble of them) for TMLE.\n\nExternal data are “supervisors” but do not override the RCT.\n\n\n\n\nPool RCT and RWD data for training candidate models:\n\n(Q_{ ext{RCT}}): trained only on RCT\n\n(Q_{ ext{RWD}}): trained only on RWD\n\n(Q_{ ext{pool}}): trained on combined RCT+RWD\n\nFor each candidate Q-model:\n\nUse RCT data only\n\nRun cross-validated evaluation (e.g., deviance, negative log-likelihood)\n\nSelect (or weight) candidate Qs via SuperLearner-style metalearning.\nUse the chosen Q (and similarly chosen g, if desired) in TMLE on the RCT data.\n\nThis preserves the RCT-based identification and uses RWD as an auxiliary data source for better prediction.\n\n\n\n\n\nAdaptive TMLE (A-TMLE) generalizes ES-CV-TMLE to the estimator level.\nInstead of combining candidate nuisance models, A-TMLE combines candidate estimators (e.g., separate hybrid analyses):\n\nTMLE using RCT only\n\nTMLE using RWD only (carefully adjusted)\n\nTMLE using both RCT + RWD in a joint model\n\nOther candidate estimators\n\nIt then uses a SuperLearner-style convex combination of these estimators to:\n\nMinimize cross-validated risk, yielding an adaptive, doubly robust final estimate.\n\n\n\nMultiple data sources can provide:\n\nHigh internal validity (RCT)\n\nHigh external validity (RWD)\n\nDifferent types of bias and variance\n\nA-TMLE lets the data decide the optimal combination, subject to:\n\nConstraints (e.g., RCT estimator always included)\n\nHierarchical preferences (e.g., more weight on RCT when conflict arises)\n\n\n\n\nLet ( _1, , _K) be candidate estimators of the same target parameter ().\nA-TMLE constructs:\n[ { ext{A-TMLE}} = {k=1}^K \u0007lpha_k _k ]\nwith\n\n(\u0007lpha_k )\n\n(_k \u0007lpha_k = 1)\n\nWeights (\u0007lpha) are chosen to minimize cross-validated loss (e.g., squared error of influence curves).\n\n\n\n\n\nConsider:\n\nRCT: experimental vs placebo\n\nRWD: observational comparison between experimental drug and standard-of-care\n\n\n\ntmle_rct &lt;- tmle(\n  Y = Y_rct,\n  A = A_rct,\n  W = W_rct,\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\")\n)\npsi_rct &lt;- tmle_rct$estimates$ATE$psi\n\n\n\ntmle_rwd &lt;- tmle(\n  Y = Y_rwd,\n  A = A_rwd,\n  W = W_rwd,\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\")\n)\npsi_rwd &lt;- tmle_rwd$estimates$ATE$psi\n\n\n\nY_pool &lt;- c(Y_rct, Y_rwd)\nA_pool &lt;- c(A_rct, A_rwd)\nW_pool &lt;- rbind(W_rct, W_rwd)\n\ntmle_pool &lt;- tmle(\n  Y = Y_pool,\n  A = A_pool,\n  W = W_pool,\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\")\n)\npsi_pool &lt;- tmle_pool$estimates$ATE$psi\n\n\n\ncandidates &lt;- c(psi_rct, psi_rwd, psi_pool)\n\n# Placeholder: in practice, you would build a loss function based on influence curves\n# and use constrained optimization (e.g., nnls) with cross-validation to find weights.\n\nweights &lt;- c(0.6, 0.0, 0.4)  # e.g., chosen by cross-validation\nweights &lt;- weights / sum(weights)\n\npsi_atmle &lt;- sum(weights * candidates)\npsi_atmle\nIn a true A-TMLE implementation, the weights would be:\n\nEstimated based on CV risk\n\nPossibly constrained to ensure heavier emphasis on RCT-based estimators\n\n\n\n\n\n\n\n\nBefore attempting hybrid estimation:\n\nAlign endpoint definitions and censoring rules\n\nHarmonize covariates (coding, units, ranges)\n\nConfirm consistent definition of “treatment” across sources\n\n\n\n\nCheck covariate distributions:\nbind_rows(\n  W_rct %&gt;% mutate(source = \"RCT\"),\n  W_rwd %&gt;% mutate(source = \"RWD\")\n) %&gt;%\n  pivot_longer(cols = -source) %&gt;%\n  ggplot(aes(x = value, fill = source)) +\n  geom_density(alpha = 0.4) +\n  facet_wrap(~ name, scales = \"free\")\nLook for:\n\nLarge discrepancies → may require transportability modeling\n\nNon-overlapping regions → positivity issues\n\n\n\n\n\nRe-estimate using RCT-only TMLE\n\nVary the degree of borrowing (e.g., by up-weighting/down-weighting RWD in hybrid estimators)\n\nUse E-values or QBA to examine impact of unmeasured confounding in RWD component\n\nApply negative control analyses in the RWD part\n\n\n\n\n\n\nHybrid designs are appropriate when:\n\nRWD is of reasonable quality\n\nKey confounders in RWD are measured\n\nOutcome definitions are compatible\n\nThere is substantial overlap in covariate distributions\n\nThe trial alone is underpowered or narrow in scope\n\nThey may be inappropriate when:\n\nRWD is subject to severe unmeasured confounding\n\nData sources are poorly harmonized\n\nThere is little overlap in covariate or treatment patterns\n\nIn those cases, a pure RCT analysis with careful interpretation may be preferable.\n\n\n\n\nHybrid RCT–RWD designs extend the causal roadmap to a richer evidence ecosystem:\n\nExternal controls can augment sparse trial control arms\n\nTransport and generalizability methods can extend findings to broader populations\n\nES-CV-TMLE leverages RWD for nuisance modeling while preserving internal validity\n\nA-TMLE adaptively combines estimators from multiple sources using targeted learning and cross-validation\n\nUsed carefully, these tools can:\n\nImprove precision\n\nEnhance generalizability\n\nProvide robust, transparent evidence that respects the strengths and limitations of both RCT and RWD\n\n\n\nCode\nsessionInfo()\n\n\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26200)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.2    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.4.2       htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10      \n [9] rmarkdown_2.29    knitr_1.49        jsonlite_2.0.0    xfun_0.49        \n[13] digest_0.6.37     rlang_1.1.6       evaluate_1.0.5"
  },
  {
    "objectID": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#when-rwd-meets-rct-hybrid-designs-for-causal-inference",
    "href": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#when-rwd-meets-rct-hybrid-designs-for-causal-inference",
    "title": "Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "",
    "text": "Combining randomized and observational data to improve precision and generalizability\nRandomized controlled trials (RCTs) are the gold standard for causal inference.\nBut they are:\n\nExpensive and slow\n\nOften underpowered for rare events and subgroup effects\n\nConducted in selective populations\n\nNot always feasible or ethical\n\nReal-world data (RWD) — registries, EHR, claims — provide:\n\nLarge, diverse populations\n\nNaturalistic treatment patterns\n\nLong-term safety follow-up\n\nHybrid RCT–RWD designs aim to combine:\n\nThe internal validity of RCTs\n\nThe external validity and scale of RWD\n\nThis chapter introduces:\n\nWhy hybrid designs are needed\n\nTypes of hybrid designs with external controls\n\nTransportability and generalizability concepts\n\nES-CV-TMLE (External Supervised Cross-Validated TMLE)\n\nA-TMLE (Adaptive TMLE) for integrating multiple data sources\n\nPractical considerations and diagnostics"
  },
  {
    "objectID": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#why-combine-rct-and-rwd",
    "href": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#why-combine-rct-and-rwd",
    "title": "Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "",
    "text": "Trials may be underpowered for:\n\nRare safety endpoints\n\nImportant subgroups\n\nLong-term secondary endpoints\n\nExternal RWD can add information and boost precision without enrolling more randomized patients.\n\n\n\nRCT participants tend to:\n\nBe younger and healthier\n\nHave fewer comorbidities\n\nBe more adherent and monitored\n\nThus, trial results may not fully apply to routine-care populations.\n\n\n\nHybrid designs are useful when:\n\nPlacebo or standard randomized controls are unethical\n\nOnly a single-arm trial is feasible\n\nRapid evidence is needed (e.g., post-marketing surveillance, rare diseases)"
  },
  {
    "objectID": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#basic-hybrid-designs",
    "href": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#basic-hybrid-designs",
    "title": "Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "",
    "text": "Several design patterns are commonly used.\n\n\n\nA single-arm trial (all patients get experimental treatment) may be compared against an external control arm from RWD.\nUse cases:\n\nOncology (historical controls)\n\nRare diseases\n\nWhen standard-of-care is well characterized\n\nChallenges:\n\nConfounding by indication\n\nDifferences in data capture, follow-up, eligibility\n\nTiming effects (calendar time, coding changes)\n\n\n\n\n\nAn RCT randomizes patients to:\n\nExperimental treatment vs trial control (e.g., 2:1 randomization)\n\nBut the trial control arm is augmented with external RWD controls to:\n\nImprove precision\n\nReduce required randomized control sample size\n\nSupport safety and rare-event evaluation\n\nBorrowing can be:\n\nFixed (pre-specified)\n\nDynamic / adaptive (data-driven)\n\n\n\n\n\nYou may have:\n\nAn RCT effect estimate in a selected population\n\nA target population in RWD\n\nGoal:\n\nTransport or generalize the trial effect to the RWD population.\n\nRequires:\n\nModeling the difference between trial and target populations\n\nAdjusting for “sampling bias” (who joins the trial)\n\nTechniques:\n\nInverse odds of sampling weights (IOSW)\n\nTransport / generalizability TMLE\n\nDoubly robust methods combining outcome and sampling models"
  },
  {
    "objectID": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#identification-assumptions-in-hybrid-settings",
    "href": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#identification-assumptions-in-hybrid-settings",
    "title": "Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "",
    "text": "Beyond usual RCT assumptions, hybrid designs require:\n\n\nWithin the external data:\n\nTreatment–outcome confounding must be controlled using available covariates\n\nResidual confounding may bias the hybrid estimate\n\n\n\n\nThe joint covariate space of:\n\nRCT participants\n\nRWD patients\n\nmust overlap, especially when:\n\nUsing RWD to estimate control outcomes\n\nTransporting effects across populations\n\n\n\n\nMedical coding, endpoint definitions, and measurement schemes should be compatible (or harmonized)."
  },
  {
    "objectID": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#es-cv-tmle-external-supervised-cross-validated-tmle",
    "href": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#es-cv-tmle-external-supervised-cross-validated-tmle",
    "title": "Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "",
    "text": "ES-CV-TMLE (External Supervised Cross-Validated TMLE) is a targeted learning approach that:\n\nUses external data (RWD) to help train nuisance models (e.g., outcome regressions)\n\nValidates and selects among them using cross-validation in the RCT only\n\nEnsures external data do not degrade the validity of RCT-based estimation\n\n\n\nWe may have poor precision in the RCT alone for nuisance functions (Q) and (g).\nExternal data can improve the learning of these functions, but confounding in the RWD could distort:\n\nOutcome relationships\n\nTreatment assignment mechanisms\n\nES-CV-TMLE protects against this by:\n\nProposing multiple candidate nuisance models, some learned on:\n\nRCT only\n\nRWD only\n\nCombined data\n\nUsing cross-validation on the RCT to evaluate each model’s performance (e.g., via log-likelihood loss).\n\nChoosing the best-performing nuisance model (or an ensemble of them) for TMLE.\n\nExternal data are “supervisors” but do not override the RCT.\n\n\n\n\nPool RCT and RWD data for training candidate models:\n\n(Q_{ ext{RCT}}): trained only on RCT\n\n(Q_{ ext{RWD}}): trained only on RWD\n\n(Q_{ ext{pool}}): trained on combined RCT+RWD\n\nFor each candidate Q-model:\n\nUse RCT data only\n\nRun cross-validated evaluation (e.g., deviance, negative log-likelihood)\n\nSelect (or weight) candidate Qs via SuperLearner-style metalearning.\nUse the chosen Q (and similarly chosen g, if desired) in TMLE on the RCT data.\n\nThis preserves the RCT-based identification and uses RWD as an auxiliary data source for better prediction."
  },
  {
    "objectID": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#a-tmle-adaptive-targeted-maximum-likelihood-estimation",
    "href": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#a-tmle-adaptive-targeted-maximum-likelihood-estimation",
    "title": "Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "",
    "text": "Adaptive TMLE (A-TMLE) generalizes ES-CV-TMLE to the estimator level.\nInstead of combining candidate nuisance models, A-TMLE combines candidate estimators (e.g., separate hybrid analyses):\n\nTMLE using RCT only\n\nTMLE using RWD only (carefully adjusted)\n\nTMLE using both RCT + RWD in a joint model\n\nOther candidate estimators\n\nIt then uses a SuperLearner-style convex combination of these estimators to:\n\nMinimize cross-validated risk, yielding an adaptive, doubly robust final estimate.\n\n\n\nMultiple data sources can provide:\n\nHigh internal validity (RCT)\n\nHigh external validity (RWD)\n\nDifferent types of bias and variance\n\nA-TMLE lets the data decide the optimal combination, subject to:\n\nConstraints (e.g., RCT estimator always included)\n\nHierarchical preferences (e.g., more weight on RCT when conflict arises)\n\n\n\n\nLet ( _1, , _K) be candidate estimators of the same target parameter ().\nA-TMLE constructs:\n[ { ext{A-TMLE}} = {k=1}^K \u0007lpha_k _k ]\nwith\n\n(\u0007lpha_k )\n\n(_k \u0007lpha_k = 1)\n\nWeights (\u0007lpha) are chosen to minimize cross-validated loss (e.g., squared error of influence curves)."
  },
  {
    "objectID": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#example-hybrid-workflow-conceptual",
    "href": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#example-hybrid-workflow-conceptual",
    "title": "Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "",
    "text": "Consider:\n\nRCT: experimental vs placebo\n\nRWD: observational comparison between experimental drug and standard-of-care\n\n\n\ntmle_rct &lt;- tmle(\n  Y = Y_rct,\n  A = A_rct,\n  W = W_rct,\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\")\n)\npsi_rct &lt;- tmle_rct$estimates$ATE$psi\n\n\n\ntmle_rwd &lt;- tmle(\n  Y = Y_rwd,\n  A = A_rwd,\n  W = W_rwd,\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\")\n)\npsi_rwd &lt;- tmle_rwd$estimates$ATE$psi\n\n\n\nY_pool &lt;- c(Y_rct, Y_rwd)\nA_pool &lt;- c(A_rct, A_rwd)\nW_pool &lt;- rbind(W_rct, W_rwd)\n\ntmle_pool &lt;- tmle(\n  Y = Y_pool,\n  A = A_pool,\n  W = W_pool,\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\")\n)\npsi_pool &lt;- tmle_pool$estimates$ATE$psi\n\n\n\ncandidates &lt;- c(psi_rct, psi_rwd, psi_pool)\n\n# Placeholder: in practice, you would build a loss function based on influence curves\n# and use constrained optimization (e.g., nnls) with cross-validation to find weights.\n\nweights &lt;- c(0.6, 0.0, 0.4)  # e.g., chosen by cross-validation\nweights &lt;- weights / sum(weights)\n\npsi_atmle &lt;- sum(weights * candidates)\npsi_atmle\nIn a true A-TMLE implementation, the weights would be:\n\nEstimated based on CV risk\n\nPossibly constrained to ensure heavier emphasis on RCT-based estimators"
  },
  {
    "objectID": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#practical-considerations-and-diagnostics-for-hybrid-designs",
    "href": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#practical-considerations-and-diagnostics-for-hybrid-designs",
    "title": "Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "",
    "text": "Before attempting hybrid estimation:\n\nAlign endpoint definitions and censoring rules\n\nHarmonize covariates (coding, units, ranges)\n\nConfirm consistent definition of “treatment” across sources\n\n\n\n\nCheck covariate distributions:\nbind_rows(\n  W_rct %&gt;% mutate(source = \"RCT\"),\n  W_rwd %&gt;% mutate(source = \"RWD\")\n) %&gt;%\n  pivot_longer(cols = -source) %&gt;%\n  ggplot(aes(x = value, fill = source)) +\n  geom_density(alpha = 0.4) +\n  facet_wrap(~ name, scales = \"free\")\nLook for:\n\nLarge discrepancies → may require transportability modeling\n\nNon-overlapping regions → positivity issues\n\n\n\n\n\nRe-estimate using RCT-only TMLE\n\nVary the degree of borrowing (e.g., by up-weighting/down-weighting RWD in hybrid estimators)\n\nUse E-values or QBA to examine impact of unmeasured confounding in RWD component\n\nApply negative control analyses in the RWD part"
  },
  {
    "objectID": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#when-to-use-hybrid-designs-and-when-not-to",
    "href": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#when-to-use-hybrid-designs-and-when-not-to",
    "title": "Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "",
    "text": "Hybrid designs are appropriate when:\n\nRWD is of reasonable quality\n\nKey confounders in RWD are measured\n\nOutcome definitions are compatible\n\nThere is substantial overlap in covariate distributions\n\nThe trial alone is underpowered or narrow in scope\n\nThey may be inappropriate when:\n\nRWD is subject to severe unmeasured confounding\n\nData sources are poorly harmonized\n\nThere is little overlap in covariate or treatment patterns\n\nIn those cases, a pure RCT analysis with careful interpretation may be preferable."
  },
  {
    "objectID": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#summary",
    "href": "advanced/03-06-rwd-meets-rct-hybrid-designs.html#summary",
    "title": "Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "",
    "text": "Hybrid RCT–RWD designs extend the causal roadmap to a richer evidence ecosystem:\n\nExternal controls can augment sparse trial control arms\n\nTransport and generalizability methods can extend findings to broader populations\n\nES-CV-TMLE leverages RWD for nuisance modeling while preserving internal validity\n\nA-TMLE adaptively combines estimators from multiple sources using targeted learning and cross-validation\n\nUsed carefully, these tools can:\n\nImprove precision\n\nEnhance generalizability\n\nProvide robust, transparent evidence that respects the strengths and limitations of both RCT and RWD\n\n\n\nCode\nsessionInfo()\n\n\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26200)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.2    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.4.2       htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10      \n [9] rmarkdown_2.29    knitr_1.49        jsonlite_2.0.0    xfun_0.49        \n[13] digest_0.6.37     rlang_1.1.6       evaluate_1.0.5"
  },
  {
    "objectID": "advanced/03-04-effect-modification.html",
    "href": "advanced/03-04-effect-modification.html",
    "title": "Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "incorporate Haodongs methods and causal forest\n\n\n\n\nIdentifying who benefits most (or least) from treatment\nCausal inference is not only about estimating average treatment effects.\nIn many scientific and regulatory settings, we want to know:\n\nDoes the treatment work differently for different types of patients?\n\nThis phenomenon is known as effect modification or treatment-effect heterogeneity (HTE).\nIn this chapter, you’ll learn:\n\nConceptual foundations of effect modification\n\nHow to define subgroup-specific causal estimands\n\nTMLE-based approaches to effect heterogeneity\n\nMachine-learning approaches, focusing on the causal forest\n\nHow to interpret heterogeneous effects responsibly\n\nDiagnostics, uncertainty, and false discovery concerns\n\nThis chapter builds on the causal roadmap and estimation methods from earlier modules.\n\n\n\n\nThe average treatment effect (ATE) answers:\n&gt; “What is the mean effect of treatment in the population?”\nBut patients differ:\n\nage, sex\n\ncomorbidities\n\nbiomarkers\n\nbaseline risk\n\ngenetic variation\n\nClinically and scientifically relevant questions include:\n\nDoes our osteoporosis drug reduce fracture risk more in high-risk patients?\n\nAre cardiovascular risks higher in patients with chronic kidney disease?\n\nDoes benefit differ by baseline frailty or prior CVD?\n\nEffect modification helps answer these individualized or stratified questions.\n\n\n\n\nTo study heterogeneity, we define conditional average treatment effects (CATE).\nLet (X) be a baseline covariate or set of covariates.\nThe CATE is:\n[ CATE(x) = E[Y(1) - Y(0) X = x]. ]\nFor categorical variables (e.g., age group):\n[ ATE_{ ext{age&lt;75}} = E[Y(1) - Y(0) ext{age} &lt; 75], ]\nand similarly for other strata.\nYour choice of estimand must match the scientific question:\n\nPrespecified subgroups (sex, race, CKD stage)\n\nPost hoc continuous moderators (eGFR, age)\n\nMachine-learned subgroups (via trees / forests)\n\n\n\n\n\nEffect modification estimands inherit the same assumptions as the main causal effect:\n\nExchangeability:\n( Y(a) A W )\nPositivity:\nEach subgroup must contain both treated and untreated\n\nConsistency\n\nAdditionally:\n\nModerator variables must be measured before treatment\n\nYou should avoid conditioning on post-treatment variables when defining subgroups\n\n\n\n\n\n\nDefine causal estimands (subgroup-specific ATE, CATE(x))\n\nChoose moderators\n\nPrespecified vs exploratory\n\n\nEstimate nuisance functions with SuperLearner\n\nEstimate heterogeneous effects using:\n\nTMLE (subgroup-specific or CATE-targeted)\n\nCausal forests\n\n\nQuantify uncertainty\n\nDocument all steps and prespecifications\n\nWe now walk through TMLE and causal forest approaches.\n\n\n\n\nFor prespecified subgroups, TMLE can estimate:\n[ ATE_g = E[Y(1) - Y(0) X_g = 1], ]\nwhere (X_g) indicates membership in subgroup (g).\nExample: ATE among patients younger than 75.\n\n\nCode\nlibrary(tmle)\n\n\nLoading required package: glmnet\n\n\nLoading required package: Matrix\n\n\nLoaded glmnet 4.1-8\n\n\nLoading required package: SuperLearner\n\n\nLoading required package: nnls\n\n\nLoading required package: gam\n\n\nLoading required package: splines\n\n\nLoading required package: foreach\n\n\nLoaded gam 1.22-5\n\n\nSuper Learner\n\n\nVersion: 2.0-29\n\n\nPackage created on 2024-02-06\n\n\nWelcome to the tmle package, version 2.0.1.1\n\nUse tmleNews() to see details on changes and bug fixes\n\n\nCode\nlibrary(SuperLearner)\nlibrary(tidyverse)\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'stringr' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.6.0\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ purrr::accumulate() masks foreach::accumulate()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ tidyr::unpack()     masks Matrix::unpack()\n✖ purrr::when()       masks foreach::when()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\n# Assume dat has columns: Y (outcome), A (treatment), age, cvd, eGFR, etc.\nset.seed(123)\n\ndat &lt;- tibble(\n  Y = rbinom(2000, 1, 0.2),\n  A = rbinom(2000, 1, 0.5),\n  age = rnorm(2000, 75, 6),\n  cvd = rbinom(2000, 1, 0.4),\n  eGFR = rnorm(2000, 60, 15)\n)\n\ndat &lt;- dat %&gt;%\n  mutate(age_under75 = if_else(age &lt; 75, 1, 0))\n\nsl_lib &lt;- c(\"SL.glm\", \"SL.ranger\", \"SL.mean\")\n\ntmle_sub &lt;- tmle(\n  Y = dat$Y[dat$age_under75 == 1],\n  A = dat$A[dat$age_under75 == 1],\n  W = dat %&gt;%\n    filter(age_under75 == 1) %&gt;%\n    select(cvd, eGFR),\n  family = \"binomial\",\n  Q.SL.library = sl_lib,\n  g.SL.library = sl_lib\n)\n\n\nLoading required namespace: ranger\n\n\nCode\ntmle_sub$estimates$ATE\n\n\n$psi\n[1] 0.01827827\n\n$var.psi\n[1] 0.0006070161\n\n$CI\n[1] -0.03001073  0.06656727\n\n$pvalue\n[1] 0.4581586\n\n$bs.var\n[1] NA\n\n$bs.CI.twosided\n[1] NA NA\n\n$bs.CI.onesided.lower\n[1] -Inf   NA\n\n$bs.CI.onesided.upper\n[1]  NA Inf\n\n\nInterpretation:\n\nAmong patients younger than 75, the TMLE-estimated risk difference is …\n\nThis approach:\n\nGives valid subgroup-specific estimates\n\nLeverages SuperLearner for nuisance models\n\nLimitations:\n\nDoes not provide a continuous CATE curve\n\nRequires prespecified groups and adequate sample size in each\n\n\n\n\n\nFor continuous effect modifiers, you may want:\n[ CATE(x) = E[Y(1) - Y(0) X = x] ]\nfor all x (e.g., all ages). TMLE-based approaches often use:\n\nProjection of the CATE onto basis functions of X (splines, polynomials)\nEstimation of projection coefficients via TMLE\nReconstruction of ( CATE(x) ) from the projected function\n\nA typical CATE-TMLE algorithm:\n\nExpand (X) into basis functions (h_1(X),,h_K(X))\n\nDefine target parameters of the form\n(_k = E[(Y(1) - Y(0)) h_k(X)])\n\nUse TMLE to estimate each (_k)\n\nConstruct ( (x) = _k _k h_k(x))\n\nWe won’t fully implement this here (it is mathematically intensive), but you should be aware that:\n\nTMLE can provide smooth, doubly robust CATE estimators\n\nTMLE-based variable importance methods can also quantify how much a covariate modifies the treatment effect\n\n\n\n\n\nCausal forests are tree-based methods specifically designed to estimate CATEs.\nThey extend random forests by:\n\nSplitting trees to maximize treatment-effect heterogeneity\n\nUsing “honest” sample splitting (training vs estimation sets)\n\nAveraging across many trees to obtain smooth CATE estimates\n\n\n\n\nAutomatically detect complex, nonlinear interactions\n\nProvide individual-level CATE estimates ( au(x) )\n\nOffer approximate pointwise confidence intervals\n\nUseful for exploratory HTE analysis\n\nCaveats:\n\nNot doubly robust\n\nInterpretation is essentially associational, unless we embed it in a rigorous causal framework\n\nNeeds the same identification assumptions as other causal estimators\n\n\n\n\n\n\nWe use the grf package.\n\n\nCode\n# install.packages(\"grf\")\nlibrary(grf)\n\nset.seed(2028)\n\n# Simulate data with treatment effect heterogeneity\nn &lt;- 3000\nX &lt;- tibble(\n  age = rnorm(n, 75, 6),\n  cvd = rbinom(n, 1, 0.4),\n  risk_score = rnorm(n, 0, 1)\n)\n\nA &lt;- rbinom(n, 1, plogis(-0.5 + 0.2 * X$age - 0.8 * X$risk_score))\n# Treatment effect depends on risk_score\ntau_true &lt;- -0.05 + 0.1 * (X$risk_score &gt; 0)\nY &lt;- rbinom(n, 1, plogis(-2 + tau_true * A + 0.05 * (X$age - 75) + 0.5 * X$cvd))\n\nX_mat &lt;- as.matrix(X)\n\ncf &lt;- causal_forest(\n  X = X_mat,\n  Y = Y,\n  W = A\n)\n\n# Individualized CATE estimates\ntau_hat &lt;- predict(cf)$predictions\n\nsummary(tau_hat)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n     NA      NA      NA     NaN      NA      NA    3000 \n\n\n\n\nTo do debug\n\n\nCode\nplot(X$risk_score, tau_hat,\n     xlab = \"Baseline risk score\",\n     ylab = \"Estimated CATE\",\n     pch = 16, cex = 0.3)\nabline(h = 0, col = \"red\")\n\n\nYou should see different CATE patterns for low vs high risk scores.\n\n\n\n\n\nWe can create subgroups such as:\n\n“High predicted benefit” vs “low predicted benefit”\n\n\n\nCode\nthreshold &lt;- median(tau_hat)\n\nres &lt;- X %&gt;%\n  mutate(\n    CATE_hat = tau_hat,\n    group = if_else(CATE_hat &gt; threshold, \"high benefit\", \"low benefit\")\n  )\n\ntable(res$group)\n\n\n&lt; table of extent 0 &gt;\n\n\nCode\nres %&gt;%\n  group_by(group) %&gt;%\n  summarize(\n    mean_CATE = mean(CATE_hat),\n    .groups = \"drop\"\n  )\n\n\n# A tibble: 1 × 2\n  group mean_CATE\n  &lt;chr&gt;     &lt;dbl&gt;\n1 &lt;NA&gt;        NaN\n\n\nThis is exploratory, not confirmatory.\nIt can inform:\n\nHypothesis generation\n\nPrespecified subgroup definitions in future trials\n\n\n\n\n\nTMLE (with SuperLearner):\n\nBest for prespecified subgroups\n\nCATE-TMLE gives doubly robust, efficient CATE estimates\n\nIntegrates neatly into a causal estimand framework\n\nMore transparent and parameter-focused\n\nCausal Forest:\n\nBest for exploratory heterogeneity\n\nAutomatically discovers complex interactions\n\nProvides smooth CATE functions without specifying bases\n\nGood for risk-stratified or personalized-medicine questions\n\n\n\n\nUse TMLE to estimate ATE and pre-planned subgroup effects\n\nUse causal forests to explore residual heterogeneity and generate new hypotheses\n\nWhere consistent patterns are observed, design new confirmatory analyses or studies\n\n\n\n\n\n\nEffect modification is tempting but dangerous:\n\nMultiple subgroup comparisons inflate type I error\n\n“Fishing expeditions” can produce spurious heterogeneity\n\nSmall subgroup sizes → unstable estimates\n\nBest practices:\n\nPrespecify main effect modifiers when possible\n\nCorrect for multiplicity (e.g., family-wise error or FDR) if reporting many subgroups\n\nEmphasize uncertainty (wide CIs are expected)\n\nTreat causal forest findings as exploratory unless prespecified or replicated\n\nAlways present the overall ATE alongside any heterogeneity results\n\n\n\n\n\n\n\nCode\n# Step 1: ATE with TMLE\nsl_lib &lt;- c(\"SL.glm\", \"SL.ranger\", \"SL.mean\")\n\ntmle_ate &lt;- tmle(\n  Y = Y,\n  A = A,\n  W = X,\n  family = \"binomial\",\n  Q.SL.library = sl_lib,\n  g.SL.library = sl_lib\n)\n\ntmle_ate$estimates$ATE\n\n\nNULL\n\n\nCode\n# Step 2: CATEs with causal forest (already computed as tau_hat)\nsummary(tau_hat)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n     NA      NA      NA     NaN      NA      NA    3000 \n\n\n\nTMLE gives a population-level effect (with solid identifiability and efficiency).\nCausal forest gives individual-level estimated CATEs to explore how effects vary.\n\n\n\n\n\nIn this chapter, you learned:\n\nHow to define causal estimands for effect modification and CATEs\n\nHow to estimate subgroup-specific effects via TMLE\n\nHow TMLE can be extended to continuous moderators using projection / variable importance frameworks\n\nHow causal forests provide flexible, ML-driven CATE estimates\n\nHow to interpret heterogeneous effects carefully in real-world and regulatory contexts\n\nEffect modification analysis is powerful but fragile. Combining TMLE for confirmatory, parameter-focused inference and causal forests for exploratory, data-adaptive heterogeneity learning often yields the most insightful and responsible use of HTE methods.\n\n\nCode\nsessionInfo()\n\n\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26200)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] splines   stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] grf_2.4.0           lubridate_1.9.3     forcats_1.0.0      \n [4] stringr_1.6.0       dplyr_1.1.4         purrr_1.0.2        \n [7] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n[10] ggplot2_3.5.2       tidyverse_2.0.0     tmle_2.0.1.1       \n[13] SuperLearner_2.0-29 gam_1.22-5          foreach_1.5.2      \n[16] nnls_1.6            glmnet_4.1-8        Matrix_1.7-1       \n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.4            generics_0.1.3        shape_1.4.6.1        \n [4] stringi_1.8.7         lattice_0.22-6        hms_1.1.3            \n [7] digest_0.6.37         magrittr_2.0.3        timechange_0.3.0     \n[10] evaluate_1.0.5        grid_4.4.2            iterators_1.0.14     \n[13] fastmap_1.2.0         jsonlite_2.0.0        survival_3.7-0       \n[16] fansi_1.0.6           scales_1.3.0          codetools_0.2-20     \n[19] cli_3.6.5             rlang_1.1.6           munsell_0.5.1        \n[22] withr_3.0.2           yaml_2.3.10           tools_4.4.2          \n[25] tzdb_0.4.0            colorspace_2.1-1      ranger_0.17.0        \n[28] vctrs_0.6.5           R6_2.6.1              lifecycle_1.0.4      \n[31] htmlwidgets_1.6.4     pkgconfig_2.0.3       pillar_1.9.0         \n[34] gtable_0.3.6          glue_1.8.0            Rcpp_1.0.13-1        \n[37] xfun_0.49             tidyselect_1.2.1      rstudioapi_0.17.1    \n[40] knitr_1.49            htmltools_0.5.8.1     rmarkdown_2.29       \n[43] compiler_4.4.2        WeightedROC_2020.1.31"
  },
  {
    "objectID": "advanced/03-04-effect-modification.html#to-do",
    "href": "advanced/03-04-effect-modification.html#to-do",
    "title": "Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "incorporate Haodongs methods and causal forest"
  },
  {
    "objectID": "advanced/03-04-effect-modification.html#effect-modification-and-heterogeneous-treatment-effects",
    "href": "advanced/03-04-effect-modification.html#effect-modification-and-heterogeneous-treatment-effects",
    "title": "Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "Identifying who benefits most (or least) from treatment\nCausal inference is not only about estimating average treatment effects.\nIn many scientific and regulatory settings, we want to know:\n\nDoes the treatment work differently for different types of patients?\n\nThis phenomenon is known as effect modification or treatment-effect heterogeneity (HTE).\nIn this chapter, you’ll learn:\n\nConceptual foundations of effect modification\n\nHow to define subgroup-specific causal estimands\n\nTMLE-based approaches to effect heterogeneity\n\nMachine-learning approaches, focusing on the causal forest\n\nHow to interpret heterogeneous effects responsibly\n\nDiagnostics, uncertainty, and false discovery concerns\n\nThis chapter builds on the causal roadmap and estimation methods from earlier modules."
  },
  {
    "objectID": "advanced/03-04-effect-modification.html#why-study-effect-modification",
    "href": "advanced/03-04-effect-modification.html#why-study-effect-modification",
    "title": "Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "The average treatment effect (ATE) answers:\n&gt; “What is the mean effect of treatment in the population?”\nBut patients differ:\n\nage, sex\n\ncomorbidities\n\nbiomarkers\n\nbaseline risk\n\ngenetic variation\n\nClinically and scientifically relevant questions include:\n\nDoes our osteoporosis drug reduce fracture risk more in high-risk patients?\n\nAre cardiovascular risks higher in patients with chronic kidney disease?\n\nDoes benefit differ by baseline frailty or prior CVD?\n\nEffect modification helps answer these individualized or stratified questions."
  },
  {
    "objectID": "advanced/03-04-effect-modification.html#causal-estimands-for-effect-modification",
    "href": "advanced/03-04-effect-modification.html#causal-estimands-for-effect-modification",
    "title": "Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "To study heterogeneity, we define conditional average treatment effects (CATE).\nLet (X) be a baseline covariate or set of covariates.\nThe CATE is:\n[ CATE(x) = E[Y(1) - Y(0) X = x]. ]\nFor categorical variables (e.g., age group):\n[ ATE_{ ext{age&lt;75}} = E[Y(1) - Y(0) ext{age} &lt; 75], ]\nand similarly for other strata.\nYour choice of estimand must match the scientific question:\n\nPrespecified subgroups (sex, race, CKD stage)\n\nPost hoc continuous moderators (eGFR, age)\n\nMachine-learned subgroups (via trees / forests)"
  },
  {
    "objectID": "advanced/03-04-effect-modification.html#identification-assumptions",
    "href": "advanced/03-04-effect-modification.html#identification-assumptions",
    "title": "Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "Effect modification estimands inherit the same assumptions as the main causal effect:\n\nExchangeability:\n( Y(a) A W )\nPositivity:\nEach subgroup must contain both treated and untreated\n\nConsistency\n\nAdditionally:\n\nModerator variables must be measured before treatment\n\nYou should avoid conditioning on post-treatment variables when defining subgroups"
  },
  {
    "objectID": "advanced/03-04-effect-modification.html#a-workflow-for-effect-modification",
    "href": "advanced/03-04-effect-modification.html#a-workflow-for-effect-modification",
    "title": "Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "Define causal estimands (subgroup-specific ATE, CATE(x))\n\nChoose moderators\n\nPrespecified vs exploratory\n\n\nEstimate nuisance functions with SuperLearner\n\nEstimate heterogeneous effects using:\n\nTMLE (subgroup-specific or CATE-targeted)\n\nCausal forests\n\n\nQuantify uncertainty\n\nDocument all steps and prespecifications\n\nWe now walk through TMLE and causal forest approaches."
  },
  {
    "objectID": "advanced/03-04-effect-modification.html#tmle-for-subgroup-specific-effects",
    "href": "advanced/03-04-effect-modification.html#tmle-for-subgroup-specific-effects",
    "title": "Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "For prespecified subgroups, TMLE can estimate:\n[ ATE_g = E[Y(1) - Y(0) X_g = 1], ]\nwhere (X_g) indicates membership in subgroup (g).\nExample: ATE among patients younger than 75.\n\n\nCode\nlibrary(tmle)\n\n\nLoading required package: glmnet\n\n\nLoading required package: Matrix\n\n\nLoaded glmnet 4.1-8\n\n\nLoading required package: SuperLearner\n\n\nLoading required package: nnls\n\n\nLoading required package: gam\n\n\nLoading required package: splines\n\n\nLoading required package: foreach\n\n\nLoaded gam 1.22-5\n\n\nSuper Learner\n\n\nVersion: 2.0-29\n\n\nPackage created on 2024-02-06\n\n\nWelcome to the tmle package, version 2.0.1.1\n\nUse tmleNews() to see details on changes and bug fixes\n\n\nCode\nlibrary(SuperLearner)\nlibrary(tidyverse)\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'stringr' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.6.0\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ purrr::accumulate() masks foreach::accumulate()\n✖ tidyr::expand()     masks Matrix::expand()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ tidyr::pack()       masks Matrix::pack()\n✖ tidyr::unpack()     masks Matrix::unpack()\n✖ purrr::when()       masks foreach::when()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\n# Assume dat has columns: Y (outcome), A (treatment), age, cvd, eGFR, etc.\nset.seed(123)\n\ndat &lt;- tibble(\n  Y = rbinom(2000, 1, 0.2),\n  A = rbinom(2000, 1, 0.5),\n  age = rnorm(2000, 75, 6),\n  cvd = rbinom(2000, 1, 0.4),\n  eGFR = rnorm(2000, 60, 15)\n)\n\ndat &lt;- dat %&gt;%\n  mutate(age_under75 = if_else(age &lt; 75, 1, 0))\n\nsl_lib &lt;- c(\"SL.glm\", \"SL.ranger\", \"SL.mean\")\n\ntmle_sub &lt;- tmle(\n  Y = dat$Y[dat$age_under75 == 1],\n  A = dat$A[dat$age_under75 == 1],\n  W = dat %&gt;%\n    filter(age_under75 == 1) %&gt;%\n    select(cvd, eGFR),\n  family = \"binomial\",\n  Q.SL.library = sl_lib,\n  g.SL.library = sl_lib\n)\n\n\nLoading required namespace: ranger\n\n\nCode\ntmle_sub$estimates$ATE\n\n\n$psi\n[1] 0.01827827\n\n$var.psi\n[1] 0.0006070161\n\n$CI\n[1] -0.03001073  0.06656727\n\n$pvalue\n[1] 0.4581586\n\n$bs.var\n[1] NA\n\n$bs.CI.twosided\n[1] NA NA\n\n$bs.CI.onesided.lower\n[1] -Inf   NA\n\n$bs.CI.onesided.upper\n[1]  NA Inf\n\n\nInterpretation:\n\nAmong patients younger than 75, the TMLE-estimated risk difference is …\n\nThis approach:\n\nGives valid subgroup-specific estimates\n\nLeverages SuperLearner for nuisance models\n\nLimitations:\n\nDoes not provide a continuous CATE curve\n\nRequires prespecified groups and adequate sample size in each"
  },
  {
    "objectID": "advanced/03-04-effect-modification.html#tmle-extensions-for-continuous-effect-modification",
    "href": "advanced/03-04-effect-modification.html#tmle-extensions-for-continuous-effect-modification",
    "title": "Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "For continuous effect modifiers, you may want:\n[ CATE(x) = E[Y(1) - Y(0) X = x] ]\nfor all x (e.g., all ages). TMLE-based approaches often use:\n\nProjection of the CATE onto basis functions of X (splines, polynomials)\nEstimation of projection coefficients via TMLE\nReconstruction of ( CATE(x) ) from the projected function\n\nA typical CATE-TMLE algorithm:\n\nExpand (X) into basis functions (h_1(X),,h_K(X))\n\nDefine target parameters of the form\n(_k = E[(Y(1) - Y(0)) h_k(X)])\n\nUse TMLE to estimate each (_k)\n\nConstruct ( (x) = _k _k h_k(x))\n\nWe won’t fully implement this here (it is mathematically intensive), but you should be aware that:\n\nTMLE can provide smooth, doubly robust CATE estimators\n\nTMLE-based variable importance methods can also quantify how much a covariate modifies the treatment effect"
  },
  {
    "objectID": "advanced/03-04-effect-modification.html#modern-ml-approach-causal-forests",
    "href": "advanced/03-04-effect-modification.html#modern-ml-approach-causal-forests",
    "title": "Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "Causal forests are tree-based methods specifically designed to estimate CATEs.\nThey extend random forests by:\n\nSplitting trees to maximize treatment-effect heterogeneity\n\nUsing “honest” sample splitting (training vs estimation sets)\n\nAveraging across many trees to obtain smooth CATE estimates\n\n\n\n\nAutomatically detect complex, nonlinear interactions\n\nProvide individual-level CATE estimates ( au(x) )\n\nOffer approximate pointwise confidence intervals\n\nUseful for exploratory HTE analysis\n\nCaveats:\n\nNot doubly robust\n\nInterpretation is essentially associational, unless we embed it in a rigorous causal framework\n\nNeeds the same identification assumptions as other causal estimators"
  },
  {
    "objectID": "advanced/03-04-effect-modification.html#implementing-causal-forests-in-r",
    "href": "advanced/03-04-effect-modification.html#implementing-causal-forests-in-r",
    "title": "Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "We use the grf package.\n\n\nCode\n# install.packages(\"grf\")\nlibrary(grf)\n\nset.seed(2028)\n\n# Simulate data with treatment effect heterogeneity\nn &lt;- 3000\nX &lt;- tibble(\n  age = rnorm(n, 75, 6),\n  cvd = rbinom(n, 1, 0.4),\n  risk_score = rnorm(n, 0, 1)\n)\n\nA &lt;- rbinom(n, 1, plogis(-0.5 + 0.2 * X$age - 0.8 * X$risk_score))\n# Treatment effect depends on risk_score\ntau_true &lt;- -0.05 + 0.1 * (X$risk_score &gt; 0)\nY &lt;- rbinom(n, 1, plogis(-2 + tau_true * A + 0.05 * (X$age - 75) + 0.5 * X$cvd))\n\nX_mat &lt;- as.matrix(X)\n\ncf &lt;- causal_forest(\n  X = X_mat,\n  Y = Y,\n  W = A\n)\n\n# Individualized CATE estimates\ntau_hat &lt;- predict(cf)$predictions\n\nsummary(tau_hat)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n     NA      NA      NA     NaN      NA      NA    3000 \n\n\n\n\nTo do debug\n\n\nCode\nplot(X$risk_score, tau_hat,\n     xlab = \"Baseline risk score\",\n     ylab = \"Estimated CATE\",\n     pch = 16, cex = 0.3)\nabline(h = 0, col = \"red\")\n\n\nYou should see different CATE patterns for low vs high risk scores."
  },
  {
    "objectID": "advanced/03-04-effect-modification.html#subgrouping-using-cate-estimates",
    "href": "advanced/03-04-effect-modification.html#subgrouping-using-cate-estimates",
    "title": "Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "We can create subgroups such as:\n\n“High predicted benefit” vs “low predicted benefit”\n\n\n\nCode\nthreshold &lt;- median(tau_hat)\n\nres &lt;- X %&gt;%\n  mutate(\n    CATE_hat = tau_hat,\n    group = if_else(CATE_hat &gt; threshold, \"high benefit\", \"low benefit\")\n  )\n\ntable(res$group)\n\n\n&lt; table of extent 0 &gt;\n\n\nCode\nres %&gt;%\n  group_by(group) %&gt;%\n  summarize(\n    mean_CATE = mean(CATE_hat),\n    .groups = \"drop\"\n  )\n\n\n# A tibble: 1 × 2\n  group mean_CATE\n  &lt;chr&gt;     &lt;dbl&gt;\n1 &lt;NA&gt;        NaN\n\n\nThis is exploratory, not confirmatory.\nIt can inform:\n\nHypothesis generation\n\nPrespecified subgroup definitions in future trials"
  },
  {
    "objectID": "advanced/03-04-effect-modification.html#causal-forest-vs.-tmle-which-should-you-use",
    "href": "advanced/03-04-effect-modification.html#causal-forest-vs.-tmle-which-should-you-use",
    "title": "Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "TMLE (with SuperLearner):\n\nBest for prespecified subgroups\n\nCATE-TMLE gives doubly robust, efficient CATE estimates\n\nIntegrates neatly into a causal estimand framework\n\nMore transparent and parameter-focused\n\nCausal Forest:\n\nBest for exploratory heterogeneity\n\nAutomatically discovers complex interactions\n\nProvides smooth CATE functions without specifying bases\n\nGood for risk-stratified or personalized-medicine questions\n\n\n\n\nUse TMLE to estimate ATE and pre-planned subgroup effects\n\nUse causal forests to explore residual heterogeneity and generate new hypotheses\n\nWhere consistent patterns are observed, design new confirmatory analyses or studies"
  },
  {
    "objectID": "advanced/03-04-effect-modification.html#interpretation-and-reporting-avoiding-pitfalls",
    "href": "advanced/03-04-effect-modification.html#interpretation-and-reporting-avoiding-pitfalls",
    "title": "Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "Effect modification is tempting but dangerous:\n\nMultiple subgroup comparisons inflate type I error\n\n“Fishing expeditions” can produce spurious heterogeneity\n\nSmall subgroup sizes → unstable estimates\n\nBest practices:\n\nPrespecify main effect modifiers when possible\n\nCorrect for multiplicity (e.g., family-wise error or FDR) if reporting many subgroups\n\nEmphasize uncertainty (wide CIs are expected)\n\nTreat causal forest findings as exploratory unless prespecified or replicated\n\nAlways present the overall ATE alongside any heterogeneity results"
  },
  {
    "objectID": "advanced/03-04-effect-modification.html#example-combining-tmle-and-causal-forests",
    "href": "advanced/03-04-effect-modification.html#example-combining-tmle-and-causal-forests",
    "title": "Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "Code\n# Step 1: ATE with TMLE\nsl_lib &lt;- c(\"SL.glm\", \"SL.ranger\", \"SL.mean\")\n\ntmle_ate &lt;- tmle(\n  Y = Y,\n  A = A,\n  W = X,\n  family = \"binomial\",\n  Q.SL.library = sl_lib,\n  g.SL.library = sl_lib\n)\n\ntmle_ate$estimates$ATE\n\n\nNULL\n\n\nCode\n# Step 2: CATEs with causal forest (already computed as tau_hat)\nsummary(tau_hat)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n     NA      NA      NA     NaN      NA      NA    3000 \n\n\n\nTMLE gives a population-level effect (with solid identifiability and efficiency).\nCausal forest gives individual-level estimated CATEs to explore how effects vary."
  },
  {
    "objectID": "advanced/03-04-effect-modification.html#summary",
    "href": "advanced/03-04-effect-modification.html#summary",
    "title": "Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "In this chapter, you learned:\n\nHow to define causal estimands for effect modification and CATEs\n\nHow to estimate subgroup-specific effects via TMLE\n\nHow TMLE can be extended to continuous moderators using projection / variable importance frameworks\n\nHow causal forests provide flexible, ML-driven CATE estimates\n\nHow to interpret heterogeneous effects carefully in real-world and regulatory contexts\n\nEffect modification analysis is powerful but fragile. Combining TMLE for confirmatory, parameter-focused inference and causal forests for exploratory, data-adaptive heterogeneity learning often yields the most insightful and responsible use of HTE methods.\n\n\nCode\nsessionInfo()\n\n\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26200)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] splines   stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] grf_2.4.0           lubridate_1.9.3     forcats_1.0.0      \n [4] stringr_1.6.0       dplyr_1.1.4         purrr_1.0.2        \n [7] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n[10] ggplot2_3.5.2       tidyverse_2.0.0     tmle_2.0.1.1       \n[13] SuperLearner_2.0-29 gam_1.22-5          foreach_1.5.2      \n[16] nnls_1.6            glmnet_4.1-8        Matrix_1.7-1       \n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.4            generics_0.1.3        shape_1.4.6.1        \n [4] stringi_1.8.7         lattice_0.22-6        hms_1.1.3            \n [7] digest_0.6.37         magrittr_2.0.3        timechange_0.3.0     \n[10] evaluate_1.0.5        grid_4.4.2            iterators_1.0.14     \n[13] fastmap_1.2.0         jsonlite_2.0.0        survival_3.7-0       \n[16] fansi_1.0.6           scales_1.3.0          codetools_0.2-20     \n[19] cli_3.6.5             rlang_1.1.6           munsell_0.5.1        \n[22] withr_3.0.2           yaml_2.3.10           tools_4.4.2          \n[25] tzdb_0.4.0            colorspace_2.1-1      ranger_0.17.0        \n[28] vctrs_0.6.5           R6_2.6.1              lifecycle_1.0.4      \n[31] htmlwidgets_1.6.4     pkgconfig_2.0.3       pillar_1.9.0         \n[34] gtable_0.3.6          glue_1.8.0            Rcpp_1.0.13-1        \n[37] xfun_0.49             tidyselect_1.2.1      rstudioapi_0.17.1    \n[40] knitr_1.49            htmltools_0.5.8.1     rmarkdown_2.29       \n[43] compiler_4.4.2        WeightedROC_2020.1.31"
  },
  {
    "objectID": "advanced/02-04-superlearner.html",
    "href": "advanced/02-04-superlearner.html",
    "title": "Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "",
    "text": "Flexible prediction to strengthen causal effect estimation\nModern causal inference relies on estimating nuisance functions (outcome regressions and treatment / censoring mechanisms) that are as accurate as possible. If these models are mis-specified, even sophisticated causal estimators can be biased.\nRather than gambling on a single model (e.g., logistic regression), we can stack many candidate learners and let the data decide how to combine them. This is what SuperLearner does.\nIn this chapter you will learn:\n\nThe intuition behind SuperLearner (SL) and stacking\n\nHow cross-validation is used to avoid overfitting\n\nHow to build and interpret SuperLearner models in R\n\nWhen and why to choose different loss functions (MSE, log-likelihood, AUC)\n\nHow to customize SL libraries and tune algorithms\n\nHow SL integrates with TMLE and other causal estimators\n\nThis chapter leans heavily on the excellent visual tutorial by Katherine Hoffman and the SuperLearner demo by David Benkeser (both provided as PDFs), and recasts them in a causal-inference focused Quarto format.\n\n\n\nCausal estimators such as g-computation, IPTW, AIPW, and TMLE rely on estimating:\n\nThe outcome regression:\n( Q(W, A) = E[Y W, A] )\nThe treatment (or censoring) mechanism:\n( g(W) = P(A = 1 W) )\n\nIn traditional practice, both are often modeled with simple GLMs. This is dangerous when:\n\nRelationships are nonlinear\nInteractions are present\nThere are many covariates\nWe are unsure about which variables to include or in what functional form\n\nSuperLearner helps by:\n\nCombining multiple algorithms (GLM, random forests, LASSO, boosted trees, etc.)\nUsing K-fold cross-validation to evaluate and weight each algorithm\nProducing an ensemble predictor with theoretical guarantees (an “oracle inequality”): asymptotically, SL performs nearly as well as the best algorithm in the library\n\nIn causal inference, we rarely care about prediction for its own sake, but good prediction of nuisance functions leads to better causal effect estimation.\n\n\n\n\nAt a high level, SuperLearner does the following:\n\nPick a set of candidate learners (the library).\nSplit the data into K folds.\nFor each learner:\n\nFit on K-1 folds (training data),\nPredict on the held-out fold (validation data).\n\nCollect cross-validated predictions for every observation and every learner.\nFit a metalearner (often a linear regression) that finds the optimal weighted combination of the learners’ predictions to minimize a chosen loss function (e.g., mean squared error, negative log-likelihood).\nRefit each base learner on the full dataset.\nUse the metalearner and the refit base learners to form the final ensemble and obtain predictions for new data.\n\nThis is exactly the workflow illustrated in the “VISUAL GUIDE TO SUPERLEARNING” figure in the KHstats tutorial.\n\n\n\n\nWe’ll start with a simple prediction problem, then connect it back to causal inference later.\n\n\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'stringr' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.6.0\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(SuperLearner)\n\n\nLoading required package: nnls\nLoading required package: gam\nLoading required package: splines\nLoading required package: foreach\n\nAttaching package: 'foreach'\n\nThe following objects are masked from 'package:purrr':\n\n    accumulate, when\n\nLoaded gam 1.22-5\n\nSuper Learner\nVersion: 2.0-29\nPackage created on 2024-02-06\n\n\nCode\nset.seed(7)\nn &lt;- 2000\n\nobs &lt;- tibble(\n  id = 1:n,\n  x1 = rnorm(n),\n  x2 = rbinom(n, 1, plogis(10 * x1)),\n  x3 = rbinom(n, 1, plogis(x1 * x2 + 0.5 * x2)),\n  x4 = rnorm(n, mean = x1 * x2, sd = 0.5 * x3),\n  y  = x1 + x2 + x2 * x3 + sin(x4) + rnorm(n, sd = 0.2)\n)\n\nglimpse(obs)\n\n\nRows: 2,000\nColumns: 6\n$ id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, …\n$ x1 &lt;dbl&gt; 2.287247161, -1.196771682, -0.694292510, -0.412292951, -0.970673341…\n$ x2 &lt;int&gt; 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1…\n$ x3 &lt;int&gt; 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1…\n$ x4 &lt;dbl&gt; 1.50283924, 0.04260947, 0.00000000, 0.00000000, 0.00000000, 1.07555…\n$ y  &lt;dbl&gt; 5.03669124, -1.13306036, -0.38284042, -0.28671230, -0.87539307, -0.…\n\n\nThe outcome y is a nonlinear function of the covariates, with interactions and a sine term. GLMs will struggle here.\n\n\n\n\n\n\n\nWe’ll start with a small library for illustration.\n\n\nCode\nset.seed(1234)\n\nX &lt;- obs %&gt;% select(x1:x4) %&gt;% as.data.frame()\nY &lt;- obs$y\n\nSL.lib &lt;- c(\"SL.glm\",      # simple GLM\n            \"SL.mean\",     # intercept-only\n            \"SL.earth\",    # multivariate adaptive regression splines (MARS)\n            \"SL.ranger\")   # random forest\n\nsl_fit &lt;- SuperLearner(\n  Y = Y,\n  X = X,\n  newX = NULL,\n  family = gaussian(),\n  SL.library = SL.lib,\n  method = \"method.NNLS\",  # non-negative least squares metalearner\n  cvControl = list(V = 10L)\n)\n\n\nLoading required namespace: earth\n\n\nLoading required namespace: ranger\n\n\nCode\nsl_fit\n\n\n\nCall:  \nSuperLearner(Y = Y, X = X, newX = NULL, family = gaussian(), SL.library = SL.lib,  \n    method = \"method.NNLS\", cvControl = list(V = 10L)) \n\n                    Risk      Coef\nSL.glm_All    0.15038334 0.0000000\nSL.mean_All   4.52716718 0.0000000\nSL.earth_All  0.04408952 0.8593302\nSL.ranger_All 0.05735981 0.1406698\n\n\nKey outputs:\n\nRisk: cross-validated risk (e.g., MSE) for each learner\nCoef: weight given to each learner in the ensemble\n\nThe learner with the smallest CV-risk often gets the largest weight, but SL can combine learners.\nWe can access the ensemble predictions:\n\n\nCode\nhead(sl_fit$SL.predict)\n\n\n         [,1]\n1  5.36960217\n2 -1.15651994\n3 -0.66557910\n4 -0.39653932\n5 -0.94879355\n6 -0.04451723\n\n\nand predictions from individual learners:\n\n\nCode\nhead(sl_fit$library.predict)\n\n\n  SL.glm_All SL.mean_All SL.earth_All SL.ranger_All\n1  4.9119003    1.145784   5.44169210     4.9292158\n2 -0.9619611    1.145784  -1.14585410    -1.2216759\n3 -0.8907976    1.145784  -0.67326080    -0.6186528\n4 -0.6300543    1.145784  -0.40211488    -0.3624791\n5 -1.1463457    1.145784  -0.94947428    -0.9446351\n6 -0.1673960    1.145784  -0.01723667    -0.2111701\n\n\n\n\n\n\n\nSuperLearner allows different loss functions, which define what we mean by “best” prediction.\n\n\n\nDefault for family = gaussian()\nAppropriate for continuous outcomes when we care about squared error: \\[ L(y, \\hat{y}) = (y - \\hat{y})^2 \\]\nGood when we want well-calibrated mean predictions\n\nExample (already used above): method = \"method.NNLS\" with family = gaussian()\n\n\n\n\nNatural choice for binary outcomes when we care about probability calibration: \\[ L(y, \\hat{p}) = -[y \\log(\\hat{p}) + (1-y) \\log(1-\\hat{p})] \\]\nStrongly penalizes confident but wrong predictions\nRecommended for:\n\nOutcome models (Y binary)\nTreatment models (A binary) in causal inference\n\n\nUse method = \"method.NNloglik\" with family = binomial().\nExample:\n\n\nCode\n# suppose Y is binary\nY_bin &lt;- rbinom(n, 1, plogis(X$x1 + X$x2))\n\nsl_loglik &lt;- SuperLearner(\n  Y = Y_bin,\n  X = X,\n  family = binomial(),\n  SL.library = c(\"SL.glm\", \"SL.mean\", \"SL.ranger\"),\n  method = \"method.NNloglik\"\n)\n\nsl_loglik\n\n\n\nCall:  \nSuperLearner(Y = Y_bin, X = X, family = binomial(), SL.library = c(\"SL.glm\",  \n    \"SL.mean\", \"SL.ranger\"), method = \"method.NNloglik\") \n\n                   Risk      Coef\nSL.glm_All    0.5286216 0.8914129\nSL.mean_All   0.6818619 0.0000000\nSL.ranger_All 0.5537130 0.1085871\n\n\n\n\n\n\nFor classification problems where the ranking of probabilities matters more than calibration\nCommon when choosing a threshold later (e.g., risk stratification)\nSuperLearner implementation: method = \"method.AUC\"\nParticularly useful when interested in discriminatory ability (e.g., disease risk scores)\n\nExample:\n\n\nCode\nlibrary(cvAUC)   # required by method.AUC\n\nsl_auc &lt;- SuperLearner(\n  Y = Y_bin,\n  X = X,\n  family = binomial(),\n  SL.library = c(\"SL.glm\", \"SL.mean\", \"SL.ranger\"),\n  method = \"method.AUC\"\n)\n\n\nWarning in method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames, :\noptim didn't converge when estimating the super learner coefficients, reason\n(see ?optim): 52 optim message: ERROR: ABNORMAL_TERMINATION_IN_LNSRCH\n\n\nCode\nsl_auc\n\n\n\nCall:  \nSuperLearner(Y = Y_bin, X = X, family = binomial(), SL.library = c(\"SL.glm\",  \n    \"SL.mean\", \"SL.ranger\"), method = \"method.AUC\") \n\n                   Risk         Coef\nSL.glm_All    0.1938743 0.9988292700\nSL.mean_All   0.5268196 0.0006672332\nSL.ranger_All 0.2104779 0.0005034968\n\n\n\n\n\n\nFor outcome models in TMLE/AIPW:\n\nIf binary → log-likelihood (binomial deviance)\n\nIf continuous → MSE or other appropriate distribution-based loss\n\n\nFor treatment / censoring models in causal inference:\n\nTypically log-likelihood (because we want accurate estimates of P(A | W))\n\nFor pure classification (no causal estimation):\n\nConsider AUC loss (method.AUC) if ranking is the priority\n\n\n\n\n\n\n\n\n\nCode\nsl_fit$cvRisk\n\n\n   SL.glm_All   SL.mean_All  SL.earth_All SL.ranger_All \n   0.15038334    4.52716718    0.04408952    0.05735981 \n\n\nCode\nsl_fit$coef\n\n\n   SL.glm_All   SL.mean_All  SL.earth_All SL.ranger_All \n    0.0000000     0.0000000     0.8593302     0.1406698 \n\n\n\ncvRisk shows cross-validated risk for each algorithm\ncoef gives the ensemble weights (metalearner solution)\n\nAn algorithm might have:\n\nLow risk → high weight\n\nHigh risk → weight near zero (effectively excluded)\n\nThis matches the demonstration in the Benkeser notes where GLM dominates mean-only models when predicting MI.\n\n\n\n\n\n\nWe can define bounded random forest variants with different hyperparameters.\n\n\nCode\nSL.ranger_mtry3 &lt;- function(..., mtry = 3) {\n  SL.ranger(..., mtry = mtry)\n}\n\nSL.ranger_mtry5 &lt;- function(..., mtry = 5) {\n  SL.ranger(..., mtry = mtry)\n}\n\nSL.lib_tuned &lt;- c(\"SL.glm\",\n                  \"SL.earth\",\n                  \"SL.ranger_mtry3\",\n                  \"SL.ranger_mtry5\")\n\n\nThen run:\n\n\nCode\nset.seed(123)\nsl_tuned &lt;- SuperLearner(\n  Y = Y,\n  X = X,\n  family = gaussian(),\n  SL.library = SL.lib_tuned,\n  method = \"method.NNLS\"\n)\n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5  on full data \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nWarning in SuperLearner(Y = Y, X = X, family = gaussian(), SL.library =\nSL.lib_tuned, : Coefficients already 0 for all failed algorithm(s)\n\n\nCode\nsl_tuned$cvRisk\n\n\n         SL.glm_All        SL.earth_All SL.ranger_mtry3_All SL.ranger_mtry5_All \n          0.1506218           0.0440174           0.0505784                  NA \n\n\nCode\nsl_tuned$coef\n\n\n         SL.glm_All        SL.earth_All SL.ranger_mtry3_All SL.ranger_mtry5_All \n            0.00000             0.73464             0.26536             0.00000 \n\n\nSuperLearner automatically picks which tuned version (or combination) works best.\n\n\n\n\n\nCV.SuperLearner adds an outer layer of cross-validation to evaluate SL versus its components objectively.\n\n\nCode\nset.seed(123)\ncv_sl &lt;- CV.SuperLearner(\n  Y = Y,\n  X = X,\n  V = 5,\n  family = gaussian(),\n  SL.library = SL.lib\n)\n\n\nLoading required namespace: earth\n\n\nLoading required namespace: ranger\n\n\nCode\ncv_sl\n\n\n\nCall:  \nCV.SuperLearner(Y = Y, X = X, V = 5, family = gaussian(), SL.library = SL.lib) \n\n\n\nCross-validated predictions from the SuperLearner:  SL.predict \n\nCross-validated predictions from the discrete super learner (cross-validation selector):  discreteSL.predict \n\nWhich library algorithm was the discrete super learner:  whichDiscreteSL \n\nCross-validated prediction for all algorithms in the library:  library.predict\n\n\nCode\nplot(cv_sl)\n\n\n\n\n\n\n\n\n\nThe plot shows:\n\nCross-validated risks and confidence intervals for each learner\nPerformance of the discrete and continuous SuperLearner\n\nThis step is particularly helpful when you want to justify using SL rather than a single, simpler algorithm.\n\n\n\n\nSo far we focused on prediction. How does this relate to causal inference?\nFor a point-treatment ATE, a TMLE analysis might look like:\n\n\nCode\n# Example skeleton (you will flesh this out later with your own data)\nlibrary(tmle)\n\ntmle_fit &lt;- tmle(\n  Y = Y_bin,          # binary outcome\n  A = A,              # treatment\n  W = X,              # covariates\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\", \"SL.earth\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\", \"SL.mean\")\n)\n\ntmle_fit$estimates$ATE\n\n\nHere:\n\nQ.SL.library is used to estimate outcome regression E[Y|A,W]\ng.SL.library is used to estimate propensity scores P(A|W)\nTMLE combines these with targeting to produce an efficient, doubly robust estimate\n\nKey advantages:\n\nYou no longer need to guess the “right” model for Y or A\n\nYou can include many flexible learners without overfitting (thanks to SL + CV)\n\nYour causal inference relies less on arbitrary parametric modeling choices\n\n\n\n\n\n\nStart with a modest but diverse library\n\nGLM (SL.glm)\n\nRandom forest (SL.ranger or SL.randomForest)\n\nMARS (SL.earth)\n\nPenalized regression (SL.glmnet)\n\nPick loss functions that match your problem\n\nBinary → log-likelihood (for calibration) or AUC (for ranking)\n\nContinuous → MSE\n\nWatch computation time\n\nSL is more expensive than a single GLM, especially with many learners and CV folds.\n\nUse SL primarily on nuisance functions\n\nDon’t use SL to directly estimate the causal effect; instead, use SL to estimate Q and g and feed these into TMLE, AIPW, etc.\n\nInspect SL outputs\n\nWhich learners are getting weight?\n\nAre any learners consistently poor performers?\n\nDo you need to adjust your library?\n\n\n\n\n\n\nIn this chapter you learned\n\nHow SuperLearner combines multiple algorithms using cross-validation and a metalearner\n\nThe role of loss functions (MSE, log-likelihood, AUC) and when to choose each\n\nHow to implement SuperLearner in R, inspect CV-risk and weights, and customize the library\n\nHow SuperLearner supports reliable causal inference by improving nuisance function estimation and integrating seamlessly with TMLE and other estimators\n\nNext, we move to Module 3, where we tackle longitudinal data, dynamic treatment regimes, and modified treatment policies, often using SuperLearner as a core building block."
  },
  {
    "objectID": "advanced/02-04-superlearner.html#why-use-superlearner-in-causal-inference",
    "href": "advanced/02-04-superlearner.html#why-use-superlearner-in-causal-inference",
    "title": "Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "",
    "text": "Causal estimators such as g-computation, IPTW, AIPW, and TMLE rely on estimating:\n\nThe outcome regression:\n( Q(W, A) = E[Y W, A] )\nThe treatment (or censoring) mechanism:\n( g(W) = P(A = 1 W) )\n\nIn traditional practice, both are often modeled with simple GLMs. This is dangerous when:\n\nRelationships are nonlinear\nInteractions are present\nThere are many covariates\nWe are unsure about which variables to include or in what functional form\n\nSuperLearner helps by:\n\nCombining multiple algorithms (GLM, random forests, LASSO, boosted trees, etc.)\nUsing K-fold cross-validation to evaluate and weight each algorithm\nProducing an ensemble predictor with theoretical guarantees (an “oracle inequality”): asymptotically, SL performs nearly as well as the best algorithm in the library\n\nIn causal inference, we rarely care about prediction for its own sake, but good prediction of nuisance functions leads to better causal effect estimation."
  },
  {
    "objectID": "advanced/02-04-superlearner.html#conceptual-overview-of-superlearner",
    "href": "advanced/02-04-superlearner.html#conceptual-overview-of-superlearner",
    "title": "Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "",
    "text": "At a high level, SuperLearner does the following:\n\nPick a set of candidate learners (the library).\nSplit the data into K folds.\nFor each learner:\n\nFit on K-1 folds (training data),\nPredict on the held-out fold (validation data).\n\nCollect cross-validated predictions for every observation and every learner.\nFit a metalearner (often a linear regression) that finds the optimal weighted combination of the learners’ predictions to minimize a chosen loss function (e.g., mean squared error, negative log-likelihood).\nRefit each base learner on the full dataset.\nUse the metalearner and the refit base learners to form the final ensemble and obtain predictions for new data.\n\nThis is exactly the workflow illustrated in the “VISUAL GUIDE TO SUPERLEARNING” figure in the KHstats tutorial."
  },
  {
    "objectID": "advanced/02-04-superlearner.html#a-minimal-working-example",
    "href": "advanced/02-04-superlearner.html#a-minimal-working-example",
    "title": "Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "",
    "text": "We’ll start with a simple prediction problem, then connect it back to causal inference later.\n\n\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'stringr' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.6.0\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(SuperLearner)\n\n\nLoading required package: nnls\nLoading required package: gam\nLoading required package: splines\nLoading required package: foreach\n\nAttaching package: 'foreach'\n\nThe following objects are masked from 'package:purrr':\n\n    accumulate, when\n\nLoaded gam 1.22-5\n\nSuper Learner\nVersion: 2.0-29\nPackage created on 2024-02-06\n\n\nCode\nset.seed(7)\nn &lt;- 2000\n\nobs &lt;- tibble(\n  id = 1:n,\n  x1 = rnorm(n),\n  x2 = rbinom(n, 1, plogis(10 * x1)),\n  x3 = rbinom(n, 1, plogis(x1 * x2 + 0.5 * x2)),\n  x4 = rnorm(n, mean = x1 * x2, sd = 0.5 * x3),\n  y  = x1 + x2 + x2 * x3 + sin(x4) + rnorm(n, sd = 0.2)\n)\n\nglimpse(obs)\n\n\nRows: 2,000\nColumns: 6\n$ id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, …\n$ x1 &lt;dbl&gt; 2.287247161, -1.196771682, -0.694292510, -0.412292951, -0.970673341…\n$ x2 &lt;int&gt; 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1…\n$ x3 &lt;int&gt; 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1…\n$ x4 &lt;dbl&gt; 1.50283924, 0.04260947, 0.00000000, 0.00000000, 0.00000000, 1.07555…\n$ y  &lt;dbl&gt; 5.03669124, -1.13306036, -0.38284042, -0.28671230, -0.87539307, -0.…\n\n\nThe outcome y is a nonlinear function of the covariates, with interactions and a sine term. GLMs will struggle here."
  },
  {
    "objectID": "advanced/02-04-superlearner.html#using-the-superlearner-package",
    "href": "advanced/02-04-superlearner.html#using-the-superlearner-package",
    "title": "Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "",
    "text": "We’ll start with a small library for illustration.\n\n\nCode\nset.seed(1234)\n\nX &lt;- obs %&gt;% select(x1:x4) %&gt;% as.data.frame()\nY &lt;- obs$y\n\nSL.lib &lt;- c(\"SL.glm\",      # simple GLM\n            \"SL.mean\",     # intercept-only\n            \"SL.earth\",    # multivariate adaptive regression splines (MARS)\n            \"SL.ranger\")   # random forest\n\nsl_fit &lt;- SuperLearner(\n  Y = Y,\n  X = X,\n  newX = NULL,\n  family = gaussian(),\n  SL.library = SL.lib,\n  method = \"method.NNLS\",  # non-negative least squares metalearner\n  cvControl = list(V = 10L)\n)\n\n\nLoading required namespace: earth\n\n\nLoading required namespace: ranger\n\n\nCode\nsl_fit\n\n\n\nCall:  \nSuperLearner(Y = Y, X = X, newX = NULL, family = gaussian(), SL.library = SL.lib,  \n    method = \"method.NNLS\", cvControl = list(V = 10L)) \n\n                    Risk      Coef\nSL.glm_All    0.15038334 0.0000000\nSL.mean_All   4.52716718 0.0000000\nSL.earth_All  0.04408952 0.8593302\nSL.ranger_All 0.05735981 0.1406698\n\n\nKey outputs:\n\nRisk: cross-validated risk (e.g., MSE) for each learner\nCoef: weight given to each learner in the ensemble\n\nThe learner with the smallest CV-risk often gets the largest weight, but SL can combine learners.\nWe can access the ensemble predictions:\n\n\nCode\nhead(sl_fit$SL.predict)\n\n\n         [,1]\n1  5.36960217\n2 -1.15651994\n3 -0.66557910\n4 -0.39653932\n5 -0.94879355\n6 -0.04451723\n\n\nand predictions from individual learners:\n\n\nCode\nhead(sl_fit$library.predict)\n\n\n  SL.glm_All SL.mean_All SL.earth_All SL.ranger_All\n1  4.9119003    1.145784   5.44169210     4.9292158\n2 -0.9619611    1.145784  -1.14585410    -1.2216759\n3 -0.8907976    1.145784  -0.67326080    -0.6186528\n4 -0.6300543    1.145784  -0.40211488    -0.3624791\n5 -1.1463457    1.145784  -0.94947428    -0.9446351\n6 -0.1673960    1.145784  -0.01723667    -0.2111701"
  },
  {
    "objectID": "advanced/02-04-superlearner.html#choosing-a-loss-function-mse-vs-log-likelihood-vs-auc",
    "href": "advanced/02-04-superlearner.html#choosing-a-loss-function-mse-vs-log-likelihood-vs-auc",
    "title": "Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "",
    "text": "SuperLearner allows different loss functions, which define what we mean by “best” prediction.\n\n\n\nDefault for family = gaussian()\nAppropriate for continuous outcomes when we care about squared error: \\[ L(y, \\hat{y}) = (y - \\hat{y})^2 \\]\nGood when we want well-calibrated mean predictions\n\nExample (already used above): method = \"method.NNLS\" with family = gaussian()\n\n\n\n\nNatural choice for binary outcomes when we care about probability calibration: \\[ L(y, \\hat{p}) = -[y \\log(\\hat{p}) + (1-y) \\log(1-\\hat{p})] \\]\nStrongly penalizes confident but wrong predictions\nRecommended for:\n\nOutcome models (Y binary)\nTreatment models (A binary) in causal inference\n\n\nUse method = \"method.NNloglik\" with family = binomial().\nExample:\n\n\nCode\n# suppose Y is binary\nY_bin &lt;- rbinom(n, 1, plogis(X$x1 + X$x2))\n\nsl_loglik &lt;- SuperLearner(\n  Y = Y_bin,\n  X = X,\n  family = binomial(),\n  SL.library = c(\"SL.glm\", \"SL.mean\", \"SL.ranger\"),\n  method = \"method.NNloglik\"\n)\n\nsl_loglik\n\n\n\nCall:  \nSuperLearner(Y = Y_bin, X = X, family = binomial(), SL.library = c(\"SL.glm\",  \n    \"SL.mean\", \"SL.ranger\"), method = \"method.NNloglik\") \n\n                   Risk      Coef\nSL.glm_All    0.5286216 0.8914129\nSL.mean_All   0.6818619 0.0000000\nSL.ranger_All 0.5537130 0.1085871\n\n\n\n\n\n\nFor classification problems where the ranking of probabilities matters more than calibration\nCommon when choosing a threshold later (e.g., risk stratification)\nSuperLearner implementation: method = \"method.AUC\"\nParticularly useful when interested in discriminatory ability (e.g., disease risk scores)\n\nExample:\n\n\nCode\nlibrary(cvAUC)   # required by method.AUC\n\nsl_auc &lt;- SuperLearner(\n  Y = Y_bin,\n  X = X,\n  family = binomial(),\n  SL.library = c(\"SL.glm\", \"SL.mean\", \"SL.ranger\"),\n  method = \"method.AUC\"\n)\n\n\nWarning in method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames, :\noptim didn't converge when estimating the super learner coefficients, reason\n(see ?optim): 52 optim message: ERROR: ABNORMAL_TERMINATION_IN_LNSRCH\n\n\nCode\nsl_auc\n\n\n\nCall:  \nSuperLearner(Y = Y_bin, X = X, family = binomial(), SL.library = c(\"SL.glm\",  \n    \"SL.mean\", \"SL.ranger\"), method = \"method.AUC\") \n\n                   Risk         Coef\nSL.glm_All    0.1938743 0.9988292700\nSL.mean_All   0.5268196 0.0006672332\nSL.ranger_All 0.2104779 0.0005034968\n\n\n\n\n\n\nFor outcome models in TMLE/AIPW:\n\nIf binary → log-likelihood (binomial deviance)\n\nIf continuous → MSE or other appropriate distribution-based loss\n\n\nFor treatment / censoring models in causal inference:\n\nTypically log-likelihood (because we want accurate estimates of P(A | W))\n\nFor pure classification (no causal estimation):\n\nConsider AUC loss (method.AUC) if ranking is the priority"
  },
  {
    "objectID": "advanced/02-04-superlearner.html#interpreting-cv-risk-and-coefficient-weights",
    "href": "advanced/02-04-superlearner.html#interpreting-cv-risk-and-coefficient-weights",
    "title": "Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "",
    "text": "Code\nsl_fit$cvRisk\n\n\n   SL.glm_All   SL.mean_All  SL.earth_All SL.ranger_All \n   0.15038334    4.52716718    0.04408952    0.05735981 \n\n\nCode\nsl_fit$coef\n\n\n   SL.glm_All   SL.mean_All  SL.earth_All SL.ranger_All \n    0.0000000     0.0000000     0.8593302     0.1406698 \n\n\n\ncvRisk shows cross-validated risk for each algorithm\ncoef gives the ensemble weights (metalearner solution)\n\nAn algorithm might have:\n\nLow risk → high weight\n\nHigh risk → weight near zero (effectively excluded)\n\nThis matches the demonstration in the Benkeser notes where GLM dominates mean-only models when predicting MI."
  },
  {
    "objectID": "advanced/02-04-superlearner.html#customizing-the-library-and-tuning-learners",
    "href": "advanced/02-04-superlearner.html#customizing-the-library-and-tuning-learners",
    "title": "Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "",
    "text": "We can define bounded random forest variants with different hyperparameters.\n\n\nCode\nSL.ranger_mtry3 &lt;- function(..., mtry = 3) {\n  SL.ranger(..., mtry = mtry)\n}\n\nSL.ranger_mtry5 &lt;- function(..., mtry = 5) {\n  SL.ranger(..., mtry = mtry)\n}\n\nSL.lib_tuned &lt;- c(\"SL.glm\",\n                  \"SL.earth\",\n                  \"SL.ranger_mtry3\",\n                  \"SL.ranger_mtry5\")\n\n\nThen run:\n\n\nCode\nset.seed(123)\nsl_tuned &lt;- SuperLearner(\n  Y = Y,\n  X = X,\n  family = gaussian(),\n  SL.library = SL.lib_tuned,\n  method = \"method.NNLS\"\n)\n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n\n\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5  on full data \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n\n\nWarning in SuperLearner(Y = Y, X = X, family = gaussian(), SL.library =\nSL.lib_tuned, : Coefficients already 0 for all failed algorithm(s)\n\n\nCode\nsl_tuned$cvRisk\n\n\n         SL.glm_All        SL.earth_All SL.ranger_mtry3_All SL.ranger_mtry5_All \n          0.1506218           0.0440174           0.0505784                  NA \n\n\nCode\nsl_tuned$coef\n\n\n         SL.glm_All        SL.earth_All SL.ranger_mtry3_All SL.ranger_mtry5_All \n            0.00000             0.73464             0.26536             0.00000 \n\n\nSuperLearner automatically picks which tuned version (or combination) works best."
  },
  {
    "objectID": "advanced/02-04-superlearner.html#cross-validated-superlearner-cv.superlearner",
    "href": "advanced/02-04-superlearner.html#cross-validated-superlearner-cv.superlearner",
    "title": "Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "",
    "text": "CV.SuperLearner adds an outer layer of cross-validation to evaluate SL versus its components objectively.\n\n\nCode\nset.seed(123)\ncv_sl &lt;- CV.SuperLearner(\n  Y = Y,\n  X = X,\n  V = 5,\n  family = gaussian(),\n  SL.library = SL.lib\n)\n\n\nLoading required namespace: earth\n\n\nLoading required namespace: ranger\n\n\nCode\ncv_sl\n\n\n\nCall:  \nCV.SuperLearner(Y = Y, X = X, V = 5, family = gaussian(), SL.library = SL.lib) \n\n\n\nCross-validated predictions from the SuperLearner:  SL.predict \n\nCross-validated predictions from the discrete super learner (cross-validation selector):  discreteSL.predict \n\nWhich library algorithm was the discrete super learner:  whichDiscreteSL \n\nCross-validated prediction for all algorithms in the library:  library.predict\n\n\nCode\nplot(cv_sl)\n\n\n\n\n\n\n\n\n\nThe plot shows:\n\nCross-validated risks and confidence intervals for each learner\nPerformance of the discrete and continuous SuperLearner\n\nThis step is particularly helpful when you want to justify using SL rather than a single, simpler algorithm."
  },
  {
    "objectID": "advanced/02-04-superlearner.html#integrating-superlearner-into-causal-inference",
    "href": "advanced/02-04-superlearner.html#integrating-superlearner-into-causal-inference",
    "title": "Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "",
    "text": "So far we focused on prediction. How does this relate to causal inference?\nFor a point-treatment ATE, a TMLE analysis might look like:\n\n\nCode\n# Example skeleton (you will flesh this out later with your own data)\nlibrary(tmle)\n\ntmle_fit &lt;- tmle(\n  Y = Y_bin,          # binary outcome\n  A = A,              # treatment\n  W = X,              # covariates\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\", \"SL.earth\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\", \"SL.mean\")\n)\n\ntmle_fit$estimates$ATE\n\n\nHere:\n\nQ.SL.library is used to estimate outcome regression E[Y|A,W]\ng.SL.library is used to estimate propensity scores P(A|W)\nTMLE combines these with targeting to produce an efficient, doubly robust estimate\n\nKey advantages:\n\nYou no longer need to guess the “right” model for Y or A\n\nYou can include many flexible learners without overfitting (thanks to SL + CV)\n\nYour causal inference relies less on arbitrary parametric modeling choices"
  },
  {
    "objectID": "advanced/02-04-superlearner.html#practical-tips-for-using-superlearner",
    "href": "advanced/02-04-superlearner.html#practical-tips-for-using-superlearner",
    "title": "Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "",
    "text": "Start with a modest but diverse library\n\nGLM (SL.glm)\n\nRandom forest (SL.ranger or SL.randomForest)\n\nMARS (SL.earth)\n\nPenalized regression (SL.glmnet)\n\nPick loss functions that match your problem\n\nBinary → log-likelihood (for calibration) or AUC (for ranking)\n\nContinuous → MSE\n\nWatch computation time\n\nSL is more expensive than a single GLM, especially with many learners and CV folds.\n\nUse SL primarily on nuisance functions\n\nDon’t use SL to directly estimate the causal effect; instead, use SL to estimate Q and g and feed these into TMLE, AIPW, etc.\n\nInspect SL outputs\n\nWhich learners are getting weight?\n\nAre any learners consistently poor performers?\n\nDo you need to adjust your library?"
  },
  {
    "objectID": "advanced/02-04-superlearner.html#summary",
    "href": "advanced/02-04-superlearner.html#summary",
    "title": "Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "",
    "text": "In this chapter you learned\n\nHow SuperLearner combines multiple algorithms using cross-validation and a metalearner\n\nThe role of loss functions (MSE, log-likelihood, AUC) and when to choose each\n\nHow to implement SuperLearner in R, inspect CV-risk and weights, and customize the library\n\nHow SuperLearner supports reliable causal inference by improving nuisance function estimation and integrating seamlessly with TMLE and other estimators\n\nNext, we move to Module 3, where we tackle longitudinal data, dynamic treatment regimes, and modified treatment policies, often using SuperLearner as a core building block."
  },
  {
    "objectID": "advanced/02-02-iptw.html",
    "href": "advanced/02-02-iptw.html",
    "title": "Chapter 2.2: Inverse Probability of Treatment Weighting (IPTW)",
    "section": "",
    "text": "Inverse probability of treatment weighting (IPTW) is a core method in modern causal inference. Instead of modeling the outcome directly as in g computation, IPTW uses a model for treatment assignment to create a pseudo population where treatment is independent of confounders.\nIn this chapter we will\n\nBuild intuition for IPTW\nDerive the weights and connect them to the causal estimand\nShow how to estimate and diagnose propensity scores\nImplement IPTW in R with tidyverse style\nDiscuss stabilized weights and truncation\nCompare IPTW to g computation on the same simulated data\n\nThis is still point treatment only. Longitudinal extensions come later."
  },
  {
    "objectID": "advanced/02-02-iptw.html#direct-weighted-mean-of-outcomes",
    "href": "advanced/02-02-iptw.html#direct-weighted-mean-of-outcomes",
    "title": "Chapter 2.2: Inverse Probability of Treatment Weighting (IPTW)",
    "section": "6.1 Direct weighted mean of outcomes",
    "text": "6.1 Direct weighted mean of outcomes\nEstimated risk under treatment\n\n\nCode\nrisk1_ipw &lt;- with(dat, sum(sw_ipw * Y * (A == 1)) / sum(sw_ipw * (A == 1)))\nrisk0_ipw &lt;- with(dat, sum(sw_ipw * Y * (A == 0)) / sum(sw_ipw * (A == 0)))\n\nate_ipw &lt;- risk1_ipw - risk0_ipw\nc(risk1 = risk1_ipw, risk0 = risk0_ipw, ate = ate_ipw)\n\n\n    risk1     risk0       ate \n0.4109454 0.2991691 0.1117762 \n\n\nThis matches the formula\n\\[\n\\hat E[Y(1)] = \\frac{\\sum_i SW_i Y_i I(A_i = 1)}{\\sum_i SW_i I(A_i = 1)}\n\\]"
  },
  {
    "objectID": "advanced/02-02-iptw.html#weighted-regression-model",
    "href": "advanced/02-02-iptw.html#weighted-regression-model",
    "title": "Chapter 2.2: Inverse Probability of Treatment Weighting (IPTW)",
    "section": "6.2 Weighted regression model",
    "text": "6.2 Weighted regression model\nWe can also fit a weighted regression with treatment as the only predictor.\n\n\nCode\nlibrary(sandwich)\nlibrary(lmtest)\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nCode\n# Fit a simple weighted model\nfit_ipw &lt;- glm(Y ~ A, family = binomial, weights = sw_ipw, data = dat)\n\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\nCode\n# Robust standard errors\ncov_ipw &lt;- vcovHC(fit_ipw, type = \"HC0\")\ncoeftest(fit_ipw, cov_ipw)\n\n\n\nz test of coefficients:\n\n             Estimate Std. Error  z value  Pr(&gt;|z|)    \n(Intercept) -0.851258   0.066105 -12.8773 &lt; 2.2e-16 ***\nA            0.491199   0.080535   6.0992 1.066e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nInterpretation\n\nThe coefficient of A (on the log odds scale) now estimates a marginal effect in the pseudo population\nYou can compute marginal risk differences or ratios by predicting from the model at A=1 and A=0 and standardizing"
  },
  {
    "objectID": "advanced/01-03-identification-estimands.html",
    "href": "advanced/01-03-identification-estimands.html",
    "title": "Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models",
    "section": "",
    "text": "In this chapter, we connect the causal estimand—the quantity that answers our scientific question—to a statistical estimand, which is something we can estimate from observed data. This is the crucial middle step of the Causal Roadmap: translating what we want to know into what we can learn from the dataset at hand.\nWe will walk carefully through: - Identification: when causal effects are estimable from data - Statistical estimands: mapping causal parameters to observable quantities - Positivity, consistency, and exchangeability in practice - Why regression coefficients are not causal effects - How to compute identified estimands using real R code"
  },
  {
    "objectID": "advanced/01-03-identification-estimands.html#consistency",
    "href": "advanced/01-03-identification-estimands.html#consistency",
    "title": "Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models",
    "section": "1. Consistency",
    "text": "1. Consistency\nThe observed outcome equals the counterfactual outcome under the treatment actually received:\n\\[\nY = Y(A)\n\\]\nMeaning: - If someone took denosumab, their observed outcome equals their potential outcome under denosumab\n- If they took ZA, their observed outcome equals their potential outcome under ZA"
  },
  {
    "objectID": "advanced/01-03-identification-estimands.html#exchangeability-no-unmeasured-confounding",
    "href": "advanced/01-03-identification-estimands.html#exchangeability-no-unmeasured-confounding",
    "title": "Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models",
    "section": "2. Exchangeability (No Unmeasured Confounding)",
    "text": "2. Exchangeability (No Unmeasured Confounding)\nFormally:\n\\[\nY(a) \\perp A \\mid W\n\\]\nInterpretation: - After adjusting for confounders (W), treatment groups are comparable. - In a randomized trial, randomization ensures this. - In observational data, we must assume it (and diagnose it).\nIf there are unmeasured factors that influence both treatment and outcome, identification fails."
  },
  {
    "objectID": "advanced/01-03-identification-estimands.html#positivity",
    "href": "advanced/01-03-identification-estimands.html#positivity",
    "title": "Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models",
    "section": "3. Positivity",
    "text": "3. Positivity\nEveryone has a positive probability of receiving either treatment at each level of covariates:\n\\[\n0 &lt; P(A=a \\mid W=w) &lt; 1\n\\]\nViolations are common in real-world data (e.g., frail patients may never receive a certain drug).\nWe will practice diagnosing this with R shortly."
  },
  {
    "objectID": "advanced/01-03-identification-estimands.html#overlap-check",
    "href": "advanced/01-03-identification-estimands.html#overlap-check",
    "title": "Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models",
    "section": "6.1 Overlap check",
    "text": "6.1 Overlap check\n\n\nCode\nplot(density(predict(glm(A ~ age + cvd, family = binomial, data = dat), type = \"response\")),\n     main = \"Propensity Score Overlap\", xlab = \"Estimated Propensity Score\")\n\n\n\n\n\n\n\n\n\nCode\nps &lt;- predict(glm(A ~ age + cvd, family = binomial, data = dat), type = \"response\")\n\n\nLook for: - Mass near 0 or 1 → positivity problems\n- Poor overlap → biased or unstable estimates"
  },
  {
    "objectID": "advanced/01-01-regression-vs-causal.html",
    "href": "advanced/01-01-regression-vs-causal.html",
    "title": "Chapter 1.1: Limitations of Standard Regression Analyses",
    "section": "",
    "text": "In this chapter, we motivate the need for modern causal inference tools by walking through real-world examples where traditional regression fails. We also introduce the counterfactual (potential outcomes) framework as the foundation for defining causal effects."
  },
  {
    "objectID": "advanced/01-01-regression-vs-causal.html#why-not-just-use-regression",
    "href": "advanced/01-01-regression-vs-causal.html#why-not-just-use-regression",
    "title": "Chapter 1.1: Limitations of Standard Regression Analyses",
    "section": "Why Not Just Use Regression?",
    "text": "Why Not Just Use Regression?\nMultivariable regression has long been the standard tool in observational research for “adjusting” for confounders. But regression coefficients don’t always represent causal effects.\nLet’s consider a motivating example based on a real-world study comparing two osteoporosis treatments: denosumab (Prolia) and zoledronic acid.\n\nMotivating Example: Comparing Osteoporosis Treatments\nImagine we’re interested in whether patients who initiate denosumab have higher 3-year risk of heart attack or stroke compared to those initiating zoledronic acid.\nWe might be tempted to run the following:\n\n\nCode\n# simulate crude comparison (not real data)\nset.seed(123)\nn &lt;- 2000\ntreatment &lt;- rbinom(n, 1, 0.5) # 1 = denosumab, 0 = zoledronic acid\nage &lt;- rnorm(n, 75, 6)\ncvd_history &lt;- rbinom(n, 1, plogis(0.1 * (age - 70)))\n\n# outcome depends on age and history\nrisk &lt;- plogis(-2 + 0.4 * treatment + 0.05 * (age - 70) + 1 * cvd_history)\noutcome &lt;- rbinom(n, 1, risk)\n\nmodel1 &lt;- glm(outcome ~ treatment, family = binomial)\nsummary(model1)\n\n\n\nCall:\nglm(formula = outcome ~ treatment, family = binomial)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.05939    0.07197 -14.720  &lt; 2e-16 ***\ntreatment    0.33425    0.09887   3.381 0.000723 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2414.0  on 1999  degrees of freedom\nResidual deviance: 2402.5  on 1998  degrees of freedom\nAIC: 2406.5\n\nNumber of Fisher Scoring iterations: 4\n\n\nThis gives us a crude estimate of association, which is confounded by differences in age and comorbidities.\n\n\nAdjusting for Confounders\nWe add adjustment:\n\n\nCode\nmodel2 &lt;- glm(outcome ~ treatment + age + cvd_history, family = binomial)\nsummary(model2)\n\n\n\nCall:\nglm(formula = outcome ~ treatment + age + cvd_history, family = binomial)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -6.398207   0.694981  -9.206  &lt; 2e-16 ***\ntreatment    0.366412   0.103506   3.540    4e-04 ***\nage          0.060479   0.009213   6.564 5.22e-11 ***\ncvd_history  1.090838   0.121918   8.947  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2414.0  on 1999  degrees of freedom\nResidual deviance: 2223.1  on 1996  degrees of freedom\nAIC: 2231.1\n\nNumber of Fisher Scoring iterations: 4\n\n\nBut is this causal? Not necessarily. We’re making strong parametric assumptions (e.g., log-linear effect of age), and regression implicitly defines the estimand. The treatment coefficient reflects a log-odds ratio comparing denosumab vs ZA, conditional on covariates. But this is not the average treatment effect in the population."
  },
  {
    "objectID": "advanced/01-01-regression-vs-causal.html#enter-the-counterfactual-framework",
    "href": "advanced/01-01-regression-vs-causal.html#enter-the-counterfactual-framework",
    "title": "Chapter 1.1: Limitations of Standard Regression Analyses",
    "section": "Enter the Counterfactual Framework",
    "text": "Enter the Counterfactual Framework\nTo define a causal effect, we introduce counterfactual outcomes:\n\nY(1): outcome if a person received denosumab\nY(0): outcome if a person received zoledronic acid\n\nThe average treatment effect (ATE) is:\n\\[\nE[Y(1) - Y(0)]\n\\]\nBut in reality, each person only receives one treatment. The counterfactual under the other treatment is missing.\nUnder assumptions (exchangeability, consistency, positivity), we can identify the causal effect from observed data. For example, we can estimate:\n\\[\nE_W[ E[Y | A = 1, W] - E[Y | A = 0, W] ]\n\\]\nThis motivates standardization, IPTW, and targeted learning."
  },
  {
    "objectID": "advanced/01-01-regression-vs-causal.html#when-regression-fails",
    "href": "advanced/01-01-regression-vs-causal.html#when-regression-fails",
    "title": "Chapter 1.1: Limitations of Standard Regression Analyses",
    "section": "When Regression Fails",
    "text": "When Regression Fails\nEven if we include the right confounders, misspecification of functional form (e.g., assuming linearity, ignoring interactions) can bias results.\nLet’s compare regression to a nonparametric substitution estimator (g-computation):\n\n\nCode\n# Fit model\nmodel3 &lt;- glm(outcome ~ treatment + age + cvd_history, family = binomial)\n\n# Predict counterfactual outcomes\nnewdata1 &lt;- data.frame(treatment = 1, age = age, cvd_history = cvd_history)\np1 &lt;- predict(model3, newdata = newdata1, type = \"response\")\n\nnewdata0 &lt;- data.frame(treatment = 0, age = age, cvd_history = cvd_history)\np0 &lt;- predict(model3, newdata = newdata0, type = \"response\")\n\n# Estimate marginal risk difference\nmean(p1 - p0)  # this is g-computation\n\n\n[1] 0.06897059\n\n\nCompare this to the regression coefficient:\n\n\nCode\ncoef(model3)[\"treatment\"]\n\n\ntreatment \n0.3664119 \n\n\nThe coefficient gives you a conditional odds ratio, but the g-comp version gives you a marginal risk difference — a more interpretable, population-level quantity."
  },
  {
    "objectID": "advanced/01-01-regression-vs-causal.html#summary",
    "href": "advanced/01-01-regression-vs-causal.html#summary",
    "title": "Chapter 1.1: Limitations of Standard Regression Analyses",
    "section": "Summary",
    "text": "Summary\n\nRegression is not inherently causal — it estimates conditional associations under model assumptions.\nCausal inference starts by defining a causal question and target estimand.\nThe counterfactual framework clarifies what we want to estimate.\nG-computation, IPTW, and TMLE allow estimating causal effects without relying on regression coefficients."
  },
  {
    "objectID": "advanced/01-01-regression-vs-causal.html#next",
    "href": "advanced/01-01-regression-vs-causal.html#next",
    "title": "Chapter 1.1: Limitations of Standard Regression Analyses",
    "section": "Next",
    "text": "Next\nIn the next chapter, we’ll introduce the Causal Roadmap — a structured workflow for planning and executing causal analyses."
  },
  {
    "objectID": "workshop/index.html",
    "href": "workshop/index.html",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "This workshop introduces the Causal Roadmap and Targeted Maximum Likelihood Estimation (TMLE) through a motivating example: a post-market evaluation of cardiovascular safety among patients treated with denosumab (Prolia) vs. zoledronic acid for osteoporosis. The goal is to show how causal inference frameworks help produce transparent, reproducible real-world evidence.\nIn 2023, Amgen conducted a large-scale retrospective cohort study across two US claims databases, comparing denosumab with zoledronic acid. After adjusting for confounding using inverse probability weighting, the study found no increased risk of myocardial infarction or stroke up to 36 months of follow-up【204†source】. Here, we will reconstruct a simplified version of this question using the causal roadmap and a TMLE implementation.\n\n\n\n\n\n\nNote\n\n\n\nGoal: Learn how to define, identify, and estimate a causal effect with TMLE, using machine learning for nuisance function estimation.\n\n\n Figure 1. The Causal Roadmap, adapted for pharmacoepidemiologic safety analysis.\n\n\n\n(Joy) Make a bit more narrative versus bullet pointed\n(Andrew) Add more on the causal roadmap\n(Andrew) Include a Worked Interpretation Section (Not Just the computation)\nMaybe add Q&A’s throughout for those taking it asynchronously?\n(joy) add references (key roadmap, tmle, and superlearner papers- ask Andrew if you need any specific ones)\n\n\n\n\nThis tutorial provides a gentle introduction to the Causal Roadmap and its applications in pharmaco-epidemiologic research. It is designed for a broad audience, including learners from both academia and industry. We systematically walk through each step of the Causal Roadmap—from explicitly formulating a research question, to translating it into a formal causal estimand, to identifying and estimating that estimand from observed data, and finally to drawing valid inferences and interpreting results. Each step is illustrated using a working example from a pharmaco-epidemiology setting, accompanied by interactive, built-in code to facilitate hands-on learning. The structure and content of this tutorial follow, in an analytical way, the Introduction to Causal Inference and the causal Roadmap course (htp://www.ucbbiostat.com/) Petersen and Balzer.\n\n\n\nAdopting the Causal Roadmap in our approach to research in causal inference enables us to clearly state a scientific question and select an analtyic approach that matches the question being asked while ensuring systematic assessment of our ability/feasibility to answer this question from the data we observe (identifiability). Head to head analysis method comparison lets us select the best approach.\nWe will now formally introduce the Causal Roadmap but before let us go over some notation!\n\n\n\n\nA: Exposure/Treatement\n\nThe term treatment is often used in causal inference even with exposures that are not medical treatments. We shall use A=1 for exposed (treated) and A=0 for unexposed (untreated)\n\nY: outcome\nW: set of measured confounding variables\nU: set of unmeasured factors\n\\(\\mathbb{E}[Y|A=a]\\): expected outcome Y among those who experience exposure A=a in our population. This is a descriptive measure\n\\(\\mathbb{E}[Y_{a}]\\): expected counterfactual outcome \\(Y_a\\) when all experience exposure A=a in our population. This is a causal quantity. Generally \\(\\mathbb{E}[Y|A=a]\\) does not equal to \\(\\mathbb{E}[Y_{a}]\\) and this is the fundamental problem of causal inference\n\\(\\mathbb{E}[Y|A=a,W=w]\\): expected outcome Y among those who expereince exposure A=a and have covariates W=w, in our population. For example this can be the mean outcome among exposed men. These conditional expectations are often estimated using multivariable regression models.\n\\(\\mathbb{E}[\\mathbb{E}[Y|A=a,W=w]]\\):expected outcome Y among those who experience exposure A=a and have covariates W=w,averaged across covariate strata in the population. This is a marginal expectation.\n\n\n\n\nGiven our motivating example, suppose we are interested in understanding the causal impact of denosumab (Prolia) versus zoledronic acid on the risk of myocardial infarction or stroke among postmenopausal women with osteoporosis. In many applied settings, a common analytic approach would be to collect data on treatment assignment, the binary cardiovascular outcome, and a set of measured covariates. Because the outcome is binary, analysts often default to fitting a logistic regression model and interpreting the exponentiated coefficient on treatment as an estimate of the conditional odds ratio.\nHowever, this approach has an important limitation: it allows the statistical tool i.e. logistic regression to implicitly define the scientific question being answered. Rather than starting with a clearly articulated causal question and picking amongst the tools that allow us answer it, we risk answering a question that is convenient for the model, such as a conditional odds ratio, which may not align with the effect measure of true scientific or clinical interest.\nTo address this issue, we introduce the Causal Roadmap, a principled framework that emphasizes starting with a well-defined causal question and then selecting appropriate statistical tools to answer that question. By separating the scientific question from the estimation method, the Causal Roadmap helps ensure that our analyses are aligned with the causal effect we truly care about, rather than being driven by default modeling choices.\n\n\n\nNOTE Make below a numbered list, reference Dang et al 2022 JCTS paper (and make sure the steps line up)\nThe Causal Roadmap is a framework that provides a systematic process to move from a research question to estimation and interpretation which guides investigators on how to design and analyse their studies a priori. This framework has the following steps [@dang2022causal];\n\nStep 1a: Stating the research question and defining the causal estimand.\nStep 1b: Defining the causal model and parameter of interest\nStep 2: Linking the causal model to the observed data and defining the statistical model\nStep 3: Assessing identifiability: are the data and knowledge about their generation sufficient to answer the causal question of interest?\nStep 4: Defining the statistical estimand\nStep 5: Selecting and applying the estimator and an estimate of the sampling distribution (method of inference)\nStep 6: Specify the sensitivity analyses (interpreting findings)\nStep 7: Compare feasible study designs.\n\nWe shall now delve into each of these steps in details!\n\n\n\nThe first step of the Causal Roadmap is to clearly state the scientific question and define the corresponding causal estimand. A helpful way to do this is to explicitly state the hypothetical experiment that would unambiguously yield an estimate of the causal effect of interest.For example, consider the question: What is the effect of denosumab (Prolia) versus zoledronic acid on the risk of myocardial infarction or stroke among postmenopausal women with osteoporosis?\nOne way to formalize this question is to imagine a hypothetical experiment in which all eligible women are assigned to receive denosumab (Prolia), and to compare their myocardial infarction or stroke incidence to what would have been observed had all the same women instead received zoledronic. To sharply define this research question, it is important to be explicit about several components of the hypothetical experiment. These include the target population (e.g., postmenopausal women of a particular age range or geographic region), the exposure or intervention (including dosage, formulation, and frequency), the outcome (and the time window over which it is measured), and the intervention strategies under consideration.\nImportantly, many different hypothetical experiments may be of interest, even within the same clinical context. For instance, one could ask what the difference in myocardial infarction or stroke incidence would be if patients were initiated on denosumab (Prolia) only after reaching a certain cardiovascular risk threshold, compared to initiating denosumab (Prolia) regardless of baseline risk.\nAlternatively, one might consider a policy-relevant estimand, such as the difference in cardiovascular disease incidence if an additional 10% of patients received the intervention compared to if treatment uptake remained at its observed level. These examples highlight that there is substantial flexibility in how hypothetical experiments can be defined.\nOnce a causal question is clearly define, the causal estimand represents the question in mathematical terms must be defined. The ICH E9 (R1) [@ich2019estimand] and Target Trial Emulation [@hernan2016target] frameworks provide detailed guidelines of defining a causal question and estimand.\n\n\n\n\nAdding something about ICH E9 (R1) estimand framework and target trial emulation\n\n\n\n\nCausal modeling provides a formal way to encode our scientific knowledge, however limited it may be,about how variables relate to one another. By explicitly stating assumptions, causal models allow us to explore which variables affect each other, consider the potential role of unmeasured factors, and reason about the functional form of relationships among variables. In this tutorial, we focus on structural causal models and their corresponding causal graphs as introduced by Pearl (2000). We note, however, that this is only one of several available causal inference frameworks, each with its own strengths and areas of application.\n\nThe figure 1 below corresponds to a simple causal graph with corresponding structural casual model as follows;\n\n\\(W= f_w(U_w)\\)\n\\(A= f_A(W,U_A)\\)\n\\(Y = f_Y(W,A,U_Y)\\)\n\nWe make no assumptions on the background factors \\((U_w,U_A,U_Y)\\) or on the functional forms of functions \\((f_w,f_A,f_Y)\\)\n\n\n\n\n\n\n\n\n\n\n\nIf you believed no unmeasured confounding, a possible causal model and graph (figure 2) would be;\n\n\\(W= f_w(U_w)\\)\n\\(A= f_A(W,U_A)\\)\n\\(Y = f_Y(W,A,U_Y)\\)\n\nHere we assume that the background factors are all independent but still make no assumption on the functional forms of \\((f_w,f_A,f_Y)\\)\nHowever, it is important to note that wishing for something does not make it true.\n\n\n\n\n\n\n\n\n\n\n\nWe now define counterfactuals by intervening on the causal model. We can do this by setting the exposure to a specific level e.g A=1 for all units.\n\n\\(W= f_w(U_w)\\)\n\\(A= 1\\)\n\\(Y_1 = f_Y(W,1,U_Y)\\) where \\(Y_1\\) is the outcome if possibly-contrary to fact, the unit was exposed (A=1)\n\n\n\n\n\n\n\n\n\n\n\n\nAnalogously, we can intervene on the causal model by setting A=0\n\n\\(W= f_w(U_w)\\)\n\\(A= 0\\)\n\\(Y_0 = f_Y(W,0,U_Y)\\) where \\(Y_0\\) is the outcome if possibly-contrary to fact, the unit was exposed (A=0)\n\n\n\n\n\n\n\n\n\n\n\nWe use counterfactual outcomes to formally define causal parameters. For example, one common estimand is the average treatment effect (ATE), defined as the difference between the expected outcomes under two interventions i.e \\(\\mathbb{E}[Y_1]-\\mathbb{E}[Y_0]\\).When the outcome is binary, this contrast is often expressed as the causal risk difference (CRD) given by \\(\\mathbb{P}(Y_1=1)-\\mathbb{P}(Y_0=1)\\).\nImportantly, these are just two examples. Many other causal parameters can be defined depending on the scientific question of interest, the outcome type, and the decision context.\n\n\n\nWe denote the observed data by O=(W,A,Y), where W represents measured covariates, A is the exposure, and Y is the outcome. We assume that the causal model describes the data-generating process both under the existing conditions of the real world (the observed data) and under hypothetical interventions (the counterfactual world).This provides a link between the causal world and the observed world.\nAs a result, the causal model implies a statistical model, defined as the set of possible probability distributions for the observed data. The causal model may but often does not place any restrictions on the statistical model in which case the statistical model is non parametric.For example, a causal model may state that the exposure A,is generated as a function of covariates W, and unmeasured factors \\(U_A\\), written as A= \\(f_A(W,U_A)\\) but does not specify the functional form of \\(f_A\\).If substantive knowledge justifies a particular functional form, that information should be encoded explicitly in the causal model; otherwise, the model remains agnostic, leading to a flexible, nonparametric statistical model.\n\n\n\n\nThis step of the roadmap involves linking the causal effect to the parameter estimable from observed data. This requires some assumptions as follows:\n\nTemporality: exposure precedes the outcome. This is indicated by an arrow on the causal graph from A to Y\nConsistency: \\(Y_a\\)=Y where A=a. If an individual received treatment A=a, then their observed outcome Y is equal to their potential outcome under that treatment \\(Y_a\\).\nStability: We require no interference between units. This is indicated by the fact that the outcomes Y are only a function of each unit’s exposure A in the causal model and graph.\nRandomization:No unmeasured confounding such that \\(Y_a \\perp A \\mid W\\)\nPositivity: We require sufficient variability in exposure within confounder values i.e. \\(0 &lt; \\mathbb{P}(A=1|W)&lt;1\\).\n\n\n\n\n\nUnder these assumptions, we can express our causal target parameter—which is defined in terms of counterfactuals as a function of the observed data. Specifically i.e \\[\n    \\begin{aligned}\n    \\mathbb{E}(Y_a)\n      &= \\mathbb{E}\\big[ \\mathbb{E}(Y_a \\mid W) \\big] \\\\\n      &= \\mathbb{E}\\big[ \\mathbb{E}(Y_a \\mid A=a, W) \\big]  under \\ randomization\\\\\n      &= \\mathbb{E}\\big[ \\mathbb{E}(Y \\mid A=a, W) \\big] under \\ consistency\n    \\end{aligned}\n    \\]\nOf course, simply wishing these assumptions to hold does not make them true. Their plausibility must be carefully assessed using subject-matter knowledge, study design considerations, and an understanding of the data-generating process.\nWhen the assumptions are deemed reasonable, we obtain the G-computation identifiability result (Robins, 1986). In particular, the average treatment effect can be written as \\(\\mathbb{E}[Y_1-Y_0] = \\mathbb{E}\\big[\\mathbb{E}(Y\\mid A=1,W)-\\mathbb{E}(Y\\mid A=0,W)]\\) where the right-hand side is a function of the observed data distribution and therefore defines our statistical estimand. For a binary outcome, this corresponds to the marginal risk difference, $$. This is marginal because the outer expectation averages over the confounder distribution.\nFinally, it is important to consider what happens when one or more of the identifying assumptions may not hold—for example, if there is concern about unmeasured confounding or if the data structure does not clearly establish temporality. In such cases, possible options include:\n\nGiving up (rarely the most satisfying choice)\nChanging the research question, the exposure, the outcome or the target population\nProceeding to do the best job possible estimating the target parameter provided the question is still well-defined and interpretable and that we can still get as close as possible to the wished for causal parameter given the limitations in the data.\n\n\n\n\nAn estimator is an algorithm that, when applied to observed data, produces an estimate of the statistical parameter of interest. In our setting, this statistical parameter corresponds to the average treatment effect (ATE) when the identifiability assumptions hold. There are several classes of estimators that can be used to estimate this parameter. These include substitution estimators, such as parametric G-computation; propensity score–based estimators, including inverse probability of treatment weighting (IPTW) and matching; and doubly robust estimators, such as targeted maximum likelihood estimation (TMLE) and augmented IPTW (A-IPTW). Each of these approaches relies on different modeling strategies and assumptions, and each has its own strengths and limitations.\nBefore exploring these estimators in detail, it is helpful to pause and reflect on the approach that is most commonly used in practice. In many applied analyses, one would simply fit a logistic regression model for the binary outcome Y (e.g., risk of cardiovascular disease) as a function of the exposure (denosumab (Prolia) versus zoledronic acid) and baseline confounders W, and then interpret the resulting coefficient on the exposure as the effect of interest.\n\\[\n\\text{logit}\\big( \\mathbb{E}(Y \\mid A, W) \\big)\n    = \\beta_0 + \\beta_1 A + \\beta_2 W_1 + \\cdots + \\beta_{19} W_{18}.\n\\]\nThey would then exponentiate the coefficient on the exposure and interpret the result as an odds ratio, often described as a conditional effect, meaning the association between treatment and outcome while holding other covariates constant.The problem here is that our target parameter (ATE) does not equal \\(e^{\\beta_{1}}\\). Rather we are letting the estimation approach drive the question. Additionally, this estimation approach relies on the main terms logisitic regression being correct.\nEstimation strategies can be broadly categorized as parametric, nonparametric, or semiparametric, depending on the assumptions made about the relationships among the covariates W, the exposure A and the outcome Y.\nA parametric estimation approach assumes we know the relationship between covariates W, the exposure A and the outcome Y and have correctly specified this relation with a finite set of constants called “parameters”. For example, we can specify a regression with main terms for covariates and a few interactions or squared terms that we think are reasonable. If we had this knowledge, we should encode it in our causal model so we avoid introducing new assumptions during estimation. However, with parametric regression models, we are likely assuming we know more than we actually know.\nA non-parametric estimation approach acknowledges that we do not know the form of the relations beetween the covariates W, the exposure A and the outcome Y.For example, one could divide the data into all combinations of (A,W), calculate and average the stratum specific A and Y relations. Unfortunately, when the number of covariates is large or when covariates are continuous, this approach quickly becomes infeasible due to sparse or empty strata. This phenomenon is commonly referred to as the curse of dimensionality since the number of strata increases exponentially with dimension of W!\nIn a semi parametric estimation approach, we often “know nothing” (i.e. have a non-paramteric statistical model) but also need to smooth over regions of data with weak support during estimation.This is typically achieved using data-adaptive methods or machine learning. Rather than committing to a single algorithm such as stepwise regression, LOESS, or polynomial splines without a principled basis for choosing among them, we allow a broad class of candidate algorithms to compete and we select the best algorithm with cross-validation. This is the basis of Super Learner which we will focus on in this tutorial.\nRecall our statistical parameter is \\(\\mathbb{E}\\big[\\mathbb{E}(Y\\mid A=1,W)-\\mathbb{E}(Y\\mid A=0,W)\\big]\\) which equals the ATE if the identifiability results hold. We shall now discuss the following estimators and provide example implementations in R; - Simple substitution estimator a.k.a paramteric G-computation or parametric g-formula - Inverse probability of treatment weighting (IPTW) - Targeted maximum likelihood estimation (TMLE) with Super Learner\n\n\nTo build intuition for the simple substitution estimator, it is helpful to think of causal inference as a problem of missing information. For each individual, we observe the outcome under the observed exposure, but we are missing the outcome under the alternative exposure condition. In this approach, we use a parametric regression model to estimate the conditional mean outcome as a function of the exposure and measured confounders. This model is then used to predict each individual’s outcome under both exposure conditions. Finally, we average these predicted outcomes across individuals and compare them to obtain an estimate of the causal effect. We now describe this procedure step by step. First, we load the simulated dataset, CausalWorkshop.csv, and set the random seed to ensure reproducibility.\n\n\nCode\nlibrary(readr)\ndata &lt;-  read_csv(\"CausalWorkshop.csv\")\n\n\nRows: 200 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (6): W1, W2, W3, W4, A, Y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nhead(data)\n\n\n# A tibble: 6 × 6\n     W1    W2     W3     W4     A      Y\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     1 0.704  0.312  0.441     0 0.0467\n2     0 0.696  0.438  1.38      0 0.0771\n3     0 0.394 -0.538 -1.44      0 0.177 \n4     0 0.642  0.767  1.25      0 0.0330\n5     1 0.426 -0.203 -0.146     0 0.105 \n6     1 0.458  1.60   0.709     0 0.0228\n\n\nCode\ntail(data)\n\n\n# A tibble: 6 × 6\n     W1     W2     W3      W4     A       Y\n  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1     0 0.856   1.17   2.10       1 0.00278\n2     0 0.434   0.545 -0.238      0 0.0469 \n3     1 0.243  -1.80  -0.769      0 0.0675 \n4     0 0.629  -0.229  0.0750     1 0.109  \n5     0 0.0913 -0.100  0.761      0 0.117  \n6     1 0.543  -1.48  -0.794      0 0.0531 \n\n\nCode\ndim(data)\n\n\n[1] 200   6\n\n\nCode\nset.seed(1)\n\n\n\nWe the estimate the mean outcome Y as a function of exposure (treatment) A and measured confounders W. In this example we run a main terms logistic regression.\n\n\n\nCode\noutcome.regression &lt;- glm(Y ~ A + W1+W2+W3+W4, family='binomial', data=data)\n\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\n\nWe use estimates from 1 above to predict outcomes for each unit while “setting” the exposure to different values e.g. A=1 and A=0\n\n\n\nCode\ndata.A1 &lt;- data.A0 &lt;- data\ndata.A1$A &lt;- 1\ndata.A0$A &lt;- 0\ncolMeans(data.A1)\n\n\n         W1          W2          W3          W4           A           Y \n 0.52000000  0.51459003  0.02187934 -0.01958053  1.00000000  0.06244803 \n\n\nCode\ncolMeans(data.A0)\n\n\n         W1          W2          W3          W4           A           Y \n 0.52000000  0.51459003  0.02187934 -0.01958053  0.00000000  0.06244803 \n\n\nCode\npredict.outcome.A1 &lt;- predict( outcome.regression, newdata=data.A1, \n                               type='response')\npredict.outcome.A0 &lt;- predict(outcome.regression, newdata=data.A0, \n                              type='response')\n\n\n\nAverage predictions to estimate the marginal risks in the population under exposure and no exposure. To compare estimates, take the difference in means.\n\n\n\nCode\nmean(predict.outcome.A1)\n\n\n[1] 0.03877997\n\n\nCode\nmean(predict.outcome.A0)\n\n\n[1] 0.07258282\n\n\nCode\nSimple.Subs &lt;- mean(predict.outcome.A1 - predict.outcome.A0)\nSimple.Subs\n\n\n[1] -0.03380285\n\n\n\n\n\nThe intuition behind inverse probability of treatment weighting (IPTW) is to view confounding as a problem of biased sampling. In observational data, some exposure–covariate subgroups are overrepresented, while others are underrepresented, relative to what we would expect in a randomized trial.\nIPTW addresses this issue by reweighting the data to create a pseudo-population in which treatment assignment is independent of measured confounders. Weights are applied to up-weight under-represented units and down-weight over-represented units. Causal effects are then estimated by averaging and comparing the weighted outcomes across treatment groups. The algorithm for implementing the IPTW estimator is described below.\n\nEstimate the probability of being exposed/treated A as a function of measured confounders W:\\(\\mathbb{P}(A=1\\mid W)\\). This is often referred to as the propensity score. We can estimate the propensity score by running a main terms logistic regression as illustrated below\n\n\n\nCode\npscore.regression &lt;- glm(A~ W1+W2+W3+W4, family='binomial',\n                         data=data)\nsummary(pscore.regression)\n\n\n\nCall:\nglm(formula = A ~ W1 + W2 + W3 + W4, family = \"binomial\", data = data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -1.3445     0.3821  -3.519 0.000433 ***\nW1            0.4637     0.3130   1.482 0.138399    \nW2            0.5113     0.5629   0.908 0.363744    \nW3            0.4483     0.3208   1.397 0.162360    \nW4           -0.2676     0.3095  -0.865 0.387227    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 247.64  on 199  degrees of freedom\nResidual deviance: 241.99  on 195  degrees of freedom\nAIC: 251.99\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nWe then use estimates from 1 above to calculate exposed/treated weights: 1/\\(\\mathbb{P}(A=1\\mid W)\\) and unexposed/untreated weights:1/\\(\\mathbb{P}(A=0\\mid W)\\)\n\n\n\nCode\npredict.prob.A1 &lt;- predict(pscore.regression, type='response')\nsummary(predict.prob.A1)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.1555  0.2521  0.3034  0.3100  0.3658  0.5145 \n\n\nCode\npredict.prob.A0 &lt;- 1 - predict.prob.A1\nwt1 &lt;- as.numeric( data$A==1)/predict.prob.A1\nwt0 &lt;- as.numeric( data$A==0)/predict.prob.A0\nhead(data.frame(cbind(A=data$A, 1/predict.prob.A1, wt1, wt0)))\n\n\n  A       V2 wt1      wt0\n1 0 2.646982   0 1.607171\n2 0 4.197342   0 1.312760\n3 0 3.718918   0 1.367793\n4 0 3.735871   0 1.365514\n5 0 3.044577   0 1.489099\n6 0 2.128806   0 1.885892\n\n\n\nWe then apply the weights and average the weighted outcomes to estimate the marginal risks in the population under A=1 and A=0. To compare estimates, we take the difference in weighted means.\n\n\n\nCode\nmean(wt1*data$Y)\n\n\n[1] 0.03973564\n\n\nCode\nmean(wt0*data$Y)\n\n\n[1] 0.07234258\n\n\nCode\nIPW &lt;- mean(wt1*data$Y) - mean(wt0*data$Y)\nIPW\n\n\n[1] -0.03260694\n\n\nCode\nmean( (wt1-wt0)*data$Y)\n\n\n[1] -0.03260694\n\n\n\n\n\nTo build intuition for targeted maximum likelihood estimation (TMLE), we again view causal inference as a problem of missing information.As in simple substitution, the first step is to predict outcomes for all units under both the exposed and unexposed conditions.TMLE begins by fitting an initial outcome regression using a flexible estimation approach, such as Super Learner, to avoid relying on strong parametric assumptions when the true regression model is unknown. When reliable parametric knowledge is available, it can be incorporated directly.\nTMLE then incorporates information about the exposure–covariate relationship through a targeted update of the initial estimator.This targeting step is designed specifically to improve estimation of the causal parameter of interest. Because TMLE uses both the outcome model and the exposure model, it offers double robustness: the estimator remains consistent if at least one of these models is correctly specified. This estimator is also asymptotically linear and therefore we can obtain normal curve inference.Finally, causal effects are obtained by averaging and comparing the targeted predicted outcomes under exposure and no exposure.\n\n\nThis is a supervised machine learning algorithm that offers a flexible and data daptive approach to learn complex relationships from data. This algorithm uses cross-validation(sample splitting) to evaluate the performance of a library of candidate estimators.The library should be diverse including simple (e.g expert informed parametric regressions) and more adaptive algorithms (e.g penalized regressions, stepwise regression, adaptive splines) Performance is assessed using a specified loss function, such as the squared prediction error, which quantifies how well each algorithm predicts outcomes on new data.\nCross-validation allows us to compare algorithms based on how they perform on independent data. The data are partitioned into folds, and each algorithm is repeatedly trained on a subset of the data and evaluated on the held-out validation set. This process is rotated across folds, and the resulting risk estimates are averaged to obtain a single cross-validated performance measure for each algorithm. Rather than selecting only the single best-performing algorithm, Super Learner constructs an optimal weighted combination of algorithm-specific predictions. In the next section, we illustrate how to fit a Super Learner in practice.\n\n\nCode\nlibrary('SuperLearner')\nSL.library &lt;- c('SL.glm', 'SL.step.interaction', 'SL.gam'\n)\nSL.outcome.regression &lt;- suppressWarnings(SuperLearner(Y=data$Y, \n                                      X=subset(data, select=-Y),\n                                      SL.library=SL.library, \n                                      family='binomial'))\nSL.outcome.regression\n\n\n\nCall:  \nSuperLearner(Y = data$Y, X = subset(data, select = -Y), family = \"binomial\",  \n    SL.library = SL.library) \n\n                               Risk      Coef\nSL.glm_All              0.002745489 0.0000000\nSL.step.interaction_All 0.001407506 0.1134166\nSL.gam_All              0.001164327 0.8865834\n\n\nCode\nSL.predict.outcome &lt;- predict(SL.outcome.regression, \n                              newdata=subset(data, select=-Y))$pred\nhead(SL.predict.outcome)\n\n\n           [,1]\n[1,] 0.06057937\n[2,] 0.03497212\n[3,] 0.09365564\n[4,] 0.02889967\n[5,] 0.08963054\n[6,] 0.01211914\n\n\n\n\n\nWe could use Super Learner to predict the outcomes for each unit while “setting” the exposure to different levels and then average and contrast the predictions.\n\n\nCode\nSL.predict.outcome.A1 &lt;- predict(SL.outcome.regression, \n                                 newdata=subset(data.A1, select=-Y))$pred\nhead(SL.predict.outcome.A1)\n\n\n            [,1]\n[1,] 0.037893675\n[2,] 0.021656007\n[3,] 0.059409745\n[4,] 0.017819346\n[5,] 0.056743415\n[6,] 0.007417174\n\n\nCode\nSL.predict.outcome.A0 &lt;- predict(SL.outcome.regression, newdata=subset(data.A0, select=-Y))$pred\n\n# simple subst estimator\nmean(SL.predict.outcome.A1) - mean(SL.predict.outcome.A0)\n\n\n[1] -0.02523567\n\n\nHowever, Super Learner is focused on \\(\\mathbb{E}(Y\\mid A,W)\\) and not our parameter of interest. It makes the wrong bias-variance trade-off and specifically incurs too much bias.There is also no reliable way to obtain statistical inference (i.e create 95% confidence intervals)\n\n\n\nTargeting step uses information in the estimated propensity score \\(\\mathbb{P}(A=1\\mid W)\\) to update the initial (Super Learner) estimator of \\(\\mathbb{E}(Y\\mid A,W)\\). It involves running a univariate regression of the outcome Y on a clever covariate with offset the initial estimator. Why “clever”? It ensures that the targeting step moves the initial estimator in a direction that removes bias. The estimated coefficient from this regression is then used to update the initial predicted outcomes under both the exposed and unexposed conditions.\n\n\n\n\nUse Super Learner to estimate the propensity score \\(\\mathbb{P}(A=1\\mid W)\\)\n\n\n\nCode\nSL.pscore &lt;- SuperLearner(Y=data$A, X=subset(data, select=-c(A,Y)),\n                          SL.library=SL.library, family='binomial')\nSL.pscore\n\n\n\nCall:  \nSuperLearner(Y = data$A, X = subset(data, select = -c(A, Y)), family = \"binomial\",  \n    SL.library = SL.library) \n\n                             Risk      Coef\nSL.glm_All              0.2193296 0.0000000\nSL.step.interaction_All 0.2073331 0.2986055\nSL.gam_All              0.2048874 0.7013945\n\n\nCode\nSL.predict.prob.A1 &lt;- SL.pscore$SL.predict\nsummary(SL.predict.prob.A1 - predict(SL.pscore, newdata=subset(data,select=-c(A,Y)))$pred)\n\n\n       V1   \n Min.   :0  \n 1st Qu.:0  \n Median :0  \n Mean   :0  \n 3rd Qu.:0  \n Max.   :0  \n\n\nCode\nsummary(SL.predict.prob.A1)\n\n\n       V1        \n Min.   :0.1560  \n 1st Qu.:0.2378  \n Median :0.2748  \n Mean   :0.3100  \n 3rd Qu.:0.3501  \n Max.   :0.9270  \n\n\nCode\nSL.predict.prob.A0 &lt;- 1 - SL.predict.prob.A1\n\n\nNote: As you run this code you might encounter a warning “non-integer #successes in a binomial glm!”. This simply means that our outcome Y is not binary much as it’s bounded between 0 and 1. This is okay and can be ignored.\n\nCalculate the “clever covariate”\n\n\\[H(A,W)= \\frac{\\mathbb{I}(A=1)}{\\mathbb{P}(A=1\\mid W)}- \\frac{\\mathbb{I}(A=0)}{\\mathbb{P}(A=0\\mid W)}\\]\nHere’s code to evaluate the “clever covariate”\n\n\nCode\nH.AW &lt;- (data$A==1)/SL.predict.prob.A1 - (data$A==0)/SL.predict.prob.A0\nsummary(H.AW)\n\n\n       V1           \n Min.   :-2.186965  \n 1st Qu.:-1.407155  \n Median :-1.301617  \n Mean   : 0.006879  \n 3rd Qu.: 1.988451  \n Max.   : 5.879362  \n\n\nCode\nH.1W &lt;- 1/SL.predict.prob.A1\nH.0W &lt;- -1/SL.predict.prob.A0\ntail(data.frame(A=data$A, H.AW, H.1W, H.0W))\n\n\n    A      H.AW     H.1W      H.0W\n195 1  2.475907 2.475907 -1.677550\n196 0 -1.394124 3.537274 -1.394124\n197 0 -1.326598 4.061867 -1.326598\n198 1  5.371782 5.371782 -1.228740\n199 0 -1.184825 6.410513 -1.184825\n200 0 -1.339610 3.944556 -1.339610\n\n\n3.Run logistic regression of the outcome on this covariate using logit of the initial estimator \\(\\mathbb{E}(Y\\mid A,W)\\) as offset where logit(x)= log[x/(1-x)]\n\n\nCode\nlogitUpdate &lt;- glm( data$Y ~ -1 +offset( qlogis(SL.predict.outcome)) +\n                      H.AW, family='binomial')\n\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\nCode\nepsilon &lt;- logitUpdate$coef\nepsilon\n\n\n       H.AW \n0.004130237 \n\n\n\nPlug in the estimated coefficient \\(\\epsilon\\) to yield our targeted estimator \\(\\mathbb{E^*}(Y\\mid A,W)\\) and use the targeted estimator \\(\\mathbb{E^*}(Y\\mid A,W)\\) to predict outcomes for all under A=1 and A=0\n\n\n\nCode\ntarget.predict.outcome.A1 &lt;- plogis( qlogis(SL.predict.outcome.A1)+\n                                       epsilon*H.1W)\ntarget.predict.outcome.A0 &lt;- plogis( qlogis(SL.predict.outcome.A0)+\n                                      epsilon*H.0W)\n\n\n\nAverage the predictions to estimate the marginal risks in the population under exposure and no exposure. Compare the estimates by taking the difference.\n\n\n\nCode\nTMLE &lt;- mean( target.predict.outcome.A1 - target.predict.outcome.A0)\nTMLE\n\n\n[1] -0.02419038\n\n\n\n\n\n\nWe have now discussed three estimators and walked through their implementation. We next summarize the key properties of each estimator and highlight important considerations when choosing among them;\n\nSimple substitution estimator\n\nThis relies on consistently estimating the mean outcome \\(\\mathbb{E^*}(Y\\mid A,W)\\). In settings where there is strong substantive knowledge about the relationship between the outcome and the exposure–covariate set, a correctly specified parametric regression model may perform well. However, in many applications our knowledge of this relationship is limited. In such cases, assuming an incorrect parametric form can lead to biased estimates and misleading inference\n\nIPTW\n\nRelies on consistently estimating the propensity score \\(\\mathbb{P}(A=1\\mid W)\\). While sometimes we have a lot of knowledge about how the exposure was assigned, other times our knowledge is limited and assuming a parametric regression model can result in bias and misleading inference. This estimator is also unstable under positivity violations. When covariate groups only have a few exposed or unexposed observations, weights can blow up!!. If some strata contain no exposed or no unexposed observations, the estimator may appear numerically stable, but it will generally be biased and its variance underestimated.\n\nTMLE\n\nThis estimator is doubly robust i.e. yields a consistent estimate if either the conditional mean \\(\\mathbb{E^*}(Y\\mid A,W)\\) or the propensity score \\(\\mathbb{P}(A=1\\mid W)\\) is consistently estimated. We get two chances to get it right !!TMLE is also semiparametrically efficient, achieving the lowest possible asymptotic variance among a broad class of estimators when both models are estimated at sufficient rates. Importantly, TMLE is supported by formal theory that allows for valid statistical inference under mild conditions even when machine learning methods are used.Being a substitution estimator (plug-in), it is robust under positivity violations,strong confounding and rare outcomes. In addition, there is well-developed software available for implementation, including packages such as ltmle,lmptp packages in R.\n\n\nAfter estimating the parameter of interest, the next step is to quantify statistical uncertainty.Doing so requires an estimate of the sampling distribution.We can consider doing a non-parametric bootstrap where we re-sample the observed data with replacement, apply the entire estimation process (including machine learning algorithms) to the re-sampled data, repeat X times and estimate the variance with the bootstrapped point estimates. Alternatively, we can use influence curve based inference asymptotic linearity to directly estimate standard errors. We shall not discuss this here but this form of inference is available in the R packages.\nWith this, we conclude the estimation component of the analysis. Having selected an estimator and obtained an estimate of our parameter of interest and inference, we now return to the broader Causal Roadmap to consider interpretation, diagnostics, and sensitivity to assumptions\n\n\n\n\n\n\n\n\nThe final step of the Causal Roadmap is to interpret the findings. At this stage, we evaluate whether and to what extent the underlying assumptions have been met in order to determine the strength of interpretation.\nFindings support a statistical interpretation if (1) the statistical estimator has negligible bias and its variance is well estimated\nFindings support a causal interpretation if 1 holds and (2) if the non testable identifiability assumptions hold.\nCan be interpreted as if implemented in the real-world if 1 and 2 hold and if (3) the intervention is feasible and applicable to the real world population.\nFindings can be interpreted as if we had emulated a randomized trial if 1-3 hold and the exposure could have been randomized to that population.\nIf there are concerns about causal assumptions (e.g. temporal odering is unclear, unmeasured confounding), the results can be interpreted as associational. In this case the estimand, \\(\\mathbb{E}\\big[\\mathbb{E}(Y\\mid A=1,W)-\\mathbb{E}(Y\\mid A=0,W)]\\) can be interpreted as;\n\nThe marginal difference in the expected outcome associated with the exposure, after accounting for the measured confounders\nThe difference in the mean outcome between persons exposed versus unexposed but with the same values of the adjustment covariates (averaged with respect to the distribution of those covariates in the population).e.g The difference in the risk of cardiovascular disease with intervention A vs B is X, accounting for region,age,sex,SES etc\nAlternatively one can report that this is as close as we can get to the causal effet of A on Y given the limitations of the data detailing all limitations and including a causal graph to empower the reader to assess the plausibility of assumptions.\n\nIf the authors believe causal assumptions are met, the parameter can be interpreted as the population average treatment effect \\(\\mathbb{E}\\big[Y_1-Y_0\\big]\\).\n\nIn words, this would be the difference in the expected outcome if everyone were exposed compared if everyone were unexposed. For example, there would be an X difference in the risk of cardiovascular disease if all patients in the population received intervention A vs B.\n\n\n\n\n\n\n\n\nTMLE with Super Learner is a powerful approach, but it should be viewed as one tool within a broader toolbox. No matter how sophisticated the estimator, careful thinking throughout the earlier steps of the Causal Roadmap remains essential.\nIt is especially important to formally derive adjustment sets and clearly define the statistical parameter before estimation. Failure to do so can lead to errors of causal model neglect, where the quantity being estimated differs meaningfully from any interpretable causal effect.\nDoubly robust estimators (e.g TMLE or A-IPW) can incorporate machine learning while maintaining basis for valid statistical inference. This helps us avoid errors of “statistical model neglect”, occurring when relying on unsubstantiated (parametric) assumptions during estimation.However, these benefits depend on careful implementation. In particular, the Super Learner library must be specified thoughtfully: diversity among candidate learners is crucial, and overfitting should be avoided through proper sample splitting and cross-validation.\nIn practice, positivity violations can and do occur. Poor support for certain exposure–covariate combinations may lead to bias and underestimated variance. Potential strategies for addressing these issues include using substitution estimators such as G-computation or TMLE, modifying the targeting step in TMLE (e.g., via weighted regression), employing robust variance estimators (e.g., Tran et al., 2018; Benkeser et al., 2017), or bounding estimated propensity scores away from zero and one.\nFinally, simulation studies play a critical role in responsible causal analysis. By simulating data that mimic key features of the observed setting—such as sample size, confounding structure, missingness mechanisms, sparsity, dependence, or practical positivity challenges—we can better understand estimator behavior and use these insights to guide analytic decisions.\n\n\n\nCongratulations! You have successfully worked through this tutorial and implemented three core estimators for causal inference: the simple substitution estimator, inverse probability of treatment weighting (IPTW), and targeted maximum likelihood estimation (TMLE). Along the way, you have built both intuitive and technical understanding of how these estimators operate, what assumptions they rely on, and how they behave in practice.\nYou have also completed a high-speed tour of the Causal Roadmap, and by now its strengths should be apparent. The Roadmap emphasizes the importance of starting with clearly defined scientific questions and ensures that the parameters we estimate are aligned with those questions. It makes explicit the assumptions required to interpret estimates as causal effects.When assumptions are not met, the unmet assumptions provide clear guidance on how future research must be improved to increase the potential of causal interpretation.Working in this framework can improve interpretability and relevance of epidemiologic research.\nAlthough this tutorial focused on estimating the average treatment effect, the same framework naturally extends to a wide range of causal questions and data structures, including effects among treated or untreated populations, mediation analyses, longitudinal interventions, and dynamic treatment regimes.\nFor readers interested in exploring these more advanced settings, we provide links to additional resources below."
  },
  {
    "objectID": "workshop/index.html#to-add",
    "href": "workshop/index.html#to-add",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "(Joy) Make a bit more narrative versus bullet pointed\n(Andrew) Add more on the causal roadmap\n(Andrew) Include a Worked Interpretation Section (Not Just the computation)\nMaybe add Q&A’s throughout for those taking it asynchronously?\n(joy) add references (key roadmap, tmle, and superlearner papers- ask Andrew if you need any specific ones)"
  },
  {
    "objectID": "workshop/index.html#introduction",
    "href": "workshop/index.html#introduction",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "This tutorial provides a gentle introduction to the Causal Roadmap and its applications in pharmaco-epidemiologic research. It is designed for a broad audience, including learners from both academia and industry. We systematically walk through each step of the Causal Roadmap—from explicitly formulating a research question, to translating it into a formal causal estimand, to identifying and estimating that estimand from observed data, and finally to drawing valid inferences and interpreting results. Each step is illustrated using a working example from a pharmaco-epidemiology setting, accompanied by interactive, built-in code to facilitate hands-on learning. The structure and content of this tutorial follow, in an analytical way, the Introduction to Causal Inference and the causal Roadmap course (htp://www.ucbbiostat.com/) Petersen and Balzer."
  },
  {
    "objectID": "workshop/index.html#why-venture-down-a-new-path",
    "href": "workshop/index.html#why-venture-down-a-new-path",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "Adopting the Causal Roadmap in our approach to research in causal inference enables us to clearly state a scientific question and select an analtyic approach that matches the question being asked while ensuring systematic assessment of our ability/feasibility to answer this question from the data we observe (identifiability). Head to head analysis method comparison lets us select the best approach.\nWe will now formally introduce the Causal Roadmap but before let us go over some notation!"
  },
  {
    "objectID": "workshop/index.html#notation",
    "href": "workshop/index.html#notation",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "A: Exposure/Treatement\n\nThe term treatment is often used in causal inference even with exposures that are not medical treatments. We shall use A=1 for exposed (treated) and A=0 for unexposed (untreated)\n\nY: outcome\nW: set of measured confounding variables\nU: set of unmeasured factors\n\\(\\mathbb{E}[Y|A=a]\\): expected outcome Y among those who experience exposure A=a in our population. This is a descriptive measure\n\\(\\mathbb{E}[Y_{a}]\\): expected counterfactual outcome \\(Y_a\\) when all experience exposure A=a in our population. This is a causal quantity. Generally \\(\\mathbb{E}[Y|A=a]\\) does not equal to \\(\\mathbb{E}[Y_{a}]\\) and this is the fundamental problem of causal inference\n\\(\\mathbb{E}[Y|A=a,W=w]\\): expected outcome Y among those who expereince exposure A=a and have covariates W=w, in our population. For example this can be the mean outcome among exposed men. These conditional expectations are often estimated using multivariable regression models.\n\\(\\mathbb{E}[\\mathbb{E}[Y|A=a,W=w]]\\):expected outcome Y among those who experience exposure A=a and have covariates W=w,averaged across covariate strata in the population. This is a marginal expectation."
  },
  {
    "objectID": "workshop/index.html#motivation",
    "href": "workshop/index.html#motivation",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "Given our motivating example, suppose we are interested in understanding the causal impact of denosumab (Prolia) versus zoledronic acid on the risk of myocardial infarction or stroke among postmenopausal women with osteoporosis. In many applied settings, a common analytic approach would be to collect data on treatment assignment, the binary cardiovascular outcome, and a set of measured covariates. Because the outcome is binary, analysts often default to fitting a logistic regression model and interpreting the exponentiated coefficient on treatment as an estimate of the conditional odds ratio.\nHowever, this approach has an important limitation: it allows the statistical tool i.e. logistic regression to implicitly define the scientific question being answered. Rather than starting with a clearly articulated causal question and picking amongst the tools that allow us answer it, we risk answering a question that is convenient for the model, such as a conditional odds ratio, which may not align with the effect measure of true scientific or clinical interest.\nTo address this issue, we introduce the Causal Roadmap, a principled framework that emphasizes starting with a well-defined causal question and then selecting appropriate statistical tools to answer that question. By separating the scientific question from the estimation method, the Causal Roadmap helps ensure that our analyses are aligned with the causal effect we truly care about, rather than being driven by default modeling choices."
  },
  {
    "objectID": "workshop/index.html#the-causal-roadmap",
    "href": "workshop/index.html#the-causal-roadmap",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "NOTE Make below a numbered list, reference Dang et al 2022 JCTS paper (and make sure the steps line up)\nThe Causal Roadmap is a framework that provides a systematic process to move from a research question to estimation and interpretation which guides investigators on how to design and analyse their studies a priori. This framework has the following steps [@dang2022causal];\n\nStep 1a: Stating the research question and defining the causal estimand.\nStep 1b: Defining the causal model and parameter of interest\nStep 2: Linking the causal model to the observed data and defining the statistical model\nStep 3: Assessing identifiability: are the data and knowledge about their generation sufficient to answer the causal question of interest?\nStep 4: Defining the statistical estimand\nStep 5: Selecting and applying the estimator and an estimate of the sampling distribution (method of inference)\nStep 6: Specify the sensitivity analyses (interpreting findings)\nStep 7: Compare feasible study designs.\n\nWe shall now delve into each of these steps in details!"
  },
  {
    "objectID": "workshop/index.html#step-0-state-the-question",
    "href": "workshop/index.html#step-0-state-the-question",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "This is the very first step of the roadmap. A helpful way to be clear about the scientific question is to explicitly state the experiment that would unambiguously yield estimates of the causal effect of interest.\nFor example: What is the effect of a certain medication on the incidence of cardiovascular disease among postmenopausal women who initiated Drug A vs Drug B in the United States?\nWe can consider a hypothetical experiment where we ask what would be the the difference in CVD incidence if patients received the intervention drug A vs if all patients received the control drug B (or standard of care).\nTo sharply frame our research question, we want to be more specific about;\n\nThe target population (What age group? where?)\nThe exposure (What dosage? Frequency?)\nThe outcome (over what timeframe?)\nWays to change the exposure and their plausibility\n\nOther interesting hypothetical experiments could include:\n\nWhat would be the difference in CVD incidence if patients were initiated on drug A once they reached a certain risk threshold vs if all patients are initiated on Drug A regardless of their risk profile?\nWhat would be the difference in CVD incidence if an additional 10% of patients received the intervention compared to if the intervention uptake remained as observed?\n\nWe note that there is massive flexibility in how we can define our desired hypothetical experiments."
  },
  {
    "objectID": "workshop/index.html#step-1-define-the-causal-model",
    "href": "workshop/index.html#step-1-define-the-causal-model",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "Causal modeling formalizes our knowledge however limited. We are able to explore which variables affect each other, examine the role of unmeasured factors and the functional form of the relationships between variables.\nIn this tutorial, we shall focus on structural causal models and corresponding causal graphs (Pearl 2000). However, we do note that their are many other causal frameworks.\nThe figure 1 below corresponds to a simple causal graph with corresponding structural casual model as follows;\n\n\\(W= f_w(U_w)\\)\n\\(A= f_A(W,U_A)\\)\n\\(Y = f_Y(W,A,U_Y)\\)\n\nWe make no assumptions on the background factors \\((U_w,U_A,U_Y)\\) or on the functional forms of functions \\((f_w,f_A,f_Y)\\)\n\n\n\n\n\n\n\n\n\n\n\nIf you believed no unmeasured confounding, a possible causal model and graph (figure 2) would be;\n\n\\(W= f_w(U_w)\\)\n\\(A= f_A(W,U_A)\\)\n\\(Y = f_Y(W,A,U_Y)\\)\n\nHere we assume that the background factors are all independent but still make no assumption on the functional forms of \\((f_w,f_A,f_Y)\\)\nHowever, it is important to note that wishing for something does not make it true."
  },
  {
    "objectID": "workshop/index.html#step-2-define-the-causal-parameter-of-interest",
    "href": "workshop/index.html#step-2-define-the-causal-parameter-of-interest",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "We now define counterfactuals by intervening on the causal model. We can do this by setting the exposure to a specific level e.g A=1 for all units.\n\n\\(W= f_w(U_w)\\)\n\\(A= 1\\)\n\\(Y_1 = f_Y(W,1,U_Y)\\) where \\(Y_1\\) is the outcome if possibly-contrary to fact, the unit was exposed (A=1)\n\n\n\n\n\n\n\n\n\n\n\n\nAnalogously, we can intervene on the causal model by setting A=0\n\n\\(W= f_w(U_w)\\)\n\\(A= 0\\)\n\\(Y_0 = f_Y(W,0,U_Y)\\) where \\(Y_0\\) is the outcome if possibly-contrary to fact, the unit was exposed (A=0)\n\n\n\n\n\n\n\n\n\n\n\n\nWe use counterfactuals to define the causal parameter;\n\nFor example, the difference between the expected counterfactual outcomes under these two interventions i.e \\(\\mathbb{E}[Y_1]-\\mathbb{E}[Y_0]\\) which is known as the average treatment effect(ATE)\nFor a binary outcome, we define the causal risk difference (CRD) as \\(\\mathbb{P}(Y_1=1)-\\mathbb{P}(Y_0=1)\\).\n\nMany other causal parameters are possible!!"
  },
  {
    "objectID": "workshop/index.html#step-3-link-to-observed-data",
    "href": "workshop/index.html#step-3-link-to-observed-data",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "Observed data are denoted O=(W,A,Y) where W reprensents measured covariates, A is the exposure and Y is the outcome.\nWe assume that the causal model provides a description of our study under existing conditions(i.e. the real world) and under interventions (i.e.the counterfactual world)\nThis provides a link between the causal world and the real (observed) world and therefore our causal model implies our statistical model which is the set of possible distributions of observed data.\nThe causal model may but often does not place any restrictions on the statistical model in which case the statistical model is non parametric.\nFor example our model says that A is a function of W and \\(U_A\\) but does not specify the form of that function: A= \\(f_A(W,U_A)\\). However, if we know the form, that should be specified in the causal model."
  },
  {
    "objectID": "workshop/index.html#step-4-assess-identifiablity",
    "href": "workshop/index.html#step-4-assess-identifiablity",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "This process involves linking the causal effect to the parameter estimable from observed data. This requires some assumptions as follows:\n\nTemporality: exposure precedes the outcome. This is indicated by an arrow on the causal graph from A to Y\nConsistency: \\(Y_a\\)=Y where A=a. If an individual received treatment A=a, then their observed outcome Y is equal to their potential outcome under that treatment \\(Y_a\\).\nStability: We require no interference between units. This is indicated by the fact that the outcomes Y are only a function of each unit’s exposure A in the causal model and graph.\nRandomization:No unmeasured confounding such that \\(Y_a \\perp A \\mid W\\)\nPositivity: We require sufficient variability in exposure within confounder values i.e. \\(0 &lt; \\mathbb{P}(A=1|W)&lt;1\\).\n\nWith these assumptions, we can express our causal target parameter which is a function of counterfactuals in terms of our observed data i.e \\[\n\\begin{aligned}\n\\mathbb{E}(Y_a)\n  &= \\mathbb{E}\\big[ \\mathbb{E}(Y_a \\mid W) \\big] \\\\\n  &= \\mathbb{E}\\big[ \\mathbb{E}(Y_a \\mid A=a, W) \\big]  under \\ randomization\\\\\n  &= \\mathbb{E}\\big[ \\mathbb{E}(Y \\mid A=a, W) \\big] under \\ consistency\n\\end{aligned}\n\\]\nAgain wishing for something does not make it true.\nUnder the above assumptions we can have the G-computation identifiability result (Robins 1986) as\n\n\\(\\mathbb{E}[Y_1-Y_0] = \\mathbb{E}\\big[\\mathbb{E}(Y\\mid A=1,W)-\\mathbb{E}(Y\\mid A=0,W)]\\) where the right handside is our parameter of interest a.k.a our statistical estimand.\nFor a binary outcome, we have the marginal risk difference as $. This is marginal because the outer expectation averages over the confounder distribution.\n\nWhat if the assumptions are not all met? For example one might be worried about unmeasured confounders or that the data structure does not assure temporality.Possible options include;\n\nGiving up!!\nChanging the research question, the exposure, the outcome or the target population\nProceeding to do the best job possible estimating the target parameter provided the question is still well-defined and interpretable and that we can still get as close as possible to the wished for causal parameter given the limitations in the data."
  },
  {
    "objectID": "workshop/index.html#step-5-choose-and-apply-the-estimator",
    "href": "workshop/index.html#step-5-choose-and-apply-the-estimator",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "An estimator is an algorithm that, when applied to observed data, produces an estimate of the statistical parameter of interest. In our setting, this statistical parameter corresponds to the average treatment effect (ATE) when the identifiability assumptions hold. There are several classes of estimators that can be used to estimate this parameter. These include substitution estimators, such as parametric G-computation; propensity score–based estimators, including inverse probability of treatment weighting (IPTW) and matching; and doubly robust estimators, such as targeted maximum likelihood estimation (TMLE) and augmented IPTW (A-IPTW). Each of these approaches relies on different modeling strategies and assumptions, and each has its own strengths and limitations.\nBefore exploring these estimators in detail, it is helpful to pause and reflect on the approach that is most commonly used in practice. In many applied analyses, one would simply fit a logistic regression model for the binary outcome Y (e.g., risk of cardiovascular disease) as a function of the exposure (denosumab (Prolia) versus zoledronic acid) and baseline confounders W, and then interpret the resulting coefficient on the exposure as the effect of interest.\n\\[\n\\text{logit}\\big( \\mathbb{E}(Y \\mid A, W) \\big)\n    = \\beta_0 + \\beta_1 A + \\beta_2 W_1 + \\cdots + \\beta_{19} W_{18}.\n\\]\nThey would then exponentiate the coefficient on the exposure and interpret the result as an odds ratio, often described as a conditional effect, meaning the association between treatment and outcome while holding other covariates constant.The problem here is that our target parameter (ATE) does not equal \\(e^{\\beta_{1}}\\). Rather we are letting the estimation approach drive the question. Additionally, this estimation approach relies on the main terms logisitic regression being correct.\nEstimation strategies can be broadly categorized as parametric, nonparametric, or semiparametric, depending on the assumptions made about the relationships among the covariates W, the exposure A and the outcome Y.\nA parametric estimation approach assumes we know the relationship between covariates W, the exposure A and the outcome Y and have correctly specified this relation with a finite set of constants called “parameters”. For example, we can specify a regression with main terms for covariates and a few interactions or squared terms that we think are reasonable. If we had this knowledge, we should encode it in our causal model so we avoid introducing new assumptions during estimation. However, with parametric regression models, we are likely assuming we know more than we actually know.\nA non-parametric estimation approach acknowledges that we do not know the form of the relations beetween the covariates W, the exposure A and the outcome Y.For example, one could divide the data into all combinations of (A,W), calculate and average the stratum specific A and Y relations. Unfortunately, when the number of covariates is large or when covariates are continuous, this approach quickly becomes infeasible due to sparse or empty strata. This phenomenon is commonly referred to as the curse of dimensionality since the number of strata increases exponentially with dimension of W!\nIn a semi parametric estimation approach, we often “know nothing” (i.e. have a non-paramteric statistical model) but also need to smooth over regions of data with weak support during estimation.This is typically achieved using data-adaptive methods or machine learning. Rather than committing to a single algorithm such as stepwise regression, LOESS, or polynomial splines without a principled basis for choosing among them, we allow a broad class of candidate algorithms to compete and we select the best algorithm with cross-validation. This is the basis of Super Learner which we will focus on in this tutorial.\nRecall our statistical parameter is \\(\\mathbb{E}\\big[\\mathbb{E}(Y\\mid A=1,W)-\\mathbb{E}(Y\\mid A=0,W)\\big]\\) which equals the ATE if the identifiability results hold. We shall now discuss the following estimators and provide example implementations in R; - Simple substitution estimator a.k.a paramteric G-computation or parametric g-formula - Inverse probability of treatment weighting (IPTW) - Targeted maximum likelihood estimation (TMLE) with Super Learner\n\n\nTo build intuition for the simple substitution estimator, it is helpful to think of causal inference as a problem of missing information. For each individual, we observe the outcome under the observed exposure, but we are missing the outcome under the alternative exposure condition. In this approach, we use a parametric regression model to estimate the conditional mean outcome as a function of the exposure and measured confounders. This model is then used to predict each individual’s outcome under both exposure conditions. Finally, we average these predicted outcomes across individuals and compare them to obtain an estimate of the causal effect. We now describe this procedure step by step. First, we load the simulated dataset, CausalWorkshop.csv, and set the random seed to ensure reproducibility.\n\n\nCode\nlibrary(readr)\ndata &lt;-  read_csv(\"CausalWorkshop.csv\")\n\n\nRows: 200 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (6): W1, W2, W3, W4, A, Y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nhead(data)\n\n\n# A tibble: 6 × 6\n     W1    W2     W3     W4     A      Y\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     1 0.704  0.312  0.441     0 0.0467\n2     0 0.696  0.438  1.38      0 0.0771\n3     0 0.394 -0.538 -1.44      0 0.177 \n4     0 0.642  0.767  1.25      0 0.0330\n5     1 0.426 -0.203 -0.146     0 0.105 \n6     1 0.458  1.60   0.709     0 0.0228\n\n\nCode\ntail(data)\n\n\n# A tibble: 6 × 6\n     W1     W2     W3      W4     A       Y\n  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1     0 0.856   1.17   2.10       1 0.00278\n2     0 0.434   0.545 -0.238      0 0.0469 \n3     1 0.243  -1.80  -0.769      0 0.0675 \n4     0 0.629  -0.229  0.0750     1 0.109  \n5     0 0.0913 -0.100  0.761      0 0.117  \n6     1 0.543  -1.48  -0.794      0 0.0531 \n\n\nCode\ndim(data)\n\n\n[1] 200   6\n\n\nCode\nset.seed(1)\n\n\n\nWe the estimate the mean outcome Y as a function of exposure (treatment) A and measured confounders W. In this example we run a main terms logistic regression.\n\n\n\nCode\noutcome.regression &lt;- glm(Y ~ A + W1+W2+W3+W4, family='binomial', data=data)\n\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\n\nWe use estimates from 1 above to predict outcomes for each unit while “setting” the exposure to different values e.g. A=1 and A=0\n\n\n\nCode\ndata.A1 &lt;- data.A0 &lt;- data\ndata.A1$A &lt;- 1\ndata.A0$A &lt;- 0\ncolMeans(data.A1)\n\n\n         W1          W2          W3          W4           A           Y \n 0.52000000  0.51459003  0.02187934 -0.01958053  1.00000000  0.06244803 \n\n\nCode\ncolMeans(data.A0)\n\n\n         W1          W2          W3          W4           A           Y \n 0.52000000  0.51459003  0.02187934 -0.01958053  0.00000000  0.06244803 \n\n\nCode\npredict.outcome.A1 &lt;- predict( outcome.regression, newdata=data.A1, \n                               type='response')\npredict.outcome.A0 &lt;- predict(outcome.regression, newdata=data.A0, \n                              type='response')\n\n\n\nAverage predictions to estimate the marginal risks in the population under exposure and no exposure. To compare estimates, take the difference in means.\n\n\n\nCode\nmean(predict.outcome.A1)\n\n\n[1] 0.03877997\n\n\nCode\nmean(predict.outcome.A0)\n\n\n[1] 0.07258282\n\n\nCode\nSimple.Subs &lt;- mean(predict.outcome.A1 - predict.outcome.A0)\nSimple.Subs\n\n\n[1] -0.03380285\n\n\n\n\n\nThe intuition behind inverse probability of treatment weighting (IPTW) is to view confounding as a problem of biased sampling. In observational data, some exposure–covariate subgroups are overrepresented, while others are underrepresented, relative to what we would expect in a randomized trial.\nIPTW addresses this issue by reweighting the data to create a pseudo-population in which treatment assignment is independent of measured confounders. Weights are applied to up-weight under-represented units and down-weight over-represented units. Causal effects are then estimated by averaging and comparing the weighted outcomes across treatment groups. The algorithm for implementing the IPTW estimator is described below.\n\nEstimate the probability of being exposed/treated A as a function of measured confounders W:\\(\\mathbb{P}(A=1\\mid W)\\). This is often referred to as the propensity score. We can estimate the propensity score by running a main terms logistic regression as illustrated below\n\n\n\nCode\npscore.regression &lt;- glm(A~ W1+W2+W3+W4, family='binomial',\n                         data=data)\nsummary(pscore.regression)\n\n\n\nCall:\nglm(formula = A ~ W1 + W2 + W3 + W4, family = \"binomial\", data = data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -1.3445     0.3821  -3.519 0.000433 ***\nW1            0.4637     0.3130   1.482 0.138399    \nW2            0.5113     0.5629   0.908 0.363744    \nW3            0.4483     0.3208   1.397 0.162360    \nW4           -0.2676     0.3095  -0.865 0.387227    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 247.64  on 199  degrees of freedom\nResidual deviance: 241.99  on 195  degrees of freedom\nAIC: 251.99\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nWe then use estimates from 1 above to calculate exposed/treated weights: 1/\\(\\mathbb{P}(A=1\\mid W)\\) and unexposed/untreated weights:1/\\(\\mathbb{P}(A=0\\mid W)\\)\n\n\n\nCode\npredict.prob.A1 &lt;- predict(pscore.regression, type='response')\nsummary(predict.prob.A1)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.1555  0.2521  0.3034  0.3100  0.3658  0.5145 \n\n\nCode\npredict.prob.A0 &lt;- 1 - predict.prob.A1\nwt1 &lt;- as.numeric( data$A==1)/predict.prob.A1\nwt0 &lt;- as.numeric( data$A==0)/predict.prob.A0\nhead(data.frame(cbind(A=data$A, 1/predict.prob.A1, wt1, wt0)))\n\n\n  A       V2 wt1      wt0\n1 0 2.646982   0 1.607171\n2 0 4.197342   0 1.312760\n3 0 3.718918   0 1.367793\n4 0 3.735871   0 1.365514\n5 0 3.044577   0 1.489099\n6 0 2.128806   0 1.885892\n\n\n\nWe then apply the weights and average the weighted outcomes to estimate the marginal risks in the population under A=1 and A=0. To compare estimates, we take the difference in weighted means.\n\n\n\nCode\nmean(wt1*data$Y)\n\n\n[1] 0.03973564\n\n\nCode\nmean(wt0*data$Y)\n\n\n[1] 0.07234258\n\n\nCode\nIPW &lt;- mean(wt1*data$Y) - mean(wt0*data$Y)\nIPW\n\n\n[1] -0.03260694\n\n\nCode\nmean( (wt1-wt0)*data$Y)\n\n\n[1] -0.03260694\n\n\n\n\n\nTo build intuition for targeted maximum likelihood estimation (TMLE), we again view causal inference as a problem of missing information.As in simple substitution, the first step is to predict outcomes for all units under both the exposed and unexposed conditions.TMLE begins by fitting an initial outcome regression using a flexible estimation approach, such as Super Learner, to avoid relying on strong parametric assumptions when the true regression model is unknown. When reliable parametric knowledge is available, it can be incorporated directly.\nTMLE then incorporates information about the exposure–covariate relationship through a targeted update of the initial estimator.This targeting step is designed specifically to improve estimation of the causal parameter of interest. Because TMLE uses both the outcome model and the exposure model, it offers double robustness: the estimator remains consistent if at least one of these models is correctly specified. This estimator is also asymptotically linear and therefore we can obtain normal curve inference.Finally, causal effects are obtained by averaging and comparing the targeted predicted outcomes under exposure and no exposure.\n\n\nThis is a supervised machine learning algorithm that offers a flexible and data daptive approach to learn complex relationships from data. This algorithm uses cross-validation(sample splitting) to evaluate the performance of a library of candidate estimators.The library should be diverse including simple (e.g expert informed parametric regressions) and more adaptive algorithms (e.g penalized regressions, stepwise regression, adaptive splines) Performance is assessed using a specified loss function, such as the squared prediction error, which quantifies how well each algorithm predicts outcomes on new data.\nCross-validation allows us to compare algorithms based on how they perform on independent data. The data are partitioned into folds, and each algorithm is repeatedly trained on a subset of the data and evaluated on the held-out validation set. This process is rotated across folds, and the resulting risk estimates are averaged to obtain a single cross-validated performance measure for each algorithm. Rather than selecting only the single best-performing algorithm, Super Learner constructs an optimal weighted combination of algorithm-specific predictions. In the next section, we illustrate how to fit a Super Learner in practice.\n\n\nCode\nlibrary('SuperLearner')\nSL.library &lt;- c('SL.glm', 'SL.step.interaction', 'SL.gam'\n)\nSL.outcome.regression &lt;- suppressWarnings(SuperLearner(Y=data$Y, \n                                      X=subset(data, select=-Y),\n                                      SL.library=SL.library, \n                                      family='binomial'))\nSL.outcome.regression\n\n\n\nCall:  \nSuperLearner(Y = data$Y, X = subset(data, select = -Y), family = \"binomial\",  \n    SL.library = SL.library) \n\n                               Risk      Coef\nSL.glm_All              0.002745489 0.0000000\nSL.step.interaction_All 0.001407506 0.1134166\nSL.gam_All              0.001164327 0.8865834\n\n\nCode\nSL.predict.outcome &lt;- predict(SL.outcome.regression, \n                              newdata=subset(data, select=-Y))$pred\nhead(SL.predict.outcome)\n\n\n           [,1]\n[1,] 0.06057937\n[2,] 0.03497212\n[3,] 0.09365564\n[4,] 0.02889967\n[5,] 0.08963054\n[6,] 0.01211914\n\n\n\n\n\nWe could use Super Learner to predict the outcomes for each unit while “setting” the exposure to different levels and then average and contrast the predictions.\n\n\nCode\nSL.predict.outcome.A1 &lt;- predict(SL.outcome.regression, \n                                 newdata=subset(data.A1, select=-Y))$pred\nhead(SL.predict.outcome.A1)\n\n\n            [,1]\n[1,] 0.037893675\n[2,] 0.021656007\n[3,] 0.059409745\n[4,] 0.017819346\n[5,] 0.056743415\n[6,] 0.007417174\n\n\nCode\nSL.predict.outcome.A0 &lt;- predict(SL.outcome.regression, newdata=subset(data.A0, select=-Y))$pred\n\n# simple subst estimator\nmean(SL.predict.outcome.A1) - mean(SL.predict.outcome.A0)\n\n\n[1] -0.02523567\n\n\nHowever, Super Learner is focused on \\(\\mathbb{E}(Y\\mid A,W)\\) and not our parameter of interest. It makes the wrong bias-variance trade-off and specifically incurs too much bias.There is also no reliable way to obtain statistical inference (i.e create 95% confidence intervals)\n\n\n\nTargeting step uses information in the estimated propensity score \\(\\mathbb{P}(A=1\\mid W)\\) to update the initial (Super Learner) estimator of \\(\\mathbb{E}(Y\\mid A,W)\\). It involves running a univariate regression of the outcome Y on a clever covariate with offset the initial estimator. Why “clever”? It ensures that the targeting step moves the initial estimator in a direction that removes bias. The estimated coefficient from this regression is then used to update the initial predicted outcomes under both the exposed and unexposed conditions.\n\n\n\n\nUse Super Learner to estimate the propensity score \\(\\mathbb{P}(A=1\\mid W)\\)\n\n\n\nCode\nSL.pscore &lt;- SuperLearner(Y=data$A, X=subset(data, select=-c(A,Y)),\n                          SL.library=SL.library, family='binomial')\nSL.pscore\n\n\n\nCall:  \nSuperLearner(Y = data$A, X = subset(data, select = -c(A, Y)), family = \"binomial\",  \n    SL.library = SL.library) \n\n                             Risk      Coef\nSL.glm_All              0.2193296 0.0000000\nSL.step.interaction_All 0.2073331 0.2986055\nSL.gam_All              0.2048874 0.7013945\n\n\nCode\nSL.predict.prob.A1 &lt;- SL.pscore$SL.predict\nsummary(SL.predict.prob.A1 - predict(SL.pscore, newdata=subset(data,select=-c(A,Y)))$pred)\n\n\n       V1   \n Min.   :0  \n 1st Qu.:0  \n Median :0  \n Mean   :0  \n 3rd Qu.:0  \n Max.   :0  \n\n\nCode\nsummary(SL.predict.prob.A1)\n\n\n       V1        \n Min.   :0.1560  \n 1st Qu.:0.2378  \n Median :0.2748  \n Mean   :0.3100  \n 3rd Qu.:0.3501  \n Max.   :0.9270  \n\n\nCode\nSL.predict.prob.A0 &lt;- 1 - SL.predict.prob.A1\n\n\nNote: As you run this code you might encounter a warning “non-integer #successes in a binomial glm!”. This simply means that our outcome Y is not binary much as it’s bounded between 0 and 1. This is okay and can be ignored.\n\nCalculate the “clever covariate”\n\n\\[H(A,W)= \\frac{\\mathbb{I}(A=1)}{\\mathbb{P}(A=1\\mid W)}- \\frac{\\mathbb{I}(A=0)}{\\mathbb{P}(A=0\\mid W)}\\]\nHere’s code to evaluate the “clever covariate”\n\n\nCode\nH.AW &lt;- (data$A==1)/SL.predict.prob.A1 - (data$A==0)/SL.predict.prob.A0\nsummary(H.AW)\n\n\n       V1           \n Min.   :-2.186965  \n 1st Qu.:-1.407155  \n Median :-1.301617  \n Mean   : 0.006879  \n 3rd Qu.: 1.988451  \n Max.   : 5.879362  \n\n\nCode\nH.1W &lt;- 1/SL.predict.prob.A1\nH.0W &lt;- -1/SL.predict.prob.A0\ntail(data.frame(A=data$A, H.AW, H.1W, H.0W))\n\n\n    A      H.AW     H.1W      H.0W\n195 1  2.475907 2.475907 -1.677550\n196 0 -1.394124 3.537274 -1.394124\n197 0 -1.326598 4.061867 -1.326598\n198 1  5.371782 5.371782 -1.228740\n199 0 -1.184825 6.410513 -1.184825\n200 0 -1.339610 3.944556 -1.339610\n\n\n3.Run logistic regression of the outcome on this covariate using logit of the initial estimator \\(\\mathbb{E}(Y\\mid A,W)\\) as offset where logit(x)= log[x/(1-x)]\n\n\nCode\nlogitUpdate &lt;- glm( data$Y ~ -1 +offset( qlogis(SL.predict.outcome)) +\n                      H.AW, family='binomial')\n\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\nCode\nepsilon &lt;- logitUpdate$coef\nepsilon\n\n\n       H.AW \n0.004130237 \n\n\n\nPlug in the estimated coefficient \\(\\epsilon\\) to yield our targeted estimator \\(\\mathbb{E^*}(Y\\mid A,W)\\) and use the targeted estimator \\(\\mathbb{E^*}(Y\\mid A,W)\\) to predict outcomes for all under A=1 and A=0\n\n\n\nCode\ntarget.predict.outcome.A1 &lt;- plogis( qlogis(SL.predict.outcome.A1)+\n                                       epsilon*H.1W)\ntarget.predict.outcome.A0 &lt;- plogis( qlogis(SL.predict.outcome.A0)+\n                                      epsilon*H.0W)\n\n\n\nAverage the predictions to estimate the marginal risks in the population under exposure and no exposure. Compare the estimates by taking the difference.\n\n\n\nCode\nTMLE &lt;- mean( target.predict.outcome.A1 - target.predict.outcome.A0)\nTMLE\n\n\n[1] -0.02419038\n\n\n\n\n\n\nWe have now discussed three estimators and walked through their implementation. We next summarize the key properties of each estimator and highlight important considerations when choosing among them;\n\nSimple substitution estimator\n\nThis relies on consistently estimating the mean outcome \\(\\mathbb{E^*}(Y\\mid A,W)\\). In settings where there is strong substantive knowledge about the relationship between the outcome and the exposure–covariate set, a correctly specified parametric regression model may perform well. However, in many applications our knowledge of this relationship is limited. In such cases, assuming an incorrect parametric form can lead to biased estimates and misleading inference\n\nIPTW\n\nRelies on consistently estimating the propensity score \\(\\mathbb{P}(A=1\\mid W)\\). While sometimes we have a lot of knowledge about how the exposure was assigned, other times our knowledge is limited and assuming a parametric regression model can result in bias and misleading inference. This estimator is also unstable under positivity violations. When covariate groups only have a few exposed or unexposed observations, weights can blow up!!. If some strata contain no exposed or no unexposed observations, the estimator may appear numerically stable, but it will generally be biased and its variance underestimated.\n\nTMLE\n\nThis estimator is doubly robust i.e. yields a consistent estimate if either the conditional mean \\(\\mathbb{E^*}(Y\\mid A,W)\\) or the propensity score \\(\\mathbb{P}(A=1\\mid W)\\) is consistently estimated. We get two chances to get it right !!TMLE is also semiparametrically efficient, achieving the lowest possible asymptotic variance among a broad class of estimators when both models are estimated at sufficient rates. Importantly, TMLE is supported by formal theory that allows for valid statistical inference under mild conditions even when machine learning methods are used.Being a substitution estimator (plug-in), it is robust under positivity violations,strong confounding and rare outcomes. In addition, there is well-developed software available for implementation, including packages such as ltmle,lmptp packages in R.\n\n\nAfter estimating the parameter of interest, the next step is to quantify statistical uncertainty.Doing so requires an estimate of the sampling distribution.We can consider doing a non-parametric bootstrap where we re-sample the observed data with replacement, apply the entire estimation process (including machine learning algorithms) to the re-sampled data, repeat X times and estimate the variance with the bootstrapped point estimates. Alternatively, we can use influence curve based inference asymptotic linearity to directly estimate standard errors. We shall not discuss this here but this form of inference is available in the R packages.\nWith this, we conclude the estimation component of the analysis. Having selected an estimator and obtained an estimate of our parameter of interest and inference, we now return to the broader Causal Roadmap to consider interpretation, diagnostics, and sensitivity to assumptions"
  },
  {
    "objectID": "workshop/index.html#step-6-statistical-uncertainty",
    "href": "workshop/index.html#step-6-statistical-uncertainty",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "To do statistical inference, we need to derive an estimate of the sampling distribution.\nWe can consider doing a non-parametric bootstrap where we re-sample the observed data with replacement, apply the entire estimation process (including machine learning algorithms) to the re-sampled data, repeat X times and estimate the variance with the bootstrapped point estimates.\nAlternatively, we can use influence curve based inference. We shall not discuss this here but this form of inference is available in the R packages."
  },
  {
    "objectID": "workshop/index.html#step-7-interpret-findings",
    "href": "workshop/index.html#step-7-interpret-findings",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "The final step of the Causal Roadmap is to interpret the findings. At this stage, we evaluate whether and to what extent the underlying assumptions have been met in order to determine the strength of interpretation.\nFindings support a statistical interpretation if (1) the statistical estimator has negligible bias and its variance is well estimated\nFindings support a causal interpretation if 1 holds and (2) if the non testable identifiability assumptions hold.\nCan be interpreted as if implemented in the real-world if 1 and 2 hold and if (3) the intervention is feasible and applicable to the real world population.\nFindings can be interpreted as if we had emulated a randomized trial if 1-3 hold and the exposure could have been randomized to that population.\nIf there are concerns about causal assumptions (e.g. temporal odering is unclear, unmeasured confounding), the results can be interpreted as associational. In this case the estimand, \\(\\mathbb{E}\\big[\\mathbb{E}(Y\\mid A=1,W)-\\mathbb{E}(Y\\mid A=0,W)]\\) can be interpreted as;\n\nThe marginal difference in the expected outcome associated with the exposure, after accounting for the measured confounders\nThe difference in the mean outcome between persons exposed versus unexposed but with the same values of the adjustment covariates (averaged with respect to the distribution of those covariates in the population).e.g The difference in the risk of cardiovascular disease with intervention A vs B is X, accounting for region,age,sex,SES etc\nAlternatively one can report that this is as close as we can get to the causal effet of A on Y given the limitations of the data detailing all limitations and including a causal graph to empower the reader to assess the plausibility of assumptions.\n\nIf the authors believe causal assumptions are met, the parameter can be interpreted as the population average treatment effect \\(\\mathbb{E}\\big[Y_1-Y_0\\big]\\).\n\nIn words, this would be the difference in the expected outcome if everyone were exposed compared if everyone were unexposed. For example, there would be an X difference in the risk of cardiovascular disease if all patients in the population received intervention A vs B."
  },
  {
    "objectID": "workshop/index.html#summary-and-discussion",
    "href": "workshop/index.html#summary-and-discussion",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "Congratulations! You have successfully worked through this tutorial and implemented three core estimators for causal inference: the simple substitution estimator, inverse probability of treatment weighting (IPTW), and targeted maximum likelihood estimation (TMLE). Along the way, you have built both intuitive and technical understanding of how these estimators operate, what assumptions they rely on, and how they behave in practice.\nYou have also completed a high-speed tour of the Causal Roadmap, and by now its strengths should be apparent. The Roadmap emphasizes the importance of starting with clearly defined scientific questions and ensures that the parameters we estimate are aligned with those questions. It makes explicit the assumptions required to interpret estimates as causal effects.When assumptions are not met, the unmet assumptions provide clear guidance on how future research must be improved to increase the potential of causal interpretation.Working in this framework can improve interpretability and relevance of epidemiologic research.\nAlthough this tutorial focused on estimating the average treatment effect, the same framework naturally extends to a wide range of causal questions and data structures, including effects among treated or untreated populations, mediation analyses, longitudinal interventions, and dynamic treatment regimes.\nFor readers interested in exploring these more advanced settings, we provide links to additional resources below."
  },
  {
    "objectID": "workshop/index.html#caution-use-your-tools-well.",
    "href": "workshop/index.html#caution-use-your-tools-well.",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "TMLE with Super Learner is a powerful approach, but it should be viewed as one tool within a broader toolbox. No matter how sophisticated the estimator, careful thinking throughout the earlier steps of the Causal Roadmap remains essential.\nIt is especially important to formally derive adjustment sets and clearly define the statistical parameter before estimation. Failure to do so can lead to errors of causal model neglect, where the quantity being estimated differs meaningfully from any interpretable causal effect.\nDoubly robust estimators (e.g TMLE or A-IPW) can incorporate machine learning while maintaining basis for valid statistical inference. This helps us avoid errors of “statistical model neglect”, occurring when relying on unsubstantiated (parametric) assumptions during estimation.However, these benefits depend on careful implementation. In particular, the Super Learner library must be specified thoughtfully: diversity among candidate learners is crucial, and overfitting should be avoided through proper sample splitting and cross-validation.\nIn practice, positivity violations can and do occur. Poor support for certain exposure–covariate combinations may lead to bias and underestimated variance. Potential strategies for addressing these issues include using substitution estimators such as G-computation or TMLE, modifying the targeting step in TMLE (e.g., via weighted regression), employing robust variance estimators (e.g., Tran et al., 2018; Benkeser et al., 2017), or bounding estimated propensity scores away from zero and one.\nFinally, simulation studies play a critical role in responsible causal analysis. By simulating data that mimic key features of the observed setting—such as sample size, confounding structure, missingness mechanisms, sparsity, dependence, or practical positivity challenges—we can better understand estimator behavior and use these insights to guide analytic decisions."
  },
  {
    "objectID": "workshop/archive/05-integrated-analysis.html",
    "href": "workshop/archive/05-integrated-analysis.html",
    "title": "5. Putting It All Together",
    "section": "",
    "text": "Integrating the Steps\nIn this final section, we bring together all steps of the Causal Roadmap and Targeted Learning pipeline.\n\n\nCode\n# Full workflow\n\n\n Figure 5. Integrating the Causal Roadmap and Targeted Learning for real-world evidence."
  },
  {
    "objectID": "workshop/archive/03-tmle.html",
    "href": "workshop/archive/03-tmle.html",
    "title": "3. TMLE Concepts and Implementation",
    "section": "",
    "text": "Why TMLE?\nTMLE provides a robust, efficient estimator for causal effects combining outcome regression and propensity score modeling.\nIt is doubly robust and allows the use of machine learning while preserving valid inference.\n\n\nCode\nlibrary(tmle)\nlibrary(SuperLearner)\nset.seed(123)\nfit &lt;- tmle(Y, A, W, family = \"binomial\",\n            Q.SL.library = c(\"SL.glm\", \"SL.glmnet\", \"SL.ranger\"),\n            g.SL.library = c(\"SL.glm\", \"SL.ranger\"))\nsummary(fit)\n\n\n Initial estimation of Q\n     Procedure: cv-SuperLearner, ensemble\n     Model:\n         Y ~  SL.glm_All + SL.glmnet_All + SL.ranger_All\n\n     Coefficients: \n          SL.glm_All    1 \n       SL.glmnet_All    0 \n       SL.ranger_All    0 \n\n     Cross-validated pseudo R squared :  0.0489 \n\n Estimation of g (treatment mechanism)\n     Procedure: SuperLearner, ensemble\n     Model:\n         A ~  SL.glm_All + SL.ranger_All \n\n     Coefficients: \n          SL.glm_All    1 \n       SL.ranger_All    0 \n\n Estimation of g.Z (intermediate variable assignment mechanism)\n     Procedure: No intermediate variable \n\n Estimation of g.Delta (missingness mechanism)\n     Procedure: No missingness, ensemble\n\n Bounds on g: (0.0229, 1) \n\n Bounds on g for ATT/ATC: (0.0229, 0.9771) \n\n Marginal Mean under Treatment (EY1)\n   Parameter Estimate:  0.8545\n   Estimated Variance:  0.00021034\n              p-value:  &lt;2e-16\n    95% Conf Interval:  (0.82607, 0.88292)\n\n Marginal Mean under Comparator (EY0)\n   Parameter Estimate:  0.7213\n   Estimated Variance:  0.00049874\n              p-value:  &lt;2e-16\n    95% Conf Interval:  (0.67753, 0.76508)\n\n Additive Effect\n   Parameter Estimate:  0.1332\n   Estimated Variance:  0.00070162\n              p-value:  4.9435e-07\n    95% Conf Interval:  (0.081279, 0.18511)\n\n Additive Effect among the Treated\n   Parameter Estimate:  0.12591\n   Estimated Variance:  0.00069858\n              p-value:  1.9004e-06\n    95% Conf Interval:  (0.074105, 0.17771)\n\n Additive Effect among the Controls\n   Parameter Estimate:  0.14433\n   Estimated Variance:  0.0007439\n              p-value:  1.2115e-07\n    95% Conf Interval:  (0.090873, 0.19779)\n\n Relative Risk\n   Parameter  Estimate:  1.1847\n   Variance(log scale):  0.0012346\n               p-value:  1.4158e-06\n     95% Conf Interval:  (1.1058, 1.2691)\n\n Odds Ratio\n    Parameter  Estimate:  2.2691\n    Variance(log scale):  0.02565\n                p-value:  3.1176e-07\n      95% Conf Interval:  (1.6578, 3.1059)\n\n\n Figure 3. TMLE step-by-step schematic."
  },
  {
    "objectID": "workshop/archive/01-intro-case-study.html",
    "href": "workshop/archive/01-intro-case-study.html",
    "title": "1. Introduction & Case Study: Post-Market Safety of Prolia",
    "section": "",
    "text": "Background\nThis lesson introduces our motivating example: evaluating the post-market cardiovascular safety of denosumab (Prolia) compared to zoledronic acid.\nWe’ll use this as our running example throughout the workshop to illustrate the Causal Roadmap.\n Figure 1. Study schematic for the Prolia vs. Zoledronic Acid cardiovascular safety study.\n\n\nCode\n#romain's EHR simulation package\n\nremotes::install_github(\"romainkp/LtAtStructuR\")\nlibrary(LtAtStructuR)\nlibrary(data.table)\nlibrary(lubridate)\nlibrary(future) # optional (for parallel processing)\n#plan(multiprocess) # optional (for parallel processing)\n\n## Define one cohort dataset, one exposure dataset, and one or more covariate\n## datasets\ncohort &lt;- setCohort(cohortDT, \"ID\", \"IndexDate\", \"EOFDate\", \"EOFtype\",\n                    \"AMI\", c(\"ageEntry\", \"sex\", \"race\", \"A1c\", \"eGFR\"),\n                    list(\"ageEntry\"=list(\"categorical\"=FALSE,\n                                        \"impute\"=NA,\n                                        \"impute_default_level\"=NA),\n                        \"sex\"=list(\"categorical\"=TRUE,\n                                   \"impute\"=NA,\n                                   \"impute_default_level\"=NA),\n                        \"race\"=list(\"categorical\"=TRUE,\n                                    \"impute\"=NA,\n                                    \"impute_default_level\"=NA)) )\nexposure &lt;- setExposure(expDT, \"ID\", \"startA\", \"endA\")\ncovariate1 &lt;- setCovariate(a1cDT, \"sporadic\", \"ID\", \"A1cDate\", \"A1c\",\n                           categorical = FALSE)\ncovariate2 &lt;- setCovariate(egfrDT, \"sporadic\", \"ID\", \"eGFRDate\", \"eGFR\",\n                           categorical = TRUE)\n\n## Gather each input dataset into a single object that specifies the content of\n## the output dataset to be constructed\nLtAt.specification &lt;- cohort + exposure + covariate1 + covariate2\n\n## Construct the output dataset\nLtAt.data &lt;- construct(LtAt.specification, time_unit = 15, first_exp_rule = 1,\n                       exp_threshold = 0.75)\nhead(LtAt.data)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Targeted Learning for Real-World Evidence",
    "section": "",
    "text": "Welcome!\nThis site introduces the Causal Roadmap, Targeted Maximum Likelihood Estimation (TMLE), and Super Learner for modern causal inference in epidemiology, with an emphasis on pharmacoepidemiology and clinical trial analysis.\n\n\nCode\n# to build the site\n\nlibrary(quarto)\nquarto::quarto_preview()\n\n#code to deploy\nquarto::quarto_publish_site(title=\"causal-learning-handbook\")"
  },
  {
    "objectID": "workshop/archive/02-causal-roadmap.html",
    "href": "workshop/archive/02-causal-roadmap.html",
    "title": "2. The Causal Roadmap",
    "section": "",
    "text": "Defining the Causal Question\nWe start by expressing our scientific goal in causal terms:\n\nWhat is the 3-year risk difference in cardiovascular events if everyone were treated with denosumab versus zoledronic acid?\n\n\n\nIdentify the Target Population and Assumptions\nWe use the Causal Roadmap to structure the study design and analysis.\n Figure 2. The Causal Roadmap applied to the Prolia example.\n\n\nCode\n# Simulated example of data setup\nset.seed(123)\nn &lt;- 1000\nW &lt;- data.frame(age = rnorm(n, 70, 8), ckd = rbinom(n, 1, 0.2))\nA &lt;- rbinom(n, 1, plogis(-1 + 0.02*W$age + 0.6*W$ckd))\nY &lt;- rbinom(n, 1, plogis(-2 + 0.8*A + 0.04*W$age + 0.3*W$ckd))"
  },
  {
    "objectID": "workshop/archive/04-superlearner.html",
    "href": "workshop/archive/04-superlearner.html",
    "title": "4. SuperLearner and Ensemble Methods",
    "section": "",
    "text": "The Idea Behind Super Learner\nSuper Learner combines multiple models into one optimal prediction algorithm using cross-validation.\n\n\nCode\nlibrary(SuperLearner)\n\n\nLoading required package: nnls\n\n\nLoading required package: gam\n\n\nLoading required package: splines\n\n\nLoading required package: foreach\n\n\nLoaded gam 1.22-5\n\n\nSuper Learner\n\n\nVersion: 2.0-29\n\n\nPackage created on 2024-02-06\n\n\nCode\nset.seed(123)\n#sl_lib &lt;- c(\"SL.glm\", \"SL.mean\", \"SL.glmnet\", \"SL.randomForest\")\nsl_lib &lt;- c(\"SL.glm\") #simpler library for speed\nSL_fit &lt;- SuperLearner(Y, X = W, newX = W, family = binomial(), SL.library = sl_lib)\nsummary(SL_fit)\n\n\n                  Length Class  Mode       \ncall                 6   -none- call       \nlibraryNames         1   -none- character  \nSL.library           2   -none- list       \nSL.predict        1000   -none- numeric    \ncoef                 1   -none- numeric    \nlibrary.predict   1000   -none- numeric    \nZ                 1000   -none- numeric    \ncvRisk               1   -none- numeric    \nfamily              13   family list       \nfitLibrary           1   -none- list       \ncvFitLibrary         0   -none- NULL       \nvarNames             2   -none- character  \nvalidRows           10   -none- list       \nmethod               3   -none- list       \nwhichScreen          2   -none- logical    \ncontrol              3   -none- list       \ncvControl            4   -none- list       \nerrorsInCVLibrary    1   -none- logical    \nerrorsInLibrary      1   -none- logical    \nmetaOptimizer        8   nnls   list       \nenv                  9   -none- environment\ntimes                3   -none- list       \n\n\n Figure 4. Ensemble learning in Super Learner."
  },
  {
    "objectID": "workshop/archive/tmle_osteoporosis_workshop.html",
    "href": "workshop/archive/tmle_osteoporosis_workshop.html",
    "title": "Targeted Learning Workshop: Safety and Effectiveness of Osteoporosis Treatment",
    "section": "",
    "text": "Learn to use the Targeted Learning roadmap for causal inference.\nApply G-computation, IPTW, and TMLE using R.\nImplement Super Learner for robust data-adaptive estimation.\nDesign a Targeted Learning-based Statistical Analysis Plan (SAP) aligned with ICH E9(R1).\n\n\n\n\n\nDefine and identify causal estimands.\nCompare classical and modern estimators.\nApply TMLE to estimate treatment safety effects.\nDevelop a pre-specified, reproducible SAP for real-world evidence."
  },
  {
    "objectID": "workshop/archive/tmle_osteoporosis_workshop.html#workshop-goals",
    "href": "workshop/archive/tmle_osteoporosis_workshop.html#workshop-goals",
    "title": "Targeted Learning Workshop: Safety and Effectiveness of Osteoporosis Treatment",
    "section": "",
    "text": "Learn to use the Targeted Learning roadmap for causal inference.\nApply G-computation, IPTW, and TMLE using R.\nImplement Super Learner for robust data-adaptive estimation.\nDesign a Targeted Learning-based Statistical Analysis Plan (SAP) aligned with ICH E9(R1)."
  },
  {
    "objectID": "workshop/archive/tmle_osteoporosis_workshop.html#learning-outcomes",
    "href": "workshop/archive/tmle_osteoporosis_workshop.html#learning-outcomes",
    "title": "Targeted Learning Workshop: Safety and Effectiveness of Osteoporosis Treatment",
    "section": "",
    "text": "Define and identify causal estimands.\nCompare classical and modern estimators.\nApply TMLE to estimate treatment safety effects.\nDevelop a pre-specified, reproducible SAP for real-world evidence."
  },
  {
    "objectID": "workshop/archive/tmle_osteoporosis_workshop.html#motivation",
    "href": "workshop/archive/tmle_osteoporosis_workshop.html#motivation",
    "title": "Targeted Learning Workshop: Safety and Effectiveness of Osteoporosis Treatment",
    "section": "Motivation",
    "text": "Motivation\n\nEstimating the causal effect of osteoporosis drug use on fracture and cardiovascular safety. ## The Causal Roadmap\n\n\nDefine the question and estimand.\nSpecify causal and statistical models.\nAssess identifiability.\nChoose estimators and perform inference. ## Data Example\n\n\nObservational dataset: women &gt;50 with osteoporosis treatment.\nExposure: bisphosphonate vs. selective estrogen receptor modulator.\nOutcome: cardiovascular adverse event."
  },
  {
    "objectID": "workshop/archive/tmle_osteoporosis_workshop.html#data-preprocessing",
    "href": "workshop/archive/tmle_osteoporosis_workshop.html#data-preprocessing",
    "title": "Targeted Learning Workshop: Safety and Effectiveness of Osteoporosis Treatment",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\n\nImport, clean, and summarize variables.\nIdentify confounders and missing data patterns. ## Variable Definitions\nA: exposure (treatment type)\nY: outcome (adverse event)\nW: baseline covariates (age, comorbidities, medication history) ## Visualizing Data\nCovariate balance plots\nDAG for causal structure"
  },
  {
    "objectID": "workshop/archive/tmle_osteoporosis_workshop.html#concept",
    "href": "workshop/archive/tmle_osteoporosis_workshop.html#concept",
    "title": "Targeted Learning Workshop: Safety and Effectiveness of Osteoporosis Treatment",
    "section": "Concept",
    "text": "Concept\n\nModel outcome E[Y|A,W].\nPredict counterfactual outcomes for all individuals under each treatment. ## Implementation in R\n\n\n\nCode\nlibrary(SuperLearner)\nQ.SL &lt;- SuperLearner(Y, X, family=binomial(), SL.library=c(\"SL.glm\",\"SL.glmnet\",\"SL.xgboost\"))"
  },
  {
    "objectID": "workshop/archive/tmle_osteoporosis_workshop.html#interpretation",
    "href": "workshop/archive/tmle_osteoporosis_workshop.html#interpretation",
    "title": "Targeted Learning Workshop: Safety and Effectiveness of Osteoporosis Treatment",
    "section": "Interpretation",
    "text": "Interpretation\n\nEstimate mean difference in predicted risk (ATE).\nDiscuss bias under model misspecification."
  },
  {
    "objectID": "workshop/archive/tmle_osteoporosis_workshop.html#concept-1",
    "href": "workshop/archive/tmle_osteoporosis_workshop.html#concept-1",
    "title": "Targeted Learning Workshop: Safety and Effectiveness of Osteoporosis Treatment",
    "section": "Concept",
    "text": "Concept\n\nEstimate propensity score P(A|W).\nWeight each subject by inverse probability of observed treatment. ## Implementation in R\n\n\n\nCode\ng.SL &lt;- SuperLearner(A, W, family=binomial(), SL.library=c(\"SL.glm\",\"SL.gam\",\"SL.xgboost\"))"
  },
  {
    "objectID": "workshop/archive/tmle_osteoporosis_workshop.html#diagnostics",
    "href": "workshop/archive/tmle_osteoporosis_workshop.html#diagnostics",
    "title": "Targeted Learning Workshop: Safety and Effectiveness of Osteoporosis Treatment",
    "section": "Diagnostics",
    "text": "Diagnostics\n\nCheck covariate balance after weighting.\nPlot stabilized weights. ## Interpretation\nCompare with G-computation estimates."
  },
  {
    "objectID": "workshop/archive/tmle_osteoporosis_workshop.html#conceptual-framework",
    "href": "workshop/archive/tmle_osteoporosis_workshop.html#conceptual-framework",
    "title": "Targeted Learning Workshop: Safety and Effectiveness of Osteoporosis Treatment",
    "section": "Conceptual Framework",
    "text": "Conceptual Framework\n\nInitial outcome regression Q^0\nPropensity score model g\nTargeting step using clever covariate H(A,W)\nCompute updated estimate Q^*\nEstimate ATE ## Implementation\n\n\n\nCode\nlibrary(tmle)\ntmle_fit &lt;- tmle(Y, A, W, family=\"binomial\", Q.SL.library=Q.SL.library, g.SL.library=g.SL.library)\nsummary(tmle_fit)"
  },
  {
    "objectID": "workshop/archive/tmle_osteoporosis_workshop.html#inference",
    "href": "workshop/archive/tmle_osteoporosis_workshop.html#inference",
    "title": "Targeted Learning Workshop: Safety and Effectiveness of Osteoporosis Treatment",
    "section": "Inference",
    "text": "Inference\n\nEfficient influence curve\nStandard errors and 95% CI"
  },
  {
    "objectID": "workshop/archive/tmle_osteoporosis_workshop.html#why-super-learner",
    "href": "workshop/archive/tmle_osteoporosis_workshop.html#why-super-learner",
    "title": "Targeted Learning Workshop: Safety and Effectiveness of Osteoporosis Treatment",
    "section": "Why Super Learner?",
    "text": "Why Super Learner?\n\nCombine algorithms for optimal predictive performance. ## Building a Library\nInclude SL.glm, SL.gam, SL.xgboost, SL.ranger, SL.mean. ## Practical Tips\nCross-validation folds\nScreening and variable selection\nParallel computation"
  },
  {
    "objectID": "workshop/archive/tmle_osteoporosis_workshop.html#assessing-assumptions",
    "href": "workshop/archive/tmle_osteoporosis_workshop.html#assessing-assumptions",
    "title": "Targeted Learning Workshop: Safety and Effectiveness of Osteoporosis Treatment",
    "section": "Assessing Assumptions",
    "text": "Assessing Assumptions\n\nExchangeability, positivity, consistency ## Sensitivity Analyses\nTruncating extreme weights\nComparing parametric vs. SL fits\nAssessing violations (e.g., unmeasured confounding)"
  },
  {
    "objectID": "workshop/archive/tmle_osteoporosis_workshop.html#introduction-1",
    "href": "workshop/archive/tmle_osteoporosis_workshop.html#introduction-1",
    "title": "Targeted Learning Workshop: Safety and Effectiveness of Osteoporosis Treatment",
    "section": "Introduction",
    "text": "Introduction\n\nTMLE for time-to-event data (cardiovascular safety)\nCensoring and competing risks ## Using the lmtp Package\n\n\n\nCode\nlibrary(lmtp)\nfit_lmtp &lt;- lmtp_tmle(data, trt=\"drug\", outcome=\"cv_event\", time_vary=list(...))"
  },
  {
    "objectID": "workshop/archive/tmle_osteoporosis_workshop.html#interpretation-1",
    "href": "workshop/archive/tmle_osteoporosis_workshop.html#interpretation-1",
    "title": "Targeted Learning Workshop: Safety and Effectiveness of Osteoporosis Treatment",
    "section": "Interpretation",
    "text": "Interpretation\n\nRisk difference or hazard difference at time t\nVisualizing survival curves"
  },
  {
    "objectID": "workshop/archive/tmle_osteoporosis_workshop.html#alignment-with-ich-e9r1",
    "href": "workshop/archive/tmle_osteoporosis_workshop.html#alignment-with-ich-e9r1",
    "title": "Targeted Learning Workshop: Safety and Effectiveness of Osteoporosis Treatment",
    "section": "Alignment with ICH E9(R1)",
    "text": "Alignment with ICH E9(R1)\n\nPopulation, treatment, variable, intercurrent events, summary measure. ## Checklist\n\n\nDefine estimand.\nSpecify identification assumptions.\nDescribe analytic strategy (TMLE + SL).\nPlan sensitivity analyses. ## Example Output\n\n\nStructured SAP for osteoporosis safety study."
  },
  {
    "objectID": "advanced/01-02-causal-roadmap.html",
    "href": "advanced/01-02-causal-roadmap.html",
    "title": "Chapter 1.2: The Causal Roadmap",
    "section": "",
    "text": "In this chapter, we introduce the Causal Roadmap, a structured approach for asking and answering causal questions with observational data. The roadmap helps researchers define their scientific question, translate it into a formal causal model, assess whether the causal effect is identifiable from data, and choose appropriate estimators to answer that question."
  },
  {
    "objectID": "advanced/01-02-causal-roadmap.html#why-use-a-causal-roadmap",
    "href": "advanced/01-02-causal-roadmap.html#why-use-a-causal-roadmap",
    "title": "Chapter 1.2: The Causal Roadmap",
    "section": "Why Use a Causal Roadmap?",
    "text": "Why Use a Causal Roadmap?\nTraditional analysis often starts with: “Let’s run a regression and see what we find.” But modern causal inference begins by asking: What is the causal question we are trying to answer?\nA causal roadmap ensures: - Transparency in how evidence is generated - Separation of scientific questions from statistical methods - Clear articulation of assumptions and their implications - Structured thinking in both trial and non-randomized settings\nWe’ll walk step-by-step through each part of the roadmap, with illustrative examples."
  },
  {
    "objectID": "advanced/01-02-causal-roadmap.html#step-1-define-the-causal-question",
    "href": "advanced/01-02-causal-roadmap.html#step-1-define-the-causal-question",
    "title": "Chapter 1.2: The Causal Roadmap",
    "section": "Step 1: Define the Causal Question",
    "text": "Step 1: Define the Causal Question\nThis includes: - Population: Who are we studying? - Intervention: What exposure or treatment are we manipulating? - Outcome: What effect are we interested in? - Timeframe: Over what duration?\nExample:\n\nWhat is the 3-year risk of cardiovascular events if all postmenopausal women with osteoporosis initiated denosumab compared to if all initiated zoledronic acid?\n\nThis PICO-style framing is the foundation of causal inference."
  },
  {
    "objectID": "advanced/01-02-causal-roadmap.html#step-2-specify-the-causal-model",
    "href": "advanced/01-02-causal-roadmap.html#step-2-specify-the-causal-model",
    "title": "Chapter 1.2: The Causal Roadmap",
    "section": "Step 2: Specify the Causal Model",
    "text": "Step 2: Specify the Causal Model\nWe now draw out how we believe the data were generated. This includes:\n\nVariables: Treatment (A), outcome (Y), and covariates (W)\nDAGs: Directed acyclic graphs to encode assumptions\nPotential Outcomes: \\(Y(1)\\) and \\(Y(0)\\) for each individual\n\nWe are making an implicit Structural Causal Model (SCM):\n\\[\nW = f_W(U_W),\\\nA = f_A(W, U_A),\\\nY = f_Y(W, A, U_Y)\n\\]\nWhere \\(U\\) terms represent unmeasured variables.\nA simple DAG:\nW → A → Y\n \\    ↘\n  →────→\nThis DAG implies: - W (confounders) affect both A and Y - A (treatment) affects Y - No unmeasured confounding (U nodes omitted for simplicity)"
  },
  {
    "objectID": "advanced/01-02-causal-roadmap.html#step-3-define-the-target-causal-estimand",
    "href": "advanced/01-02-causal-roadmap.html#step-3-define-the-target-causal-estimand",
    "title": "Chapter 1.2: The Causal Roadmap",
    "section": "Step 3: Define the Target Causal Estimand",
    "text": "Step 3: Define the Target Causal Estimand\nWe often want the Average Treatment Effect (ATE):\n\\[\nATE = E[Y(1) - Y(0)]\n\\]\nOr equivalently, Risk Difference:\n\\[\nE[Y | do(A=1)] - E[Y | do(A=0)]\n\\]\nWe might also want: - Risk ratios - Hazard ratios (with caveats) - Median survival differences - Effects in subgroups (CATEs)"
  },
  {
    "objectID": "advanced/01-02-causal-roadmap.html#step-4-link-the-causal-estimand-to-the-observed-data",
    "href": "advanced/01-02-causal-roadmap.html#step-4-link-the-causal-estimand-to-the-observed-data",
    "title": "Chapter 1.2: The Causal Roadmap",
    "section": "Step 4: Link the Causal Estimand to the Observed Data",
    "text": "Step 4: Link the Causal Estimand to the Observed Data\nThis is the identification step. It answers the question: Can we estimate the causal effect from the data we have?\nRequires three assumptions: - Exchangeability (No unmeasured confounding): \\(Y(a) \\perp A | W\\) - Positivity: Everyone has a nonzero probability of receiving each treatment, given W - Consistency: The observed outcome equals the potential outcome under the received treatment\nIf satisfied, we can identify:\n\\[\nE[Y(1) - Y(0)] = E_W[ E[Y | A = 1, W] - E[Y | A = 0, W] ]\n\\]"
  },
  {
    "objectID": "advanced/01-02-causal-roadmap.html#step-5-choose-a-statistical-estimator",
    "href": "advanced/01-02-causal-roadmap.html#step-5-choose-a-statistical-estimator",
    "title": "Chapter 1.2: The Causal Roadmap",
    "section": "Step 5: Choose a Statistical Estimator",
    "text": "Step 5: Choose a Statistical Estimator\nThis step translates the identified quantity into an algorithm we can apply to data.\nOptions include: - G-computation: Predict outcomes under each treatment, average over W - IPTW: Weight observations by inverse probability of treatment - TMLE: Targeted learning that combines outcome and treatment models\nWe’ll explore these in later chapters. The choice depends on: - Assumptions you’re willing to make - Sample size - Tolerance for model misspecification"
  },
  {
    "objectID": "advanced/01-02-causal-roadmap.html#step-6-evaluate-and-interpret",
    "href": "advanced/01-02-causal-roadmap.html#step-6-evaluate-and-interpret",
    "title": "Chapter 1.2: The Causal Roadmap",
    "section": "Step 6: Evaluate and Interpret",
    "text": "Step 6: Evaluate and Interpret\nOnce you’ve estimated your parameter, interpretation is not automatic.\n\nAre your assumptions plausible?\nWhat does your estimate mean for real-world decisions?\nCan you generalize to other populations?\n\nTools for evaluation: - Sensitivity analyses - Negative control outcomes - Covariate balance checks - Expert consultation"
  },
  {
    "objectID": "advanced/01-02-causal-roadmap.html#a-simple-simulated-example",
    "href": "advanced/01-02-causal-roadmap.html#a-simple-simulated-example",
    "title": "Chapter 1.2: The Causal Roadmap",
    "section": "A Simple Simulated Example",
    "text": "A Simple Simulated Example\nWe’ll simulate a small dataset to show how steps 1-5 look in practice.\n\n\nCode\nset.seed(42)\nn &lt;- 1000\nage &lt;- rnorm(n, 75, 6)\ncvd_history &lt;- rbinom(n, 1, plogis(0.1 * (age - 70)))\nW &lt;- data.frame(age, cvd_history)\nA &lt;- rbinom(n, 1, plogis(-1 + 0.05 * (age - 70) + 1.5 * cvd_history))\nY &lt;- rbinom(n, 1, plogis(-2 + 0.4 * A + 0.1 * (age - 70) + 1 * cvd_history))\ndata &lt;- data.frame(W, A, Y)\n\n\nEstimate ATE using g-computation:\n\n\nCode\nmodel &lt;- glm(Y ~ A + age + cvd_history, family = binomial, data = data)\nnewdata1 &lt;- transform(data, A = 1)\nnewdata0 &lt;- transform(data, A = 0)\np1 &lt;- predict(model, newdata = newdata1, type = \"response\")\np0 &lt;- predict(model, newdata = newdata0, type = \"response\")\nmean(p1 - p0)\n\n\n[1] 0.1206902"
  },
  {
    "objectID": "advanced/01-02-causal-roadmap.html#summary",
    "href": "advanced/01-02-causal-roadmap.html#summary",
    "title": "Chapter 1.2: The Causal Roadmap",
    "section": "Summary",
    "text": "Summary\nThe Causal Roadmap gives a rigorous framework for designing and evaluating real-world effect estimates. Before choosing a statistical method, start with the science: - Define your causal question - Specify your model and assumptions - Decide how to express the effect - Choose a transparent, defensible method\nIn the next chapter, we’ll explore different estimation strategies in detail."
  },
  {
    "objectID": "advanced/02-01-gcomputation.html",
    "href": "advanced/02-01-gcomputation.html",
    "title": "Chapter 2.1: Outcome Modeling and Standardization (G-Computation)",
    "section": "",
    "text": "G-computation as a foundation for causal estimation\nOutcome modeling and standardization—often referred to as g-computation—is one of the oldest and most intuitive approaches to causal inference. In this chapter, we’ll build intuition, walk carefully through why the method works, show where it fails, and provide fully reproducible examples in R (using tidyverse style).\nThis chapter is intentionally thorough, designed for students new to causal inference but with working knowledge of regression."
  },
  {
    "objectID": "advanced/02-01-gcomputation.html#step-1-fit-an-outcome-model",
    "href": "advanced/02-01-gcomputation.html#step-1-fit-an-outcome-model",
    "title": "Chapter 2.1: Outcome Modeling and Standardization (G-Computation)",
    "section": "Step 1: Fit an Outcome Model",
    "text": "Step 1: Fit an Outcome Model\nWe fit a logistic regression model predicting the outcome from treatment and confounders:\n\n\nCode\nmod &lt;- glm(Y ~ A + age + cvd, family = binomial, data = dat)\nsummary(mod)\n\n\n\nCall:\nglm(formula = Y ~ A + age + cvd, family = binomial, data = dat)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -9.445955   0.594115 -15.899  &lt; 2e-16 ***\nA            0.498637   0.088087   5.661 1.51e-08 ***\nage          0.107847   0.007951  13.563  &lt; 2e-16 ***\ncvd          1.271786   0.094031  13.525  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 4127.2  on 2999  degrees of freedom\nResidual deviance: 3422.0  on 2996  degrees of freedom\nAIC: 3430\n\nNumber of Fisher Scoring iterations: 4\n\n\nThis alone is not a causal effect. Instead, it’s a conditional log-odds ratio.\nWe will now standardize using predictions."
  },
  {
    "objectID": "advanced/02-01-gcomputation.html#step-2-predict-counterfactual-outcomes",
    "href": "advanced/02-01-gcomputation.html#step-2-predict-counterfactual-outcomes",
    "title": "Chapter 2.1: Outcome Modeling and Standardization (G-Computation)",
    "section": "Step 2: Predict Counterfactual Outcomes",
    "text": "Step 2: Predict Counterfactual Outcomes\n\n\nCode\n# create counterfactual datasets\ndat1 &lt;- dat %&gt;% mutate(A = 1)\ndat0 &lt;- dat %&gt;% mutate(A = 0)\n\n# predict potential outcomes\np1 &lt;- predict(mod, newdata = dat1, type = \"response\")\np0 &lt;- predict(mod, newdata = dat0, type = \"response\")\n\n\nHere: - p1[i] = predicted outcome for person i if treated\n- p0[i] = predicted outcome for person i if untreated"
  },
  {
    "objectID": "advanced/02-01-gcomputation.html#step-3-standardize-average-over-covariates",
    "href": "advanced/02-01-gcomputation.html#step-3-standardize-average-over-covariates",
    "title": "Chapter 2.1: Outcome Modeling and Standardization (G-Computation)",
    "section": "Step 3: Standardize (Average Over Covariates)",
    "text": "Step 3: Standardize (Average Over Covariates)\n\n\nCode\nrisk1 &lt;- mean(p1)\nrisk0 &lt;- mean(p0)\nate  &lt;- risk1 - risk0\n\nlist(risk1 = risk1, risk0 = risk0, ate = ate)\n\n\n$risk1\n[1] 0.4890903\n\n$risk0\n[1] 0.3890304\n\n$ate\n[1] 0.1000599\n\n\nThis gives: - Risk under treatment - Risk under control - Risk difference (ATE)\nInterpretation example:\n\n“Initiating denosumab rather than ZA is estimated to increase/decrease 3-year MI/stroke risk by X percentage points.”"
  },
  {
    "objectID": "advanced/02-01-gcomputation.html#model-misspecification",
    "href": "advanced/02-01-gcomputation.html#model-misspecification",
    "title": "Chapter 2.1: Outcome Modeling and Standardization (G-Computation)",
    "section": "6.1 Model Misspecification",
    "text": "6.1 Model Misspecification\nIf your model for (E[Y | A, W]) is wrong (e.g., omits interactions, assumes linearity), g-computation may be biased.\nCheck residuals, fit alternative models, or use machine learning (next chapter)."
  },
  {
    "objectID": "advanced/02-01-gcomputation.html#poor-positivity",
    "href": "advanced/02-01-gcomputation.html#poor-positivity",
    "title": "Chapter 2.1: Outcome Modeling and Standardization (G-Computation)",
    "section": "6.2 Poor Positivity",
    "text": "6.2 Poor Positivity\nIf some strata almost never receive a treatment:\n\n\nCode\nps &lt;- predict(glm(A ~ age + cvd, family = binomial, data = dat), type = \"response\")\nsummary(ps)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.1569  0.3715  0.6402  0.5647  0.7218  0.9025 \n\n\nLook for: - Scores near 0 or 1 → dangerous for extrapolation\n- G-computation may have to predict outcomes in unobserved regions"
  },
  {
    "objectID": "advanced/02-01-gcomputation.html#unmeasured-confounding",
    "href": "advanced/02-01-gcomputation.html#unmeasured-confounding",
    "title": "Chapter 2.1: Outcome Modeling and Standardization (G-Computation)",
    "section": "6.3 Unmeasured Confounding",
    "text": "6.3 Unmeasured Confounding\nNo modeling strategy fixes missing confounders.\nBut g-computation makes assumptions very clear, which is an advantage for interpretation."
  },
  {
    "objectID": "advanced/02-03-doubly-robust-tmle.html",
    "href": "advanced/02-03-doubly-robust-tmle.html",
    "title": "Chapter 2.3: Doubly Robust Estimators and Targeted Learning (AIPW + TMLE)",
    "section": "",
    "text": "Bridging outcome modeling and weighting for more robust causal effect estimation\nIn previous chapters, you learned:\n\nG-computation depends on correctly modeling the outcome\n\nIPTW depends on correctly modeling the treatment mechanism\n\nBut what if you could use both models, and as long as either one is correct, your estimator is still consistent?\nThis is exactly what doubly robust estimators provide.\nWe explore:\n\nWhy doubly robust estimators matter\n\nAIPW (Augmented IPTW)\n\nTMLE (Targeted Maximum Likelihood Estimation)\n\nHow to implement both with tidyverse-friendly R code\n\nWhy TMLE is preferred in modern causal inference"
  },
  {
    "objectID": "advanced/02-03-doubly-robust-tmle.html#formula",
    "href": "advanced/02-03-doubly-robust-tmle.html#formula",
    "title": "Chapter 2.3: Doubly Robust Estimators and Targeted Learning (AIPW + TMLE)",
    "section": "2.1 Formula",
    "text": "2.1 Formula\nLet:\n\n( e(W) = P(A = 1 | W) )\n\n( m(a, W) = E[Y | A = a, W] )\n\nThen:\n[ _1 = \frac{1}{n} _i ]\n[ _0 = \frac{1}{n} _i ]\nATE = ( _1 - _0 )"
  },
  {
    "objectID": "advanced/03-03-longitudinal-case-study.html",
    "href": "advanced/03-03-longitudinal-case-study.html",
    "title": "Chapter 3.3: Case Study – Real-World Application in Longitudinal Analysis",
    "section": "",
    "text": "This chapter walks through a complete applied example of longitudinal causal inference using real-world data concepts.\nThe goal is to help you translate the earlier theoretical chapters into a practical analysis workflow.\nWe use the motivating real-world question:\n\nWhat is the 3-year cardiovascular risk difference if all eligible patients initiating osteoporosis therapy remained on denosumab vs. zoledronic acid under full adherence?\n\nAlthough we cannot use the proprietary data from the actual studies, this chapter recreates a plausible longitudinal structure and walks you through the entire pipeline:\n\nConstructing the longitudinal dataset\n\nDefining the causal question, intervention, and estimand\n\nIdentifying longitudinal confounders and censoring\n\nUsing SuperLearner for nuisance function estimation\n\nApplying TMLE or LMTP for longitudinal causal effects\n\nInterpreting the results in a regulatory and clinical context\n\nThis chapter integrates lessons from Chapter 1 (causal roadmap) and Chapter 2 (estimation)."
  },
  {
    "objectID": "advanced/03-03-longitudinal-case-study.html#case-study-real-world-longitudinal-causal-inference-using-targeted-learning",
    "href": "advanced/03-03-longitudinal-case-study.html#case-study-real-world-longitudinal-causal-inference-using-targeted-learning",
    "title": "Chapter 3.3: Case Study – Real-World Application in Longitudinal Analysis",
    "section": "",
    "text": "This chapter walks through a complete applied example of longitudinal causal inference using real-world data concepts.\nThe goal is to help you translate the earlier theoretical chapters into a practical analysis workflow.\nWe use the motivating real-world question:\n\nWhat is the 3-year cardiovascular risk difference if all eligible patients initiating osteoporosis therapy remained on denosumab vs. zoledronic acid under full adherence?\n\nAlthough we cannot use the proprietary data from the actual studies, this chapter recreates a plausible longitudinal structure and walks you through the entire pipeline:\n\nConstructing the longitudinal dataset\n\nDefining the causal question, intervention, and estimand\n\nIdentifying longitudinal confounders and censoring\n\nUsing SuperLearner for nuisance function estimation\n\nApplying TMLE or LMTP for longitudinal causal effects\n\nInterpreting the results in a regulatory and clinical context\n\nThis chapter integrates lessons from Chapter 1 (causal roadmap) and Chapter 2 (estimation)."
  },
  {
    "objectID": "advanced/03-05-advanced-diagnostics.html",
    "href": "advanced/03-05-advanced-diagnostics.html",
    "title": "Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "",
    "text": "Ensuring credible causal conclusions in real-world longitudinal data\nCausal inference is never just about estimating an effect — it is about credibly defending that effect.\nDiagnostics and sensitivity analyses are essential components of the causal roadmap because:\n\nIdentifying assumptions are never fully testable\n\nReal-world data contain missingness, selection, unmeasured confounding, and misclassification\n\nPositivity and model misspecification can quietly undermine estimation\n\nRegulatory-grade RWE requires transparency and robustness checks\n\nThis chapter walks through:\n\nDiagnostics for identification assumptions\n\nPositivity and overlap assessment\n\nDiagnostics for nuisance models (Q and g)\n\nWeight diagnostics\n\nSensitivity analyses for unmeasured confounding\n\nNegative controls\n\nTMLE-specific diagnostics\n\nLongitudinal diagnostics (LMTP / longitudinal TMLE)\n\n\n\n\n\nThe core identification assumptions are:\n\nConsistency\n\nExchangeability (No unmeasured confounding)\n\nPositivity\n\nCorrect nuisance model specification\n\nWhile not directly testable, their empirical implications can be evaluated.\n\n\nBefore causal modeling:\n\nVerify time ordering\n\nConfirm treatment and outcome timestamps\n\nInspect missingness patterns\n\nLook for coding shifts (ICD-9 to ICD-10)\n\nExamine distributions and implausible values\n\n\n\n\nA DAG clarifies:\n\nAdjustment sets\n\nPotential unmeasured confounding\n\nVariables that should not be adjusted for (mediators, colliders)\n\nUse DAGs as a communication tool with clinical partners.\n\n\n\n\n\nPositivity requires:\n\nEvery combination of covariates has a non-zero probability of receiving each treatment.\n\nViolations cause unstable weights and unreliable estimates.\n\n\nps &lt;- predict(glm(A ~ W1 + W2, family = binomial), type = \"response\")\n\nlibrary(ggplot2)\nggplot(tibble(ps = ps, A = A), aes(x = ps, fill = factor(A))) +\n  geom_density(alpha = 0.4)\nIndicators of concern:\n\nMass near 0 or 1\n\nDisjoint distributions\n\n\n\n\nH &lt;- A/ps - (1-A)/(1-ps)\nsummary(H)\nExtreme values imply near-positivity violations.\n\n\n\n\nRestrict to regions with support (“overlap population”)\nTruncate weights\n\nUse stochastic interventions instead of static ones\n\nSimplify interventions\n\n\n\n\n\n\nAccurate nuisance models are crucial for TMLE, AIPW, and LMTP.\n\n\n\nAUC for binary outcomes\n\nMSE/R² for continuous\n\nCross-validated risk from SuperLearner\n\n\n\n\ndat %&gt;% \n  mutate(pred = Qhat) %&gt;% \n  ggplot(aes(x = pred, y = Y)) +\n    geom_point(alpha = 0.3) +\n    geom_smooth()\n\n\n\nCompare:\n\nTraining loss\n\nCross-validated loss\n\nLarge discrepancy → overfitting.\n\n\n\nEnsure top predictors are clinically plausible.\n\n\n\n\n\nFor IPTW, MSMs, and censoring weights.\n\n\nsummary(weights)\nquantile(weights, probs = c(0.01, 0.99))\nRed flags:\n\nMean far from 1\n\nVery heavy tail\n\nHuge max weights\n\n\n\n\nggplot(tibble(w = weights), aes(x = w)) +\n  geom_histogram()\n\n\n\nlower &lt;- quantile(weights, 0.01)\nupper &lt;- quantile(weights, 0.99)\nw_trunc &lt;- pmin(pmax(weights, lower), upper)\n\n\n\n\n\n\n\nMeasures minimum strength of confounding needed to explain away an effect.\n\n\n\nSimulates impact of:\n\nUnmeasured confounder prevalence\n\nUnmeasured confounder associations\n\nR packages: episensr, causalsens\n\n\n\nFor matched studies.\n\n\n\nLMTP can quantify robustness of static intervention effects.\n\n\n\n\n\nNegative control outcomes (NCOs):\n\nCausally unrelated to treatment\n\nShare confounding structures\n\nIf TMLE of treatment → NCO ≠ 0 → likely confounding remains.\nExample:\ntmle_nco &lt;- tmle(\n  Y = dat$negative_event,\n  A = dat$treatment,\n  W = dat[, confounders]\n)\nNegative control exposures are also useful.\n\n\n\n\n\n\nExtreme clever covariate values lead to unstable targeting.\n\n\n\nCheck for warnings in logistic fluctuation:\nglm.fit: algorithm did not converge\n\n\n\nIC &lt;- tmle_fit$ic\nmean(IC); var(IC)\nHeavy tails → avoid Wald intervals, use bootstrap.\n\n\n\n\n\n\n\nCheck treatment probabilities at each timepoint.\n\n\n\ncumw &lt;- apply(weight_matrix, 1, prod)\nhist(cumw)\nExtreme cumulative weights → instability.\n\n\n\nTruncate weights at each time step or truncate cumulative weights.\n\n\n\nEnsure intermediate variables are not inappropriate colliders.\n\n\n\n\n\n\n\n\nConfirm time-ordering\n\nDraw a DAG\n\nCheck missingness\n\nSummarize covariate distributions by treatment\n\n\n\n\n\nCheck PS overlap\n\nEvaluate weight distributions\n\nInspect Q and g predictions\n\nCheck TMLE targeting step\n\n\n\n\n\nSensitivity analyses\n\nNegative controls\n\nCompare across estimators (IPTW, TMLE, AIPW)\n\nRobustness checks (population restriction, alternative confounder sets)\n\n\n\n\n\n\nTo produce defensible causal evidence, diagnostics must be:\n\nSystematic\n\nTransparent\n\nDocumented in the analysis plan\n\nInterpreted with domain expertise\n\nWith these tools, analysts can judge the credibility, robustness, and transportability of causal findings — essential for regulatory, clinical, and scientific decision‑making.\n\n\nCode\nsessionInfo()\n\n\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26200)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.2    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.4.2       htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10      \n [9] rmarkdown_2.29    knitr_1.49        jsonlite_2.0.0    xfun_0.49        \n[13] digest_0.6.37     rlang_1.1.6       evaluate_1.0.5"
  },
  {
    "objectID": "advanced/03-05-advanced-diagnostics.html#advanced-diagnostics-and-sensitivity-analyses",
    "href": "advanced/03-05-advanced-diagnostics.html#advanced-diagnostics-and-sensitivity-analyses",
    "title": "Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "",
    "text": "Ensuring credible causal conclusions in real-world longitudinal data\nCausal inference is never just about estimating an effect — it is about credibly defending that effect.\nDiagnostics and sensitivity analyses are essential components of the causal roadmap because:\n\nIdentifying assumptions are never fully testable\n\nReal-world data contain missingness, selection, unmeasured confounding, and misclassification\n\nPositivity and model misspecification can quietly undermine estimation\n\nRegulatory-grade RWE requires transparency and robustness checks\n\nThis chapter walks through:\n\nDiagnostics for identification assumptions\n\nPositivity and overlap assessment\n\nDiagnostics for nuisance models (Q and g)\n\nWeight diagnostics\n\nSensitivity analyses for unmeasured confounding\n\nNegative controls\n\nTMLE-specific diagnostics\n\nLongitudinal diagnostics (LMTP / longitudinal TMLE)"
  },
  {
    "objectID": "advanced/03-05-advanced-diagnostics.html#diagnostics-for-identification-assumptions",
    "href": "advanced/03-05-advanced-diagnostics.html#diagnostics-for-identification-assumptions",
    "title": "Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "",
    "text": "The core identification assumptions are:\n\nConsistency\n\nExchangeability (No unmeasured confounding)\n\nPositivity\n\nCorrect nuisance model specification\n\nWhile not directly testable, their empirical implications can be evaluated.\n\n\nBefore causal modeling:\n\nVerify time ordering\n\nConfirm treatment and outcome timestamps\n\nInspect missingness patterns\n\nLook for coding shifts (ICD-9 to ICD-10)\n\nExamine distributions and implausible values\n\n\n\n\nA DAG clarifies:\n\nAdjustment sets\n\nPotential unmeasured confounding\n\nVariables that should not be adjusted for (mediators, colliders)\n\nUse DAGs as a communication tool with clinical partners."
  },
  {
    "objectID": "advanced/03-05-advanced-diagnostics.html#positivity-diagnostics",
    "href": "advanced/03-05-advanced-diagnostics.html#positivity-diagnostics",
    "title": "Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "",
    "text": "Positivity requires:\n\nEvery combination of covariates has a non-zero probability of receiving each treatment.\n\nViolations cause unstable weights and unreliable estimates.\n\n\nps &lt;- predict(glm(A ~ W1 + W2, family = binomial), type = \"response\")\n\nlibrary(ggplot2)\nggplot(tibble(ps = ps, A = A), aes(x = ps, fill = factor(A))) +\n  geom_density(alpha = 0.4)\nIndicators of concern:\n\nMass near 0 or 1\n\nDisjoint distributions\n\n\n\n\nH &lt;- A/ps - (1-A)/(1-ps)\nsummary(H)\nExtreme values imply near-positivity violations.\n\n\n\n\nRestrict to regions with support (“overlap population”)\nTruncate weights\n\nUse stochastic interventions instead of static ones\n\nSimplify interventions"
  },
  {
    "objectID": "advanced/03-05-advanced-diagnostics.html#diagnostics-for-nuisance-functions-q-and-g",
    "href": "advanced/03-05-advanced-diagnostics.html#diagnostics-for-nuisance-functions-q-and-g",
    "title": "Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "",
    "text": "Accurate nuisance models are crucial for TMLE, AIPW, and LMTP.\n\n\n\nAUC for binary outcomes\n\nMSE/R² for continuous\n\nCross-validated risk from SuperLearner\n\n\n\n\ndat %&gt;% \n  mutate(pred = Qhat) %&gt;% \n  ggplot(aes(x = pred, y = Y)) +\n    geom_point(alpha = 0.3) +\n    geom_smooth()\n\n\n\nCompare:\n\nTraining loss\n\nCross-validated loss\n\nLarge discrepancy → overfitting.\n\n\n\nEnsure top predictors are clinically plausible."
  },
  {
    "objectID": "advanced/03-05-advanced-diagnostics.html#weight-diagnostics",
    "href": "advanced/03-05-advanced-diagnostics.html#weight-diagnostics",
    "title": "Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "",
    "text": "For IPTW, MSMs, and censoring weights.\n\n\nsummary(weights)\nquantile(weights, probs = c(0.01, 0.99))\nRed flags:\n\nMean far from 1\n\nVery heavy tail\n\nHuge max weights\n\n\n\n\nggplot(tibble(w = weights), aes(x = w)) +\n  geom_histogram()\n\n\n\nlower &lt;- quantile(weights, 0.01)\nupper &lt;- quantile(weights, 0.99)\nw_trunc &lt;- pmin(pmax(weights, lower), upper)"
  },
  {
    "objectID": "advanced/03-05-advanced-diagnostics.html#sensitivity-analyses-for-unmeasured-confounding",
    "href": "advanced/03-05-advanced-diagnostics.html#sensitivity-analyses-for-unmeasured-confounding",
    "title": "Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "",
    "text": "Measures minimum strength of confounding needed to explain away an effect.\n\n\n\nSimulates impact of:\n\nUnmeasured confounder prevalence\n\nUnmeasured confounder associations\n\nR packages: episensr, causalsens\n\n\n\nFor matched studies.\n\n\n\nLMTP can quantify robustness of static intervention effects."
  },
  {
    "objectID": "advanced/03-05-advanced-diagnostics.html#negative-controls",
    "href": "advanced/03-05-advanced-diagnostics.html#negative-controls",
    "title": "Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "",
    "text": "Negative control outcomes (NCOs):\n\nCausally unrelated to treatment\n\nShare confounding structures\n\nIf TMLE of treatment → NCO ≠ 0 → likely confounding remains.\nExample:\ntmle_nco &lt;- tmle(\n  Y = dat$negative_event,\n  A = dat$treatment,\n  W = dat[, confounders]\n)\nNegative control exposures are also useful."
  },
  {
    "objectID": "advanced/03-05-advanced-diagnostics.html#tmle-specific-diagnostics",
    "href": "advanced/03-05-advanced-diagnostics.html#tmle-specific-diagnostics",
    "title": "Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "",
    "text": "Extreme clever covariate values lead to unstable targeting.\n\n\n\nCheck for warnings in logistic fluctuation:\nglm.fit: algorithm did not converge\n\n\n\nIC &lt;- tmle_fit$ic\nmean(IC); var(IC)\nHeavy tails → avoid Wald intervals, use bootstrap."
  },
  {
    "objectID": "advanced/03-05-advanced-diagnostics.html#longitudinal-diagnostics-lmtp-longitudinal-tmle",
    "href": "advanced/03-05-advanced-diagnostics.html#longitudinal-diagnostics-lmtp-longitudinal-tmle",
    "title": "Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "",
    "text": "Check treatment probabilities at each timepoint.\n\n\n\ncumw &lt;- apply(weight_matrix, 1, prod)\nhist(cumw)\nExtreme cumulative weights → instability.\n\n\n\nTruncate weights at each time step or truncate cumulative weights.\n\n\n\nEnsure intermediate variables are not inappropriate colliders."
  },
  {
    "objectID": "advanced/03-05-advanced-diagnostics.html#recommended-diagnostics-workflow",
    "href": "advanced/03-05-advanced-diagnostics.html#recommended-diagnostics-workflow",
    "title": "Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "",
    "text": "Confirm time-ordering\n\nDraw a DAG\n\nCheck missingness\n\nSummarize covariate distributions by treatment\n\n\n\n\n\nCheck PS overlap\n\nEvaluate weight distributions\n\nInspect Q and g predictions\n\nCheck TMLE targeting step\n\n\n\n\n\nSensitivity analyses\n\nNegative controls\n\nCompare across estimators (IPTW, TMLE, AIPW)\n\nRobustness checks (population restriction, alternative confounder sets)"
  },
  {
    "objectID": "advanced/03-05-advanced-diagnostics.html#summary",
    "href": "advanced/03-05-advanced-diagnostics.html#summary",
    "title": "Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "",
    "text": "To produce defensible causal evidence, diagnostics must be:\n\nSystematic\n\nTransparent\n\nDocumented in the analysis plan\n\nInterpreted with domain expertise\n\nWith these tools, analysts can judge the credibility, robustness, and transportability of causal findings — essential for regulatory, clinical, and scientific decision‑making.\n\n\nCode\nsessionInfo()\n\n\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26200)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.2    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.4.2       htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10      \n [9] rmarkdown_2.29    knitr_1.49        jsonlite_2.0.0    xfun_0.49        \n[13] digest_0.6.37     rlang_1.1.6       evaluate_1.0.5"
  },
  {
    "objectID": "advanced/03-07-longitudinal-td-confounding.html",
    "href": "advanced/03-07-longitudinal-td-confounding.html",
    "title": "Chapter 3.7: Longitudinal Causal Inference and Time-Dependent Confounding",
    "section": "",
    "text": "This is a placeholder. Full chapter content will go here."
  },
  {
    "objectID": "advanced/03-07-longitudinal-td-confounding.html#longitudinal-causal-inference-and-time-dependent-confounding",
    "href": "advanced/03-07-longitudinal-td-confounding.html#longitudinal-causal-inference-and-time-dependent-confounding",
    "title": "Chapter 3.7: Longitudinal Causal Inference and Time-Dependent Confounding",
    "section": "",
    "text": "This is a placeholder. Full chapter content will go here."
  },
  {
    "objectID": "advanced/chapter_covariate_adjustment_tmle.html",
    "href": "advanced/chapter_covariate_adjustment_tmle.html",
    "title": "Chapter X: Covariate Adjustment in RCTs and Precision Gains with TMLE",
    "section": "",
    "text": "This is a placeholder test file to ensure download works."
  },
  {
    "objectID": "advanced/chapter_covariate_adjustment_tmle.html#covariate-adjustment-in-rcts-and-precision-gains-with-tmle",
    "href": "advanced/chapter_covariate_adjustment_tmle.html#covariate-adjustment-in-rcts-and-precision-gains-with-tmle",
    "title": "Chapter X: Covariate Adjustment in RCTs and Precision Gains with TMLE",
    "section": "",
    "text": "This is a placeholder test file to ensure download works."
  },
  {
    "objectID": "advanced/index.html",
    "href": "advanced/index.html",
    "title": "Advanced Targeted Learning Methods",
    "section": "",
    "text": "to add:\n\n-dynamic and stoachastic treatment regimes\n-ltmle labs"
  },
  {
    "objectID": "bibliography/index.html",
    "href": "bibliography/index.html",
    "title": "Annotated Bibliography: Modern Causal Inference and Targeted Learning",
    "section": "",
    "text": "This bibliography introduces key readings in modern causal inference, targeted learning, and real-world evidence generation. Each annotation summarizes why the paper is important and what it contributes to causal reasoning and applied biostatistics.\n\n\nTargeted learning in real-world comparative effectiveness research with time-varying interventions https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6099\n\n\n\n\nDang et al. (2023) – A causal roadmap for generating high-quality real-world evidence.\nIntroduces the Causal Roadmap framework for structuring causal analyses in observational data. Emphasizes transparency, assumptions, and reproducibility in real-world evidence.\nGruber et al. (2023) – Evaluating and improving real-world evidence with Targeted Learning.\nApplies the roadmap to re-analyze published results using TMLE, highlighting the link between causal identification and robust estimation.\nWilliamson et al. (2023) – An application of the Causal Roadmap in two safety monitoring case studies.\nDemonstrates roadmap principles in practice for safety monitoring and outcome prediction using electronic health records.\nHernán & Robins (2016) – Using big data to emulate a target trial when a randomized trial is not available.\nDefines target trial emulation, a cornerstone idea for translating causal inference principles to observational study design.\n\n\n\n\nICH E9 (R1) Addendum (2019) – Addendum on Estimands and Sensitivity Analyses in Clinical Trials.\nEstablishes the estimand framework to align clinical trial objectives, analyses, and interpretations.\nRufibach (2019) – Treatment effect quantification for time-to-event endpoints – Estimands, analysis strategies, and beyond.\nApplies the estimand framework to survival outcomes, clarifying how censoring and non-proportional hazards affect effect interpretation.\n\n\n\n\nvan der Laan, Polley & Hubbard (2007) – Super Learner.\nA foundational paper introducing ensemble learning via cross-validation for optimal prediction and causal estimation.\nPhillips et al. (2023) – Practical considerations for specifying a Super Learner.\nA practical tutorial on constructing and validating Super Learners, including library specification, cross-validation, and reproducibility.\n\n\n\n\nGruber & van der Laan (2010) – Targeted Maximum Likelihood Estimation: A Gentle Introduction.\nProvides a clear step-by-step introduction to TMLE, integrating machine learning and influence function theory for efficient, doubly robust estimation.\n\n\n\n\nPetersen (2014) – Applying a Causal Road Map in Settings with Time-dependent Confounding.\nDiscusses longitudinal causal inference and how to handle time-dependent confounding through g-methods and TMLE.\nStensrud et al. (2019) – Limitations of hazard ratios in clinical trials.\nExplains why hazard ratios can be misleading as causal measures and encourages absolute or survival-based contrasts.\nMartinussen (2022) – Causality and the Cox Regression Model.\nClarifies the mathematical and conceptual limitations of hazard ratios, advocating more interpretable causal estimands.\n\n\n\n\nChakraborty & Murphy (2014) – Dynamic Treatment Regimes.\nA comprehensive overview of adaptive treatment strategies and their estimation through sequential designs and reinforcement learning methods.\nKennedy (2019) – Nonparametric causal effects based on incremental propensity score interventions.\nIntroduces stochastic interventions that shift treatment probabilities incrementally, addressing positivity violations and improving policy relevance.\n\n\n\n\nLendle et al. (2017) – ltmle: An R package implementing targeted ML for longitudinal data.\nPresents practical TMLE tools for longitudinal data in R, connecting theory to applied estimation in complex settings with time-varying confounders.\n\n\n\n\nDang et al. (2023) and Hernán & Robins (2016) – conceptual grounding\n\nvan der Laan et al. (2007) and Gruber & van der Laan (2010) – estimation and implementation\n\nLendle et al. (2017) and Kennedy (2019) – advanced longitudinal and stochastic methods\n\n\n\n\n\n\n01 Causal Intro – Dang et al. (2023)\n\n03 TL Intro – Gruber et al. (2023)\n\nWilliamson et al. (2023)\n\nRufibach (2019)\n\nPracticalSL (Phillips et al., 2023)\n\nGruber & van der Laan (2010)\n\nPetersen (2014)\n\nStensrud (2019)\n\nMartinussen (2022)\n\nKennedy (2019)\n\nLendle et al. (2017)"
  },
  {
    "objectID": "bibliography/index.html#causal-inference-roadmap-and-target-trial-emulation",
    "href": "bibliography/index.html#causal-inference-roadmap-and-target-trial-emulation",
    "title": "Annotated Bibliography: Modern Causal Inference and Targeted Learning",
    "section": "",
    "text": "Dang et al. (2023) – A causal roadmap for generating high-quality real-world evidence.\nIntroduces the Causal Roadmap framework for structuring causal analyses in observational data. Emphasizes transparency, assumptions, and reproducibility in real-world evidence.\nGruber et al. (2023) – Evaluating and improving real-world evidence with Targeted Learning.\nApplies the roadmap to re-analyze published results using TMLE, highlighting the link between causal identification and robust estimation.\nWilliamson et al. (2023) – An application of the Causal Roadmap in two safety monitoring case studies.\nDemonstrates roadmap principles in practice for safety monitoring and outcome prediction using electronic health records.\nHernán & Robins (2016) – Using big data to emulate a target trial when a randomized trial is not available.\nDefines target trial emulation, a cornerstone idea for translating causal inference principles to observational study design."
  },
  {
    "objectID": "bibliography/index.html#estimand-specification-in-clinical-studies",
    "href": "bibliography/index.html#estimand-specification-in-clinical-studies",
    "title": "Annotated Bibliography: Modern Causal Inference and Targeted Learning",
    "section": "",
    "text": "ICH E9 (R1) Addendum (2019) – Addendum on Estimands and Sensitivity Analyses in Clinical Trials.\nEstablishes the estimand framework to align clinical trial objectives, analyses, and interpretations.\nRufibach (2019) – Treatment effect quantification for time-to-event endpoints – Estimands, analysis strategies, and beyond.\nApplies the estimand framework to survival outcomes, clarifying how censoring and non-proportional hazards affect effect interpretation."
  },
  {
    "objectID": "bibliography/index.html#super-learner-ensemble-learning",
    "href": "bibliography/index.html#super-learner-ensemble-learning",
    "title": "Annotated Bibliography: Modern Causal Inference and Targeted Learning",
    "section": "",
    "text": "van der Laan, Polley & Hubbard (2007) – Super Learner.\nA foundational paper introducing ensemble learning via cross-validation for optimal prediction and causal estimation.\nPhillips et al. (2023) – Practical considerations for specifying a Super Learner.\nA practical tutorial on constructing and validating Super Learners, including library specification, cross-validation, and reproducibility."
  },
  {
    "objectID": "bibliography/index.html#targeted-maximum-likelihood-estimation-tmle",
    "href": "bibliography/index.html#targeted-maximum-likelihood-estimation-tmle",
    "title": "Annotated Bibliography: Modern Causal Inference and Targeted Learning",
    "section": "",
    "text": "Gruber & van der Laan (2010) – Targeted Maximum Likelihood Estimation: A Gentle Introduction.\nProvides a clear step-by-step introduction to TMLE, integrating machine learning and influence function theory for efficient, doubly robust estimation."
  },
  {
    "objectID": "bibliography/index.html#time-dependent-confounding-and-intercurrent-events",
    "href": "bibliography/index.html#time-dependent-confounding-and-intercurrent-events",
    "title": "Annotated Bibliography: Modern Causal Inference and Targeted Learning",
    "section": "",
    "text": "Petersen (2014) – Applying a Causal Road Map in Settings with Time-dependent Confounding.\nDiscusses longitudinal causal inference and how to handle time-dependent confounding through g-methods and TMLE.\nStensrud et al. (2019) – Limitations of hazard ratios in clinical trials.\nExplains why hazard ratios can be misleading as causal measures and encourages absolute or survival-based contrasts.\nMartinussen (2022) – Causality and the Cox Regression Model.\nClarifies the mathematical and conceptual limitations of hazard ratios, advocating more interpretable causal estimands."
  },
  {
    "objectID": "bibliography/index.html#dynamic-treatment-regimes-and-stochastic-interventions",
    "href": "bibliography/index.html#dynamic-treatment-regimes-and-stochastic-interventions",
    "title": "Annotated Bibliography: Modern Causal Inference and Targeted Learning",
    "section": "",
    "text": "Chakraborty & Murphy (2014) – Dynamic Treatment Regimes.\nA comprehensive overview of adaptive treatment strategies and their estimation through sequential designs and reinforcement learning methods.\nKennedy (2019) – Nonparametric causal effects based on incremental propensity score interventions.\nIntroduces stochastic interventions that shift treatment probabilities incrementally, addressing positivity violations and improving policy relevance."
  },
  {
    "objectID": "bibliography/index.html#longitudinal-tmle-and-related-methods",
    "href": "bibliography/index.html#longitudinal-tmle-and-related-methods",
    "title": "Annotated Bibliography: Modern Causal Inference and Targeted Learning",
    "section": "",
    "text": "Lendle et al. (2017) – ltmle: An R package implementing targeted ML for longitudinal data.\nPresents practical TMLE tools for longitudinal data in R, connecting theory to applied estimation in complex settings with time-varying confounders.\n\n\n\n\nDang et al. (2023) and Hernán & Robins (2016) – conceptual grounding\n\nvan der Laan et al. (2007) and Gruber & van der Laan (2010) – estimation and implementation\n\nLendle et al. (2017) and Kennedy (2019) – advanced longitudinal and stochastic methods\n\n\n\n\n\n\n01 Causal Intro – Dang et al. (2023)\n\n03 TL Intro – Gruber et al. (2023)\n\nWilliamson et al. (2023)\n\nRufibach (2019)\n\nPracticalSL (Phillips et al., 2023)\n\nGruber & van der Laan (2010)\n\nPetersen (2014)\n\nStensrud (2019)\n\nMartinussen (2022)\n\nKennedy (2019)\n\nLendle et al. (2017)"
  },
  {
    "objectID": "workshop/index.html#step-1a-state-the-question-and-define-the-causal-estimand",
    "href": "workshop/index.html#step-1a-state-the-question-and-define-the-causal-estimand",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "The first step of the Causal Roadmap is to clearly state the scientific question and define the corresponding causal estimand. A helpful way to do this is to explicitly state the hypothetical experiment that would unambiguously yield an estimate of the causal effect of interest.For example, consider the question: What is the effect of denosumab (Prolia) versus zoledronic acid on the risk of myocardial infarction or stroke among postmenopausal women with osteoporosis?\nOne way to formalize this question is to imagine a hypothetical experiment in which all eligible women are assigned to receive denosumab (Prolia), and to compare their myocardial infarction or stroke incidence to what would have been observed had all the same women instead received zoledronic. To sharply define this research question, it is important to be explicit about several components of the hypothetical experiment. These include the target population (e.g., postmenopausal women of a particular age range or geographic region), the exposure or intervention (including dosage, formulation, and frequency), the outcome (and the time window over which it is measured), and the intervention strategies under consideration.\nImportantly, many different hypothetical experiments may be of interest, even within the same clinical context. For instance, one could ask what the difference in myocardial infarction or stroke incidence would be if patients were initiated on denosumab (Prolia) only after reaching a certain cardiovascular risk threshold, compared to initiating denosumab (Prolia) regardless of baseline risk.\nAlternatively, one might consider a policy-relevant estimand, such as the difference in cardiovascular disease incidence if an additional 10% of patients received the intervention compared to if treatment uptake remained at its observed level. These examples highlight that there is substantial flexibility in how hypothetical experiments can be defined.\nOnce a causal question is clearly define, the causal estimand represents the question in mathematical terms must be defined. The ICH E9 (R1) [@ich2019estimand] and Target Trial Emulation [@hernan2016target] frameworks provide detailed guidelines of defining a causal question and estimand."
  },
  {
    "objectID": "workshop/index.html#notes",
    "href": "workshop/index.html#notes",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "Adding something about ICH E9 (R1) estimand framework and target trial emulation"
  },
  {
    "objectID": "workshop/index.html#step-1b-define-the-causal-model",
    "href": "workshop/index.html#step-1b-define-the-causal-model",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "Causal modeling provides a formal way to encode our scientific knowledge, however limited it may be,about how variables relate to one another. By explicitly stating assumptions, causal models allow us to explore which variables affect each other, consider the potential role of unmeasured factors, and reason about the functional form of relationships among variables. In this tutorial, we focus on structural causal models and their corresponding causal graphs as introduced by Pearl (2000). We note, however, that this is only one of several available causal inference frameworks, each with its own strengths and areas of application.\n\nThe figure 1 below corresponds to a simple causal graph with corresponding structural casual model as follows;\n\n\\(W= f_w(U_w)\\)\n\\(A= f_A(W,U_A)\\)\n\\(Y = f_Y(W,A,U_Y)\\)\n\nWe make no assumptions on the background factors \\((U_w,U_A,U_Y)\\) or on the functional forms of functions \\((f_w,f_A,f_Y)\\)\n\n\n\n\n\n\n\n\n\n\n\nIf you believed no unmeasured confounding, a possible causal model and graph (figure 2) would be;\n\n\\(W= f_w(U_w)\\)\n\\(A= f_A(W,U_A)\\)\n\\(Y = f_Y(W,A,U_Y)\\)\n\nHere we assume that the background factors are all independent but still make no assumption on the functional forms of \\((f_w,f_A,f_Y)\\)\nHowever, it is important to note that wishing for something does not make it true.\n\n\n\n\n\n\n\n\n\n\n\nWe now define counterfactuals by intervening on the causal model. We can do this by setting the exposure to a specific level e.g A=1 for all units.\n\n\\(W= f_w(U_w)\\)\n\\(A= 1\\)\n\\(Y_1 = f_Y(W,1,U_Y)\\) where \\(Y_1\\) is the outcome if possibly-contrary to fact, the unit was exposed (A=1)\n\n\n\n\n\n\n\n\n\n\n\n\nAnalogously, we can intervene on the causal model by setting A=0\n\n\\(W= f_w(U_w)\\)\n\\(A= 0\\)\n\\(Y_0 = f_Y(W,0,U_Y)\\) where \\(Y_0\\) is the outcome if possibly-contrary to fact, the unit was exposed (A=0)\n\n\n\n\n\n\n\n\n\n\n\nWe use counterfactual outcomes to formally define causal parameters. For example, one common estimand is the average treatment effect (ATE), defined as the difference between the expected outcomes under two interventions i.e \\(\\mathbb{E}[Y_1]-\\mathbb{E}[Y_0]\\).When the outcome is binary, this contrast is often expressed as the causal risk difference (CRD) given by \\(\\mathbb{P}(Y_1=1)-\\mathbb{P}(Y_0=1)\\).\nImportantly, these are just two examples. Many other causal parameters can be defined depending on the scientific question of interest, the outcome type, and the decision context."
  },
  {
    "objectID": "workshop/index.html#step-2-link-to-observed-data",
    "href": "workshop/index.html#step-2-link-to-observed-data",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "We denote the observed data by O=(W,A,Y), where W represents measured covariates, A is the exposure, and Y is the outcome. We assume that the causal model describes the data-generating process both under the existing conditions of the real world (the observed data) and under hypothetical interventions (the counterfactual world).This provides a link between the causal world and the observed world.\nAs a result, the causal model implies a statistical model, defined as the set of possible probability distributions for the observed data. The causal model may but often does not place any restrictions on the statistical model in which case the statistical model is non parametric.For example, a causal model may state that the exposure A,is generated as a function of covariates W, and unmeasured factors \\(U_A\\), written as A= \\(f_A(W,U_A)\\) but does not specify the functional form of \\(f_A\\).If substantive knowledge justifies a particular functional form, that information should be encoded explicitly in the causal model; otherwise, the model remains agnostic, leading to a flexible, nonparametric statistical model."
  },
  {
    "objectID": "workshop/index.html#step-3-assess-identifiablity",
    "href": "workshop/index.html#step-3-assess-identifiablity",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "This step of the roadmap involves linking the causal effect to the parameter estimable from observed data. This requires some assumptions as follows:\n\nTemporality: exposure precedes the outcome. This is indicated by an arrow on the causal graph from A to Y\nConsistency: \\(Y_a\\)=Y where A=a. If an individual received treatment A=a, then their observed outcome Y is equal to their potential outcome under that treatment \\(Y_a\\).\nStability: We require no interference between units. This is indicated by the fact that the outcomes Y are only a function of each unit’s exposure A in the causal model and graph.\nRandomization:No unmeasured confounding such that \\(Y_a \\perp A \\mid W\\)\nPositivity: We require sufficient variability in exposure within confounder values i.e. \\(0 &lt; \\mathbb{P}(A=1|W)&lt;1\\)."
  },
  {
    "objectID": "workshop/index.html#step-4-define-the-statistical-estimand",
    "href": "workshop/index.html#step-4-define-the-statistical-estimand",
    "title": "Workshop: The Causal Roadmap and TMLE in Pharmacoepidemiology",
    "section": "",
    "text": "Under these assumptions, we can express our causal target parameter—which is defined in terms of counterfactuals as a function of the observed data. Specifically i.e \\[\n    \\begin{aligned}\n    \\mathbb{E}(Y_a)\n      &= \\mathbb{E}\\big[ \\mathbb{E}(Y_a \\mid W) \\big] \\\\\n      &= \\mathbb{E}\\big[ \\mathbb{E}(Y_a \\mid A=a, W) \\big]  under \\ randomization\\\\\n      &= \\mathbb{E}\\big[ \\mathbb{E}(Y \\mid A=a, W) \\big] under \\ consistency\n    \\end{aligned}\n    \\]\nOf course, simply wishing these assumptions to hold does not make them true. Their plausibility must be carefully assessed using subject-matter knowledge, study design considerations, and an understanding of the data-generating process.\nWhen the assumptions are deemed reasonable, we obtain the G-computation identifiability result (Robins, 1986). In particular, the average treatment effect can be written as \\(\\mathbb{E}[Y_1-Y_0] = \\mathbb{E}\\big[\\mathbb{E}(Y\\mid A=1,W)-\\mathbb{E}(Y\\mid A=0,W)]\\) where the right-hand side is a function of the observed data distribution and therefore defines our statistical estimand. For a binary outcome, this corresponds to the marginal risk difference, $$. This is marginal because the outer expectation averages over the confounder distribution.\nFinally, it is important to consider what happens when one or more of the identifying assumptions may not hold—for example, if there is concern about unmeasured confounding or if the data structure does not clearly establish temporality. In such cases, possible options include:\n\nGiving up (rarely the most satisfying choice)\nChanging the research question, the exposure, the outcome or the target population\nProceeding to do the best job possible estimating the target parameter provided the question is still well-defined and interpretable and that we can still get as close as possible to the wished for causal parameter given the limitations in the data."
  }
]