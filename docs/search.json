[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Causal Learning Handbook",
    "section": "",
    "text": "Welcome!\nThis handbook introduces the Causal Roadmap, Targeted Maximum Likelihood Estimation (TMLE), and Super Learner for modern causal inference in epidemiology, with an emphasis on pharmacoepidemiology and clinical trial analysis. Each chapter builds on the previous ones, progressing from foundational concepts to advanced methods with worked R code examples throughout.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Causal Learning Handbook</span>"
    ]
  },
  {
    "objectID": "index.html#how-to-use-this-book",
    "href": "index.html#how-to-use-this-book",
    "title": "Causal Learning Handbook",
    "section": "0.1 How to use this book",
    "text": "0.1 How to use this book\nThe chapters are organized into three parts plus appendices. Part I builds the conceptual foundations you need before running any estimator. Part II walks through each major estimation strategy with hands-on code. Part III covers advanced topics that extend these methods to realistic, complex settings. You can read the book front-to-back or jump to specific chapters as needed.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Causal Learning Handbook</span>"
    ]
  },
  {
    "objectID": "index.html#part-i-foundations",
    "href": "index.html#part-i-foundations",
    "title": "Causal Learning Handbook",
    "section": "0.2 Part I: Foundations",
    "text": "0.2 Part I: Foundations\nThese chapters establish the conceptual framework for causal inference — why standard regression is not enough, how the Causal Roadmap structures an analysis, and how we formally link causal questions to quantities we can estimate from data.\n\n\n\nChapter\nDescription\n\n\n\n\n1.1 Regression vs. Causal Inference\nWhy regression coefficients are not causal effects, and what the counterfactual framework offers instead.\n\n\n1.2 The Causal Roadmap\nThe six-step Causal Roadmap for structuring any causal analysis: from question to interpretation.\n\n\n1.3 Identification and Estimands\nFormal identification assumptions (consistency, exchangeability, positivity) and how to translate causal parameters into statistical estimands.\n\n\nCausal Roadmap Tutorial\nAn interactive, end-to-end walkthrough of the Causal Roadmap applied to a pharmacoepidemiology example, with full R code for g-computation, IPTW, and TMLE.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Causal Learning Handbook</span>"
    ]
  },
  {
    "objectID": "index.html#part-ii-estimation-methods",
    "href": "index.html#part-ii-estimation-methods",
    "title": "Causal Learning Handbook",
    "section": "0.3 Part II: Estimation Methods",
    "text": "0.3 Part II: Estimation Methods\nThese chapters cover the core estimation approaches for causal inference, from outcome modeling to doubly robust methods, with progressive worked examples in R.\n\n\n\nChapter\nDescription\n\n\n\n\n2.1 G-Computation\nOutcome modeling and standardization: fit a model for \\(E[Y \\mid A, W]\\), predict under interventions, and average to get marginal causal effects.\n\n\n2.2 Inverse Probability of Treatment Weighting\nPropensity-score-based estimation: reweight the sample to create a pseudo-population where treatment is independent of confounders. Covers stabilized weights, truncation, and diagnostics.\n\n\n2.3 Doubly Robust Estimation and TMLE\nAIPW and TMLE side by side: why combining outcome and treatment models gives you two chances to get it right, with efficient influence curve–based inference.\n\n\n2.4 From Question to Estimate — TMLE in Practice\nA progressive, illustrated walkthrough comparing naive, g-computation, IPTW, AIPW, and TMLE estimators on a single cardiovascular safety dataset. Includes diagnostic checks and Super Learner integration.\n\n\nSuperLearner and Machine Learning\nHow ensemble machine learning (SuperLearner) improves nuisance function estimation for causal inference: cross-validation, loss functions, library specification, and integration with TMLE.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Causal Learning Handbook</span>"
    ]
  },
  {
    "objectID": "index.html#part-iii-advanced-topics",
    "href": "index.html#part-iii-advanced-topics",
    "title": "Causal Learning Handbook",
    "section": "0.4 Part III: Advanced Topics",
    "text": "0.4 Part III: Advanced Topics\nThese chapters extend the core methods to realistic settings: longitudinal data with time-varying confounding, effect modification, advanced diagnostics, hybrid trial–observational designs, and mediation analysis.\n\n\n\nChapter\nDescription\n\n\n\n\n3.3 Longitudinal Case Study\nA worked case study applying the Causal Roadmap to a longitudinal pharmacoepidemiology setting with time-varying confounding (denosumab vs. zoledronic acid).\n\n\n3.4 Effect Modification\nConditional average treatment effects (CATE), TMLE-based subgroup analyses, and causal forests for heterogeneous treatment effect estimation.\n\n\n3.5 Advanced Diagnostics\nE-values, quantitative bias analysis, negative control outcomes and exposures, influence curve diagnostics, and calibration checks for causal analyses.\n\n\n3.6 RWD Meets RCT: Hybrid Designs\nExternal control arms, transportability, ES-CV-TMLE, and A-TMLE for combining randomized and real-world data sources.\n\n\n3.7 Imperfect Adherence and Longitudinal TMLE\nTime-dependent confounding affected by prior treatment, and longitudinal TMLE (L-TMLE) for treatment-policy and per-protocol estimands.\n\n\n3.8 TMLE in the Clean-Room Framework\nA from-scratch, pedagogical implementation of TMLE with no package dependencies — every step transparent and annotated.\n\n\n3.9 An Illustrated Guide to Longitudinal TMLE\nA visual, step-by-step guide to L-TMLE: backwards sequential regression, cumulative treatment probabilities, and time-step-specific targeting, following the KH Stats style.\n\n\n3.10 TMLE for Mediation Analysis\nNatural direct and indirect effects via TMLE: density ratio clever covariates, Monte Carlo integration, and cross-world assumptions for mediation decomposition.\n\n\n3.11 Estimands in Time-to-Event Safety Analyses\nHow treatment-policy, while-on-treatment, and hypothetical estimand strategies change what a safety analysis measures, with simulation-based comparisons of KM, IPCW, and TMLE estimators.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Causal Learning Handbook</span>"
    ]
  },
  {
    "objectID": "index.html#appendices",
    "href": "index.html#appendices",
    "title": "Causal Learning Handbook",
    "section": "0.5 Appendices",
    "text": "0.5 Appendices\n\n\n\nChapter\nDescription\n\n\n\n\nCommon Pitfalls\nA catalog of the most frequent mistakes in causal inference — from confusing association with causation to ignoring positivity violations — and how to avoid them.\n\n\nAnnotated Bibliography\nKey readings in causal inference, targeted learning, and real-world evidence generation, with annotations summarizing each paper’s contribution.\n\n\nOther Resources\nLinks to external courses, tutorials, and reference sites for further learning.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Causal Learning Handbook</span>"
    ]
  },
  {
    "objectID": "index.html#package-installations",
    "href": "index.html#package-installations",
    "title": "Causal Learning Handbook",
    "section": "0.6 Package installations",
    "text": "0.6 Package installations\nTo run the code examples in this book, install the following R packages:\n\n## Core CRAN packages\ncran_pkgs &lt;- c(\n  \"tidyverse\", \"here\", \"sandwich\", \"lmtest\", \"Matrix\", \"survival\"\n)\n\n## Super Learner ecosystem\nsl_pkgs &lt;- c(\n  \"SuperLearner\", \"glmnet\", \"gam\", \"ranger\", \"randomForest\", \"xgboost\"\n)\n\n## Targeted Learning and causal inference\ncausal_pkgs &lt;- c(\n  \"tmle\", \"ltmle\", \"lmtp\", \"hal9001\", \"origami\"\n)\n\n## Diagnostics and sensitivity analysis\ndiagnostic_pkgs &lt;- c(\"EValue\", \"episensr\", \"causalsens\")\n\n## Combine and install missing packages\nall_pkgs &lt;- unique(c(cran_pkgs, sl_pkgs, causal_pkgs, diagnostic_pkgs))\ninstalled &lt;- rownames(installed.packages())\nto_install &lt;- setdiff(all_pkgs, installed)\n\nif (length(to_install) &gt; 0) {\n  install.packages(to_install, dependencies = TRUE)\n}",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Causal Learning Handbook</span>"
    ]
  },
  {
    "objectID": "01-01-regression-vs-causal.html",
    "href": "01-01-regression-vs-causal.html",
    "title": "2  Chapter 1.1: Limitations of Standard Regression Analyses",
    "section": "",
    "text": "2.1 Why Not Just Use Regression?\nIn this chapter, we motivate the need for modern causal inference tools by walking through real-world examples where traditional regression fails. We also introduce the counterfactual (potential outcomes) framework as the foundation for defining causal effects.\nLet’s consider a motivating example based on a real-world study comparing two osteoporosis treatments: denosumab (Prolia) and zoledronic acid.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Chapter 1.1: Limitations of Standard Regression Analyses</span>"
    ]
  },
  {
    "objectID": "01-01-regression-vs-causal.html#why-not-just-use-regression",
    "href": "01-01-regression-vs-causal.html#why-not-just-use-regression",
    "title": "2  Chapter 1.1: Limitations of Standard Regression Analyses",
    "section": "",
    "text": "The “Just Run a Regression” Trap\n\n\n\nMultivariable regression has long been the standard tool in observational research for “adjusting” for confounders. But regression coefficients don’t always represent causal effects. In fact, they almost never do without additional assumptions and deliberate analytic choices that go beyond what standard regression provides.\nIf you’ve been trained to interpret an adjusted regression coefficient as “the effect of X on Y, holding all else equal,” you’re in good company — but that interpretation quietly smuggles in causal language that the model itself cannot justify. The coefficient tells you about the conditional association within strata defined by the other variables in the model. Whether that association equals a causal effect depends on assumptions that regression alone cannot verify.\n\n\n\n\n2.1.1 Motivating Example: Comparing Osteoporosis Treatments\nImagine we’re interested in whether patients who initiate denosumab have higher 3-year risk of heart attack or stroke compared to those initiating zoledronic acid.\nWe might be tempted to run the following:\n\n# simulate crude comparison (not real data)\nset.seed(123)\nn &lt;- 2000\ntreatment &lt;- rbinom(n, 1, 0.5) # 1 = denosumab, 0 = zoledronic acid\nage &lt;- rnorm(n, 75, 6)\ncvd_history &lt;- rbinom(n, 1, plogis(0.1 * (age - 70)))\n\n# outcome depends on age and history\nrisk &lt;- plogis(-2 + 0.4 * treatment + 0.05 * (age - 70) + 1 * cvd_history)\noutcome &lt;- rbinom(n, 1, risk)\n\nmodel1 &lt;- glm(outcome ~ treatment, family = binomial)\nsummary(model1)\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = outcome ~ treatment, family = binomial)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) -1.05939    0.07197 -14.720  &lt; 2e-16 ***\n#&gt; treatment    0.33425    0.09887   3.381 0.000723 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 2414.0  on 1999  degrees of freedom\n#&gt; Residual deviance: 2402.5  on 1998  degrees of freedom\n#&gt; AIC: 2406.5\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\nWhat the Crude Estimate Conflates\n\n\n\nThis crude estimate of association is confounded by differences in age and comorbidities between the treatment groups. Because older patients and those with cardiovascular disease history may be preferentially channeled toward one treatment over another, the crude coefficient bundles together (1) any true treatment effect, (2) the influence of age on the outcome, and (3) the influence of CVD history on the outcome. You cannot disentangle these from a simple unadjusted regression — the estimate is a mixture of the treatment’s association with the outcome and the confounders’ effects. This is the classic confounding bias problem that motivates adjustment, but as we will see, adjustment alone is not enough.\n\n\n\n\n2.1.2 Adjusting for Confounders\nWe add adjustment:\n\nmodel2 &lt;- glm(outcome ~ treatment + age + cvd_history, family = binomial)\nsummary(model2)\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = outcome ~ treatment + age + cvd_history, family = binomial)\n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) -6.398207   0.694981  -9.206  &lt; 2e-16 ***\n#&gt; treatment    0.366412   0.103506   3.540    4e-04 ***\n#&gt; age          0.060479   0.009213   6.564 5.22e-11 ***\n#&gt; cvd_history  1.090838   0.121918   8.947  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 2414.0  on 1999  degrees of freedom\n#&gt; Residual deviance: 2223.1  on 1996  degrees of freedom\n#&gt; AIC: 2231.1\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\nThe Adjusted Coefficient Is Still NOT a Causal Effect\n\n\n\nEven after adjustment, the treatment coefficient from logistic regression is a conditional log-odds ratio — it tells you how the log-odds of the outcome change when comparing treated vs. untreated individuals who share the same values of age and CVD history. This is fundamentally different from a marginal causal effect (like a risk difference or risk ratio averaged over the whole population).\nHere is why this matters for your research:\n\nConditional vs. marginal: The conditional log-odds ratio describes an association within strata. The marginal risk difference describes what would happen at the population level if everyone were treated vs. if everyone were untreated. These answer different questions, and in nonlinear models (like logistic regression), they are generally not equal — even if the model is correctly specified.\nNon-collapsibility of the odds ratio: Even without confounding, a conditional odds ratio and a marginal odds ratio will differ. This is a mathematical property of the odds ratio, not a bias — but it means you cannot simply interpret the adjusted odds ratio as “the population-level effect.”\nParametric assumptions baked in: The model assumes the effect of age is log-linear, that there are no treatment-covariate interactions, and that the logistic link is correct. If any of these are wrong, the coefficient is biased for any causal quantity.\n\nBottom line: adjustment gets you closer, but the regression coefficient from a logistic model is not, in general, the average treatment effect you are looking for.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Chapter 1.1: Limitations of Standard Regression Analyses</span>"
    ]
  },
  {
    "objectID": "01-01-regression-vs-causal.html#enter-the-counterfactual-framework",
    "href": "01-01-regression-vs-causal.html#enter-the-counterfactual-framework",
    "title": "2  Chapter 1.1: Limitations of Standard Regression Analyses",
    "section": "2.2 Enter the Counterfactual Framework",
    "text": "2.2 Enter the Counterfactual Framework\n\n\n\n\n\n\nDefining Causal Effects with Potential Outcomes\n\n\n\nTo define a causal effect precisely, we introduce counterfactual (potential) outcomes. For each person in the study, we imagine two hypothetical worlds:\n\nY(1): the outcome that would occur if the person received denosumab\nY(0): the outcome that would occur if the person received zoledronic acid\n\nThe individual causal effect is Y(1) - Y(0) for a single person. The average treatment effect (ATE) is the population average of these individual effects:\n\\[\nATE = E[Y(1) - Y(0)]\n\\]\nThe fundamental problem of causal inference is that each person only receives one treatment — we observe Y(1) or Y(0), never both. The counterfactual under the other treatment is missing data.\nUnder three key identification assumptions — exchangeability (no unmeasured confounding), consistency (the observed outcome under the treatment actually received equals the potential outcome), and positivity (every individual has a nonzero probability of receiving either treatment given their covariates) — we can identify the causal ATE from observed data using the g-computation formula:\n\\[\nATE = E_W\\big[ E[Y \\mid A = 1, W] - E[Y \\mid A = 0, W] \\big]\n\\]\nwhere W represents the measured confounders and A is the treatment. This expression says: within each confounder stratum, compute the difference in expected outcomes between treated and untreated, then average over the distribution of confounders in the population.\nThis formula motivates standardization (g-computation), inverse probability of treatment weighting (IPTW), and targeted minimum loss-based estimation (TMLE) — all of which are designed to estimate this population-level causal quantity.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Chapter 1.1: Limitations of Standard Regression Analyses</span>"
    ]
  },
  {
    "objectID": "01-01-regression-vs-causal.html#when-regression-fails",
    "href": "01-01-regression-vs-causal.html#when-regression-fails",
    "title": "2  Chapter 1.1: Limitations of Standard Regression Analyses",
    "section": "2.3 When Regression Fails",
    "text": "2.3 When Regression Fails\n\n\n\n\n\n\nModel Misspecification Can Silently Bias Your Results\n\n\n\nEven if we include the right confounders, regression can still give misleading answers if the functional form is wrong. Standard regression assumes specific relationships — linearity on the log-odds scale, no interactions between treatment and covariates, and correct specification of how confounders relate to the outcome. In practice, these assumptions are rarely checked and often violated.\nThe danger is that misspecification bias is silent: the model will still produce coefficients, standard errors, and p-values. Nothing in the output warns you that the answer is wrong. This is one of the strongest motivations for using more flexible, semiparametric estimators (like TMLE with machine learning) that can relax these assumptions.\n\n\nLet’s compare regression to a nonparametric substitution estimator (g-computation):\n\n# Fit model\nmodel3 &lt;- glm(outcome ~ treatment + age + cvd_history, family = binomial)\n\n# Predict counterfactual outcomes\nnewdata1 &lt;- data.frame(treatment = 1, age = age, cvd_history = cvd_history)\np1 &lt;- predict(model3, newdata = newdata1, type = \"response\")\n\nnewdata0 &lt;- data.frame(treatment = 0, age = age, cvd_history = cvd_history)\np0 &lt;- predict(model3, newdata = newdata0, type = \"response\")\n\n# Estimate marginal risk difference\nmean(p1 - p0)  # this is g-computation\n#&gt; [1] 0.06897059\n\n\n\n\n\n\n\nWhy G-Computation Gives You a Population-Level Causal Effect\n\n\n\nThe g-computation procedure above does something fundamentally different from reading off a regression coefficient — even though it uses the same regression model under the hood.\nHere is the key insight: instead of reporting a conditional coefficient, g-computation predicts what would happen to every person in the dataset under treatment (A = 1) and under control (A = 0), then averages the difference across the whole population. This is the standardization step, and it maps directly onto the g-computation formula from the counterfactual framework.\nThe result is a marginal risk difference — the estimated change in population-level risk if everyone were treated with denosumab versus if everyone were treated with zoledronic acid. This is the quantity that policymakers, clinicians, and patients actually care about.\nBy contrast, the regression coefficient coef(model3)[\"treatment\"] gives you a conditional log-odds ratio, which lives on a different scale, answers a different question, and (because the odds ratio is non-collapsible) cannot be directly translated into a population-level effect.\n\n\nCompare this to the regression coefficient:\n\ncoef(model3)[\"treatment\"]\n#&gt; treatment \n#&gt; 0.3664119\n\nThe coefficient gives you a conditional odds ratio, but the g-comp version gives you a marginal risk difference — a more interpretable, population-level quantity.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Chapter 1.1: Limitations of Standard Regression Analyses</span>"
    ]
  },
  {
    "objectID": "01-01-regression-vs-causal.html#summary",
    "href": "01-01-regression-vs-causal.html#summary",
    "title": "2  Chapter 1.1: Limitations of Standard Regression Analyses",
    "section": "2.4 Summary",
    "text": "2.4 Summary\n\n\n\n\n\n\nKey Takeaways\n\n\n\n\nRegression is not inherently causal — it estimates conditional associations under strong model assumptions. An adjusted coefficient is not the same as a causal effect.\nCausal inference starts with a question, not a model — define your causal question and target estimand (e.g., the ATE on the risk difference scale) before choosing an analytic method.\nThe counterfactual framework clarifies what we want to estimate — Y(1), Y(0), and the ATE give us precise, model-free definitions of causal effects.\nG-computation, IPTW, and TMLE estimate marginal causal effects — these methods target the population-level quantity defined by the g-computation formula, rather than relying on regression coefficients that conflate the estimand with the model.\nThe conditional log-odds ratio from logistic regression is not the ATE — this is perhaps the single most important distinction for epidemiologists moving from traditional regression to causal inference methods.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Chapter 1.1: Limitations of Standard Regression Analyses</span>"
    ]
  },
  {
    "objectID": "01-01-regression-vs-causal.html#next",
    "href": "01-01-regression-vs-causal.html#next",
    "title": "2  Chapter 1.1: Limitations of Standard Regression Analyses",
    "section": "2.5 Next",
    "text": "2.5 Next\nIn the next chapter, we’ll introduce the Causal Roadmap — a structured workflow for planning and executing causal analyses.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Chapter 1.1: Limitations of Standard Regression Analyses</span>"
    ]
  },
  {
    "objectID": "01-01-regression-vs-causal.html#sources-and-further-reading",
    "href": "01-01-regression-vs-causal.html#sources-and-further-reading",
    "title": "2  Chapter 1.1: Limitations of Standard Regression Analyses",
    "section": "2.6 Sources and further reading",
    "text": "2.6 Sources and further reading\n\nHernan MA, Robins JM (2020). Causal Inference: What If. Chapman & Hall/CRC. Free online\nGreenland S, Pearl J, Robins JM (1999). Causal diagrams for epidemiologic research. Epidemiology 10(1):37-48.\nPearl J (2009). Causality: Models, Reasoning, and Inference. 2nd ed. Cambridge University Press.\nWestreich D, Greenland S (2013). The table 2 fallacy: presenting and interpreting confounder and modifier coefficients. Am J Epidemiol 177(4):292-298.\nvan der Laan MJ, Rose S (2011). Targeted Learning. Springer.\nPetersen ML, van der Laan MJ (2014). Causal models and learning from data. Epidemiology 25(3):418-426.\ntmle R package: CRAN\nSuperLearner R package: CRAN",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Chapter 1.1: Limitations of Standard Regression Analyses</span>"
    ]
  },
  {
    "objectID": "01-01-regression-vs-causal.html#software-implementation-r",
    "href": "01-01-regression-vs-causal.html#software-implementation-r",
    "title": "2  Chapter 1.1: Limitations of Standard Regression Analyses",
    "section": "2.7 Software Implementation (R)",
    "text": "2.7 Software Implementation (R)\nThis example uses the tmle package to estimate the average treatment effect (ATE) for a point treatment, and contrasts the result with a naive regression coefficient.\n\nSimulate a simple confounded dataset: \\(W\\) causes both \\(A\\) and \\(Y\\)\nNaive regression of \\(Y\\) on \\(A\\) (ignoring confounding) yields a biased coefficient\nThe tmle package estimates the ATE using outcome modeling + targeting\nCompare: the naive coefficient ≠ the causal ATE\n\n\nset.seed(1)\nn &lt;- 500\nW &lt;- rnorm(n)\nA &lt;- rbinom(n, 1, plogis(0.5 * W))\nY &lt;- 0.8 * A + 1.2 * W + rnorm(n, sd = 0.5)  # true ATE = 0.8\n\n## ── Naive regression (biased) ──\nnaive_fit &lt;- lm(Y ~ A)\ncat(\"Naive regression coefficient on A:\", round(coef(naive_fit)[\"A\"], 3), \"\\n\")\n\n## ── TMLE (targets the ATE) ──\nif (requireNamespace(\"tmle\", quietly = TRUE)) {\n  library(tmle)\n  tmle_fit &lt;- tmle(\n    Y = Y, A = A,\n    W = data.frame(W = W),\n    Q.SL.library = \"SL.glm\",\n    g.SL.library  = \"SL.glm\"\n  )\n  cat(\"TMLE ATE estimate:\", round(tmle_fit$estimates$ATE$psi, 3), \"\\n\")\n  cat(\"95% CI:\", round(tmle_fit$estimates$ATE$CI, 3), \"\\n\")\n} else {\n  message(\"Install the 'tmle' package:  install.packages('tmle')\")\n}",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Chapter 1.1: Limitations of Standard Regression Analyses</span>"
    ]
  },
  {
    "objectID": "01-02-causal-roadmap.html",
    "href": "01-02-causal-roadmap.html",
    "title": "3  Chapter 1.2: The Causal Roadmap",
    "section": "",
    "text": "3.1 A Simple Simulated Example\nIn this chapter, we introduce the Causal Roadmap, a structured approach for asking and answering causal questions with observational data. The roadmap helps researchers define their scientific question, translate it into a formal causal model, assess whether the causal effect is identifiable from data, and choose appropriate estimators to answer that question.\nWe’ll simulate a small dataset to show how steps 1-5 look in practice.\nset.seed(42)\nn &lt;- 1000\nage &lt;- rnorm(n, 75, 6)\ncvd_history &lt;- rbinom(n, 1, plogis(0.1 * (age - 70)))\nW &lt;- data.frame(age, cvd_history)\nA &lt;- rbinom(n, 1, plogis(-1 + 0.05 * (age - 70) + 1.5 * cvd_history))\nY &lt;- rbinom(n, 1, plogis(-2 + 0.4 * A + 0.1 * (age - 70) + 1 * cvd_history))\ndata &lt;- data.frame(W, A, Y)\nEstimate ATE using g-computation:\nmodel &lt;- glm(Y ~ A + age + cvd_history, family = binomial, data = data)\nnewdata1 &lt;- transform(data, A = 1)\nnewdata0 &lt;- transform(data, A = 0)\np1 &lt;- predict(model, newdata = newdata1, type = \"response\")\np0 &lt;- predict(model, newdata = newdata0, type = \"response\")\nmean(p1 - p0)\n#&gt; [1] 0.1206902",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 1.2: The Causal Roadmap</span>"
    ]
  },
  {
    "objectID": "01-02-causal-roadmap.html#a-simple-simulated-example",
    "href": "01-02-causal-roadmap.html#a-simple-simulated-example",
    "title": "3  Chapter 1.2: The Causal Roadmap",
    "section": "",
    "text": "Interpreting the G-Computation Result\n\n\n\nThe number produced by mean(p1 - p0) is the estimated average causal risk difference. In plain language: it tells you how much the probability of the outcome (e.g., a cardiovascular event) would change, on average, if everyone in the study population had received treatment (A = 1) compared to if everyone had received no treatment (A = 0). For example, a value of 0.07 means that treatment is estimated to increase the risk of the outcome by 7 percentage points on average across the population, after adjusting for age and CVD history. This is the core quantity that g-computation targets—a population-level “what if” comparison.\n\n\n\n\n\n\n\n\n\nSummary\n\n\n\nThe Causal Roadmap gives a rigorous framework for designing and evaluating real-world effect estimates. Before choosing a statistical method, start with the science: - Define your causal question - Specify your model and assumptions - Decide how to express the effect - Choose a transparent, defensible method\nIn the next chapter, we’ll explore different estimation strategies in detail.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 1.2: The Causal Roadmap</span>"
    ]
  },
  {
    "objectID": "01-02-causal-roadmap.html#sources-and-further-reading",
    "href": "01-02-causal-roadmap.html#sources-and-further-reading",
    "title": "3  Chapter 1.2: The Causal Roadmap",
    "section": "3.2 Sources and further reading",
    "text": "3.2 Sources and further reading\n\nDang LE, Tager I, Petersen ML (2023). A causal roadmap for generating high-quality real-world evidence. Journal of Clinical and Translational Science 7(1):e127.\nHernan MA, Robins JM (2016). Using big data to emulate a target trial when a randomized trial is not available. Am J Epidemiol 183(8):758-764.\nPetersen ML, van der Laan MJ (2014). Causal models and learning from data. Epidemiology 25(3):418-426.\nHernan MA, Robins JM (2020). Causal Inference: What If. Chapman & Hall/CRC. Free online\nGruber S, van der Laan MJ (2010). A targeted maximum likelihood estimator of a causal effect on a bounded continuous outcome. Int J Biostat 6(1):Article 26.\nICH E9 (R1) Addendum (2019). Addendum on estimands and sensitivity analyses in clinical trials.\nvan der Laan MJ, Rose S (2011). Targeted Learning. Springer.\ntmle R package: CRAN",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 1.2: The Causal Roadmap</span>"
    ]
  },
  {
    "objectID": "01-02-causal-roadmap.html#software-implementation-r",
    "href": "01-02-causal-roadmap.html#software-implementation-r",
    "title": "3  Chapter 1.2: The Causal Roadmap",
    "section": "3.3 Software Implementation (R)",
    "text": "3.3 Software Implementation (R)\nThis example maps the six-step Causal Roadmap to a single tmle call. Each comment below labels the roadmap step that the corresponding code addresses.\n\nStep 1 (Question): Average treatment effect of a binary exposure on a continuous outcome\nStep 2 (Causal model): Observed data \\((W, A, Y)\\); \\(W\\) confounds \\(A \\to Y\\)\nStep 3 (Assumptions): Consistency, exchangeability given \\(W\\), positivity\nStep 4 (Estimand): \\(\\psi = E[E(Y \\mid A=1, W)] - E[E(Y \\mid A=0, W)]\\)\nSteps 5–6 (Estimation + Inference): TMLE with Super Learner for \\(Q\\) and \\(g\\)\n\n\nset.seed(1)\nn &lt;- 500\n\n## ── Step 2: Simulate from a causal model ──\nW1 &lt;- rnorm(n)\nW2 &lt;- rbinom(n, 1, 0.4)\nA  &lt;- rbinom(n, 1, plogis(-0.5 + 0.6 * W1 + 0.3 * W2))\nY  &lt;- A + 0.8 * W1 - 0.5 * W2 + rnorm(n)  # true ATE = 1.0\n\n## ── Steps 5–6: Estimation and inference via TMLE ──\nif (requireNamespace(\"tmle\", quietly = TRUE)) {\n  library(tmle)\n  tmle_fit &lt;- tmle(\n    Y = Y, A = A,\n    W = data.frame(W1 = W1, W2 = W2),\n    Q.SL.library = c(\"SL.glm\", \"SL.mean\"),\n    g.SL.library  = c(\"SL.glm\", \"SL.mean\")\n  )\n  cat(\"Roadmap Step 5 – TMLE ATE:\", round(tmle_fit$estimates$ATE$psi, 3), \"\\n\")\n  cat(\"Roadmap Step 6 – 95% CI: \", round(tmle_fit$estimates$ATE$CI, 3), \"\\n\")\n} else {\n  message(\"Install the ‘tmle’ package:  install.packages(‘tmle’)\")\n}",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Chapter 1.2: The Causal Roadmap</span>"
    ]
  },
  {
    "objectID": "01-03-identification-estimands.html",
    "href": "01-03-identification-estimands.html",
    "title": "4  Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models",
    "section": "",
    "text": "5 1. What Does It Mean to Identify a Causal Effect?\nIn this chapter, we connect the causal estimand—the quantity that answers our scientific question—to a statistical estimand, which is something we can estimate from observed data. This is the crucial middle step of the Causal Roadmap: translating what we want to know into what we can learn from the dataset at hand.\nWe will walk carefully through: - Identification: when causal effects are estimable from data - Statistical estimands: mapping causal parameters to observable quantities - Positivity, consistency, and exchangeability in practice - Why regression coefficients are not causal effects - How to compute identified estimands using real R code\nThe three key assumptions required for identification are:",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models</span>"
    ]
  },
  {
    "objectID": "01-03-identification-estimands.html#overlap-check",
    "href": "01-03-identification-estimands.html#overlap-check",
    "title": "4  Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models",
    "section": "10.1 6.1 Overlap check",
    "text": "10.1 6.1 Overlap check\n\n\n\n\n\n\nWhat Positivity Violations Look Like in Practice\n\n\n\nThe propensity score plot below is your primary diagnostic for positivity. You are looking for red flags in the distribution of estimated propensity scores:\n\nMass piling up near 0 or 1: This means some patients have a near-certain probability of receiving (or not receiving) treatment given their covariates. These are practical positivity violations – the data contain little or no information about what would happen if these patients received the other treatment.\nPoor overlap between treated and untreated groups: If the propensity score distributions for \\(A=1\\) and \\(A=0\\) do not share substantial common support, any causal estimate in the non-overlapping region relies on extrapolation rather than data.\n\nWhen you see these patterns, consider restricting the analysis to the region of common support, trimming extreme weights, or acknowledging the limitations in your interpretation.\n\n\n\nplot(density(predict(glm(A ~ age + cvd, family = binomial, data = dat), type = \"response\")),\n     main = \"Propensity Score Overlap\", xlab = \"Estimated Propensity Score\")\n\n\n\n\n\n\n\n\nps &lt;- predict(glm(A ~ age + cvd, family = binomial, data = dat), type = \"response\")",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models</span>"
    ]
  },
  {
    "objectID": "01-03-identification-estimands.html#sources-and-further-reading",
    "href": "01-03-identification-estimands.html#sources-and-further-reading",
    "title": "4  Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models",
    "section": "12.1 Sources and further reading",
    "text": "12.1 Sources and further reading\n\nHernan MA, Robins JM (2020). Causal Inference: What If. Chapters 1-3. Free online\nPearl J (2009). Causality: Models, Reasoning, and Inference. 2nd ed. Cambridge University Press.\nRobins JM (1986). A new approach to causal inference in mortality studies with sustained exposure periods. Mathematical Modelling 7:1393-1512.\nvan der Laan MJ, Rose S (2011). Targeted Learning. Springer. Chapter 2.\nPetersen ML, van der Laan MJ (2014). Causal models and learning from data. Epidemiology 25(3):418-426.\nKennedy EH (2019). Nonparametric causal effects based on incremental propensity score interventions. JASA 114(526):645-656.\nlmtp R package: CRAN\ntmle R package: CRAN",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models</span>"
    ]
  },
  {
    "objectID": "01-03-identification-estimands.html#software-implementation-r",
    "href": "01-03-identification-estimands.html#software-implementation-r",
    "title": "4  Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models",
    "section": "12.2 Software Implementation (R)",
    "text": "12.2 Software Implementation (R)\nThis example estimates the effect of a modified treatment policy (a stochastic intervention that shifts treatment probability) using the lmtp package. This connects directly to the identification results in this chapter: rather than asking “what if everyone were treated?”, we ask “what if each person’s probability of treatment increased?”\n\nSimulate panel data with a single time point\nUse lmtp_tmle() to estimate the effect of shifting the treatment mechanism\nFalls back to tmle for a standard ATE if lmtp is unavailable\n\n\nset.seed(1)\nn &lt;- 500\nW1 &lt;- rnorm(n)\nW2 &lt;- rbinom(n, 1, 0.5)\nA  &lt;- rbinom(n, 1, plogis(-0.3 + 0.5 * W1))\nY  &lt;- as.numeric(rbinom(n, 1, plogis(-1 + 0.8 * A + 0.6 * W1 + 0.3 * W2)))\n\nif (requireNamespace(\"lmtp\", quietly = TRUE)) {\n  library(lmtp)\n\n  dat &lt;- data.frame(W1 = W1, W2 = W2, A = A, Y = Y)\n\n  ## Modified treatment policy: shift everyone to A = 1\n  result &lt;- lmtp_tmle(\n    data = dat,\n    trt = \"A\",\n    outcome = \"Y\",\n    baseline = c(\"W1\", \"W2\"),\n    shift = function(data, trt) rep(1, nrow(data)),\n    outcome_type = \"binomial\",\n    learners_outcome = \"SL.glm\",\n    learners_trt = \"SL.glm\",\n    folds = 5\n  )\n  print(result)\n} else if (requireNamespace(\"tmle\", quietly = TRUE)) {\n  message(\"lmtp not available; falling back to tmle for a standard ATE.\")\n  library(tmle)\n  fit &lt;- tmle(Y = Y, A = A, W = data.frame(W1, W2),\n              Q.SL.library = \"SL.glm\", g.SL.library = \"SL.glm\")\n  cat(\"ATE:\", round(fit$estimates$ATE$psi, 3), \"\\n\")\n  cat(\"95% CI:\", round(fit$estimates$ATE$CI, 3), \"\\n\")\n} else {\n  message(\"Install 'lmtp' or 'tmle':\n    install.packages('lmtp')\n    install.packages('tmle')\")\n}",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html",
    "href": "roadmap_tutorial.html",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "",
    "text": "5.1 To do\n(This workshop is in progress- updates to be made:)",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html#to-do",
    "href": "roadmap_tutorial.html#to-do",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "",
    "text": "Make example data simulated within sheet for reproducibility, and make Y binary\nAdd webr implementation\nAdd more details on inference (step 6)\nAdd TMLE and LMTP code at the end",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html#introduction",
    "href": "roadmap_tutorial.html#introduction",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "5.2 Introduction",
    "text": "5.2 Introduction\nThis tutorial provides a gentle introduction to the Causal Roadmap and its applications in pharmaco-epidemiologic research. It is designed for a broad audience, including learners from both academia and industry. We systematically walk through each step of the Causal Roadmap—from explicitly formulating a research question, to translating it into a formal causal estimand, to identifying and estimating that estimand from observed data, and finally to drawing valid inferences and interpreting results. Each step is illustrated using a working example from a pharmaco-epidemiology setting, accompanied by interactive, built-in code to facilitate hands-on learning. The structure and content of this tutorial are informed by the Introduction to Causal Inference and Causal Roadmap course developed by Maya Petersen and Laura Balzer (UC Berkeley Biostatistics): http://www.ucbbiostat.com/.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html#why-venture-down-a-new-path",
    "href": "roadmap_tutorial.html#why-venture-down-a-new-path",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "5.3 Why venture down a new path?",
    "text": "5.3 Why venture down a new path?\nAdopting the Causal Roadmap in our approach to research in causal inference enables us to clearly state a scientific question and select an analytic approach that matches the question being asked while ensuring systematic assessment of our ability/feasibility to answer this question from the data we observe (identifiability). Comparing candidate estimators under a shared estimand supports principled method selection.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html#motivation",
    "href": "roadmap_tutorial.html#motivation",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "5.4 Motivation",
    "text": "5.4 Motivation\n\nSuppose we are interested in the impact of Drug A vs Drug B on risk of cardiovascular disease among postmenopausal women with osteoporosis.\nOur usual approach would be to collect data on the intervention, outcome (cardiovascular disease ) and some covariates.\n\nA common default is logistic regression, which targets a conditional odds ratio by exponentiating the regression coefficient on the intervention (treatment).. However, this conditional odds ratio is often not the estimand that matches the scientific question in real-world evidence settings. * The problem with this approach is that it allows the tool i.e. logistic regression to define the question we answer rather than starting with the question and picking amongst tools that allow us to answer the question. * To address this problem, we introduce the Causal Roadmap!",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html#the-causal-roadmap",
    "href": "roadmap_tutorial.html#the-causal-roadmap",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "5.5 The Causal Roadmap",
    "text": "5.5 The Causal Roadmap\nThe Causal Roadmap is a framework that provides a systematic process to move from a research question to estimation and interpretation which guides investigators on how to design and analyse their studies a priori. This framework has the following steps;\n\nStating the research question and hypothetical experiment\nDefining the causal model and parameter of interest\nLinking the causal model to the observed data and defining the statistical model\nAssessing identifiability: linking the causal effect to a parameter estimable from the observed data\nSelecting and applying the estimator\nDeriving an estimate of the sampling distribution (statistical uncertainty)\nMaking inference (interpreting findings)\n\nWe shall now delve into each of these steps in details after we go over some notation!",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html#notation",
    "href": "roadmap_tutorial.html#notation",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "5.6 Notation",
    "text": "5.6 Notation\n\nA: Exposure/Treatment\n\nThe term treatment is often used in causal inference even with exposures that are not medical treatments. We shall use A=1 for exposed (treated) and A=0 for unexposed (untreated)\n\nY: outcome\nW: set of measured confounding variables\nU: set of unmeasured factors\n\\(\\mathbb{E}[Y|A=a]\\): expected outcome Y among those who experience exposure A=a in our population. This is a descriptive measure\n\\(\\mathbb{E}[Y_{a}]\\): expected counterfactual outcome \\(Y_a\\) when all experience exposure A=a in our population. This is a causal quantity. Generally \\(\\mathbb{E}[Y|A=a]\\) does not equal to \\(\\mathbb{E}[Y_{a}]\\) and this is the fundamental problem of causal inference\n\\(\\mathbb{E}[Y|A=a,W=w]\\): expected outcome Y among those who expereince exposure A=a and have covariates W=w, in our population. For example this can be the mean outcome among exposed men. These conditional expectations are often estimated using multivariable regression models.\n\\(\\mathbb{E}[\\mathbb{E}[Y|A=a,W=w]]\\):expected outcome Y among those who experience exposure A=a and have covariates W=w,averaged across covariate strata in the population. This is a marginal expectation.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html#step-0-state-the-question",
    "href": "roadmap_tutorial.html#step-0-state-the-question",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "5.7 Step 0: State the question",
    "text": "5.7 Step 0: State the question\n\nThis is the very first step of the roadmap. A helpful way to be clear about the scientific question is to explicitly state the experiment that would unambiguously yield estimates of the causal effect of interest.\nFor example: What is the effect of a certain medication on the incidence of cardiovascular disease among postmenopausal women who initiated Drug A vs Drug B in the United States?\nWe can consider a hypothetical experiment where we ask what would be the the difference in CVD incidence if patients received the intervention drug A vs if all patients received the control drug B (or standard of care).\nTo sharply frame our research question, we want to be more specific about;\n\nThe target population (What age group? where?)\nThe exposure (What dosage? Frequency?)\nThe outcome (over what timeframe?)\nWays to change the exposure and their plausibility\n\nOther interesting hypothetical experiments could include:\n\nWhat would be the difference in CVD incidence if patients were initiated on drug A once they reached a certain risk threshold vs if all patients are initiated on Drug A regardless of their risk profile?\nWhat would be the difference in CVD incidence if an additional 10% of patients received the intervention compared to if the intervention uptake remained as observed?\n\nWe note that there is massive flexibility in how we can define our desired hypothetical experiments.\n\n\n5.7.1 Target Trial Emulation\nThe hypothetical experiment defined in Step 0 can be viewed as a target trial.\nObservational studies aim to emulate this trial by aligning eligibility criteria, treatment assignment, follow-up, outcome definitions, and estimands.\nThe Causal Roadmap provides the formal structure for conducting such emulations transparently.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html#step-1-define-the-causal-model",
    "href": "roadmap_tutorial.html#step-1-define-the-causal-model",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "5.8 Step 1: Define the causal model",
    "text": "5.8 Step 1: Define the causal model\n\nCausal modeling formalizes our knowledge however limited. We are able to explore which variables affect each other, examine the role of unmeasured factors and the functional form of the relationships between variables.\nIn this tutorial, we shall focus on structural causal models and corresponding causal graphs (Pearl 2000). However, we do note that there are many other causal frameworks.\nThe figure 1 below corresponds to a simple causal graph with corresponding structural causal model as follows;\n\n\\(W= f_w(U_w)\\)\n\\(A= f_A(W,U_A)\\)\n\\(Y = f_Y(W,A,U_Y)\\)\n\nWe make no assumptions on the background factors \\((U_w,U_A,U_Y)\\) or on the functional forms of functions \\((f_w,f_A,f_Y)\\)\n\n\n\n\n\n\n\n\n\n\nIf you believed no unmeasured confounding, a possible causal model and graph (figure 2) would be: * \\(W= f_w(U_w)\\) * \\(A= f_A(W,U_A)\\) * \\(Y = f_Y(W,A,U_Y)\\)\nHere we assume that the background factors are all independent but still make no assumption on the functional forms of \\((f_w,f_A,f_Y)\\). However, keep in mind that this is an assumption we are making, and",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html#step-2-define-the-causal-parameter-of-interest",
    "href": "roadmap_tutorial.html#step-2-define-the-causal-parameter-of-interest",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "5.9 Step 2: Define the causal parameter of interest",
    "text": "5.9 Step 2: Define the causal parameter of interest\n\nWe now define counterfactuals by intervening on the causal model. We can do this by setting the exposure to a specific level e.g A=1 for all units.\n\n\\(W= f_w(U_w)\\)\n\\(A= 1\\)\n\\(Y_1 = f_Y(W,1,U_Y)\\) where \\(Y_1\\) is the outcome if possibly-contrary to fact, the unit was exposed (A=1)\n\n\n\n\n\n\n\n\n\n\n\n\nAnalogously, we can intervene on the causal model by setting A=0\n\n\\(W= f_w(U_w)\\)\n\\(A= 0\\)\n\\(Y_0 = f_Y(W,0,U_Y)\\) where \\(Y_0\\) is the outcome if possibly-contrary to fact, the unit was exposed (A=0)\n\n\n\n\n\n\n\n\n\n\n\nWe use counterfactuals to define the causal parameter:\n\nFor example, the difference between the expected counterfactual outcomes under these two interventions i.e \\(\\mathbb{E}[Y_1]-\\mathbb{E}[Y_0]\\) which is known as the average treatment effect(ATE)\nFor a binary outcome, like in this example. we define the causal risk difference (CRD) as \\(\\mathbb{P}(Y_1=1)-\\mathbb{P}(Y_0=1)\\).\n\nMany other causal parameters are possible!!\n\n5.9.1 Estimand Specification\nAn estimand precisely defines the treatment effect of interest by specifying all attributes of the causal question.\n\n\n\n\n\n\n\nAttribute\nSpecification\n\n\n\n\nPopulation\nEligible individuals meeting study inclusion criteria\n\n\nTreatment Strategies\nIntervention A versus comparator B\n\n\nEndpoint\nBinary or time-to-event outcome within a fixed horizon\n\n\nIntercurrent Events\nAddressed via treatment-policy or hypothetical strategy\n\n\nSummary Measure\nRisk difference, risk ratio, or mean difference\n\n\n\nExplicit estimand specification ensures alignment between the scientific question, identification assumptions, and estimation strategy.\nNOTE: cite ICH E9[R1] Framework here\n\n\n5.9.2 Treatment-Policy versus Hypothetical Estimands\nA treatment-policy estimand contrasts outcomes under initial treatment assignment regardless of subsequent treatment changes (i.e., intention-to-treat estimates as presented in this workshop).\nA hypothetical estimand contrasts outcomes under a counterfactual world in which intercurrent events (e.g., switching or discontinuation) do not occur.\nThe choice between these estimands reflects different scientific questions and determines how intercurrent events are handled during analysis.\n\n\n5.9.3 Intercurrent Events\nIntercurrent events are post-treatment events that affect the interpretation or existence of the outcome, such as treatment switching, discontinuation, or death.\nHandling of intercurrent events must be specified at the estimand stage, not deferred to estimation. Common strategies include:\n\nTreatment-policy: ignore the intercurrent event\nHypothetical: censor or reweight to eliminate its occurrence\nComposite: redefine the outcome to include the event\n\nThis choice determines the causal question being answered.\n\n\n5.9.4 Time-to-Event Outcomes and Risk-Based Estimands\nIn many applications, outcomes occur over time and are subject to censoring.\nRather than targeting hazard ratios, the Causal Roadmap naturally accommodates risk-based estimands, such as cumulative incidence at a fixed time horizon.\nFor example, the causal risk difference at 90 days compares the probability of experiencing the event by day 90 under each treatment strategy.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html#step-3-link-to-observed-data",
    "href": "roadmap_tutorial.html#step-3-link-to-observed-data",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "5.10 Step 3: Link to observed data",
    "text": "5.10 Step 3: Link to observed data\n\nObserved data are denoted O=(W,A,Y) where W reprensents measured covariates, A is the exposure and Y is the outcome.\nWe assume that the causal model provides a description of our study under existing conditions(i.e. the real world) and under interventions (i.e.the counterfactual world)\nThis provides a link between the causal world and the real (observed) world and therefore our causal model implies our statistical model which is the set of possible distributions of observed data.\nThe causal model may but often does not place any restrictions on the statistical model in which case the statistical model is non parametric.\nFor example our model says that A is a function of W and \\(U_A\\) but does not specify the form of that function: A= \\(f_A(W,U_A)\\). However, if we know the form, that should be specified in the causal model.\n\n\n5.10.1 Observed-Data Censoring Rules\nThe observed data structure must specify which events terminate follow-up and how they relate to the estimand.\nCensoring may occur due to administrative end of follow-up, loss to follow-up, or treatment switching.\nWhether censoring is causal or administrative depends on the estimand and must be addressed through design or analysis.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html#step-4-assess-identifiablity",
    "href": "roadmap_tutorial.html#step-4-assess-identifiablity",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "5.11 Step 4: Assess Identifiablity",
    "text": "5.11 Step 4: Assess Identifiablity\n\nThis process involves linking the causal effect to the parameter estimable from observed data. This requires some assumptions as follows:\n\nTemporality: exposure precedes the outcome. This is indicated by an arrow on the causal graph from A to Y\nConsistency: \\(Y_a\\)=Y where A=a. If an individual received treatment A=a, then their observed outcome Y is equal to their potential outcome under that treatment \\(Y_a\\).\nStability: We require no interference between units. This is indicated by the fact that the outcomes Y are only a function of each unit’s exposure A in the causal model and graph.\nRandomization:No unmeasured confounding such that \\(Y_a \\perp A \\mid W\\)\nPositivity: We require sufficient variability in exposure within confounder values i.e. \\(0 &lt; \\mathbb{P}(A=1|W)&lt;1\\).\n\nWith these assumptions, we can express our causal target parameter which is a function of counterfactuals in terms of our observed data i.e\n\n\\[\n\\begin{aligned}\n\\mathbb{E}(Y_a)\n    &= \\mathbb{E}\\big[ \\mathbb{E}(Y_a \\mid W) \\big] \\\\\n    &= \\mathbb{E}\\big[ \\mathbb{E}(Y_a \\mid A=a, W) \\big]  under \\ randomization\\\\\n    &= \\mathbb{E}\\big[ \\mathbb{E}(Y \\mid A=a, W) \\big] under \\ consistency\n\\end{aligned}\n\\]\n\nAgain wishing for something does not make it true.\nUnder the above assumptions we can have the G-computation identifiability result (Robins 1986) as\n\n\\(\\mathbb{E}[Y_1-Y_0] = \\mathbb{E}\\big[\\mathbb{E}(Y\\mid A=1,W)-\\mathbb{E}(Y\\mid A=0,W)]\\) where the right handside is our parameter of interest a.k.a our statistical estimand. Connection to estimation: The g-computation (simple substitution) estimator in Step 5 directly implements this identified functional by estimating (E[Y A, W]), predicting under (A=1) and (A=0), and averaging over (W). In other words, Step 5 begins by turning the Step 4 identification formula into an explicit computational procedure.\nFor a binary outcome, we have the marginal risk difference as $. This is marginal because the outer expectation averages over the confounder distribution.\n\n\nWhat if the assumptions are not all met? For example one might be worried about unmeasured confounders or that the data structure does not assure temporality.Possible options include: * Giving up!! * Changing the research question, the exposure, the outcome or the target population * Proceeding to do the best job possible estimating the target parameter provided the question is still well-defined and interpretable and that we can still get as close as possible to the wished for causal parameter given the limitations in the data.\nAssessing Assumptions in Real-World Data The plausibility of identification assumptions depends on the data source. For example, claims data may offer rich information on diagnoses and procedures but limited clinical detail.Explicitly discussing data limitations strengthens interpretation and guides sensitivity analyses.\nHaving established the causal estimand, the observed-data structure, and the assumptions under which the estimand is identified, we now turn to estimation. At this stage of the Causal Roadmap, the scientific question has been translated into a well-defined statistical target, and the remaining tasks concern how best to estimate this target from finite data, assess precision, and diagnose potential threats such as model misspecification or practical violations of assumptions. The choice of estimator should therefore be guided by the estimand and identification results, rather than driving them.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html#step-5-choose-and-apply-the-estimator",
    "href": "roadmap_tutorial.html#step-5-choose-and-apply-the-estimator",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "5.12 Step 5: Choose and apply the estimator",
    "text": "5.12 Step 5: Choose and apply the estimator\n\nAn estimator is an algorithm that when applied to the data generates an estimate of the parameter of interest.\nThere are several estimators available for the statistical parameter (which equals the ATE if the identifiability assumptions hold). Among these are:\n\nSubstitution estimators (e.g. paramteric G-computation)\nPropensity score based estimators (e.g. IPTW, matching)\nDouble robust estimators (e.g.TMLE, A-IPTW)\n\nBut before we dive into these estimators, let us pause to recall the usual approach. One would usually run a logistic regression of the outcome Y( risk of Cardiovasicular disease) on exposure (drug A or B) and baseline confounders W:\n\n\\[\n\\text{logit}\\big( \\mathbb{E}(Y \\mid A, W) \\big)\n    = \\beta_0 + \\beta_1 A + \\beta_2 W_1 + \\cdots + \\beta_{19} W_{18}.\n\\]\n\nThey would then exponentiate the coefficient on the exposure and interpret the association in terms of an odds ratio.\n\nConditional OR: “While holding other factors constant”\n\nThe problem here is that our target parameter (ATE) does not equal \\(e^{\\beta_{1}}\\). Rather we are letting the estimation approach drive the question. Additionally, this estimation approach relies on the main terms logisitic regression being correct.\nA parametric estimation approach assumes we know the relationship between covariates W, the exposure A and the outcome Y and have correctly specified this relation with a finite set of constants called “parameters”.\n\nFor example, we can specify a regression with main terms for covaritaes and a few interactions or squared terms that we think are reasonable.\nIf we had this knowledge, we should encode it in our causal model so we avoid introducing new assumptions during estimation.\nWith parametric regression models, we are likely assuming we know more than we actually know.\n\nA non-parametric estimation approach acknowledges that we do not know the form of the relations beetween the covariates W, the exposure A and the outcome Y.\n\nFor example, one could divide the data into all combinations of (A,W), calculate and average the stratum specific A and Y relations.\nUnfortunately we typically have too many covariates and/or continuous covariates which would result into empty cells. This is known as the curse of dimensionality as the number of strata increases exponentially with dimension of W!\n\nIn a semi parametric estimation approach, we often “know nothing” (i.e. have a non-paramteric statistical model) but also need to smooth over data with weak support during estimation.\n\nWe utilize “data-adaptive estimation” or “machine learning”.\nOne could choose an algorithm (e.g. stepwise regression, loess or polynomial splines), but we have no basis for choosing one over the other.\nInstead we allow a large class of algorthims to compete and we select the best algorithm with cross-validation. This is the basis of Super Learner which we will focus on in this tutorial.\n\n\nRecall our statistical parameter is \\(\\mathbb{E}\\big[\\mathbb{E}(Y\\mid A=1,W)-\\mathbb{E}(Y\\mid A=0,W)\\big]\\) which equals the ATE if the identifiability results hold.\nWe shall now discuss the following estimators with example implementation code in R: * Simple substitution estimator a.k.a paramteric G-computation or parametric g-formula * Inverse probability of treatment weighting (IPTW) * Targeted maximum likelihood estimation (TMLE) with Super Learner\n\n5.12.1 Simple substitution estimator (g-computation)\nWhy start with g-computation? G-computation (outcome modeling and standardization) is often the most intuitive entry point for causal estimation because it does not interpret a regression coefficient as a causal effect. Instead, it implements the identification formula by estimating the conditional mean outcome (E[Y A, W]), predicting counterfactual outcomes under (A=1) and (A=0) for each individual, and then standardizing (averaging) those predictions over the empirical distribution of (W). The resulting contrast is a marginal (population-level) estimand, such as a risk difference.\nTo get some intuition behind this estimator, let us think of causal inference as a problem of missing information where we know the outcome under the observed exposure but are missing the outcome under the other exposure condition. We therefore use parametric regression to estimate outcomes for all under both exposed and unexposed conditions after controlling for the measured confounders. We then average and compare predicted outcomes. The algorithm is as follows. First we shall load in our simulated dataset “CausalWorkshop.csv” and set the random seed.\nAlgorithm (standardization / g-computation):\n\nFit an outcome model (Q(A,W) = E[Y A, W]).\n\nCreate two counterfactual datasets by setting (A=1) for everyone and (A=0) for everyone.\n\nPredict outcomes under each intervention and average predictions over the observed (W) distribution:\n\n\\[\nE[Y^a] = E_W\\{E[Y \\mid A=a, W]\\}.\n\\]\n\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'stringr' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.6.0\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readr)\ndata &lt;- as.data.frame(read_csv(\"CausalWorkshop.csv\"))\n\nRows: 200 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (6): W1, W2, W3, W4, A, Y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(data)\n\n  W1        W2         W3         W4 A          Y\n1  1 0.7040728  0.3122141  0.4414994 0 0.04669768\n2  0 0.6962875  0.4380506  1.3836186 0 0.07710665\n3  0 0.3938895 -0.5381666 -1.4355267 0 0.17743687\n4  0 0.6422344  0.7668415  1.2486485 0 0.03303451\n5  1 0.4257656 -0.2033714 -0.1459042 0 0.10488589\n6  1 0.4578941  1.5954809  0.7091765 0 0.02280160\n\ntail(data)\n\n    W1         W2         W3          W4 A           Y\n195  0 0.85578904  1.1663078  2.10450450 1 0.002777352\n196  0 0.43430486  0.5446386 -0.23810871 0 0.046925226\n197  1 0.24331831 -1.7955021 -0.76891635 0 0.067511199\n198  0 0.62919489 -0.2291413  0.07503677 1 0.109081662\n199  0 0.09132161 -0.1004926  0.76101300 0 0.116936200\n200  1 0.54266527 -1.4793356 -0.79376429 0 0.053090261\n\ndim(data)\n\n[1] 200   6\n\n# set.seed(1)\n# n &lt;- 2000\n# \n# data &lt;- tibble(\n#   # Baseline covariates (W): representative of postmenopausal osteoporosis patients\n#   age = pmin(pmax(rnorm(n, mean = 72, sd = 7), 50), 90),             # years\n#   prior_cvd = rbinom(n, 1, plogis((age - 70) / 8 - 1.2)),            # prior cardiovascular disease\n#   frailty = rnorm(n, mean = 0, sd = 1),                              # latent frailty proxy\n#   smoke = rbinom(n, 1, plogis(-0.5 + 0.02 * (age - 70) + 0.4 * frailty)),\n#   sbp = rnorm(n, mean = 130 + 8 * prior_cvd + 3 * smoke, sd = 12),   # systolic BP\n#   bmd_t = rnorm(n, mean = -2.5 - 0.3 * frailty, sd = 0.6)            # bone mineral density T-score\n# ) %&gt;%\n#   mutate(\n#     # Treatment assignment A: Drug A (1) vs Drug B (0), confounded by baseline risk and severity\n#     # More frail / higher CVD risk patients are more likely to be given Drug B (A=0), for example.\n#     ps_true = plogis(\n#       0.4 - 0.06 * (age - 70) - 0.7 * prior_cvd - 0.25 * frailty + 0.35 * (bmd_t &lt; -2.8) - 0.15 * smoke\n#     ),\n#     A = rbinom(n, 1, ps_true)\n#   ) %&gt;%\n#   mutate(\n#     # Outcome model (truth): binary 1-year CVD event\n#     # Includes (i) nonlinearity in age and (ii) an A-by-prior_cvd interaction.\n#     # This makes a main-terms logistic regression for Y misspecified.\n#     lp_y_true =\n#       -3.4 +\n#       0.06 * (age - 70) +\n#       0.02 * (age - 70)^2 / 10 +           # mild nonlinearity\n#       0.9 * prior_cvd +\n#       0.35 * smoke +\n#       0.015 * (sbp - 130) +\n#       0.25 * frailty +\n#       0.10 * (bmd_t &lt; -2.8) +\n#       (-0.25) * A +                         # average protective effect\n#       (-0.55) * A * prior_cvd,              # stronger protection among those with prior CVD\n#     p_y_true = plogis(lp_y_true),\n#     Y = rbinom(n, 1, p_y_true)\n#   ) %&gt;%\n#   select(\n#     # Keep W as W1-W4 to minimize changes downstream, plus keep interpretable versions for teaching\n#     W1 = age, W2 = prior_cvd, W3 = sbp, W4 = bmd_t, A, Y,\n#     age, prior_cvd, sbp, bmd_t, frailty, smoke\n#   )\n# \n# # View data\n# glimpse(data)\n\n\nWe the estimate the mean outcome Y as a function of exposure (treatment) A and measured confounders W. In this example we run a main terms logistic regression.\nWe estimate the conditional mean outcome \\(Q(A,W)=E(Y∣A,W)\\) using a main-terms logistic regression. In the simulated osteoporosis example, the true outcome mechanism includes nonlinearity in age and an A × prior CVD interaction, so this main-terms logistic regression is intentionally misspecified.\n\n\noutcome.regression &lt;- glm(Y ~ A + W1+W2+W3+W4, family='binomial', data=data)\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\n\nKey point: Regression coefficients (for example, an odds ratio from a logistic model) are typically conditional measures given (W). The Roadmap target in this workshop is a marginal contrast (for example, a risk difference). Standardization (g-computation) converts an outcome regression into a marginal estimand by averaging predicted outcomes over the covariate distribution.\n\nWe use estimates from 1 above to predict outcomes for each unit while “setting” the exposure to different values e.g. A=1 and A=0\n\n\ndata.A1 &lt;- data.A0 &lt;- data\ndata.A1$A &lt;- 1\ndata.A0$A &lt;- 0\ncolMeans(data.A1)\n\n         W1          W2          W3          W4           A           Y \n 0.52000000  0.51459003  0.02187934 -0.01958053  1.00000000  0.06244803 \n\ncolMeans(data.A0)\n\n         W1          W2          W3          W4           A           Y \n 0.52000000  0.51459003  0.02187934 -0.01958053  0.00000000  0.06244803 \n\npredict.outcome.A1 &lt;- predict( outcome.regression, newdata=data.A1, \n                               type='response')\npredict.outcome.A0 &lt;- predict(outcome.regression, newdata=data.A0, \n                              type='response')\n\n\nAverage predictions to estimate the marginal risks in the population under exposure and no exposure. To compare estimates, take the difference in means.\n\n\nmean(predict.outcome.A1)\n\n[1] 0.03877997\n\nmean(predict.outcome.A0)\n\n[1] 0.07258282\n\nSimple.Subs &lt;- mean(predict.outcome.A1 - predict.outcome.A0)\nSimple.Subs\n\n[1] -0.03380285\n\n\n\n5.12.1.1 When can g-computation fail?\n\nOutcome model misspecification: If (E[Y A, W]) is misspecified (wrong functional form, missing interactions), the standardized estimate can be biased. Here, we missed a true interaction in the data-generating process.\nPractical positivity violations: If some covariate strata rarely receive one treatment, g-computation must extrapolate to regions with little or no support.\nUnmeasured confounding: No outcome-modeling approach can correct for confounders that are not measured.\n\nThese failure modes motivate (i) overlap diagnostics, (ii) flexible nuisance estimation (for example, SuperLearner), and (iii) doubly robust estimators such as TMLE.\nPreview: One way to reduce reliance on parametric assumptions is to estimate (Q(A,W)) with flexible learners (for example, generalized additive models, random forests, boosting) or an ensemble via SuperLearner. In the next sections, we use SuperLearner first for nuisance estimation and then integrate it with TMLE, which targets the causal estimand while retaining a basis for statistical inference.\n\n\n\n5.12.2 IPTW- Inverse Probability of Treatment Weighting estimator\nIntuition (pseudo-population): IPTW treats confounding as a form of biased sampling. Units who received a treatment that was unlikely given their covariates receive larger weights, and units who received an expected treatment receive smaller weights. In the resulting weighted pseudo-population, treatment is approximately independent of measured covariates (if the propensity score model is correct), mimicking a randomized experiment.\nThe intuition behind this estimation approach is to think of confounding as a problem of biased sampling, where certain exposure–covariate subgroups are overrepresented relative to what we would observe in a randomized trial, while others are underrepresented. We apply weights to up-weight under-represented units and down-weight over-represented units We then average and compare weighted outcomes. The algorithm is as follows;\n\nEstimate the probability of being exposed/treated A as a function of measured confounders W:\\(\\mathbb{P}(A=1\\mid W)\\). This is often referred to as the propensity score. We can estimate the propensity score by running a main terms logistic regression as illustrated below\n\n\npscore.regression &lt;- glm(A~ W1+W2+W3+W4, family=binomial(), data=data)\nsummary(pscore.regression)\n\n\nCall:\nglm(formula = A ~ W1 + W2 + W3 + W4, family = binomial(), data = data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -1.3445     0.3821  -3.519 0.000433 ***\nW1            0.4637     0.3130   1.482 0.138399    \nW2            0.5113     0.5629   0.908 0.363744    \nW3            0.4483     0.3208   1.397 0.162360    \nW4           -0.2676     0.3095  -0.865 0.387227    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 247.64  on 199  degrees of freedom\nResidual deviance: 241.99  on 195  degrees of freedom\nAIC: 251.99\n\nNumber of Fisher Scoring iterations: 4\n\n\nIdentification link: Under consistency, exchangeability given (W), and positivity, we can write \\[\nE\\{Y(1)\\} = E\\left[\\frac{\\mathbb{I}(A=1)Y}{e(W)}\\right], \\qquad\nE\\{Y(0)\\} = E\\left[\\frac{\\mathbb{I}(A=0)Y}{1-e(W)}\\right],\n\\]\nwhere (e(W)=P(A=1W)). IPTW replaces the expectation with a sample average and replaces (e(W)) with an estimate.\n\nWe then use estimates from 1 above to calculate exposed/treated weights: 1/\\(\\mathbb{P}(A=1\\mid W)\\) and unexposed/untreated weights:1/\\(\\mathbb{P}(A=0\\mid W)\\)\n\n\npredict.prob.A1 &lt;- predict(pscore.regression, type='response')\nsummary(predict.prob.A1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.1555  0.2521  0.3034  0.3100  0.3658  0.5145 \n\npredict.prob.A0 &lt;- 1 - predict.prob.A1\nwt1 &lt;- as.numeric( data$A==1)/predict.prob.A1\nwt0 &lt;- as.numeric( data$A==0)/predict.prob.A0\nhead(data.frame(cbind(A=data$A, 1/predict.prob.A1, wt1, wt0)))\n\n  A       V2 wt1      wt0\n1 0 2.646982   0 1.607171\n2 0 4.197342   0 1.312760\n3 0 3.718918   0 1.367793\n4 0 3.735871   0 1.365514\n5 0 3.044577   0 1.489099\n6 0 2.128806   0 1.885892\n\n\n\nWe then apply the weights and average the weighted outcomes to estimate the marginal risks in the population under A=1 and A=0. To compare estimates, we take the difference in weighted means.\n\n\nmean(wt1*data$Y)\n\n[1] 0.03973564\n\nmean(wt0*data$Y)\n\n[1] 0.07234258\n\nIPW &lt;- mean(wt1*data$Y) - mean(wt0*data$Y)\nIPW\n\n[1] -0.03260694\n\nmean( (wt1-wt0)*data$Y)\n\n[1] -0.03260694\n\n\n\n5.12.2.1 Stabilized weights (optional but common in practice)\nUnstabilized weights can be variable in finite samples. A common alternative is to use stabilized weights, which multiply by the marginal probability of observed treatment:\n\\[\nSW_i =\n\\begin{cases}\n\\frac{P(A=1)}{e(W_i)}, & A_i=1 \\\\\n\\frac{P(A=0)}{1-e(W_i)}, & A_i=0.\n\\end{cases}\n\\]\nStabilized weights often reduce variance and improve numerical stability without changing the large-sample target under correct specification.\n\npA &lt;- mean(data$A)\nsw1 &lt;- as.numeric(data$A==1) * pA / predict.prob.A1\nsw0 &lt;- as.numeric(data$A==0) * (1-pA) / (1 - predict.prob.A1)\nsw  &lt;- sw1 + sw0\nsummary(sw)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.6025  0.8991  0.9700  1.0013  1.0937  1.9930 \n\n\nImplementation note: IPTW can be implemented either by directly computing weighted means of (Y) within treatment groups (as shown here) or by fitting a weighted regression of (Y) on (A) using robust standard errors. These approaches target the same marginal contrast when implemented consistently.\n\n\n5.12.2.2 Diagnostics and practical tips (IPTW)\n\nOverlap: Inspect the distribution of (e(W)) by treatment group. Limited overlap indicates practical positivity problems and increases variance.\nWeight tails: Summarize weights (mean, sd, extreme quantiles). A heavy right tail indicates instability and sensitivity to a small number of observations.\nTruncation: Truncating weights (for example, at the 1st and 99th percentiles) can reduce variance at the cost of potential bias. In finite samples, truncation can improve mean squared error, but it should be reported transparently as a sensitivity analysis.\n\n\nw &lt;- wt1 + wt0\nlo &lt;- quantile(w, 0.01)\nhi &lt;- quantile(w, 0.99)\nw_trunc &lt;- pmin(pmax(w, lo), hi)\nsummary(w_trunc)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.212   1.359   1.525   1.993   2.455   4.885 \n\n\n\n\n\n5.12.3 TMLE- targeted maximum likelihood estimation\n\n5.12.3.1 Why doubly robust estimators?\nBoth g-computation and IPTW rely on strong modeling assumptions: g-computation requires a correct outcome model, while IPTW requires a correct treatment model. Doubly robust estimators combine both approaches and are consistent if either the outcome model or the treatment model is correctly specified. This property is particularly valuable in real-world data settings, where all models are approximations.\n\nFor intuition here, we again think of causal inference as a problem of missing information.\nWe predict the outcomes for all units under both exposed and unexposed conditions. We use a flexible estimation approach e.g. Super Learner to avoid assuming regression models that are not known or we use parametric knowledge if known.\nWe incorporate information on the covariate-exposure relation to improve the initial estimator. Why TMLE?\n\nAgain here we use a flexible estimation approach or parameteric knowledge if available.\nWe have a second chance to control for confounding hence this method is doubly robust\nWe are able to hone our estimator towards the parameter of interest.\nThis estimator is asymptotically linear and therefore we can obtain normal curve inference\n\nFinally, we average and compare the targeted predictions under exposure and no exposure.\n\n\n\n5.12.3.2 What is Super Learner?\n\nThis is a supervised machine learning algorithm that offers a flexible and data daptive approach to learn complex relationships from data.\nThis algorithm uses cross-validation(sample splitting) to evaluate the performance of a library of candidate estimators.\n\nThe library should be diverse including simple (e.g expert informed parametric regressions) and more adaptive algorithms (e.g penalized regressions, stepwise regression, adaptive splines)\nPerformance is measured by a loss function e.g squared prediction error\n\nCross-validation allows us to compare algorithms based on how they perform on independent data. Here we partition data in “folds”, fit each algorithm on the training set and evaluate its performance (called “risk”) on the validation set. We rotate through the folds and average the cross-validated risk estimates across the folds to obtain one measure of performance for each algorithm.\nWe could choose the algorithm with the best performance (e.g the lowest cross-validated MSE)\nInstead, Super Learner builds the best combination of algorithm- specific predictions. We now illustrate below how to fit a Super Learner.\n\n\nlibrary('SuperLearner')\n\nSL.library &lt;- c(\"SL.glm\", \"SL.step.interaction\", \"SL.gam\")\n\nX_Q &lt;- select(data, A, W1, W2, W3, W4)\nY_Q &lt;- data$Y\n\nSL.outcome.regression &lt;- suppressWarnings(\n  SuperLearner(Y = Y_Q, X = X_Q, SL.library = SL.library, family = binomial())\n)\nSL.outcome.regression\n\n\nCall:  \nSuperLearner(Y = Y_Q, X = X_Q, family = binomial(), SL.library = SL.library) \n\n                               Risk       Coef\nSL.glm_All              0.002778865 0.00000000\nSL.step.interaction_All 0.001459048 0.07867521\nSL.gam_All              0.001182814 0.92132479\n\nSL.predict.outcome &lt;- predict(SL.outcome.regression, \n                              newdata=subset(data, select=-Y))$pred\nhead(SL.predict.outcome)\n\n           [,1]\n[1,] 0.06091060\n[2,] 0.03514467\n[3,] 0.09372118\n[4,] 0.02939087\n[5,] 0.08990822\n[6,] 0.01237438\n\n\n\n\n5.12.3.3 Why do I need to target?\n\nWe could use Super Learner to predict the outcomes for each unit while “setting” the exposure to different levels and then average and contrast the predictions.\n\n\nSL.predict.outcome.A1 &lt;- predict(SL.outcome.regression, \n                                 newdata=subset(data.A1, select=-Y))$pred\nhead(SL.predict.outcome.A1)\n\n            [,1]\n[1,] 0.038035992\n[2,] 0.021723371\n[3,] 0.059333993\n[4,] 0.018101507\n[5,] 0.056817294\n[6,] 0.007565834\n\nSL.predict.outcome.A0 &lt;- predict(SL.outcome.regression, newdata=subset(data.A0, select=-Y))$pred\n\n# simple subst estimator\nmean(SL.predict.outcome.A1) - mean(SL.predict.outcome.A0)\n\n[1] -0.02534228\n\n\n\nBut Super Learner is focused on \\(\\mathbb{E}(Y\\mid A,W)\\) and not our parameter of interest. It makes the wrong bias-variance trade-off and specifically incurs too much bias.\nThere is also no reliable way to obtain statistical inference (i.e create 95% confidence intervals)\n\n\n\n5.12.3.4 What is targeting?\n\nTargeting involves using information in the estimated propensity score \\(\\mathbb{P}(A=1\\mid W)\\) to update the initial (Super Learner) estimator of \\(\\mathbb{E}(Y\\mid A,W)\\).\nIt involves running a univariate regression of the outcome Y on a clever covariate with offset the initial estimator. Why “clever”? It ensures that the targeting step moves the initial estimator in a direction that removes bias.\nWe then use the estimated coefficient to update our initial predictions of the outcome under the exposure and no exposure.\n\n\n\n5.12.3.5 How do i target? (One approach)\n\nUse Super Learner to estimate the propensity score \\(\\mathbb{P}(A=1\\mid W)\\)\n\n\nSL.pscore &lt;- SuperLearner(Y=data$A, X=subset(data, select=-c(A,Y)),\n                          SL.library=SL.library, family=binomial())\nSL.pscore\n\n\nCall:  \nSuperLearner(Y = data$A, X = subset(data, select = -c(A, Y)), family = binomial(),  \n    SL.library = SL.library) \n\n                             Risk      Coef\nSL.glm_All              0.2153962 0.0000000\nSL.step.interaction_All 0.2096272 0.1167303\nSL.gam_All              0.2050174 0.8832697\n\nSL.predict.prob.A1 &lt;- SL.pscore$SL.predict\nsummary(SL.predict.prob.A1 - predict(SL.pscore, newdata=subset(data,select=-c(A,Y)))$pred)\n\n       V1   \n Min.   :0  \n 1st Qu.:0  \n Median :0  \n Mean   :0  \n 3rd Qu.:0  \n Max.   :0  \n\nsummary(SL.predict.prob.A1)\n\n       V1        \n Min.   :0.1537  \n 1st Qu.:0.2331  \n Median :0.2764  \n Mean   :0.3100  \n 3rd Qu.:0.3589  \n Max.   :0.9152  \n\nSL.predict.prob.A0 &lt;- 1 - SL.predict.prob.A1\n\nNote: As you run this code you might encounter a warning “non-integer #successes in a binomial glm!”. This simply means that our outcome Y is not binary much as it’s bounded between 0 and 1. This is okay and can be ignored.\n\nCalculate the “clever covariate”\n\n\\[H(A,W)= \\frac{\\mathbb{I}(A=1)}{\\mathbb{P}(A=1\\mid W)}- \\frac{\\mathbb{I}(A=0)}{\\mathbb{P}(A=0\\mid W)}\\]\nHere’s code to evaluate the “clever covariate”\n\nH.AW &lt;- (data$A==1)/SL.predict.prob.A1 - (data$A==0)/SL.predict.prob.A0\nsummary(H.AW)\n\n       V1           \n Min.   :-2.207960  \n 1st Qu.:-1.411579  \n Median :-1.302509  \n Mean   : 0.004165  \n 3rd Qu.: 1.955975  \n Max.   : 5.893745  \n\nH.1W &lt;- 1/SL.predict.prob.A1\nH.0W &lt;- -1/SL.predict.prob.A0\ntail(data.frame(A=data$A, H.AW, H.1W, H.0W))\n\n    A      H.AW     H.1W      H.0W\n195 1  2.563149 2.563149 -1.639734\n196 0 -1.385142 3.596447 -1.385142\n197 0 -1.352029 3.840674 -1.352029\n198 1  5.448316 5.448316 -1.224804\n199 0 -1.181615 6.506164 -1.181615\n200 0 -1.360020 3.777621 -1.360020\n\n\n3.Run logistic regression of the outcome on this covariate using logit of the initial estimator \\(\\mathbb{E}(Y\\mid A,W)\\) as offset where logit(x)= log[x/(1-x)]\n\nlogitUpdate &lt;- glm( data$Y ~ -1 +offset( qlogis(SL.predict.outcome)) +\n                      H.AW, family='binomial')\n\nWarning in eval(family$initialize): non-integer #successes in a binomial glm!\n\nepsilon &lt;- logitUpdate$coef\nepsilon\n\n       H.AW \n0.003211247 \n\n\n\nPlug in the estimated coefficient \\(\\epsilon\\) to yield our targeted estimator \\(\\mathbb{E^*}(Y\\mid A,W)\\) and use the targeted estimator \\(\\mathbb{E^*}(Y\\mid A,W)\\) to predict outcomes for all under A=1 and A=0\n\n\ntarget.predict.outcome.A1 &lt;- plogis( qlogis(SL.predict.outcome.A1)+\n                                       epsilon*H.1W)\ntarget.predict.outcome.A0 &lt;- plogis( qlogis(SL.predict.outcome.A0)+\n                                      epsilon*H.0W)\n\n\nAverage the predictions to estimate the marginal risks in the population under exposure and no exposure. Compare the estimates by taking the difference.\n\n\nTMLE &lt;- mean( target.predict.outcome.A1 - target.predict.outcome.A0)\nTMLE\n\n[1] -0.02453077\n\n\n\n\n\n5.12.4 Estimator Properties\n\nWe have discussed three estimators and gone through their implementation. We shall now go over the properties and each of them and points of consideration.\nSimple substitution estimator\n\nRelies on consistently estimating the mean outcome \\(\\mathbb{E^*}(Y\\mid A,W)\\). Sometimes we have a lot of knowledge about how the relationship between the outcome Y and the exposure-covariates (A,W) but other times, our knowldege is limited and assuming a parametric regression model can result in bias and misleading inferences.\n\nIPTW\n\nRelies on consistently estimating the propensity score \\(\\mathbb{P}(A=1\\mid W)\\). While sometimes we have a lot of knowledge about how the exposure was assigned, other times our knowledge is limited and assuming a parametric regression model can result in bias and misleading inference.\nThis estimator is unstable under positivity violations. When covariate groups only have a few exposed or unexposed observations, weights can blow up!!. When there are covariate groups with 0 exposed or unexposed observations, weights will not blow up but the estimator will likely be biased and varaince will be underestimated.\n\nTMLE\n\nThis estimator is doubly robust i.e. yields a consistent estimate if either the conditional mean \\(\\mathbb{E^*}(Y\\mid A,W)\\) or the propensity score \\(\\mathbb{P}(A=1\\mid W)\\) is consistently estimated. We get two chances to get it right !!\nIt is also semi-parametric efficient which means it achieves the lowest asymptotic variance (most precision) among a large class of estimators if both the conditional mean and propensity score are consistently estimated at reasonable rates.\nThis estimator has formal theory to support valid statistical inference under mild conditions even when using machine learning.\nBeing a substitution estimator (plug-in), it is robust under positivity violations,strong confounding and rare outcomes.\nThere is readily available software to implement this estimator e.g. ltmle package, lmptp package in R among others\n\nWe have now come to the end of our estimation exercise assuming we have selected an estimating approach and estimated our parameter of interest. We now move back to the general Roadmap.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html#step-6-statistical-uncertainty",
    "href": "roadmap_tutorial.html#step-6-statistical-uncertainty",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "5.13 Step 6: Statistical Uncertainty",
    "text": "5.13 Step 6: Statistical Uncertainty\n\nTo do statistical inference, we need to derive an estimate of the sampling distribution.\nWe can consider doing a non-parametric bootstrap where we re-sample the observed data with replacement, apply the entire estimation process (including machine learning algorithms) to the re-sampled data, repeat X times and estimate the variance with the bootstrapped point estimates.\nAlternatively, we can use influence curve based inference. We shall not discuss this here but this form of inference is available in the R packages.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html#step-7-interpret-findings",
    "href": "roadmap_tutorial.html#step-7-interpret-findings",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "5.14 Step 7: Interpret findings",
    "text": "5.14 Step 7: Interpret findings\n\nThe final step of the Causal Roadmap is to interpret the findings. At this stage, we evaluate whether and to what extent the underlying assumptions have been met in order to determine the strength of interpretation.\nFindings support a statistical interpretation if (1) the statistical estimator has negligible bias and its variance is well estimated\nFindings support a causal interpretation if 1 holds and (2) if the non testable identifiability assumptions hold.\nCan be interpreted as if implemented in the real-world if 1 and 2 hold and if (3) the intervention is feasible and applicable to the real world population.\nFindings can be interpreted as if we had emulated a randomized trial if 1-3 hold and the exposure could have been randomized to that population.\nIf there are concerns about causal assumptions (e.g. temporal odering is unclear, unmeasured confounding), the results can be interpreted as associational. In this case the estimand, \\(\\mathbb{E}\\big[\\mathbb{E}(Y\\mid A=1,W)-\\mathbb{E}(Y\\mid A=0,W)]\\) can be interpreted as;\n\nThe marginal difference in the expected outcome associated with the exposure, after accounting for the measured confounders\nThe difference in the mean outcome between persons exposed versus unexposed but with the same values of the adjustment covariates (averaged with respect to the distribution of those covariates in the population).e.g The difference in the risk of cardiovascular disease with intervention A vs B is X, accounting for region,age,sex,SES etc\nAlternatively one can report that this is as close as we can get to the causal effet of A on Y given the limitations of the data detailing all limitations and including a causal graph to empower the reader to assess the plausibility of assumptions.\n\nIf the authors believe causal assumptions are met, the parameter can be interpreted as the population average treatment effect \\(\\mathbb{E}\\big[Y_1-Y_0\\big]\\).\n\nIn words, this would be the difference in the expected outcome if everyone were exposed compared if everyone were unexposed. For example, there would be an X difference in the risk of cardiovascular disease if all patients in the population received intervention A vs B.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html#summary-and-discussion",
    "href": "roadmap_tutorial.html#summary-and-discussion",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "5.15 Summary and Discussion",
    "text": "5.15 Summary and Discussion\n\nCongratulations!! You have successfully gone through the causal roadmap tutorial and successfully implemented the simple substitution, IPTW and TMLE estimators.\nHopefully, you have increased your intuitive and technical understanding of these estimators.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "roadmap_tutorial.html#caution-use-your-tools-well.",
    "href": "roadmap_tutorial.html#caution-use-your-tools-well.",
    "title": "5  Causal Roadmap for Real-world Evidence Generation: A Tutorial",
    "section": "5.16 Caution: Use your tools well.",
    "text": "5.16 Caution: Use your tools well.\n\nUse TMLE with Super Learner as part of a toolbox. Recall, fancy estimation tools cannot replace careful thinking throughout the rest of the Roadmap.\nRemember to formally derive adjustment sets and the statistical parameter.\n\nAvoid errors of “causal model neglect”, occuring when estimating something differing meaningfully from any interpretable causal effect.\n\nDoubly robust estimators (e.g TMLE or A-IPW) can incorporate machine learning while maintaining basis for valid statistical inference. This helps us avoid errors of “statistical model neglect”, occurring when relying on unsubstantiated (parametric) assumptions during estimation. However, not without conditions.\n\nSpecify the Super Learner library with care.\nDiversity is key\nAvoid overfitting by using sample splitting\n\nPractical positivity violations can happen. This can result from poor support for exposures of interest and can lead to bias and/or underestimates of variance. Some solutions to this include;\n\nUsing a substitution estimator (G-comp,TMLE)\nDoing targeting in TMLE through weighted regression instead of a clever covariate\nUsing a robust variance estimator e.g Tran et al.(2018), Benkeser et al. (2017)\nBounding the estimated propensity score away from O\n\nRun a simulation study mimicking key patterns of the observed data for example sample size, confounding structure, missing data mechanisms, practical violations, sparsity of the exposure and/or outcome, dependence structure etc and use results to guide analyses.\nYou have also survived a high speed tour through the Roadmap, and hopefully can appreciate some of its strengths.\n\nIt necessitates clearly defined research questions, and ensures the parameters estimated will match the questions posed.\nElaborates what assumptions are necessary to interpret estimates as a causal effect\nWhen assumptions are not met, the unmet assumptions provide clear guidance on how future research must be improved to increase the potential of causal interpretation.\nWorking in this framework can improve interpretability and relevance of epidemiologic research.\nDespite focusing on the ATE, this framework is applicable to other causal questions and data structures such as estimating effects among treated/untreated, mediation, longitudinal interventions, dynamic regimes etc.\n\nIf you are interested in learning about more advanced settings, here are some links to other resources.",
    "crumbs": [
      "Part I: Foundations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Causal Roadmap for Real-world Evidence Generation: A Tutorial</span>"
    ]
  },
  {
    "objectID": "02-01-gcomputation.html",
    "href": "02-01-gcomputation.html",
    "title": "6  Chapter 2.1: Outcome Modeling and Standardization (G-Computation)",
    "section": "",
    "text": "7 Chapter 2.1: Outcome Modeling and Standardization\nG-computation as a foundation for causal estimation\nOutcome modeling and standardization—often referred to as g-computation—is one of the oldest and most intuitive approaches to causal inference. In this chapter, we’ll build intuition, walk carefully through why the method works, show where it fails, and provide fully reproducible examples in R (using tidyverse style).\nThis chapter is intentionally thorough, designed for students new to causal inference but with working knowledge of regression.",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chapter 2.1: Outcome Modeling and Standardization (G-Computation)</span>"
    ]
  },
  {
    "objectID": "02-01-gcomputation.html#software-implementation-r",
    "href": "02-01-gcomputation.html#software-implementation-r",
    "title": "6  Chapter 2.1: Outcome Modeling and Standardization (G-Computation)",
    "section": "11.1 Software Implementation (R)",
    "text": "11.1 Software Implementation (R)\nThis example implements g-computation (parametric standardization) by hand, then shows how the tmle package automates and improves on this approach with targeting.\n\nSimulate a confounded point-treatment dataset\nFit an outcome model \\(\\hat{Q}(A,W) = E[Y \\mid A, W]\\)\nPredict under \\(A=1\\) and \\(A=0\\) for everyone, then average (g-computation)\nCompare with the TMLE estimate, which adds a targeting step for bias correction\n\n\nset.seed(1)\nn &lt;- 500\nW &lt;- rnorm(n)\nA &lt;- rbinom(n, 1, plogis(0.5 * W))\nY &lt;- rbinom(n, 1, plogis(-1 + 0.8 * A + 1.0 * W))  # true RD ≈ 0.16\n\n## ── Manual g-computation ──\nQ_mod &lt;- glm(Y ~ A + W, family = binomial, data = data.frame(Y, A, W))\n\nQ1 &lt;- predict(Q_mod, newdata = data.frame(A = 1, W = W), type = \"response\")\nQ0 &lt;- predict(Q_mod, newdata = data.frame(A = 0, W = W), type = \"response\")\ngcomp_ate &lt;- mean(Q1) - mean(Q0)\ncat(\"G-computation ATE:\", round(gcomp_ate, 3), \"\\n\")\n\n## ── TMLE (adds targeting to g-computation) ──\nif (requireNamespace(\"tmle\", quietly = TRUE)) {\n  library(tmle)\n  fit &lt;- tmle(Y = Y, A = A, W = data.frame(W = W),\n              family = \"binomial\",\n              Q.SL.library = \"SL.glm\", g.SL.library = \"SL.glm\")\n  cat(\"TMLE ATE:\", round(fit$estimates$ATE$psi, 3), \"\\n\")\n  cat(\"95% CI: \", round(fit$estimates$ATE$CI, 3), \"\\n\")\n} else {\n  message(\"Install the 'tmle' package:  install.packages('tmle')\")\n}",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chapter 2.1: Outcome Modeling and Standardization (G-Computation)</span>"
    ]
  },
  {
    "objectID": "02-02-iptw.html",
    "href": "02-02-iptw.html",
    "title": "7  Chapter 2.2: Inverse Probability of Treatment Weighting (IPTW)",
    "section": "",
    "text": "8 Chapter 2.2: Inverse Probability of Treatment Weighting\nInverse probability of treatment weighting (IPTW) is a core method in modern causal inference. Instead of modeling the outcome directly as in g computation, IPTW uses a model for treatment assignment to create a pseudo population where treatment is independent of confounders.\nIn this chapter we will\nThis is still point treatment only. Longitudinal extensions come later.",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 2.2: Inverse Probability of Treatment Weighting (IPTW)</span>"
    ]
  },
  {
    "objectID": "02-02-iptw.html#direct-weighted-mean-of-outcomes",
    "href": "02-02-iptw.html#direct-weighted-mean-of-outcomes",
    "title": "7  Chapter 2.2: Inverse Probability of Treatment Weighting (IPTW)",
    "section": "14.1 6.1 Direct weighted mean of outcomes",
    "text": "14.1 6.1 Direct weighted mean of outcomes\nEstimated risk under treatment\n\nrisk1_ipw &lt;- with(dat, sum(sw_ipw * Y * (A == 1)) / sum(sw_ipw * (A == 1)))\nrisk0_ipw &lt;- with(dat, sum(sw_ipw * Y * (A == 0)) / sum(sw_ipw * (A == 0)))\n\nate_ipw &lt;- risk1_ipw - risk0_ipw\nc(risk1 = risk1_ipw, risk0 = risk0_ipw, ate = ate_ipw)\n\n    risk1     risk0       ate \n0.4109454 0.2991691 0.1117762 \n\n\nThis matches the formula\n\\[\n\\hat E[Y(1)] = \\frac{\\sum_i SW_i Y_i I(A_i = 1)}{\\sum_i SW_i I(A_i = 1)}\n\\]",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 2.2: Inverse Probability of Treatment Weighting (IPTW)</span>"
    ]
  },
  {
    "objectID": "02-02-iptw.html#weighted-regression-model",
    "href": "02-02-iptw.html#weighted-regression-model",
    "title": "7  Chapter 2.2: Inverse Probability of Treatment Weighting (IPTW)",
    "section": "14.2 6.2 Weighted regression model",
    "text": "14.2 6.2 Weighted regression model\nWe can also fit a weighted regression with treatment as the only predictor.\n\nlibrary(sandwich)\nlibrary(lmtest)\n\n# Fit a simple weighted model\nfit_ipw &lt;- glm(Y ~ A, family = binomial, weights = sw_ipw, data = dat)\n\n# Robust standard errors\ncov_ipw &lt;- vcovHC(fit_ipw, type = \"HC0\")\ncoeftest(fit_ipw, cov_ipw)\n\nInterpretation\n\nThe coefficient of A (on the log odds scale) now estimates a marginal effect in the pseudo population\nYou can compute marginal risk differences or ratios by predicting from the model at A=1 and A=0 and standardizing",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Chapter 2.2: Inverse Probability of Treatment Weighting (IPTW)</span>"
    ]
  },
  {
    "objectID": "02-03-doubly-robust-tmle.html",
    "href": "02-03-doubly-robust-tmle.html",
    "title": "8  Chapter 2.3: Doubly Robust Estimators and Targeted Learning (AIPW + TMLE)",
    "section": "",
    "text": "9 Chapter 2.3: Doubly Robust Estimation and Targeted Learning\nBridging outcome modeling and weighting for more robust causal effect estimation\nIn previous chapters, you learned:\nBut what if you could use both models, and as long as either one is correct, your estimator is still consistent?\nThis is exactly what doubly robust estimators provide.\nWe explore:",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Chapter 2.3: Doubly Robust Estimators and Targeted Learning (AIPW + TMLE)</span>"
    ]
  },
  {
    "objectID": "02-03-doubly-robust-tmle.html#formula",
    "href": "02-03-doubly-robust-tmle.html#formula",
    "title": "8  Chapter 2.3: Doubly Robust Estimators and Targeted Learning (AIPW + TMLE)",
    "section": "11.1 2.1 Formula",
    "text": "11.1 2.1 Formula\nLet:\n\n\\(e(W) = P(A = 1 \\mid W)\\) be the propensity score\n\\(m(a, W) = E[Y \\mid A = a, W]\\) be the outcome regression\n\nThen:\n\\[\n\\hat{\\mu}_1 = \\frac{1}{n} \\sum_i \\left[ \\frac{A_i Y_i}{e(W_i)} - \\frac{A_i - e(W_i)}{e(W_i)} m(1, W_i) \\right]\n\\]\n\\[\n\\hat{\\mu}_0 = \\frac{1}{n} \\sum_i \\left[ \\frac{(1-A_i) Y_i}{1 - e(W_i)} + \\frac{A_i - e(W_i)}{1 - e(W_i)} m(0, W_i) \\right]\n\\]\nATE = \\(\\hat{\\mu}_1 - \\hat{\\mu}_0\\)",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Chapter 2.3: Doubly Robust Estimators and Targeted Learning (AIPW + TMLE)</span>"
    ]
  },
  {
    "objectID": "02-03-doubly-robust-tmle.html#software-implementation-r",
    "href": "02-03-doubly-robust-tmle.html#software-implementation-r",
    "title": "8  Chapter 2.3: Doubly Robust Estimators and Targeted Learning (AIPW + TMLE)",
    "section": "21.1 Software Implementation (R)",
    "text": "21.1 Software Implementation (R)\nThis example demonstrates the double robustness property using the tmle package. We deliberately misspecify one nuisance model at a time to show that the TMLE estimate remains consistent as long as at least one model is correct.\n\nSimulate data with a nonlinear confounder–outcome relationship\nScenario A: correct \\(Q\\), wrong \\(g\\) → TMLE consistent\nScenario B: wrong \\(Q\\), correct \\(g\\) → TMLE consistent\nScenario C: both correct → TMLE efficient\nFalls back to a manual demonstration if tmle is unavailable\n\n\nset.seed(1)\nn &lt;- 1000\nW &lt;- rnorm(n)\nA &lt;- rbinom(n, 1, plogis(0.3 * W + 0.2 * W^2))\nY &lt;- 0.5 * A + sin(W) + rnorm(n, sd = 0.3)  # true ATE = 0.5\n\nif (requireNamespace(\"tmle\", quietly = TRUE)) {\n  library(tmle)\n\n  ## Scenario A: correct Q model, misspecified g (intercept only)\n  fit_a &lt;- tmle(Y = Y, A = A, W = data.frame(W = W),\n                Q.SL.library = c(\"SL.glm\", \"SL.earth\"),\n                g.SL.library  = \"SL.mean\")\n  cat(\"Scenario A (correct Q, wrong g):\", round(fit_a$estimates$ATE$psi, 3), \"\\n\")\n\n  ## Scenario B: misspecified Q (intercept only), correct g\n  fit_b &lt;- tmle(Y = Y, A = A, W = data.frame(W = W),\n                Q.SL.library = \"SL.mean\",\n                g.SL.library  = c(\"SL.glm\", \"SL.earth\"))\n  cat(\"Scenario B (wrong Q, correct g):\", round(fit_b$estimates$ATE$psi, 3), \"\\n\")\n\n  ## Scenario C: both reasonably specified\n  fit_c &lt;- tmle(Y = Y, A = A, W = data.frame(W = W),\n                Q.SL.library = c(\"SL.glm\", \"SL.earth\"),\n                g.SL.library  = c(\"SL.glm\", \"SL.earth\"))\n  cat(\"Scenario C (both correct):      \", round(fit_c$estimates$ATE$psi, 3), \"\\n\")\n  cat(\"95% CI:\", round(fit_c$estimates$ATE$CI, 3), \"\\n\")\n} else {\n  message(\"Install the 'tmle' package:  install.packages('tmle')\")\n}",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Chapter 2.3: Doubly Robust Estimators and Targeted Learning (AIPW + TMLE)</span>"
    ]
  },
  {
    "objectID": "02-04-tmle-teaching-examples.html",
    "href": "02-04-tmle-teaching-examples.html",
    "title": "9  Chapter 2.4: From Question to Estimate — TMLE in Practice",
    "section": "",
    "text": "10 Chapter 2.4: From Question to Estimate — TMLE in Practice\nA progressive tutorial for pharmacoepidemiologists\nThis chapter walks through a complete causal analysis from start to finish, building each estimator step-by-step so you can see exactly where bias enters, how each method addresses it, and why TMLE provides a principled solution.\nWe use a realistic post-marketing safety scenario: evaluating the cardiovascular safety of a new diabetes drug.\nBy the end of this chapter, you will have implemented:\nEach method builds on what came before. Every step includes code, diagnostics, and interpretation.",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 2.4: From Question to Estimate — TMLE in Practice</span>"
    ]
  },
  {
    "objectID": "02-04-tmle-teaching-examples.html#the-regulatory-question",
    "href": "02-04-tmle-teaching-examples.html#the-regulatory-question",
    "title": "9  Chapter 2.4: From Question to Estimate — TMLE in Practice",
    "section": "11.1 The Regulatory Question",
    "text": "11.1 The Regulatory Question\nA new sodium-glucose co-transporter 2 (SGLT2) inhibitor, dapagliflozin, has been approved for type 2 diabetes. Post-marketing surveillance data from insurance claims suggest a potential cardiovascular safety signal. The FDA’s Office of Surveillance and Epidemiology asks:\n\nDoes initiation of dapagliflozin (vs. a sulfonylurea comparator) increase the 1-year risk of major adverse cardiovascular events (MACE) in adults with type 2 diabetes?\n\nThis is a classic active comparator, new user design question.\n\n11.1.1 Key elements\n\nTarget population: Adults aged 40-85 with type 2 diabetes initiating a new oral glucose-lowering agent\nTreatment strategies: Initiate dapagliflozin (A = 1) vs. initiate sulfonylurea (A = 0)\nOutcome: 1-year MACE (composite of MI, stroke, CV death), binary\nIntercurrent events: Treatment discontinuation, switching, death from non-CV causes\nDecision: Should the label carry a cardiovascular warning? Is a formal safety trial needed?\n\n\n\n11.1.2 Why standard regression falls short\nA logistic regression of MACE on treatment will confound the effect with differences in baseline health. Patients prescribed newer, more expensive agents may differ systematically from those prescribed sulfonylureas — in age, comorbidity burden, prior cardiovascular history, renal function, and concomitant medications.\nWe need methods that explicitly separate confounding from causal effects.",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 2.4: From Question to Estimate — TMLE in Practice</span>"
    ]
  },
  {
    "objectID": "02-04-tmle-teaching-examples.html#b.-g-computation-outcome-modeling",
    "href": "02-04-tmle-teaching-examples.html#b.-g-computation-outcome-modeling",
    "title": "9  Chapter 2.4: From Question to Estimate — TMLE in Practice",
    "section": "14.1 4B. G-Computation (Outcome Modeling)",
    "text": "14.1 4B. G-Computation (Outcome Modeling)\nG-computation directly implements the identification formula by modeling \\(E[Y \\mid A, W]\\), then standardizing.\n\n\n\n\n\n\nG-Computation Step 1: Fit the Outcome Model\n\n\n\nFit a model for \\(E[Y \\mid A, W]\\) — the expected outcome given treatment and confounders. This model will be used to predict what would happen to each patient under each treatment scenario.\n\n\n\n# Parametric outcome model (logistic regression)\n# We include main effects and key interactions\nq_mod &lt;- glm(Y ~ A + age + bmi + hba1c + cvd + egfr + statin +\n               A:cvd + I(age^2),\n             family = binomial, data = dat)\n\n\n\n\n\n\n\nG-Computation Step 2: Predict Counterfactual Outcomes\n\n\n\nAsk: “What would this patient’s outcome be if they received dapagliflozin? And if they received sulfonylurea?” We generate these predictions for every patient, regardless of what they actually received.\n\n\n\n# Create counterfactual datasets\ndat1 &lt;- dat %&gt;% mutate(A = 1)\ndat0 &lt;- dat %&gt;% mutate(A = 0)\n\n# Predict potential outcomes for each individual\nQ1 &lt;- predict(q_mod, newdata = dat1, type = \"response\")\nQ0 &lt;- predict(q_mod, newdata = dat0, type = \"response\")\n\n\n\n\n\n\n\nG-Computation Step 3: Standardize (Average Over the Population)\n\n\n\nAverage the predicted outcomes across all patients. This implements the G-computation formula: \\(E_W[E[Y \\mid A=a, W]]\\).\n\n\n\ngcomp_risk1 &lt;- mean(Q1)\ngcomp_risk0 &lt;- mean(Q0)\ngcomp_ate   &lt;- gcomp_risk1 - gcomp_risk0\n\ncat(\"G-comp risk (dapagliflozin):\", round(gcomp_risk1, 4), \"\\n\")\n#&gt; G-comp risk (dapagliflozin): 0.0629\ncat(\"G-comp risk (sulfonylurea): \", round(gcomp_risk0, 4), \"\\n\")\n#&gt; G-comp risk (sulfonylurea):  0.0996\ncat(\"G-comp ATE:                 \", round(gcomp_ate, 4), \"\\n\")\n#&gt; G-comp ATE:                  -0.0367\ncat(\"True ATE:                   \", round(true_ate, 4), \"\\n\")\n#&gt; True ATE:                    -0.0338\n\n\n14.1.1 Bootstrap confidence interval for G-computation\n\nset.seed(42)\nn_boot &lt;- 500\nboot_ate &lt;- numeric(n_boot)\n\nfor (b in 1:n_boot) {\n  idx &lt;- sample(1:n, n, replace = TRUE)\n  dat_b &lt;- dat[idx, ]\n  mod_b &lt;- glm(Y ~ A + age + bmi + hba1c + cvd + egfr + statin +\n                  A:cvd + I(age^2),\n                family = binomial, data = dat_b)\n  Q1_b &lt;- predict(mod_b, newdata = dat_b %&gt;% mutate(A = 1), type = \"response\")\n  Q0_b &lt;- predict(mod_b, newdata = dat_b %&gt;% mutate(A = 0), type = \"response\")\n  boot_ate[b] &lt;- mean(Q1_b - Q0_b)\n}\n\ngcomp_se &lt;- sd(boot_ate)\ngcomp_ci &lt;- quantile(boot_ate, c(0.025, 0.975))\n\ncat(\"G-comp ATE:\", round(gcomp_ate, 4),\n    \" SE:\", round(gcomp_se, 4),\n    \" 95% CI: [\", round(gcomp_ci[1], 4), \",\", round(gcomp_ci[2], 4), \"]\\n\")\n#&gt; G-comp ATE: -0.0367  SE: 0.0098  95% CI: [ -0.0569 , -0.0191 ]\n\n\n\n\n\n\n\nWhat Just Happened?\n\n\n\nG-computation gave a much better estimate than the naive approach by adjusting for confounders. It works by predicting what would happen to each patient under each treatment, then averaging.\nBut there is a catch: G-computation depends entirely on the outcome model being correct. If we misspecified the functional form (missed interactions, nonlinearities), the estimate would be biased. And we would have no way to know.\nThis motivates IPTW — which adjusts for confounding using the treatment model instead.",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 2.4: From Question to Estimate — TMLE in Practice</span>"
    ]
  },
  {
    "objectID": "02-04-tmle-teaching-examples.html#c.-iptw-treatment-modeling",
    "href": "02-04-tmle-teaching-examples.html#c.-iptw-treatment-modeling",
    "title": "9  Chapter 2.4: From Question to Estimate — TMLE in Practice",
    "section": "14.2 4C. IPTW (Treatment Modeling)",
    "text": "14.2 4C. IPTW (Treatment Modeling)\nIPTW takes a different approach: instead of modeling the outcome, it models treatment assignment and reweights the data to create a pseudo-population where confounders are balanced.\n\n\n\n\n\n\nIPTW Step 1: Estimate the Propensity Score\n\n\n\nThe propensity score \\(g(W) = P(A = 1 \\mid W)\\) answers: given a patient’s covariates, how likely were they to receive dapagliflozin? We use this to reweight the data so that treatment looks “as-if-randomized.”\n\n\n\n# Propensity score model\ng_mod &lt;- glm(A ~ age + bmi + hba1c + cvd + egfr + statin +\n               I(age^2) + age:cvd,\n             family = binomial, data = dat)\n\ndat &lt;- dat %&gt;%\n  mutate(ps = predict(g_mod, type = \"response\"))\n\n# Summary of propensity scores\nsummary(dat$ps)\n#&gt;     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n#&gt; 0.002505 0.146338 0.220684 0.234400 0.314028 0.632319\n\n\n14.2.1 Step 2: Assess propensity score overlap\n\nggplot(dat, aes(x = ps, fill = factor(A, labels = c(\"Sulfonylurea\", \"Dapagliflozin\")))) +\n  geom_density(alpha = 0.45) +\n  labs(\n    x = \"Estimated propensity score P(A=1 | W)\",\n    y = \"Density\",\n    fill = \"Treatment\",\n    title = \"Propensity Score Overlap\"\n  ) +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"#4477AA\", \"#EE6677\"))\n\n\n\n\n\n\n\n\nGood overlap means every type of patient has some chance of getting either drug. If the distributions barely overlap, IPTW will produce extreme weights and unstable estimates.\n\n\n14.2.2 Step 3: Construct stabilized weights\n\n# Marginal treatment probability\np_A &lt;- mean(dat$A)\n\ndat &lt;- dat %&gt;%\n  mutate(\n    # Unstabilized weights\n    w_unstab = ifelse(A == 1, 1 / ps, 1 / (1 - ps)),\n    # Stabilized weights\n    sw = ifelse(A == 1, p_A / ps, (1 - p_A) / (1 - ps))\n  )\n\n\n\n14.2.3 Step 4: Diagnose weights\n\n# Weight diagnostics\ndat %&gt;%\n  group_by(A) %&gt;%\n  summarise(\n    min_w  = min(sw),\n    p01_w  = quantile(sw, 0.01),\n    median = median(sw),\n    p99_w  = quantile(sw, 0.99),\n    max_w  = max(sw),\n    mean_w = mean(sw),\n    sd_w   = sd(sw),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 2 × 8\n#&gt;       A min_w p01_w median p99_w max_w mean_w  sd_w\n#&gt;   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     0 0.768 0.784  0.960  1.50  2.08  1.00  0.161\n#&gt; 2     1 0.373 0.406  0.817  3.22  7.06  0.991 0.594\n\n\n# Weight distribution plot\nggplot(dat, aes(x = sw, fill = factor(A, labels = c(\"Sulfonylurea\", \"Dapagliflozin\")))) +\n  geom_histogram(bins = 50, alpha = 0.6, position = \"identity\") +\n  labs(\n    x = \"Stabilized IPTW weight\",\n    y = \"Count\",\n    fill = \"Treatment\",\n    title = \"Distribution of Stabilized IPTW Weights\"\n  ) +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"#4477AA\", \"#EE6677\")) +\n  geom_vline(xintercept = 1, linetype = \"dashed\", color = \"grey40\")\n\n\n\n\n\n\n\n\nWhat to look for:\n\nWeights should be centered around 1 (for stabilized weights)\nVery large weights (&gt; 10) indicate positivity problems\nThe mean of stabilized weights should be approximately 1\n\n\n\n14.2.4 Step 5: Check covariate balance after weighting\n\n# Standardized mean differences: unweighted vs weighted\ncompute_smd &lt;- function(data, var, trt, weights = NULL) {\n  if (is.null(weights)) weights &lt;- rep(1, nrow(data))\n  d1 &lt;- data[[var]][data[[trt]] == 1]\n  d0 &lt;- data[[var]][data[[trt]] == 0]\n  w1 &lt;- weights[data[[trt]] == 1]\n  w0 &lt;- weights[data[[trt]] == 0]\n  m1 &lt;- weighted.mean(d1, w1)\n  m0 &lt;- weighted.mean(d0, w0)\n  s1 &lt;- sqrt(sum(w1 * (d1 - m1)^2) / sum(w1))\n  s0 &lt;- sqrt(sum(w0 * (d0 - m0)^2) / sum(w0))\n  pooled_sd &lt;- sqrt((s1^2 + s0^2) / 2)\n  (m1 - m0) / pooled_sd\n}\n\ncovariates &lt;- c(\"age\", \"bmi\", \"hba1c\", \"cvd\", \"egfr\", \"statin\")\n\nsmd_raw &lt;- sapply(covariates, function(v) compute_smd(dat, v, \"A\"))\nsmd_wt  &lt;- sapply(covariates, function(v) compute_smd(dat, v, \"A\", dat$sw))\n\nsmd_df &lt;- tibble(\n  variable = covariates,\n  Unadjusted = abs(smd_raw),\n  Weighted   = abs(smd_wt)\n) %&gt;%\n  pivot_longer(-variable, names_to = \"Method\", values_to = \"SMD\")\n\nggplot(smd_df, aes(x = SMD, y = reorder(variable, SMD), color = Method, shape = Method)) +\n  geom_point(size = 3) +\n  geom_vline(xintercept = 0.1, linetype = \"dashed\", color = \"grey50\") +\n  labs(\n    x = \"Absolute Standardized Mean Difference\",\n    y = \"\",\n    title = \"Covariate Balance: Before and After IPTW\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"#EE6677\", \"#228833\"))\n\n\n\n\n\n\n\n\nThe dashed line at 0.1 is a common threshold. After weighting, all covariates should be below this line.\n\n\n14.2.5 Step 6: Estimate the ATE\n\n# Hajek (ratio) estimator with stabilized weights\nrisk1_iptw &lt;- with(dat, sum(sw * Y * (A == 1)) / sum(sw * (A == 1)))\nrisk0_iptw &lt;- with(dat, sum(sw * Y * (A == 0)) / sum(sw * (A == 0)))\niptw_ate   &lt;- risk1_iptw - risk0_iptw\n\ncat(\"IPTW risk (dapagliflozin):\", round(risk1_iptw, 4), \"\\n\")\n#&gt; IPTW risk (dapagliflozin): 0.0559\ncat(\"IPTW risk (sulfonylurea): \", round(risk0_iptw, 4), \"\\n\")\n#&gt; IPTW risk (sulfonylurea):  0.0996\ncat(\"IPTW ATE:                 \", round(iptw_ate, 4), \"\\n\")\n#&gt; IPTW ATE:                  -0.0438\ncat(\"True ATE:                 \", round(true_ate, 4), \"\\n\")\n#&gt; True ATE:                  -0.0338\n\n\n\n14.2.6 Weight truncation\nIf weights are extreme, truncation can improve stability at the cost of a small amount of bias:\n\n# Truncate at 1st and 99th percentiles\ntrunc_lower &lt;- quantile(dat$sw, 0.01)\ntrunc_upper &lt;- quantile(dat$sw, 0.99)\n\ndat &lt;- dat %&gt;%\n  mutate(sw_trunc = pmin(pmax(sw, trunc_lower), trunc_upper))\n\nrisk1_trunc &lt;- with(dat, sum(sw_trunc * Y * (A == 1)) / sum(sw_trunc * (A == 1)))\nrisk0_trunc &lt;- with(dat, sum(sw_trunc * Y * (A == 0)) / sum(sw_trunc * (A == 0)))\niptw_ate_trunc &lt;- risk1_trunc - risk0_trunc\n\ncat(\"IPTW ATE (truncated weights):\", round(iptw_ate_trunc, 4), \"\\n\")\n#&gt; IPTW ATE (truncated weights): -0.0472\n\n\n\n\n\n\n\nWhat Just Happened?\n\n\n\nIPTW adjusts for confounding through the treatment model alone. It does not use information about the outcome-confounder relationship.\nThe weakness: If the propensity score model is wrong, IPTW is biased. If positivity is limited, weights become extreme and the estimate becomes unstable. And unlike G-computation, IPTW does not use the outcome model at all.\nThis motivates doubly robust methods — which use BOTH the outcome model and the treatment model, so that if either one is correct, the estimate is consistent.",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 2.4: From Question to Estimate — TMLE in Practice</span>"
    ]
  },
  {
    "objectID": "02-04-tmle-teaching-examples.html#d.-aipw-augmented-inverse-probability-weighting",
    "href": "02-04-tmle-teaching-examples.html#d.-aipw-augmented-inverse-probability-weighting",
    "title": "9  Chapter 2.4: From Question to Estimate — TMLE in Practice",
    "section": "14.3 4D. AIPW (Augmented Inverse Probability Weighting)",
    "text": "14.3 4D. AIPW (Augmented Inverse Probability Weighting)\n\n\n\n\n\n\nThe Doubly Robust Idea\n\n\n\nWhat if we could use BOTH the outcome model and the treatment model, and as long as EITHER one is correct, get a consistent estimate? This is exactly what AIPW (and TMLE) provide.\n\n\nAIPW combines the outcome model and the treatment model. It is doubly robust: consistent if either model is correct.\n\n# Using models from previous steps:\n# Q1, Q0 = predicted outcomes from g-computation\n# ps     = propensity scores from IPTW\n\n# AIPW components\nmu1_aipw &lt;- with(dat, mean(\n  Q1 + A * (Y - Q1) / ps\n))\nmu0_aipw &lt;- with(dat, mean(\n  Q0 + (1 - A) * (Y - Q0) / (1 - ps)\n))\naipw_ate &lt;- mu1_aipw - mu0_aipw\n\ncat(\"AIPW risk (dapagliflozin):\", round(mu1_aipw, 4), \"\\n\")\n#&gt; AIPW risk (dapagliflozin): 0.0596\ncat(\"AIPW risk (sulfonylurea): \", round(mu0_aipw, 4), \"\\n\")\n#&gt; AIPW risk (sulfonylurea):  0.0995\ncat(\"AIPW ATE:                 \", round(aipw_ate, 4), \"\\n\")\n#&gt; AIPW ATE:                  -0.04\ncat(\"True ATE:                 \", round(true_ate, 4), \"\\n\")\n#&gt; True ATE:                  -0.0338\n\n\n14.3.1 Influence curve and inference\nThe efficient influence curve (EIC) for the ATE gives us individual-level “scores” that measure each observation’s contribution to the estimate. The variance of these scores provides valid standard errors.\n\n# Efficient influence curve for ATE\neic &lt;- with(dat,\n  (A / ps) * (Y - Q1) + Q1 - mu1_aipw -\n  ((1 - A) / (1 - ps)) * (Y - Q0) - Q0 + mu0_aipw\n)\n\naipw_se &lt;- sqrt(var(eic) / n)\naipw_ci &lt;- aipw_ate + c(-1.96, 1.96) * aipw_se\n\ncat(\"AIPW ATE:\", round(aipw_ate, 4),\n    \" SE:\", round(aipw_se, 4),\n    \" 95% CI: [\", round(aipw_ci[1], 4), \",\", round(aipw_ci[2], 4), \"]\\n\")\n#&gt; AIPW ATE: -0.04  SE: 0.0101  95% CI: [ -0.0598 , -0.0201 ]\n\nKey insight: AIPW improves on both g-computation and IPTW by using both models. However, AIPW does not “target” its initial estimates — it can produce predicted probabilities outside [0, 1], and it does not solve the efficient influence curve equation exactly when machine learning is used. TMLE addresses both issues.",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 2.4: From Question to Estimate — TMLE in Practice</span>"
    ]
  },
  {
    "objectID": "02-04-tmle-teaching-examples.html#e.-tmle-targeted-maximum-likelihood-estimation",
    "href": "02-04-tmle-teaching-examples.html#e.-tmle-targeted-maximum-likelihood-estimation",
    "title": "9  Chapter 2.4: From Question to Estimate — TMLE in Practice",
    "section": "14.4 4E. TMLE (Targeted Maximum Likelihood Estimation)",
    "text": "14.4 4E. TMLE (Targeted Maximum Likelihood Estimation)\n\n\n\n\n\n\nWhy TMLE?\n\n\n\nTMLE is the centerpiece of this chapter. It combines the best properties of all previous methods:\n\nUses both outcome and treatment models (doubly robust)\nTargets the specific estimand of interest (not just fitting a good outcome model)\nRespects natural parameter bounds (probabilities stay in [0, 1])\nSolves the efficient influence curve equation, ensuring valid inference\nIntegrates naturally with machine learning (Super Learner)\n\n\n\n\n14.4.1 Conceptual overview\n\n\n\n\n\n\nTMLE in Three Stages\n\n\n\n\nInitial estimate: Fit an outcome model \\(\\hat{Q}^0(A, W) = \\hat{E}[Y \\mid A, W]\\) (like g-computation)\nTargeting step: Update \\(\\hat{Q}^0\\) using information from the propensity score to reduce bias for the specific estimand\nSubstitution estimate: Plug the updated \\(\\hat{Q}^*\\) into the G-computation formula\n\nThe targeting step is what makes TMLE special. It uses the clever covariate — a function of the propensity score — to fluctuate the initial outcome model in the direction that solves the efficient influence curve equation.\n\n\n\n\n14.4.2 Step-by-step implementation\n\n\n\n\n\n\nStep 1: Initial Outcome Model\n\n\n\nThis is the same as G-computation — fit \\(E[Y \\mid A, W]\\). Think of this as your “first draft” of the outcome model. It does not need to be perfect; the targeting step will correct it.\n\n\n\n# Same as g-computation — fit E[Y | A, W]\nq_init &lt;- glm(Y ~ A + age + bmi + hba1c + cvd + egfr + statin +\n                A:cvd + I(age^2),\n              family = binomial, data = dat)\n\n# Initial predictions\nQ1_init &lt;- predict(q_init, newdata = dat %&gt;% mutate(A = 1), type = \"response\")\nQ0_init &lt;- predict(q_init, newdata = dat %&gt;% mutate(A = 0), type = \"response\")\nQA_init &lt;- predict(q_init, type = \"response\")  # predictions at observed A\n\n\n\n\n\n\n\nStep 2: Estimate the Propensity Score\n\n\n\nSame as IPTW — model the probability of treatment given confounders. We bound the scores away from 0 and 1 to prevent numerical instability.\n\n\n\n# Same model as IPTW\ng_fit &lt;- glm(A ~ age + bmi + hba1c + cvd + egfr + statin +\n               I(age^2) + age:cvd,\n             family = binomial, data = dat)\n\nps_tmle &lt;- predict(g_fit, type = \"response\")\n\n# Bound propensity scores away from 0 and 1 for stability\nps_tmle &lt;- pmax(0.01, pmin(0.99, ps_tmle))\n\n\n\n\n\n\n\nStep 3: Compute the Clever Covariate\n\n\n\nThe clever covariate \\(H(A, W)\\) is the bridge between the treatment model and the outcome model. It tells the targeting step which observations are most informative about the causal effect.\n\n\n\n# Clever covariate for each observation at their OBSERVED treatment\nH_A &lt;- dat$A / ps_tmle - (1 - dat$A) / (1 - ps_tmle)\n\n# Clever covariate under A=1 and A=0 (for prediction)\nH_1 &lt;- 1 / ps_tmle\nH_0 &lt;- -1 / (1 - ps_tmle)\n\nThe clever covariate is large when a patient’s treatment was unlikely given their covariates — exactly the patients who are most informative about the causal effect.\n\n\n\n\n\n\nStep 4: Fluctuation (The Targeting Step)\n\n\n\nThis is the key step that makes TMLE different from every other estimator. We fit a logistic regression of \\(Y\\) on \\(H(A, W)\\) with the initial \\(\\hat{Q}^0\\) as an offset. The coefficient \\(\\epsilon\\) tells us how much to “nudge” the initial estimate toward solving the efficient influence curve equation.\n\n\n\nlogit &lt;- function(p) log(p / (1 - p))\n\n# Fluctuation model: logit(Y) ~ offset(logit(Q_init)) + H\nfluc &lt;- glm(Y ~ -1 + offset(logit(QA_init)) + H_A,\n            family = binomial, data = dat)\n\nepsilon &lt;- coef(fluc)\ncat(\"Epsilon (fluctuation parameter):\", round(epsilon, 5), \"\\n\")\n#&gt; Epsilon (fluctuation parameter): -0.00633\n\n\n\n\n\n\n\nInterpreting Epsilon\n\n\n\nA small \\(\\epsilon\\) means the initial model was already close to solving the EIC equation. A large \\(\\epsilon\\) means the targeting step made a substantial correction.\n\n\n\n\n\n\n\n\nStep 5: Update Predictions\n\n\n\nApply the fluctuation to get the targeted predictions. Because we use the inverse-logit function (plogis), predictions are guaranteed to stay in [0, 1] — the natural bounds for a probability.\n\n\n\n# Apply the fluctuation to counterfactual predictions\nQ1_star &lt;- plogis(logit(Q1_init) + epsilon * H_1)\nQ0_star &lt;- plogis(logit(Q0_init) + epsilon * H_0)\n\n\n\n\n\n\n\nStep 6: Compute the TMLE Estimate\n\n\n\nAverage the targeted predictions across the population — just like the final step of G-computation, but now using the updated \\(\\hat{Q}^*\\) that has been targeted for our specific estimand.\n\n\n\ntmle_risk1 &lt;- mean(Q1_star)\ntmle_risk0 &lt;- mean(Q0_star)\ntmle_ate   &lt;- tmle_risk1 - tmle_risk0\n\ncat(\"TMLE risk (dapagliflozin):\", round(tmle_risk1, 4), \"\\n\")\n#&gt; TMLE risk (dapagliflozin): 0.0594\ncat(\"TMLE risk (sulfonylurea): \", round(tmle_risk0, 4), \"\\n\")\n#&gt; TMLE risk (sulfonylurea):  0.1002\ncat(\"TMLE ATE:                 \", round(tmle_ate, 4), \"\\n\")\n#&gt; TMLE ATE:                  -0.0409\ncat(\"True ATE:                 \", round(true_ate, 4), \"\\n\")\n#&gt; True ATE:                  -0.0338\n\n\n\n\n\n\n\nStep 7: Inference via the Efficient Influence Curve\n\n\n\nThe EIC gives each observation a “score” measuring its contribution to the estimate. The variance of these scores provides asymptotically valid standard errors — no bootstrap needed.\n\n\n\n# EIC evaluated at the TMLE estimates\neic_tmle &lt;- with(dat,\n  (A / ps_tmle) * (Y - Q1_star) + Q1_star - tmle_risk1 -\n  ((1 - A) / (1 - ps_tmle)) * (Y - Q0_star) - Q0_star + tmle_risk0\n)\n\ntmle_se &lt;- sqrt(var(eic_tmle) / n)\ntmle_ci &lt;- tmle_ate + c(-1.96, 1.96) * tmle_se\n\ncat(\"TMLE ATE:\", round(tmle_ate, 4),\n    \" SE:\", round(tmle_se, 4),\n    \" 95% CI: [\", round(tmle_ci[1], 4), \",\", round(tmle_ci[2], 4), \"]\\n\")\n#&gt; TMLE ATE: -0.0409  SE: 0.0102  95% CI: [ -0.0608 , -0.021 ]\n\n\n\n\n\n\n\nVerify: Is the EIC Mean Zero?\n\n\n\nA correctly implemented TMLE solves the efficient influence curve equation, meaning the sample mean of the EIC should be approximately zero. This is how you know the targeting step worked correctly.\n\n\n\ncat(\"Mean of EIC:\", round(mean(eic_tmle), 8), \"\\n\")\n#&gt; Mean of EIC: 0\ncat(\"(Should be very close to zero)\\n\")\n#&gt; (Should be very close to zero)\n\n\n\n\n\n\n\n\nPutting It All Together\n\n\n\nWe now have five estimators of the same causal quantity. Let’s see how they compare. If our models are reasonable, the doubly robust methods (AIPW and TMLE) should be closest to the truth.",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 2.4: From Question to Estimate — TMLE in Practice</span>"
    ]
  },
  {
    "objectID": "02-04-tmle-teaching-examples.html#sources-and-further-reading",
    "href": "02-04-tmle-teaching-examples.html#sources-and-further-reading",
    "title": "9  Chapter 2.4: From Question to Estimate — TMLE in Practice",
    "section": "18.1 Sources and further reading",
    "text": "18.1 Sources and further reading\n\nGruber S, van der Laan MJ (2010). A targeted maximum likelihood estimator of a causal effect on a bounded continuous outcome. Int J Biostat 6(1):Article 26.\nvan der Laan MJ, Rose S (2011). Targeted Learning. Springer.\nSchuler MS, Rose S (2017). Targeted maximum likelihood estimation for causal inference in observational studies. Am J Epidemiol 185(1):65-73.\nHoffman K (2021). An illustrated guide to TMLE. khstats.com\nLuque-Fernandez MA et al. (2018). Targeted maximum likelihood estimation for a binary treatment: a tutorial. Statistics in Medicine 37(16):2530-2546.\ntmle R package: CRAN\nSuperLearner R package: CRAN\ndrtmle R package: CRAN",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 2.4: From Question to Estimate — TMLE in Practice</span>"
    ]
  },
  {
    "objectID": "02-04-tmle-teaching-examples.html#software-implementation-r",
    "href": "02-04-tmle-teaching-examples.html#software-implementation-r",
    "title": "9  Chapter 2.4: From Question to Estimate — TMLE in Practice",
    "section": "18.2 Software Implementation (R)",
    "text": "18.2 Software Implementation (R)\nThis example brings together the progressive estimation sequence from this chapter (naive → g-computation → IPTW → TMLE) using the tmle package with Super Learner.\n\nSimulate a pharmacoepi-style dataset with multiple confounders\nRun the tmle() function with a diverse Super Learner library\nExtract and interpret: ATE, risk difference, confidence interval, and influence curve diagnostics\n\n\nset.seed(1)\nn &lt;- 800\nW1 &lt;- rnorm(n)                                      # age (standardized)\nW2 &lt;- rbinom(n, 1, 0.3)                             # diabetes indicator\nW3 &lt;- rnorm(n, mean = 0.5 * W1)                     # BMI (standardized)\nA  &lt;- rbinom(n, 1, plogis(-0.3 + 0.4 * W1 + 0.5 * W2 - 0.2 * W3))\nY  &lt;- rbinom(n, 1, plogis(-2 + 0.6 * A + 0.5 * W1 + 0.8 * W2 + 0.3 * W3))\n\nif (requireNamespace(\"tmle\", quietly = TRUE)) {\n  library(tmle)\n  W &lt;- data.frame(W1 = W1, W2 = W2, W3 = W3)\n\n  tmle_fit &lt;- tmle(\n    Y = Y, A = A, W = W,\n    family = \"binomial\",\n    Q.SL.library = c(\"SL.glm\", \"SL.step\", \"SL.mean\"),\n    g.SL.library  = c(\"SL.glm\", \"SL.step\", \"SL.mean\")\n  )\n\n  cat(\"── TMLE results ─────────────────────\\n\")\n  cat(\"ATE (risk difference):\", round(tmle_fit$estimates$ATE$psi, 4), \"\\n\")\n  cat(\"95% CI:\", round(tmle_fit$estimates$ATE$CI, 4), \"\\n\")\n  cat(\"p-value:\", format.pval(tmle_fit$estimates$ATE$pvalue, digits = 3), \"\\n\")\n\n  ## Influence curve diagnostic (mean should be ≈ 0)\n  ic &lt;- tmle_fit$estimates$ATE$IC\n  cat(\"\\nInfluence curve mean:\", round(mean(ic), 6),\n      \" (should be ≈ 0)\\n\")\n} else {\n  message(\"Install the 'tmle' package:  install.packages('tmle')\")\n}",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Chapter 2.4: From Question to Estimate — TMLE in Practice</span>"
    ]
  },
  {
    "objectID": "superlearner.html",
    "href": "superlearner.html",
    "title": "10  Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "",
    "text": "11 Chapter 2.4: SuperLearner and Machine Learning for Causal Inference\nFlexible prediction to strengthen causal effect estimation\nModern causal inference relies on estimating nuisance functions (outcome regressions and treatment / censoring mechanisms) that are as accurate as possible. If these models are mis-specified, even sophisticated causal estimators can be biased.\nRather than gambling on a single model (e.g., logistic regression), we can stack many candidate learners and let the data decide how to combine them. This is what SuperLearner does.\nIn this chapter you will learn:\nThis chapter leans heavily on the excellent visual tutorial by Katherine Hoffman and the SuperLearner demo by David Benkeser (both provided as PDFs), and recasts them in a causal-inference focused Quarto format.",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span>"
    ]
  },
  {
    "objectID": "superlearner.html#why-use-superlearner-in-causal-inference",
    "href": "superlearner.html#why-use-superlearner-in-causal-inference",
    "title": "10  Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "11.1 1. Why Use SuperLearner in Causal Inference?",
    "text": "11.1 1. Why Use SuperLearner in Causal Inference?\nCausal estimators such as g-computation, IPTW, AIPW, and TMLE rely on estimating:\n\nThe outcome regression:\n( Q(W, A) = E[Y W, A] )\nThe treatment (or censoring) mechanism:\n( g(W) = P(A = 1 W) )\n\nIn traditional practice, both are often modeled with simple GLMs. This is dangerous when:\n\nRelationships are nonlinear\nInteractions are present\nThere are many covariates\nWe are unsure about which variables to include or in what functional form\n\nSuperLearner helps by:\n\nCombining multiple algorithms (GLM, random forests, LASSO, boosted trees, etc.)\nUsing K-fold cross-validation to evaluate and weight each algorithm\nProducing an ensemble predictor with theoretical guarantees (an “oracle inequality”): asymptotically, SL performs nearly as well as the best algorithm in the library\n\nIn causal inference, we rarely care about prediction for its own sake, but good prediction of nuisance functions leads to better causal effect estimation.",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span>"
    ]
  },
  {
    "objectID": "superlearner.html#conceptual-overview-of-superlearner",
    "href": "superlearner.html#conceptual-overview-of-superlearner",
    "title": "10  Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "11.2 2. Conceptual Overview of SuperLearner",
    "text": "11.2 2. Conceptual Overview of SuperLearner\nAt a high level, SuperLearner does the following:\n\nPick a set of candidate learners (the library).\nSplit the data into K folds.\nFor each learner:\n\nFit on K-1 folds (training data),\nPredict on the held-out fold (validation data).\n\nCollect cross-validated predictions for every observation and every learner.\nFit a metalearner (often a linear regression) that finds the optimal weighted combination of the learners’ predictions to minimize a chosen loss function (e.g., mean squared error, negative log-likelihood).\nRefit each base learner on the full dataset.\nUse the metalearner and the refit base learners to form the final ensemble and obtain predictions for new data.\n\nThis is exactly the workflow illustrated in the “VISUAL GUIDE TO SUPERLEARNING” figure in the KHstats tutorial.",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span>"
    ]
  },
  {
    "objectID": "superlearner.html#a-minimal-working-example",
    "href": "superlearner.html#a-minimal-working-example",
    "title": "10  Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "11.3 3. A Minimal Working Example",
    "text": "11.3 3. A Minimal Working Example\nWe’ll start with a simple prediction problem, then connect it back to causal inference later.\n\n11.3.1 3.1 Simulated data\n\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'stringr' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.6.0\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(SuperLearner)\n\nLoading required package: nnls\nLoading required package: gam\nLoading required package: splines\nLoading required package: foreach\n\nAttaching package: 'foreach'\n\nThe following objects are masked from 'package:purrr':\n\n    accumulate, when\n\nLoaded gam 1.22-5\n\nSuper Learner\nVersion: 2.0-29\nPackage created on 2024-02-06\n\nset.seed(7)\nn &lt;- 2000\n\nobs &lt;- tibble(\n  id = 1:n,\n  x1 = rnorm(n),\n  x2 = rbinom(n, 1, plogis(10 * x1)),\n  x3 = rbinom(n, 1, plogis(x1 * x2 + 0.5 * x2)),\n  x4 = rnorm(n, mean = x1 * x2, sd = 0.5 * x3),\n  y  = x1 + x2 + x2 * x3 + sin(x4) + rnorm(n, sd = 0.2)\n)\n\nglimpse(obs)\n\nRows: 2,000\nColumns: 6\n$ id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, …\n$ x1 &lt;dbl&gt; 2.287247161, -1.196771682, -0.694292510, -0.412292951, -0.970673341…\n$ x2 &lt;int&gt; 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1…\n$ x3 &lt;int&gt; 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1…\n$ x4 &lt;dbl&gt; 1.50283924, 0.04260947, 0.00000000, 0.00000000, 0.00000000, 1.07555…\n$ y  &lt;dbl&gt; 5.03669124, -1.13306036, -0.38284042, -0.28671230, -0.87539307, -0.…\n\n\nThe outcome y is a nonlinear function of the covariates, with interactions and a sine term. GLMs will struggle here.",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span>"
    ]
  },
  {
    "objectID": "superlearner.html#using-the-superlearner-package",
    "href": "superlearner.html#using-the-superlearner-package",
    "title": "10  Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "11.4 4. Using the SuperLearner Package",
    "text": "11.4 4. Using the SuperLearner Package\n\n11.4.1 4.1 Basic call\nWe’ll start with a small library for illustration.\n\nset.seed(1234)\n\nX &lt;- obs %&gt;% select(x1:x4) %&gt;% as.data.frame()\nY &lt;- obs$y\n\nSL.lib &lt;- c(\"SL.glm\",      # simple GLM\n            \"SL.mean\",     # intercept-only\n            \"SL.earth\",    # multivariate adaptive regression splines (MARS)\n            \"SL.ranger\")   # random forest\n\nsl_fit &lt;- SuperLearner(\n  Y = Y,\n  X = X,\n  newX = NULL,\n  family = gaussian(),\n  SL.library = SL.lib,\n  method = \"method.NNLS\",  # non-negative least squares metalearner\n  cvControl = list(V = 10L)\n)\n\nLoading required namespace: earth\n\n\nLoading required namespace: ranger\n\nsl_fit\n\n\nCall:  \nSuperLearner(Y = Y, X = X, newX = NULL, family = gaussian(), SL.library = SL.lib,  \n    method = \"method.NNLS\", cvControl = list(V = 10L)) \n\n                    Risk      Coef\nSL.glm_All    0.15038334 0.0000000\nSL.mean_All   4.52716718 0.0000000\nSL.earth_All  0.04408952 0.8593302\nSL.ranger_All 0.05735981 0.1406698\n\n\nKey outputs:\n\nRisk: cross-validated risk (e.g., MSE) for each learner\nCoef: weight given to each learner in the ensemble\n\nThe learner with the smallest CV-risk often gets the largest weight, but SL can combine learners.\nWe can access the ensemble predictions:\n\nhead(sl_fit$SL.predict)\n\n         [,1]\n1  5.36960217\n2 -1.15651994\n3 -0.66557910\n4 -0.39653932\n5 -0.94879355\n6 -0.04451723\n\n\nand predictions from individual learners:\n\nhead(sl_fit$library.predict)\n\n  SL.glm_All SL.mean_All SL.earth_All SL.ranger_All\n1  4.9119003    1.145784   5.44169210     4.9292158\n2 -0.9619611    1.145784  -1.14585410    -1.2216759\n3 -0.8907976    1.145784  -0.67326080    -0.6186528\n4 -0.6300543    1.145784  -0.40211488    -0.3624791\n5 -1.1463457    1.145784  -0.94947428    -0.9446351\n6 -0.1673960    1.145784  -0.01723667    -0.2111701",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span>"
    ]
  },
  {
    "objectID": "superlearner.html#choosing-a-loss-function-mse-vs-log-likelihood-vs-auc",
    "href": "superlearner.html#choosing-a-loss-function-mse-vs-log-likelihood-vs-auc",
    "title": "10  Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "11.5 5. Choosing a Loss Function: MSE vs Log-Likelihood vs AUC",
    "text": "11.5 5. Choosing a Loss Function: MSE vs Log-Likelihood vs AUC\nSuperLearner allows different loss functions, which define what we mean by “best” prediction.\n\n11.5.1 5.1 Mean Squared Error (MSE)\n\nDefault for family = gaussian()\nAppropriate for continuous outcomes when we care about squared error: \\[ L(y, \\hat{y}) = (y - \\hat{y})^2 \\]\nGood when we want well-calibrated mean predictions\n\nExample (already used above): method = \"method.NNLS\" with family = gaussian()\n\n\n11.5.2 5.2 Negative Log-Likelihood (Binomial deviance)\n\nNatural choice for binary outcomes when we care about probability calibration: \\[ L(y, \\hat{p}) = -[y \\log(\\hat{p}) + (1-y) \\log(1-\\hat{p})] \\]\nStrongly penalizes confident but wrong predictions\nRecommended for:\n\nOutcome models (Y binary)\nTreatment models (A binary) in causal inference\n\n\nUse method = \"method.NNloglik\" with family = binomial().\nExample:\n\n# suppose Y is binary\nY_bin &lt;- rbinom(n, 1, plogis(X$x1 + X$x2))\n\nsl_loglik &lt;- SuperLearner(\n  Y = Y_bin,\n  X = X,\n  family = binomial(),\n  SL.library = c(\"SL.glm\", \"SL.mean\", \"SL.ranger\"),\n  method = \"method.NNloglik\"\n)\n\nsl_loglik\n\n\nCall:  \nSuperLearner(Y = Y_bin, X = X, family = binomial(), SL.library = c(\"SL.glm\",  \n    \"SL.mean\", \"SL.ranger\"), method = \"method.NNloglik\") \n\n                   Risk      Coef\nSL.glm_All    0.5286216 0.8914129\nSL.mean_All   0.6818619 0.0000000\nSL.ranger_All 0.5537130 0.1085871\n\n\n\n\n11.5.3 5.3 AUC / Rank Loss\n\nFor classification problems where the ranking of probabilities matters more than calibration\nCommon when choosing a threshold later (e.g., risk stratification)\nSuperLearner implementation: method = \"method.AUC\"\nParticularly useful when interested in discriminatory ability (e.g., disease risk scores)\n\nExample:\n\nlibrary(cvAUC)   # required by method.AUC\n\nsl_auc &lt;- SuperLearner(\n  Y = Y_bin,\n  X = X,\n  family = binomial(),\n  SL.library = c(\"SL.glm\", \"SL.mean\", \"SL.ranger\"),\n  method = \"method.AUC\"\n)\n\nWarning in method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames, :\noptim didn't converge when estimating the super learner coefficients, reason\n(see ?optim): 52 optim message: ERROR: ABNORMAL_TERMINATION_IN_LNSRCH\n\nsl_auc\n\n\nCall:  \nSuperLearner(Y = Y_bin, X = X, family = binomial(), SL.library = c(\"SL.glm\",  \n    \"SL.mean\", \"SL.ranger\"), method = \"method.AUC\") \n\n                   Risk         Coef\nSL.glm_All    0.1938743 0.9988292700\nSL.mean_All   0.5268196 0.0006672332\nSL.ranger_All 0.2104779 0.0005034968\n\n\n\n\n11.5.4 5.4 Which loss should I choose?\n\nFor outcome models in TMLE/AIPW:\n\nIf binary → log-likelihood (binomial deviance)\n\nIf continuous → MSE or other appropriate distribution-based loss\n\n\nFor treatment / censoring models in causal inference:\n\nTypically log-likelihood (because we want accurate estimates of P(A | W))\n\nFor pure classification (no causal estimation):\n\nConsider AUC loss (method.AUC) if ranking is the priority",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span>"
    ]
  },
  {
    "objectID": "superlearner.html#interpreting-cv-risk-and-coefficient-weights",
    "href": "superlearner.html#interpreting-cv-risk-and-coefficient-weights",
    "title": "10  Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "11.6 6. Interpreting CV-Risk and Coefficient Weights",
    "text": "11.6 6. Interpreting CV-Risk and Coefficient Weights\n\nsl_fit$cvRisk\n\n   SL.glm_All   SL.mean_All  SL.earth_All SL.ranger_All \n   0.15038334    4.52716718    0.04408952    0.05735981 \n\nsl_fit$coef\n\n   SL.glm_All   SL.mean_All  SL.earth_All SL.ranger_All \n    0.0000000     0.0000000     0.8593302     0.1406698 \n\n\n\ncvRisk shows cross-validated risk for each algorithm\ncoef gives the ensemble weights (metalearner solution)\n\nAn algorithm might have:\n\nLow risk → high weight\n\nHigh risk → weight near zero (effectively excluded)\n\nThis matches the demonstration in the Benkeser notes where GLM dominates mean-only models when predicting MI.",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span>"
    ]
  },
  {
    "objectID": "superlearner.html#customizing-the-library-and-tuning-learners",
    "href": "superlearner.html#customizing-the-library-and-tuning-learners",
    "title": "10  Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "11.7 7. Customizing the Library and Tuning Learners",
    "text": "11.7 7. Customizing the Library and Tuning Learners\n\n11.7.1 7.1 Adding tuned versions of a learner (e.g., Random Forest)\nWe can define bounded random forest variants with different hyperparameters.\n\nSL.ranger_mtry3 &lt;- function(..., mtry = 3){\n  SL.ranger(..., mtry = mtry)\n}\n\nSL.ranger_mtry4 &lt;- function(..., mtry = 4){\n  SL.ranger(..., mtry = mtry)\n}\n\nSL.lib_tuned &lt;- c(\"SL.glm\",\n                  \"SL.earth\",\n                  \"SL.ranger_mtry3\",\n                  \"SL.ranger_mtry4\")\n\nThen run:\n\nset.seed(123)\nsl_tuned &lt;- SuperLearner(\n  Y = Y,\n  X = X,\n  family = gaussian(),\n  SL.library = SL.lib_tuned,\n  method = \"method.NNLS\"\n)\n\nsl_tuned$cvRisk\n\n         SL.glm_All        SL.earth_All SL.ranger_mtry3_All SL.ranger_mtry4_All \n         0.15062184          0.04401740          0.05044671          0.05242569 \n\nsl_tuned$coef\n\n         SL.glm_All        SL.earth_All SL.ranger_mtry3_All SL.ranger_mtry4_All \n          0.0000000           0.7318382           0.2681618           0.0000000 \n\n\nSuperLearner automatically picks which tuned version (or combination) works best.",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span>"
    ]
  },
  {
    "objectID": "superlearner.html#cross-validated-superlearner-cv.superlearner",
    "href": "superlearner.html#cross-validated-superlearner-cv.superlearner",
    "title": "10  Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "11.8 8. Cross-Validated SuperLearner (CV.SuperLearner)",
    "text": "11.8 8. Cross-Validated SuperLearner (CV.SuperLearner)\nCV.SuperLearner adds an outer layer of cross-validation to evaluate SL versus its components objectively.\n\nset.seed(123)\ncv_sl &lt;- CV.SuperLearner(\n  Y = Y,\n  X = X,\n  V = 5,\n  family = gaussian(),\n  SL.library = SL.lib\n)\n\ncv_sl\n\n\nCall:  \nCV.SuperLearner(Y = Y, X = X, V = 5, family = gaussian(), SL.library = SL.lib) \n\n\n\nCross-validated predictions from the SuperLearner:  SL.predict \n\nCross-validated predictions from the discrete super learner (cross-validation selector):  discreteSL.predict \n\nWhich library algorithm was the discrete super learner:  whichDiscreteSL \n\nCross-validated prediction for all algorithms in the library:  library.predict\n\nplot(cv_sl)\n\n\n\n\n\n\n\n\nThe plot shows:\n\nCross-validated risks and confidence intervals for each learner\nPerformance of the discrete and continuous SuperLearner\n\nThis step is particularly helpful when you want to justify using SL rather than a single, simpler algorithm.",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span>"
    ]
  },
  {
    "objectID": "superlearner.html#integrating-superlearner-into-causal-inference",
    "href": "superlearner.html#integrating-superlearner-into-causal-inference",
    "title": "10  Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "11.9 9. Integrating SuperLearner into Causal Inference",
    "text": "11.9 9. Integrating SuperLearner into Causal Inference\nSo far we focused on prediction. How does this relate to causal inference?\nFor a point-treatment ATE, a TMLE analysis might look like:\n\n# Example skeleton (you will flesh this out later with your own data)\nlibrary(tmle)\n\ntmle_fit &lt;- tmle(\n  Y = Y_bin,          # binary outcome\n  A = A,              # treatment\n  W = X,              # covariates\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\", \"SL.earth\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\", \"SL.mean\")\n)\n\ntmle_fit$estimates$ATE\n\nHere:\n\nQ.SL.library is used to estimate outcome regression E[Y|A,W]\ng.SL.library is used to estimate propensity scores P(A|W)\nTMLE combines these with targeting to produce an efficient, doubly robust estimate\n\nKey advantages:\n\nYou no longer need to guess the “right” model for Y or A\n\nYou can include many flexible learners without overfitting (thanks to SL + CV)\n\nYour causal inference relies less on arbitrary parametric modeling choices",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span>"
    ]
  },
  {
    "objectID": "superlearner.html#practical-tips-for-using-superlearner",
    "href": "superlearner.html#practical-tips-for-using-superlearner",
    "title": "10  Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "11.10 10. Practical Tips for Using SuperLearner",
    "text": "11.10 10. Practical Tips for Using SuperLearner\n\nStart with a modest but diverse library\n\nGLM (SL.glm)\n\nRandom forest (SL.ranger or SL.randomForest)\n\nMARS (SL.earth)\n\nPenalized regression (SL.glmnet)\n\nPick loss functions that match your problem\n\nBinary → log-likelihood (for calibration) or AUC (for ranking)\n\nContinuous → MSE\n\nWatch computation time\n\nSL is more expensive than a single GLM, especially with many learners and CV folds.\n\nUse SL primarily on nuisance functions\n\nDon’t use SL to directly estimate the causal effect; instead, use SL to estimate Q and g and feed these into TMLE, AIPW, etc.\n\nInspect SL outputs\n\nWhich learners are getting weight?\n\nAre any learners consistently poor performers?\n\nDo you need to adjust your library?",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span>"
    ]
  },
  {
    "objectID": "superlearner.html#summary",
    "href": "superlearner.html#summary",
    "title": "10  Chapter 2.4: SuperLearner and Machine Learning for Causal Inference",
    "section": "11.11 11. Summary",
    "text": "11.11 11. Summary\nIn this chapter you learned\n\nHow SuperLearner combines multiple algorithms using cross-validation and a metalearner\n\nThe role of loss functions (MSE, log-likelihood, AUC) and when to choose each\n\nHow to implement SuperLearner in R, inspect CV-risk and weights, and customize the library\n\nHow SuperLearner supports reliable causal inference by improving nuisance function estimation and integrating seamlessly with TMLE and other estimators\n\nNext, we move to Module 3, where we tackle longitudinal data, dynamic treatment regimes, and modified treatment policies, often using SuperLearner as a core building block.",
    "crumbs": [
      "Part II: Estimation Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span>"
    ]
  },
  {
    "objectID": "03-03-longitudinal-case-study.html",
    "href": "03-03-longitudinal-case-study.html",
    "title": "11  Chapter 3.3: Case Study – Real-World Application in Longitudinal Analysis",
    "section": "",
    "text": "12 Chapter 3.3",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 3.3: Case Study – Real-World Application in Longitudinal Analysis</span>"
    ]
  },
  {
    "objectID": "03-03-longitudinal-case-study.html#case-study-real-world-longitudinal-causal-inference-using-targeted-learning",
    "href": "03-03-longitudinal-case-study.html#case-study-real-world-longitudinal-causal-inference-using-targeted-learning",
    "title": "11  Chapter 3.3: Case Study – Real-World Application in Longitudinal Analysis",
    "section": "12.1 Case Study: Real-World Longitudinal Causal Inference Using Targeted Learning",
    "text": "12.1 Case Study: Real-World Longitudinal Causal Inference Using Targeted Learning\nThis chapter walks through a complete applied example of longitudinal causal inference using real-world data concepts.\nThe goal is to help you translate the earlier theoretical chapters into a practical analysis workflow.\nWe use the motivating real-world question:\n\nWhat is the 3-year cardiovascular risk difference if all eligible patients initiating osteoporosis therapy remained on denosumab vs. zoledronic acid under full adherence?\n\nAlthough we cannot use the proprietary data from the actual studies, this chapter recreates a plausible longitudinal structure and walks you through the entire pipeline:\n\nConstructing the longitudinal dataset\n\nDefining the causal question, intervention, and estimand\n\nIdentifying longitudinal confounders and censoring\n\nUsing SuperLearner for nuisance function estimation\n\nApplying TMLE or LMTP for longitudinal causal effects\n\nInterpreting the results in a regulatory and clinical context\n\nThis chapter integrates lessons from Chapter 1 (causal roadmap) and Chapter 2 (estimation).\n\n\n\n\n\n\nLearning objectives\n\n\n\n\nConstruct a longitudinal dataset suitable for causal analysis from wide and long formats\nDefine a causal estimand for a longitudinal treatment strategy with time-varying confounders\nIdentify and handle censoring, treatment switching, and loss to follow-up in the data structure\nApply L-TMLE or LMTP to estimate the effect of a sustained treatment strategy\nInterpret longitudinal causal effect estimates in a clinical and regulatory context\n\n\n\n\n\n\n\n\n\nSources and scope\n\n\n\nThis chapter is educational. Causal conclusions depend on identification assumptions (e.g., consistency, exchangeability, positivity) and on diagnostic evidence that the data support the target estimand. When flexible machine learning is used for nuisance estimation, valid inference typically requires cross-fitting or a cross-validated TMLE variant, plus appropriate rate conditions.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 3.3: Case Study – Real-World Application in Longitudinal Analysis</span>"
    ]
  },
  {
    "objectID": "03-03-longitudinal-case-study.html#sources-and-further-reading",
    "href": "03-03-longitudinal-case-study.html#sources-and-further-reading",
    "title": "11  Chapter 3.3: Case Study – Real-World Application in Longitudinal Analysis",
    "section": "22.1 Sources and further reading",
    "text": "22.1 Sources and further reading\n\nPetersen ML, Schwab J, Gruber S, Blaser N, Schomaker M, van der Laan MJ (2014). Targeted maximum likelihood estimation for dynamic and static longitudinal marginal structural working models. J Causal Inference 2(2):147-185.\nLendle SD, Schwab J, Petersen ML, van der Laan MJ (2017). ltmle: An R package implementing targeted minimum loss-based estimation for longitudinal data. J Stat Softw 81(1):1-21.\nDang LE, Tager I, Petersen ML (2023). A causal roadmap for generating high-quality real-world evidence. J Clin Transl Sci 7(1):e127.\nDiaz I, Williams N, Hoffman KL, et al. (2023). lmtp: An R package for estimating the causal effects of modified treatment policies. Observational Studies 9:103-122.\nvan der Laan MJ, Gruber S (2012). Targeted minimum loss based estimation of causal effects of multiple time point interventions. Int J Biostat 8(1):Article 9.\nltmle R package: CRAN\nlmtp R package: CRAN",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 3.3: Case Study – Real-World Application in Longitudinal Analysis</span>"
    ]
  },
  {
    "objectID": "03-03-longitudinal-case-study.html#software-implementation-r",
    "href": "03-03-longitudinal-case-study.html#software-implementation-r",
    "title": "11  Chapter 3.3: Case Study – Real-World Application in Longitudinal Analysis",
    "section": "22.2 Software Implementation (R)",
    "text": "22.2 Software Implementation (R)\nThis example uses the ltmle package to estimate the effect of a time-varying treatment on a binary outcome, mirroring the longitudinal case study structure (denosumab vs. zoledronic acid).\n\nSimulate 2-time-point data: baseline \\(W\\), time-varying confounder \\(L_1\\), treatment at two times \\(A_0, A_1\\), and outcome \\(Y\\)\n\\(L_1\\) is affected by \\(A_0\\) (treatment-confounder feedback)\nUse ltmle() to estimate the ATE of “always treat” vs. “never treat”\nFalls back to a manual sequential regression if ltmle is unavailable\n\n\nset.seed(1)\nn &lt;- 500\nW     &lt;- rnorm(n)\nA_0   &lt;- rbinom(n, 1, plogis(0.3 * W))\nL_1   &lt;- rnorm(n, mean = 0.5 * A_0 + 0.3 * W)  # affected by A_0\nA_1   &lt;- rbinom(n, 1, plogis(0.2 * L_1 + 0.3 * W))\nY     &lt;- rbinom(n, 1, plogis(-1.5 + 0.5 * A_0 + 0.5 * A_1 + 0.4 * L_1 + 0.3 * W))\n\ndat &lt;- data.frame(W = W, A_0 = A_0, L_1 = L_1, A_1 = A_1, Y = Y)\n\nif (requireNamespace(\"ltmle\", quietly = TRUE)) {\n  library(ltmle)\n\n  result &lt;- ltmle(\n    data = dat,\n    Anodes  = c(\"A_0\", \"A_1\"),\n    Lnodes  = \"L_1\",\n    Ynodes  = \"Y\",\n    abar = list(treatment = c(1, 1), control = c(0, 0)),\n    SL.library = \"glm\"\n  )\n  cat(\"LTMLE estimate (always treat vs never treat):\\n\")\n  print(summary(result))\n} else {\n  message(\"Install the 'ltmle' package:  install.packages('ltmle')\")\n  message(\"Falling back to manual sequential regression...\\n\")\n\n  ## Manual sequential g-computation (no targeting)\n  Q_mod &lt;- glm(Y ~ A_0 + A_1 + L_1 + W, family = binomial, data = dat)\n  dat1 &lt;- dat; dat1$A_0 &lt;- 1; dat1$A_1 &lt;- 1\n  dat0 &lt;- dat; dat0$A_0 &lt;- 0; dat0$A_1 &lt;- 0\n  gcomp &lt;- mean(predict(Q_mod, dat1, type = \"response\")) -\n           mean(predict(Q_mod, dat0, type = \"response\"))\n  cat(\"G-computation ATE (no targeting):\", round(gcomp, 3), \"\\n\")\n}",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Chapter 3.3: Case Study – Real-World Application in Longitudinal Analysis</span>"
    ]
  },
  {
    "objectID": "03-04-effect-modification.html",
    "href": "03-04-effect-modification.html",
    "title": "12  Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "",
    "text": "13 Chapter 3.4",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span>"
    ]
  },
  {
    "objectID": "03-04-effect-modification.html#effect-modification-and-heterogeneous-treatment-effects",
    "href": "03-04-effect-modification.html#effect-modification-and-heterogeneous-treatment-effects",
    "title": "12  Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "13.1 Effect Modification and Heterogeneous Treatment Effects",
    "text": "13.1 Effect Modification and Heterogeneous Treatment Effects\nIdentifying who benefits most (or least) from treatment\nCausal inference is not only about estimating average treatment effects.\nIn many scientific and regulatory settings, we want to know:\n\nDoes the treatment work differently for different types of patients?\n\nThis phenomenon is known as effect modification or treatment-effect heterogeneity (HTE).\nIn this chapter, you’ll learn:\n\nConceptual foundations of effect modification\n\nHow to define subgroup-specific causal estimands\n\nTMLE-based approaches to effect heterogeneity\n\nMachine-learning approaches, focusing on the causal forest\n\nHow to interpret heterogeneous effects responsibly\n\nDiagnostics, uncertainty, and false discovery concerns\n\nThis chapter builds on the causal roadmap and estimation methods from earlier modules.\n\n\n\n\n\n\nLearning objectives\n\n\n\n\nDefine effect modification, heterogeneous treatment effects (HTE), and the conditional average treatment effect (CATE)\nDistinguish interaction from effect modification in the causal inference framework\nUse TMLE to estimate subgroup-specific causal effects\nUnderstand causal forests as a data-adaptive approach to discovering treatment effect heterogeneity\nRecognize the risks of subgroup analyses: multiple testing, post-hoc selection, and the winner’s curse\n\n\n\n\n\n\n\n\n\nSources and scope\n\n\n\nThis chapter is educational. Causal conclusions depend on identification assumptions (e.g., consistency, exchangeability, positivity) and on diagnostic evidence that the data support the target estimand. When flexible machine learning is used for nuisance estimation, valid inference typically requires cross-fitting or a cross-validated TMLE variant, plus appropriate rate conditions.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span>"
    ]
  },
  {
    "objectID": "03-04-effect-modification.html#why-study-effect-modification",
    "href": "03-04-effect-modification.html#why-study-effect-modification",
    "title": "12  Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "13.2 1. Why Study Effect Modification?",
    "text": "13.2 1. Why Study Effect Modification?\n\n\n\n\n\n\nWhy This Matters for Public Health Practice\n\n\n\nThe average treatment effect (ATE) answers: &gt; “What is the mean effect of treatment in the population?”\nBut patients differ:\n\nage, sex\ncomorbidities\nbiomarkers\nbaseline risk\ngenetic variation\n\nClinically and scientifically relevant questions include:\n\nDoes our osteoporosis drug reduce fracture risk more in high-risk patients?\nAre cardiovascular risks higher in patients with chronic kidney disease?\nDoes benefit differ by baseline frailty or prior CVD?\n\nEffect modification helps answer these individualized or stratified questions. As an epidemiologist, understanding who benefits most from an intervention – and who may even be harmed – is essential for translating population-level evidence into clinical and policy recommendations.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span>"
    ]
  },
  {
    "objectID": "03-04-effect-modification.html#causal-estimands-for-effect-modification",
    "href": "03-04-effect-modification.html#causal-estimands-for-effect-modification",
    "title": "12  Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "13.3 2. Causal Estimands for Effect Modification",
    "text": "13.3 2. Causal Estimands for Effect Modification\nTo study heterogeneity, we define conditional average treatment effects (CATE).\n\n\n\n\n\n\nWhat Is a CATE? (Plain-Language Version)\n\n\n\nThe Conditional Average Treatment Effect (CATE) answers a simple question: “What is the average treatment effect for people who share a specific characteristic?”\nFor example, the CATE among women tells you the average effect of the treatment specifically among women. The CATE at age 80 tells you the expected effect for an 80-year-old.\nFormally, let (X) be a baseline covariate or set of covariates. The CATE is:\n[ CATE(x) = E[Y(1) - Y(0) X = x]. ]\nFor categorical variables (e.g., age group):\n[ ATE_{ ext{age&lt;75}} = E[Y(1) - Y(0) ext{age} &lt; 75], ]\nand similarly for other strata.\nThink of it this way: the ATE gives you one number for everyone. The CATE gives you a different number for each subgroup, letting you see where the treatment works best (or worst).\n\n\nYour choice of estimand must match the scientific question:\n\nPrespecified subgroups (sex, race, CKD stage)\nPost hoc continuous moderators (eGFR, age)\nMachine-learned subgroups (via trees / forests)",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span>"
    ]
  },
  {
    "objectID": "03-04-effect-modification.html#identification-assumptions",
    "href": "03-04-effect-modification.html#identification-assumptions",
    "title": "12  Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "13.4 3. Identification Assumptions",
    "text": "13.4 3. Identification Assumptions\n\n\n\n\n\n\nAssumptions Still Apply – And Get Harder in Subgroups\n\n\n\nEffect modification estimands inherit the same assumptions as the main causal effect:\n\nExchangeability: ( Y(a) A W )\nPositivity: Each subgroup must contain both treated and untreated\nConsistency\n\nAdditionally:\n\nModerator variables must be measured before treatment\nYou should avoid conditioning on post-treatment variables when defining subgroups\n\nPositivity is especially fragile in subgroup analyses. When you slice the data into smaller groups, some subgroups may have very few treated or untreated individuals. Always check that both treatment arms are adequately represented in every subgroup you analyze.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span>"
    ]
  },
  {
    "objectID": "03-04-effect-modification.html#a-workflow-for-effect-modification",
    "href": "03-04-effect-modification.html#a-workflow-for-effect-modification",
    "title": "12  Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "13.5 4. A Workflow for Effect Modification",
    "text": "13.5 4. A Workflow for Effect Modification\n\n\n\n\n\n\nStep-by-Step Workflow for Investigating Effect Modification\n\n\n\n\nDefine causal estimands (subgroup-specific ATE, CATE(x))\nChoose moderators\n\nPrespecified vs exploratory\n\nEstimate nuisance functions with SuperLearner\nEstimate heterogeneous effects using:\n\nTMLE (subgroup-specific or CATE-targeted)\nCausal forests\n\nQuantify uncertainty\nDocument all steps and prespecifications\n\nThe key discipline here is to decide your subgroups and moderators before looking at results. Prespecification protects you from the temptation to cherry-pick findings. When you do explore post hoc, label those findings clearly as hypothesis-generating.\n\n\nWe now walk through TMLE and causal forest approaches.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span>"
    ]
  },
  {
    "objectID": "03-04-effect-modification.html#tmle-for-subgroup-specific-effects",
    "href": "03-04-effect-modification.html#tmle-for-subgroup-specific-effects",
    "title": "12  Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "13.6 5. TMLE for Subgroup-Specific Effects",
    "text": "13.6 5. TMLE for Subgroup-Specific Effects\n\n\n\n\n\n\nTMLE for Subgroup Effects: The Confirmatory Approach\n\n\n\nFor prespecified subgroups, TMLE can estimate:\n[ ATE_g = E[Y(1) - Y(0) X_g = 1], ]\nwhere (X_g) indicates membership in subgroup (g).\nThe idea is straightforward: subset your data to a subgroup and run TMLE within that subset. Because TMLE is doubly robust and uses SuperLearner for flexible nuisance estimation, you get reliable effect estimates even within subgroups – as long as you have enough data and positivity holds.\n\n\nExample: ATE among patients younger than 75.\n\nlibrary(tmle)\nlibrary(SuperLearner)\nlibrary(tidyverse)\n\n# Assume dat has columns: Y (outcome), A (treatment), age, cvd, eGFR, etc.\nset.seed(123)\n\ndat &lt;- tibble(\n  Y = rbinom(2000, 1, 0.2),\n  A = rbinom(2000, 1, 0.5),\n  age = rnorm(2000, 75, 6),\n  cvd = rbinom(2000, 1, 0.4),\n  eGFR = rnorm(2000, 60, 15)\n)\n\ndat &lt;- dat %&gt;%\n  mutate(age_under75 = if_else(age &lt; 75, 1, 0))\n\nsl_lib &lt;- c(\"SL.glm\", \"SL.ranger\", \"SL.mean\")\n\ntmle_sub &lt;- tmle(\n  Y = dat$Y[dat$age_under75 == 1],\n  A = dat$A[dat$age_under75 == 1],\n  W = dat %&gt;%\n    filter(age_under75 == 1) %&gt;%\n    select(cvd, eGFR),\n  family = \"binomial\",\n  Q.SL.library = sl_lib,\n  g.SL.library = sl_lib\n)\n\ntmle_sub$estimates$ATE\n\nInterpretation:\n\nAmong patients younger than 75, the TMLE-estimated risk difference is …\n\nThis approach:\n\nGives valid subgroup-specific estimates\n\nLeverages SuperLearner for nuisance models\n\nLimitations:\n\nDoes not provide a continuous CATE curve\n\nRequires prespecified groups and adequate sample size in each",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span>"
    ]
  },
  {
    "objectID": "03-04-effect-modification.html#tmle-extensions-for-continuous-effect-modification",
    "href": "03-04-effect-modification.html#tmle-extensions-for-continuous-effect-modification",
    "title": "12  Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "13.7 6. TMLE Extensions for Continuous Effect Modification",
    "text": "13.7 6. TMLE Extensions for Continuous Effect Modification\nFor continuous effect modifiers, you may want:\n[ CATE(x) = E[Y(1) - Y(0) X = x] ]\nfor all x (e.g., all ages). TMLE-based approaches often use:\n\nProjection of the CATE onto basis functions of X (splines, polynomials)\nEstimation of projection coefficients via TMLE\nReconstruction of ( CATE(x) ) from the projected function\n\n\n\n\n\n\n\nCATE-TMLE: A Smooth, Doubly Robust Curve\n\n\n\nA typical CATE-TMLE algorithm:\n\nExpand (X) into basis functions (h_1(X),,h_K(X))\nDefine target parameters of the form (_k = E[(Y(1) - Y(0)) h_k(X)])\nUse TMLE to estimate each (_k)\nConstruct ( (x) = _k _k h_k(x))\n\nWe won’t fully implement this here (it is mathematically intensive), but you should be aware that:\n\nTMLE can provide smooth, doubly robust CATE estimators\nTMLE-based variable importance methods can also quantify how much a covariate modifies the treatment effect\n\nThis gives you the best of both worlds: a continuous picture of how the treatment effect changes across a modifier, with the statistical guarantees that come from TMLE’s doubly robust framework.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span>"
    ]
  },
  {
    "objectID": "03-04-effect-modification.html#modern-ml-approach-causal-forests",
    "href": "03-04-effect-modification.html#modern-ml-approach-causal-forests",
    "title": "12  Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "13.8 7. Modern ML Approach: Causal Forests",
    "text": "13.8 7. Modern ML Approach: Causal Forests\n\n\n\n\n\n\nCausal Forests in Plain Language\n\n\n\nCausal forests are tree-based methods specifically designed to estimate CATEs. Think of them as “smart subgroup finders”: instead of you deciding which subgroups to examine, the algorithm searches across all your covariates to find the splits that reveal the biggest differences in treatment effect.\nThey extend random forests by:\n\nSplitting trees to maximize treatment-effect heterogeneity\nUsing “honest” sample splitting (training vs estimation sets)\nAveraging across many trees to obtain smooth CATE estimates\n\n\n13.8.1 7.1 Why Causal Forests?\n\nAutomatically detect complex, nonlinear interactions\nProvide individual-level CATE estimates ( (x) )\nOffer approximate pointwise confidence intervals\nUseful for exploratory HTE analysis\n\n\n\n\n\n\n\n\n\n\nImportant Caveats About Causal Forests\n\n\n\n\nNot doubly robust. Unlike TMLE, causal forests do not offer the same protection against model misspecification. If your propensity score model or outcome model is wrong, the CATE estimates may be biased.\nInterpretation is essentially associational unless we embed the forest in a rigorous causal framework with the same identification assumptions (exchangeability, positivity, consistency).\nOverfitting to noise. With many covariates and flexible splits, causal forests can find “heterogeneity” that is really just random variation – especially in small samples.\n\nTreat causal forest results as hypothesis-generating, not confirmatory. If the forest suggests a subgroup with large benefit, that finding should be validated in an independent dataset or prespecified in a future study.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span>"
    ]
  },
  {
    "objectID": "03-04-effect-modification.html#implementing-causal-forests-in-r",
    "href": "03-04-effect-modification.html#implementing-causal-forests-in-r",
    "title": "12  Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "13.9 8. Implementing Causal Forests in R",
    "text": "13.9 8. Implementing Causal Forests in R\nWe use the grf package.\n\n# install.packages(\"grf\")\nlibrary(grf)\n\nset.seed(2028)\n\n# Simulate data with treatment effect heterogeneity\nn &lt;- 3000\nX &lt;- tibble(\n  age = rnorm(n, 75, 6),\n  cvd = rbinom(n, 1, 0.4),\n  risk_score = rnorm(n, 0, 1)\n)\n\nA &lt;- rbinom(n, 1, plogis(-0.5 + 0.2 * X$age - 0.8 * X$risk_score))\n# Treatment effect depends on risk_score\ntau_true &lt;- -0.05 + 0.1 * (X$risk_score &gt; 0)\nY &lt;- rbinom(n, 1, plogis(-2 + tau_true * A + 0.05 * (X$age - 75) + 0.5 * X$cvd))\n\nX_mat &lt;- as.matrix(X)\n\ncf &lt;- causal_forest(\n  X = X_mat,\n  Y = Y,\n  W = A\n)\n\n# Individualized CATE estimates\ntau_hat &lt;- predict(cf)$predictions\n\nsummary(tau_hat)\n\n\n13.9.1 Visualizing CATE vs. risk score\nTo do debug\n\nplot(X$risk_score, tau_hat,\n     xlab = \"Baseline risk score\",\n     ylab = \"Estimated CATE\",\n     pch = 16, cex = 0.3)\nabline(h = 0, col = \"red\")\n\nYou should see different CATE patterns for low vs high risk scores.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span>"
    ]
  },
  {
    "objectID": "03-04-effect-modification.html#subgrouping-using-cate-estimates",
    "href": "03-04-effect-modification.html#subgrouping-using-cate-estimates",
    "title": "12  Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "13.10 9. Subgrouping Using CATE Estimates",
    "text": "13.10 9. Subgrouping Using CATE Estimates\nWe can create subgroups such as:\n\n“High predicted benefit” vs “low predicted benefit”\n\n\nthreshold &lt;- median(tau_hat)\n\nres &lt;- X %&gt;%\n  mutate(\n    CATE_hat = tau_hat,\n    group = if_else(CATE_hat &gt; threshold, \"high benefit\", \"low benefit\")\n  )\n\ntable(res$group)\n\nres %&gt;%\n  group_by(group) %&gt;%\n  summarize(\n    mean_CATE = mean(CATE_hat),\n    .groups = \"drop\"\n  )\n\nThis is exploratory, not confirmatory.\nIt can inform:\n\nHypothesis generation\n\nPrespecified subgroup definitions in future trials",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span>"
    ]
  },
  {
    "objectID": "03-04-effect-modification.html#causal-forest-vs.-tmle-which-should-you-use",
    "href": "03-04-effect-modification.html#causal-forest-vs.-tmle-which-should-you-use",
    "title": "12  Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "13.11 10. Causal Forest vs. TMLE: Which Should You Use?",
    "text": "13.11 10. Causal Forest vs. TMLE: Which Should You Use?\n\n\n\n\n\n\nChoosing the Right Tool for the Job\n\n\n\nTMLE (with SuperLearner):\n\nBest for prespecified subgroups\nCATE-TMLE gives doubly robust, efficient CATE estimates\nIntegrates neatly into a causal estimand framework\nMore transparent and parameter-focused\n\nCausal Forest:\n\nBest for exploratory heterogeneity\nAutomatically discovers complex interactions\nProvides smooth CATE functions without specifying bases\nGood for risk-stratified or personalized-medicine questions\n\n\n13.11.1 Practical pattern:\n\nUse TMLE to estimate ATE and pre-planned subgroup effects\nUse causal forests to explore residual heterogeneity and generate new hypotheses\nWhere consistent patterns are observed, design new confirmatory analyses or studies\n\nBottom line: Use TMLE when you know which subgroups to test. Use causal forests when you want the data to show you where heterogeneity might exist. In practice, the strongest analyses do both.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span>"
    ]
  },
  {
    "objectID": "03-04-effect-modification.html#interpretation-and-reporting-avoiding-pitfalls",
    "href": "03-04-effect-modification.html#interpretation-and-reporting-avoiding-pitfalls",
    "title": "12  Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "13.12 11. Interpretation and Reporting: Avoiding Pitfalls",
    "text": "13.12 11. Interpretation and Reporting: Avoiding Pitfalls\n\n\n\n\n\n\nThe Multiple Comparisons Trap\n\n\n\nEffect modification is tempting but dangerous:\n\nMultiple subgroup comparisons inflate type I error\n“Fishing expeditions” can produce spurious heterogeneity\nSmall subgroup sizes lead to unstable estimates\n\nConsider this: if you test 20 subgroups at alpha = 0.05, you expect one “significant” finding by chance alone – even if there is zero true heterogeneity. This is not a theoretical concern; it is one of the most common sources of irreproducible findings in epidemiology.\nBest practices:\n\nPrespecify main effect modifiers when possible\nCorrect for multiplicity (e.g., family-wise error or FDR) if reporting many subgroups\nEmphasize uncertainty (wide CIs are expected)\nTreat causal forest findings as exploratory unless prespecified or replicated\nAlways present the overall ATE alongside any heterogeneity results",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span>"
    ]
  },
  {
    "objectID": "03-04-effect-modification.html#example-combining-tmle-and-causal-forests",
    "href": "03-04-effect-modification.html#example-combining-tmle-and-causal-forests",
    "title": "12  Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "13.13 12. Example: Combining TMLE and Causal Forests",
    "text": "13.13 12. Example: Combining TMLE and Causal Forests\n\n# Step 1: ATE with TMLE\nsl_lib &lt;- c(\"SL.glm\", \"SL.ranger\", \"SL.mean\")\n\ntmle_ate &lt;- tmle(\n  Y = Y,\n  A = A,\n  W = X,\n  family = \"binomial\",\n  Q.SL.library = sl_lib,\n  g.SL.library = sl_lib\n)\n\ntmle_ate$estimates$ATE\n\n# Step 2: CATEs with causal forest (already computed as tau_hat)\nsummary(tau_hat)\n\n\nTMLE gives a population-level effect (with solid identifiability and efficiency).\nCausal forest gives individual-level estimated CATEs to explore how effects vary.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span>"
    ]
  },
  {
    "objectID": "03-04-effect-modification.html#summary",
    "href": "03-04-effect-modification.html#summary",
    "title": "12  Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "13.14 13. Summary",
    "text": "13.14 13. Summary\n\n\n\n\n\n\nSources and further reading\n\n\n\n\nAthey S, Imbens GW (2016). Recursive partitioning for heterogeneous causal effects. PNAS 113(27):7353-7360.\nWager S, Athey S (2018). Estimation and inference of heterogeneous treatment effects using random forests. JASA 113(523):1228-1242.\nvan der Laan MJ, Rose S (2011). Targeted Learning. Springer.\nLuedtke AR, van der Laan MJ (2016). Super learning of an optimal dynamic treatment rule. Int J Biostat 12(1):305-332.\nHernan MA, Robins JM (2020). Causal Inference: What If. Chapter 4 (Effect modification). Free online\nVanderWeele TJ (2009). On the distinction between interaction and effect modification. Epidemiology 20(6):863-871.\ngrf R package (causal forests): CRAN\ntmle R package: CRAN\n\n\n\n13.15 Key Takeaways\nIn this chapter, you learned:\n\nHow to define causal estimands for effect modification and CATEs\nHow to estimate subgroup-specific effects via TMLE\nHow TMLE can be extended to continuous moderators using projection / variable importance frameworks\nHow causal forests provide flexible, ML-driven CATE estimates\nHow to interpret heterogeneous effects carefully in real-world and regulatory contexts\n\nEffect modification analysis is powerful but fragile. Combining TMLE for confirmatory, parameter-focused inference and causal forests for exploratory, data-adaptive heterogeneity learning often yields the most insightful and responsible use of HTE methods.\nRemember: always report the overall ATE first, prespecify your subgroups, correct for multiple comparisons, and label exploratory findings honestly. Your readers – and your future self – will thank you.\n\n\n\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31 ucrt)\n#&gt; Platform: x86_64-w64-mingw32/x64\n#&gt; Running under: Windows 11 x64 (build 26200)\n#&gt; \n#&gt; Matrix products: default\n#&gt; \n#&gt; \n#&gt; locale:\n#&gt; [1] LC_COLLATE=English_United States.utf8 \n#&gt; [2] LC_CTYPE=English_United States.utf8   \n#&gt; [3] LC_MONETARY=English_United States.utf8\n#&gt; [4] LC_NUMERIC=C                          \n#&gt; [5] LC_TIME=English_United States.utf8    \n#&gt; \n#&gt; time zone: America/Los_Angeles\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] htmlwidgets_1.6.4 compiler_4.4.2    fastmap_1.2.0     cli_3.6.5        \n#&gt;  [5] tools_4.4.2       htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10      \n#&gt;  [9] rmarkdown_2.29    knitr_1.49        jsonlite_2.0.0    xfun_0.49        \n#&gt; [13] digest_0.6.37     rlang_1.1.6       evaluate_1.0.5",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span>"
    ]
  },
  {
    "objectID": "03-04-effect-modification.html#key-takeaways",
    "href": "03-04-effect-modification.html#key-takeaways",
    "title": "12  Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects",
    "section": "13.15 Key Takeaways",
    "text": "13.15 Key Takeaways\nIn this chapter, you learned:\n\nHow to define causal estimands for effect modification and CATEs\nHow to estimate subgroup-specific effects via TMLE\nHow TMLE can be extended to continuous moderators using projection / variable importance frameworks\nHow causal forests provide flexible, ML-driven CATE estimates\nHow to interpret heterogeneous effects carefully in real-world and regulatory contexts\n\nEffect modification analysis is powerful but fragile. Combining TMLE for confirmatory, parameter-focused inference and causal forests for exploratory, data-adaptive heterogeneity learning often yields the most insightful and responsible use of HTE methods.\nRemember: always report the overall ATE first, prespecify your subgroups, correct for multiple comparisons, and label exploratory findings honestly. Your readers – and your future self – will thank you.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span>"
    ]
  },
  {
    "objectID": "03-05-advanced-diagnostics.html",
    "href": "03-05-advanced-diagnostics.html",
    "title": "13  Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "",
    "text": "14 Chapter 3.5",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses</span>"
    ]
  },
  {
    "objectID": "03-05-advanced-diagnostics.html#advanced-diagnostics-and-sensitivity-analyses",
    "href": "03-05-advanced-diagnostics.html#advanced-diagnostics-and-sensitivity-analyses",
    "title": "13  Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "14.1 Advanced Diagnostics and Sensitivity Analyses",
    "text": "14.1 Advanced Diagnostics and Sensitivity Analyses\nEnsuring credible causal conclusions in real-world longitudinal data\n\n\n\n\n\n\nLearning objectives\n\n\n\n\nAssess positivity and overlap using propensity score diagnostics\nEvaluate nuisance model performance (outcome model and treatment model)\nPerform weight diagnostics for IPTW and TMLE, including truncation sensitivity\nCompute and interpret E-values for sensitivity to unmeasured confounding\nUse negative control outcomes and exposures to detect residual bias\nApply TMLE-specific diagnostics: influence curve summaries and calibration checks\n\n\n\n\n\n\n\n\n\nSources and scope\n\n\n\nThis chapter is educational. Causal conclusions depend on identification assumptions (e.g., consistency, exchangeability, positivity) and on diagnostic evidence that the data support the target estimand. When flexible machine learning is used for nuisance estimation, valid inference typically requires cross-fitting or a cross-validated TMLE variant, plus appropriate rate conditions.\n\n\n\n\n\n\n\n\nWhy Diagnostics Are Non-Negotiable\n\n\n\nCausal inference is never just about estimating an effect — it is about credibly defending that effect. As an epidemiologist, you know that an estimate without diagnostics is like a clinical trial without a protocol: technically possible, but not credible. Diagnostics and sensitivity analyses are essential components of the causal roadmap because:\n\nIdentifying assumptions are never fully testable\nReal-world data contain missingness, selection, unmeasured confounding, and misclassification\nPositivity and model misspecification can quietly undermine estimation\nRegulatory-grade RWE requires transparency and robustness checks\n\nThis chapter walks through:\n\nDiagnostics for identification assumptions\nPositivity and overlap assessment\nDiagnostics for nuisance models (Q and g)\nWeight diagnostics\nSensitivity analyses for unmeasured confounding\nNegative controls\nTMLE-specific diagnostics\nLongitudinal diagnostics (LMTP / longitudinal TMLE)\n\n\n\n\n\n\n\n\n\n\nDiagnostics for Identification Assumptions\n\n\n\nThe core identification assumptions are:\n\nConsistency: the observed outcome under the treatment actually received equals the potential outcome under that treatment\nExchangeability (No unmeasured confounding): conditional on measured covariates, treatment groups are comparable\nPositivity: every covariate stratum has a non-zero probability of each treatment level\nCorrect nuisance model specification: the models for treatment and outcome are well-specified enough to avoid bias\n\nWhile not directly testable, their empirical implications can be evaluated. Think of these as the load-bearing walls of your analysis – if any one fails, the whole structure is compromised.\n\n\n\n14.1.1 1.1 Data structure and quality checks\nBefore causal modeling:\n\nVerify time ordering\nConfirm treatment and outcome timestamps\nInspect missingness patterns\nLook for coding shifts (ICD-9 to ICD-10)\nExamine distributions and implausible values\n\n\n\n\n\n\n\nDAG Review: Your Causal Roadmap on Paper\n\n\n\nA DAG (Directed Acyclic Graph) is not just a statistical formality – it is your most powerful communication tool. When you sit down with clinical collaborators, a DAG makes implicit assumptions explicit. It clarifies:\n\nAdjustment sets: which variables must be conditioned on to block confounding paths\nPotential unmeasured confounding: where you lack data on important causes\nVariables that should not be adjusted for: mediators (which would block the causal path you want to estimate) and colliders (which would open bias paths)\n\nDraw the DAG before writing any code. Share it with your clinical team. If they disagree with an arrow, that disagreement is a scientific conversation worth having before you run a single model.\n\n\n\n\n\n\n\n\n\nPositivity Diagnostics: When Your Data Cannot Support Your Question\n\n\n\nPositivity requires:\n\nEvery combination of covariates has a non-zero probability of receiving each treatment.\n\nWhy this matters so much: Positivity violations are dangerous because they are silent. Your code will still run, your model will still produce a number, but that number may be driven by a handful of observations with extreme weights rather than by the actual data. In epidemiologic terms, you are extrapolating beyond the support of your data – making claims about what would happen to people for whom you have essentially no evidence.\nViolations cause unstable weights and unreliable estimates.\n\n\n\n\n14.1.2 2.1 Propensity score overlap\nps &lt;- predict(glm(A ~ W1 + W2, family = binomial), type = \"response\")\n\nlibrary(ggplot2)\nggplot(tibble(ps = ps, A = A), aes(x = ps, fill = factor(A))) +\n  geom_density(alpha = 0.4)\nIndicators of concern:\n\nMass near 0 or 1\nDisjoint distributions\n\n\n\n\n\n\n\nClever Covariate Range (TMLE)\n\n\n\nThe clever covariate (H) is the quantity TMLE uses to update its initial outcome model. When propensity scores are near 0 or 1, the clever covariate explodes in magnitude – and a single observation can hijack your entire estimate. Always inspect its range before trusting your TMLE output.\nH &lt;- A/ps - (1-A)/(1-ps)\nsummary(H)\nExtreme values imply near-positivity violations. If you see values in the hundreds or thousands, your estimate is likely unstable and you should investigate the propensity score distribution.\n\n\n\n\n\n\n\n\nRemedies for Positivity Violations\n\n\n\nWhen you detect positivity problems, do not simply ignore them. You have several practical options:\n\nRestrict to the overlap population: limit your analysis to the covariate region where both treatment groups have adequate representation. This changes your target population, but the estimate you get is actually supported by data.\nTruncate weights: cap extreme weights at a percentile (e.g., 1st and 99th). This introduces a small amount of bias but can dramatically reduce variance.\nUse stochastic interventions instead of static ones: rather than asking “what if everyone were treated?”, ask “what if the probability of treatment shifted by some amount?” This naturally respects the data support.\nSimplify the intervention: coarser treatment definitions may have better overlap.\n\n\n\n\n\n\n\n\n\n\nDiagnostics for Nuisance Functions (Q and g)\n\n\n\nIn causal inference, “nuisance functions” are the models you fit not because you care about their parameters, but because you need them to estimate the causal effect. Q is the outcome model (predicting Y given treatment and covariates) and g is the treatment model (predicting treatment probability given covariates, i.e., the propensity score). Accurate nuisance models are crucial for TMLE, AIPW, and LMTP. If these models are badly misspecified, your causal estimate inherits that bias – even with doubly robust methods, you need at least one of Q or g to be well-specified.\n\n\n\n\n14.1.3 3.1 Predictive accuracy\n\nAUC for binary outcomes\n\nMSE/R² for continuous\n\nCross-validated risk from SuperLearner\n\n\n\n14.1.4 3.2 Calibration plots\ndat %&gt;% \n  mutate(pred = Qhat) %&gt;% \n  ggplot(aes(x = pred, y = Y)) +\n    geom_point(alpha = 0.3) +\n    geom_smooth()\n\n\n14.1.5 3.3 Overfitting assessment\nCompare:\n\nTraining loss\n\nCross-validated loss\n\nLarge discrepancy → overfitting.\n\n\n14.1.6 3.4 Variable-importance sanity check\nEnsure top predictors are clinically plausible.\n\n\n\n\n\n\n\nWeight Diagnostics: Are a Few Observations Driving Your Results?\n\n\n\nInverse probability weights are used in IPTW, MSMs, and censoring models. Extreme weights are a red flag that a small number of unusual observations are exerting outsized influence on your effect estimate. Always inspect weights before reporting results.\n\n14.1.7 4.1 Weight summaries\nsummary(weights)\nquantile(weights, probs = c(0.01, 0.99))\nRed flags:\n\nMean far from 1 (for stabilized weights, the mean should be approximately 1)\nVery heavy tail\nHuge max weights (a single weight of 500 means that one person “counts” as 500 in your pseudo-population)\n\n\n\n14.1.8 4.2 Visual check\nggplot(tibble(w = weights), aes(x = w)) +\n  geom_histogram()\n\n\n14.1.9 4.3 Truncation\nlower &lt;- quantile(weights, 0.01)\nupper &lt;- quantile(weights, 0.99)\nw_trunc &lt;- pmin(pmax(weights, lower), upper)\nReport results both with and without truncation. If they differ substantially, your findings are fragile.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses</span>"
    ]
  },
  {
    "objectID": "03-05-advanced-diagnostics.html#sensitivity-analyses-for-unmeasured-confounding",
    "href": "03-05-advanced-diagnostics.html#sensitivity-analyses-for-unmeasured-confounding",
    "title": "13  Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "14.2 5. Sensitivity Analyses for Unmeasured Confounding",
    "text": "14.2 5. Sensitivity Analyses for Unmeasured Confounding\n\n\n\n\n\n\nE-values: How Strong Would Unmeasured Confounding Need to Be?\n\n\n\nAn E-value answers a simple but powerful question: What is the minimum strength of association that an unmeasured confounder would need to have with both the treatment and the outcome – above and beyond the measured covariates – to fully explain away the observed effect?\nIn plain language: if you find an E-value of 3.5, it means an unmeasured confounder would need to be associated with at least a 3.5-fold increase in both the likelihood of treatment and the likelihood of the outcome to reduce your observed effect to the null. The larger the E-value, the more robust your finding is to unmeasured confounding. A small E-value (close to 1) means even weak unmeasured confounding could account for your result.\nE-values do not prove the absence of confounding – they quantify how extreme an unmeasured confounder would need to be. This helps reviewers and decision-makers calibrate their confidence in the finding.\n\n\n\n14.2.1 5.2 Quantitative Bias Analysis (QBA)\nSimulates impact of:\n\nUnmeasured confounder prevalence\n\nUnmeasured confounder associations\n\nR packages: episensr, causalsens\n\n\n14.2.2 5.4 Sensitivity using stochastic interventions\nLMTP can quantify robustness of static intervention effects.\n\n\n\n\n\n\n\nNegative Controls: One of the Most Powerful Tools for Detecting Unmeasured Confounding\n\n\n\nNegative controls are arguably the single most informative diagnostic you can run for unmeasured confounding. The logic is elegant: pick an outcome that you know the treatment should not affect, but that shares the same confounding structure as your primary outcome. Then estimate the “effect” of treatment on that negative control outcome. If you find an association, something is wrong – and that something is almost certainly unmeasured confounding or some other systematic bias.\nNegative control outcomes (NCOs):\n\nCausally unrelated to treatment\nShare confounding structures with the real outcome\n\nIf TMLE of treatment on the NCO produces a non-null result, confounding likely remains in your primary analysis.\nExample:\ntmle_nco &lt;- tmle(\n  Y = dat$negative_event,\n  A = dat$treatment,\n  W = dat[, confounders]\n)\nNegative control exposures work similarly: pick an exposure that should not affect your outcome but shares the same confounding structure as the real treatment. Both types serve as empirical “smoke tests” for bias.\n\n\n\n\n\n\n\n\n\nTMLE-Specific Diagnostics: Things That Can Go Wrong in the Targeting Step\n\n\n\nTMLE adds a “targeting step” that updates the initial outcome model to optimize bias-variance tradeoff for your specific causal parameter. This step is powerful but can go wrong in subtle ways. Watch for these issues:\n\n14.2.3 7.1 Clever covariate behavior\nExtreme clever covariate values lead to unstable targeting. If the clever covariate has values in the hundreds or thousands, the fluctuation parameter (epsilon) is being estimated from near-singular data. Revisit your propensity score model.\n\n\n14.2.4 7.2 Targeting step convergence\nCheck for warnings in logistic fluctuation:\nglm.fit: algorithm did not converge\nThis warning means the targeting step failed to find a stable update. Common causes include near-positivity violations or a very poor initial fit.\n\n\n14.2.5 7.3 Influence-curve distribution\nIC &lt;- tmle_fit$ic\nmean(IC); var(IC)\nThe mean of the influence curve should be approximately zero (this is the efficient influence function equation that TMLE solves). Heavy tails in the IC distribution suggest that Wald-type confidence intervals may have poor coverage – consider bootstrap-based inference instead.\n\n\n\n\n\n\n\n\n\n\nLongitudinal Diagnostics: Where Problems Compound Over Time\n\n\n\nIn longitudinal settings (LMTP, longitudinal TMLE), every challenge from the cross-sectional case is amplified. Positivity must hold at every timepoint. Weights are multiplied across time, so moderate violations at each step can produce extreme cumulative weights. This section is critical for anyone working with repeated-measures or time-varying treatment data.\n\n14.2.6 8.1 Sequential positivity\nCheck treatment probabilities at each timepoint. A treatment probability of 0.05 at one time may be acceptable, but if you have 10 timepoints with similar probabilities, the cumulative probability can become vanishingly small.\n\n\n14.2.7 8.2 Cumulative weights\ncumw &lt;- apply(weight_matrix, 1, prod)\nhist(cumw)\nExtreme cumulative weights signal instability. Even if weights look reasonable at each individual time step, their product can be enormous.\n\n\n14.2.8 8.3 Truncation across time\nTruncate weights at each time step or truncate cumulative weights. Both approaches involve tradeoffs – per-step truncation is more conservative but can compound across time; cumulative truncation directly addresses the problem but is harder to interpret.\n\n\n14.2.9 8.4 Time-varying confounding sanity checks\nEnsure intermediate variables are not inappropriate colliders. In longitudinal settings, a variable can be both a confounder (of future treatment-outcome relationships) and a mediator (of past treatment effects). The DAG becomes essential for sorting out what should and should not be conditioned on at each time step.\n\n\n\n\n\n\n\n\n\n\nRecommended Diagnostics Workflow: A Practical Checklist\n\n\n\nUse this as a step-by-step checklist for every causal analysis. Print it out, tape it to your monitor, or include it in your analysis plan. Skipping steps here is how “surprising” results end up in print.\n\n14.2.10 Before estimation\n\nConfirm time-ordering of treatment, covariates, and outcome\nDraw a DAG and review it with clinical collaborators\nCheck missingness patterns (MCAR/MAR/MNAR)\nSummarize covariate distributions by treatment group (Table 1)\n\n\n\n14.2.11 During estimation\n\nCheck propensity score overlap (density plots by treatment group)\nEvaluate weight distributions (summaries, histograms, max values)\nInspect Q and g predictions (calibration, AUC, cross-validated risk)\nCheck TMLE targeting step convergence and clever covariate range\n\n\n\n14.2.12 After estimation\n\nRun sensitivity analyses (E-values, quantitative bias analysis)\nRun negative control analyses (NCOs and/or NCEs)\nCompare across estimators (IPTW, TMLE, AIPW) – agreement increases credibility\nPerform robustness checks (population restriction, alternative confounder sets, different SuperLearner libraries)\n\n\n\n\n\n\n\n\n\n\n\nSummary: Diagnostics Are the Backbone of Credible Causal Inference\n\n\n\nTo produce defensible causal evidence, diagnostics must be:\n\nSystematic: follow the workflow above for every analysis, not just when results look surprising\nTransparent: report diagnostics in your paper or supplement, not just in your internal notes\nDocumented in the analysis plan: pre-specify which diagnostics you will run and how you will respond to problems\nInterpreted with domain expertise: a propensity score distribution or E-value only becomes meaningful when contextualized by clinical knowledge\n\nWith these tools, analysts can judge the credibility, robustness, and transportability of causal findings – essential for regulatory, clinical, and scientific decision-making. An estimate without diagnostics is not a causal estimate; it is a hope.\n\n\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31 ucrt)\n#&gt; Platform: x86_64-w64-mingw32/x64\n#&gt; Running under: Windows 11 x64 (build 26200)\n#&gt; \n#&gt; Matrix products: default\n#&gt; \n#&gt; \n#&gt; locale:\n#&gt; [1] LC_COLLATE=English_United States.utf8 \n#&gt; [2] LC_CTYPE=English_United States.utf8   \n#&gt; [3] LC_MONETARY=English_United States.utf8\n#&gt; [4] LC_NUMERIC=C                          \n#&gt; [5] LC_TIME=English_United States.utf8    \n#&gt; \n#&gt; time zone: America/Los_Angeles\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] htmlwidgets_1.6.4 compiler_4.4.2    fastmap_1.2.0     cli_3.6.5        \n#&gt;  [5] tools_4.4.2       htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10      \n#&gt;  [9] rmarkdown_2.29    knitr_1.49        jsonlite_2.0.0    xfun_0.49        \n#&gt; [13] digest_0.6.37     rlang_1.1.6       evaluate_1.0.5",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses</span>"
    ]
  },
  {
    "objectID": "03-05-advanced-diagnostics.html#sources-and-further-reading",
    "href": "03-05-advanced-diagnostics.html#sources-and-further-reading",
    "title": "13  Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "14.3 Sources and further reading",
    "text": "14.3 Sources and further reading\n\nVanderWeele TJ, Ding P (2017). Sensitivity analysis in observational research: introducing the E-value. Ann Intern Med 167(4):268-274.\nLipsitch M, Tchetgen Tchetgen E, Cohen T (2010). Negative controls: a tool for detecting confounding and bias in observational studies. Epidemiology 21(3):383-388.\nPetersen ML, Porter KE, Gruber S, et al. (2012). Diagnosing and responding to violations in the positivity assumption. Stat Methods Med Res 21(1):31-54.\nGruber S, van der Laan MJ (2010). An application of collaborative targeted maximum likelihood estimation in causal inference and genomics. Int J Biostat 6(1):Article 18.\nvan der Laan MJ, Rose S (2011). Targeted Learning. Springer. Chapter 10 (Diagnostics).\nHernan MA, Robins JM (2020). Causal Inference: What If. Chapters 11-12. Free online\nEValue R package: CRAN\ndrtmle R package: CRAN",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses</span>"
    ]
  },
  {
    "objectID": "03-05-advanced-diagnostics.html#software-implementation-r",
    "href": "03-05-advanced-diagnostics.html#software-implementation-r",
    "title": "13  Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses",
    "section": "14.4 Software Implementation (R)",
    "text": "14.4 Software Implementation (R)\nThis example demonstrates key diagnostic checks for a TMLE analysis: positivity assessment, clever covariate summaries, weight truncation sensitivity, and E-value computation.\n\nSimulate a dataset with a near-positivity violation in one confounder stratum\nRun TMLE, then inspect propensity score overlap and clever covariate distribution\nShow truncation sensitivity: compare ATE estimates across different truncation levels\nCompute an E-value for robustness to unmeasured confounding\n\n\nset.seed(1)\nn &lt;- 800\nW1 &lt;- rnorm(n)\nW2 &lt;- rbinom(n, 1, 0.3)\n## Near-positivity violation: W2 = 1 strongly predicts A = 1\nA  &lt;- rbinom(n, 1, plogis(-0.5 + 0.4 * W1 + 2.5 * W2))\nY  &lt;- 0.5 * A + 0.8 * W1 - 0.3 * W2 + rnorm(n, sd = 0.5)\n\nW  &lt;- data.frame(W1 = W1, W2 = W2)\n\n## ── 1. Propensity score overlap ──\nps_mod &lt;- glm(A ~ W1 + W2, family = binomial)\nps &lt;- predict(ps_mod, type = \"response\")\ncat(\"Propensity score summary:\\n\")\nprint(summary(ps))\ncat(\"\\nMin ps:\", round(min(ps), 4),\n    \"  Max ps:\", round(max(ps), 4), \"\\n\")\n\n## ── 2. TMLE with diagnostics ──\nif (requireNamespace(\"tmle\", quietly = TRUE)) {\n  library(tmle)\n  fit &lt;- tmle(Y = Y, A = A, W = W,\n              Q.SL.library = \"SL.glm\", g.SL.library = \"SL.glm\")\n\n  ## Clever covariate summary\n  H1 &lt;- A / ps\n  H0 &lt;- (1 - A) / (1 - ps)\n  cat(\"\\nClever covariate (treated) — max:\", round(max(H1), 1),\n      \" 99th pctile:\", round(quantile(H1, 0.99), 1), \"\\n\")\n\n  ## Influence curve check\n  cat(\"EIC mean:\", round(mean(fit$estimates$ATE$IC), 6),\n      \" (should ≈ 0)\\n\")\n\n  ## ── 3. Truncation sensitivity ──\n  cat(\"\\n── Truncation sensitivity ──\\n\")\n  for (g_bound in c(0.01, 0.025, 0.05, 0.10)) {\n    fit_trunc &lt;- tmle(Y = Y, A = A, W = W,\n                      Q.SL.library = \"SL.glm\",\n                      g.SL.library = \"SL.glm\",\n                      gbound = g_bound)\n    cat(sprintf(\"  g-bound = %.3f → ATE = %.3f  (SE = %.3f)\\n\",\n                g_bound,\n                fit_trunc$estimates$ATE$psi,\n                sqrt(fit_trunc$estimates$ATE$var.psi)))\n  }\n} else {\n  message(\"Install the 'tmle' package:  install.packages('tmle')\")\n}\n\n## ── 4. E-value (no package needed) ──\n## For a risk ratio of 1.5, the E-value formula is:\n##   E = RR + sqrt(RR * (RR - 1))\nRR &lt;- 1.5\nE_val &lt;- RR + sqrt(RR * (RR - 1))\ncat(\"\\n── E-value ──\\n\")\ncat(\"Point estimate RR:\", RR, \"\\n\")\ncat(\"E-value:\", round(E_val, 2),\n    \"\\n(An unmeasured confounder would need RR ≥\",\n    round(E_val, 2), \"with both A and Y to explain away the effect)\\n\")",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses</span>"
    ]
  },
  {
    "objectID": "03-06-rwd-meets-rct-hybrid-designs.html",
    "href": "03-06-rwd-meets-rct-hybrid-designs.html",
    "title": "14  Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "",
    "text": "15 Chapter 3.6",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Chapter 3.6: When RWD Meets RCT – Hybrid Designs</span>"
    ]
  },
  {
    "objectID": "03-06-rwd-meets-rct-hybrid-designs.html#when-rwd-meets-rct-hybrid-designs-for-causal-inference",
    "href": "03-06-rwd-meets-rct-hybrid-designs.html#when-rwd-meets-rct-hybrid-designs-for-causal-inference",
    "title": "14  Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "15.1 When RWD Meets RCT – Hybrid Designs for Causal Inference",
    "text": "15.1 When RWD Meets RCT – Hybrid Designs for Causal Inference\nCombining randomized and observational data to improve precision and generalizability\nRandomized controlled trials (RCTs) are the gold standard for causal inference.\nBut they are:\n\nExpensive and slow\n\nOften underpowered for rare events and subgroup effects\n\nConducted in selective populations\n\nNot always feasible or ethical\n\nReal-world data (RWD) — registries, EHR, claims — provide:\n\nLarge, diverse populations\n\nNaturalistic treatment patterns\n\nLong-term safety follow-up\n\nHybrid RCT–RWD designs aim to combine:\n\nThe internal validity of RCTs\n\nThe external validity and scale of RWD\n\nThis chapter introduces:\n\nWhy hybrid designs are needed\n\nTypes of hybrid designs with external controls\n\nTransportability and generalizability concepts\n\nES-CV-TMLE (External Supervised Cross-Validated TMLE)\n\nA-TMLE (Adaptive TMLE) for integrating multiple data sources\n\nPractical considerations and diagnostics",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Chapter 3.6: When RWD Meets RCT – Hybrid Designs</span>"
    ]
  },
  {
    "objectID": "03-06-rwd-meets-rct-hybrid-designs.html#why-combine-rct-and-rwd",
    "href": "03-06-rwd-meets-rct-hybrid-designs.html#why-combine-rct-and-rwd",
    "title": "14  Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "15.2 1. Why Combine RCT and RWD?",
    "text": "15.2 1. Why Combine RCT and RWD?\n\n\n\n\n\n\nThree Key Motivations for Hybrid RCT-RWD Designs\n\n\n\nAs epidemiologists, we know that no single data source is perfect. RCTs give us internal validity but are often too small, too narrow, or too slow. RWD gives us scale and diversity but lacks randomization. Hybrid designs try to get the best of both worlds. There are three core reasons to combine them:\n\n15.2.1 1.1 Precision\nTrials may be underpowered for:\n\nRare safety endpoints\nImportant subgroups\nLong-term secondary endpoints\n\nExternal RWD can add information and boost precision without enrolling more randomized patients.\n\n\n15.2.2 1.2 Generalizability\nRCT participants tend to:\n\nBe younger and healthier\nHave fewer comorbidities\nBe more adherent and monitored\n\nThus, trial results may not fully apply to routine-care populations. Think of the typical phase III oncology trial – the enrolled patients are often younger and have better performance status than those you would see in a community oncology clinic.\n\n\n15.2.3 1.3 Feasibility and ethics\nHybrid designs are useful when:\n\nPlacebo or standard randomized controls are unethical\nOnly a single-arm trial is feasible\nRapid evidence is needed (e.g., post-marketing surveillance, rare diseases)",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Chapter 3.6: When RWD Meets RCT – Hybrid Designs</span>"
    ]
  },
  {
    "objectID": "03-06-rwd-meets-rct-hybrid-designs.html#basic-hybrid-designs",
    "href": "03-06-rwd-meets-rct-hybrid-designs.html#basic-hybrid-designs",
    "title": "14  Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "15.3 2. Basic Hybrid Designs",
    "text": "15.3 2. Basic Hybrid Designs\nSeveral design patterns are commonly used.\n\n\n\n\n\n\n\nExternal Control Arms\n\n\n\nIn plain language, an external control arm means: instead of randomizing some patients to a control group within your trial, you borrow the control group from outside the trial – typically from a registry, EHR database, or historical trial data.\nA single-arm trial (all patients get experimental treatment) may be compared against an external control arm from RWD.\nUse cases:\n\nOncology (historical controls)\nRare diseases\nWhen standard-of-care is well characterized\n\n\n\n\n\n\n\n\n\nChallenges of External Controls\n\n\n\nExternal controls introduce serious methodological risks that every epidemiologist should scrutinize:\n\nConfounding by indication: Patients in the RWD were not randomized. The reasons they received (or did not receive) a treatment are entangled with their prognosis.\nDifferences in data capture: The trial measures outcomes with protocol-specified visits, imaging schedules, and adjudication committees. The RWD may rely on billing codes, free-text notes, or inconsistent follow-up.\nEligibility misalignment: Trial patients passed strict inclusion/exclusion criteria. RWD patients may differ systematically.\nCalendar time and secular trends: Changes in supportive care, diagnostic coding (e.g., ICD-9 to ICD-10 transitions), or standard-of-care over time can create spurious differences.\n\nAlways ask: “Would the external controls have been eligible for the trial, and are their outcomes measured comparably?”\n\n\n\n\n\n\n\n\n\nAugmented Control Arms\n\n\n\nUnlike a fully external control, an augmented control arm retains randomization within the trial – you still have a concurrent randomized control group. The external RWD supplements it rather than replacing it entirely. Think of it as “topping up” your control arm with additional data.\nAn RCT randomizes patients to:\n\nExperimental treatment vs trial control (e.g., 2:1 randomization)\n\nBut the trial control arm is augmented with external RWD controls to:\n\nImprove precision\nReduce required randomized control sample size\nSupport safety and rare-event evaluation\n\nBorrowing can be:\n\nFixed (pre-specified): You decide before unblinding how much external data to incorporate.\nDynamic / adaptive (data-driven): The degree of borrowing depends on how similar the RWD control outcomes are to the trial control outcomes (e.g., power prior, commensurate prior approaches).\n\nThis is generally safer than a pure external control design because the concurrent randomized control arm serves as a built-in validity check.\n\n\n\n\n\n\n\n\n\nTransportability and Generalizability\n\n\n\nIn plain language: “Transporting” a trial result means taking the causal effect estimated in the trial’s selected population and asking, “What would this effect be in a different, broader population?” For example, if a trial enrolled mostly younger patients with good kidney function, transportability methods let you estimate what the treatment effect would be in the full population of Medicare beneficiaries – including older, sicker patients who were excluded from the trial.\n\nGeneralizability = extending results from the trial sample to the full population the trial was sampled from.\nTransportability = extending results to an entirely different target population.\n\nYou may have:\n\nAn RCT effect estimate in a selected population\nA target population in RWD\n\nGoal:\n\nTransport or generalize the trial effect to the RWD population.\n\nRequires:\n\nModeling the difference between trial and target populations\nAdjusting for “sampling bias” (who joins the trial)\n\nTechniques:\n\nInverse odds of sampling weights (IOSW)\nTransport / generalizability TMLE\nDoubly robust methods combining outcome and sampling models",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Chapter 3.6: When RWD Meets RCT – Hybrid Designs</span>"
    ]
  },
  {
    "objectID": "03-06-rwd-meets-rct-hybrid-designs.html#identification-assumptions-in-hybrid-settings",
    "href": "03-06-rwd-meets-rct-hybrid-designs.html#identification-assumptions-in-hybrid-settings",
    "title": "14  Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "15.4 3. Identification: Assumptions in Hybrid Settings",
    "text": "15.4 3. Identification: Assumptions in Hybrid Settings\nBeyond usual RCT assumptions, hybrid designs require:\n\n\n\n\n\n\nAssumption 3.1: No Unmeasured Confounding (for External / Observational Arms)\n\n\n\nWithin the external data:\n\nTreatment-outcome confounding must be controlled using available covariates\nResidual confounding may bias the hybrid estimate\n\nIn epi terms, this is the same exchangeability assumption you are familiar with from observational studies – but now it applies specifically to the RWD component of your hybrid design. The RCT component is protected by randomization; the RWD component is not.\n\n\n\n\n\n\n\n\nAssumption 3.2: Common Support (Overlap)\n\n\n\nThe joint covariate space of:\n\nRCT participants\nRWD patients\n\nmust overlap, especially when:\n\nUsing RWD to estimate control outcomes\nTransporting effects across populations\n\nThis is the positivity assumption applied across data sources. If trial participants are systematically different from RWD patients in ways that matter for the outcome, you cannot borrow information reliably. Check covariate distributions carefully before proceeding.\n\n\n\n\n\n\n\n\nAssumption 3.3: Consistency Across Sources\n\n\n\nMedical coding, endpoint definitions, and measurement schemes should be compatible (or harmonized).\nFor example, “progression-free survival” measured by central radiology review in a trial is not the same as “progression-free survival” inferred from claims data or chart review. If outcome definitions differ between the RCT and RWD, the hybrid estimator conflates apples and oranges.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Chapter 3.6: When RWD Meets RCT – Hybrid Designs</span>"
    ]
  },
  {
    "objectID": "03-06-rwd-meets-rct-hybrid-designs.html#es-cv-tmle-external-supervised-cross-validated-tmle",
    "href": "03-06-rwd-meets-rct-hybrid-designs.html#es-cv-tmle-external-supervised-cross-validated-tmle",
    "title": "14  Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "15.5 4. ES-CV-TMLE: External Supervised Cross-Validated TMLE",
    "text": "15.5 4. ES-CV-TMLE: External Supervised Cross-Validated TMLE\nES-CV-TMLE (External Supervised Cross-Validated TMLE) is a targeted learning approach that:\n\nUses external data (RWD) to help train nuisance models (e.g., outcome regressions)\n\nValidates and selects among them using cross-validation in the RCT only\n\nEnsures external data do not degrade the validity of RCT-based estimation\n\n\n\n\n\n\n\nES-CV-TMLE: The Core Insight\n\n\n\nHere is the key idea in plain language: External data help you train better prediction models, but the RCT is the judge. Think of it like studying for an exam with extra textbooks (the RWD), but the exam itself (cross-validation) is graded only on RCT data. If the external textbooks helped you learn real patterns, great – your exam score improves. If they taught you spurious associations driven by confounding, the exam catches that and those models get down-weighted.\nWe may have poor precision in the RCT alone for nuisance functions (Q) and (g). External data can improve the learning of these functions, but confounding in the RWD could distort:\n\nOutcome relationships\nTreatment assignment mechanisms\n\nES-CV-TMLE protects against this by:\n\nProposing multiple candidate nuisance models, some learned on:\n\nRCT only\nRWD only\nCombined data\n\nUsing cross-validation on the RCT to evaluate each model’s performance (e.g., via log-likelihood loss).\nChoosing the best-performing nuisance model (or an ensemble of them) for TMLE.\n\nExternal data are “supervisors” but do not override the RCT.\n\n\n\n\n\n\n\n\nES-CV-TMLE Algorithm (Step by Step)\n\n\n\n\nTrain candidate models by pooling RCT and RWD data in different ways:\n\n(Q_{ ext{RCT}}): trained only on RCT\n(Q_{ ext{RWD}}): trained only on RWD\n(Q_{ ext{pool}}): trained on combined RCT+RWD\n\nEvaluate each candidate using RCT data only:\n\nRun cross-validated evaluation (e.g., deviance, negative log-likelihood)\n\nSelect or weight candidates via SuperLearner-style metalearning.\nRun TMLE using the chosen Q (and similarly chosen g, if desired) on the RCT data.\n\nThis preserves the RCT-based identification and uses RWD as an auxiliary data source for better prediction. The bottom line: even if the RWD is confounded, this procedure can only help (or do no harm) relative to using the RCT alone.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Chapter 3.6: When RWD Meets RCT – Hybrid Designs</span>"
    ]
  },
  {
    "objectID": "03-06-rwd-meets-rct-hybrid-designs.html#a-tmle-adaptive-targeted-maximum-likelihood-estimation",
    "href": "03-06-rwd-meets-rct-hybrid-designs.html#a-tmle-adaptive-targeted-maximum-likelihood-estimation",
    "title": "14  Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "15.6 5. A-TMLE: Adaptive Targeted Maximum Likelihood Estimation",
    "text": "15.6 5. A-TMLE: Adaptive Targeted Maximum Likelihood Estimation\n\n\n\n\n\n\nA-TMLE: Adaptive Combination in Plain Language\n\n\n\nThink of A-TMLE as a “meta-analysis machine” that does not just combine study results, but adaptively learns the best way to blend multiple estimators from different data sources. Where ES-CV-TMLE selects among candidate prediction models (a step inside the estimator), A-TMLE operates one level up: it selects among or blends entire estimators, each of which may use different data sources or modeling strategies. The data themselves decide how much to trust each source.\n\n\nAdaptive TMLE (A-TMLE) generalizes ES-CV-TMLE to the estimator level.\nInstead of combining candidate nuisance models, A-TMLE combines candidate estimators (e.g., separate hybrid analyses):\n\nTMLE using RCT only\nTMLE using RWD only (carefully adjusted)\nTMLE using both RCT + RWD in a joint model\nOther candidate estimators\n\nIt then uses a SuperLearner-style convex combination of these estimators to:\n\nMinimize cross-validated risk, yielding an adaptive, doubly robust final estimate.\n\n\n15.6.1 5.1 Why A-TMLE?\nMultiple data sources can provide:\n\nHigh internal validity (RCT)\n\nHigh external validity (RWD)\n\nDifferent types of bias and variance\n\nA-TMLE lets the data decide the optimal combination, subject to:\n\nConstraints (e.g., RCT estimator always included)\n\nHierarchical preferences (e.g., more weight on RCT when conflict arises)\n\n\n\n15.6.2 5.2 Mathematical structure\nLet ( _1, , _K) be candidate estimators of the same target parameter ().\nA-TMLE constructs:\n[ { ext{A-TMLE}} = {k=1}^K \u0007lpha_k _k ]\nwith\n\n(\u0007lpha_k )\n\n(_k \u0007lpha_k = 1)\n\nWeights (\u0007lpha) are chosen to minimize cross-validated loss (e.g., squared error of influence curves).",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Chapter 3.6: When RWD Meets RCT – Hybrid Designs</span>"
    ]
  },
  {
    "objectID": "03-06-rwd-meets-rct-hybrid-designs.html#example-hybrid-workflow-conceptual",
    "href": "03-06-rwd-meets-rct-hybrid-designs.html#example-hybrid-workflow-conceptual",
    "title": "14  Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "15.7 6. Example Hybrid Workflow (Conceptual)",
    "text": "15.7 6. Example Hybrid Workflow (Conceptual)\nConsider:\n\nRCT: experimental vs placebo\n\nRWD: observational comparison between experimental drug and standard-of-care\n\n\n15.7.1 6.1 TMLE using RCT only\ntmle_rct &lt;- tmle(\n  Y = Y_rct,\n  A = A_rct,\n  W = W_rct,\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\")\n)\npsi_rct &lt;- tmle_rct$estimates$ATE$psi\n\n\n15.7.2 6.2 TMLE using RWD (careful confounding control)\ntmle_rwd &lt;- tmle(\n  Y = Y_rwd,\n  A = A_rwd,\n  W = W_rwd,\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\")\n)\npsi_rwd &lt;- tmle_rwd$estimates$ATE$psi\n\n\n15.7.3 6.3 Pooled-source TMLE\nY_pool &lt;- c(Y_rct, Y_rwd)\nA_pool &lt;- c(A_rct, A_rwd)\nW_pool &lt;- rbind(W_rct, W_rwd)\n\ntmle_pool &lt;- tmle(\n  Y = Y_pool,\n  A = A_pool,\n  W = W_pool,\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\")\n)\npsi_pool &lt;- tmle_pool$estimates$ATE$psi\n\n\n15.7.4 6.4 Adaptive combination (A-TMLE style idea)\ncandidates &lt;- c(psi_rct, psi_rwd, psi_pool)\n\n# Placeholder: in practice, you would build a loss function based on influence curves\n# and use constrained optimization (e.g., nnls) with cross-validation to find weights.\n\nweights &lt;- c(0.6, 0.0, 0.4)  # e.g., chosen by cross-validation\nweights &lt;- weights / sum(weights)\n\npsi_atmle &lt;- sum(weights * candidates)\npsi_atmle\nIn a true A-TMLE implementation, the weights would be:\n\nEstimated based on CV risk\n\nPossibly constrained to ensure heavier emphasis on RCT-based estimators",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Chapter 3.6: When RWD Meets RCT – Hybrid Designs</span>"
    ]
  },
  {
    "objectID": "03-06-rwd-meets-rct-hybrid-designs.html#practical-considerations-and-diagnostics-for-hybrid-designs",
    "href": "03-06-rwd-meets-rct-hybrid-designs.html#practical-considerations-and-diagnostics-for-hybrid-designs",
    "title": "14  Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "15.8 7. Practical Considerations and Diagnostics for Hybrid Designs",
    "text": "15.8 7. Practical Considerations and Diagnostics for Hybrid Designs\n\n\n\n\n\n\n7.1 Harmonization\n\n\n\nBefore attempting hybrid estimation, you must ensure that the two data sources are speaking the same language. This is often the most labor-intensive step.\n\nAlign endpoint definitions and censoring rules\nHarmonize covariates (coding, units, ranges)\nConfirm consistent definition of “treatment” across sources\n\n\n\n\n\n\n\n\n\n7.2 Assess Similarity Between RCT and RWD\n\n\n\nCheck covariate distributions before you borrow. Visualization is your first line of defense:\nbind_rows(\n  W_rct %&gt;% mutate(source = “RCT”),\n  W_rwd %&gt;% mutate(source = “RWD”)\n) %&gt;%\n  pivot_longer(cols = -source) %&gt;%\n  ggplot(aes(x = value, fill = source)) +\n  geom_density(alpha = 0.4) +\n  facet_wrap(~ name, scales = “free”)\nLook for:\n\nLarge discrepancies –&gt; may require transportability modeling\nNon-overlapping regions –&gt; positivity issues\n\n\n\n\n\n\n\n\n\n7.3 Sensitivity Analyses Are Not Optional\n\n\n\nEvery hybrid analysis should include sensitivity checks that quantify how much the result depends on the external data:\n\nRe-estimate using RCT-only TMLE (your “no-borrowing” benchmark)\nVary the degree of borrowing (e.g., by up-weighting/down-weighting RWD in hybrid estimators)\nUse E-values or quantitative bias analysis (QBA) to examine the impact of unmeasured confounding in the RWD component\nApply negative control analyses in the RWD part\n\nIf your conclusions change dramatically depending on how much RWD you include, that is a signal that the external data may be introducing bias rather than reducing variance.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Chapter 3.6: When RWD Meets RCT – Hybrid Designs</span>"
    ]
  },
  {
    "objectID": "03-06-rwd-meets-rct-hybrid-designs.html#when-to-use-hybrid-designs-and-when-not-to",
    "href": "03-06-rwd-meets-rct-hybrid-designs.html#when-to-use-hybrid-designs-and-when-not-to",
    "title": "14  Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "15.9 8. When to Use Hybrid Designs (and When Not To)",
    "text": "15.9 8. When to Use Hybrid Designs (and When Not To)\nHybrid designs are appropriate when:\n\nRWD is of reasonable quality\n\nKey confounders in RWD are measured\n\nOutcome definitions are compatible\n\nThere is substantial overlap in covariate distributions\n\nThe trial alone is underpowered or narrow in scope\n\n\n\n\n\n\n\nWhen Hybrid Designs Are Inappropriate\n\n\n\nThey may be inappropriate when:\n\nRWD is subject to severe unmeasured confounding: If the observational data lack key confounders (e.g., disease severity, performance status), borrowing from RWD can introduce more bias than it resolves.\nData sources are poorly harmonized: If outcome definitions, covariate coding, or follow-up schedules differ substantially and cannot be reconciled, the hybrid estimator is comparing incompatible quantities.\nThere is little overlap in covariate or treatment patterns: If the trial population and RWD population occupy different regions of the covariate space, extrapolation replaces estimation.\nThe trial is already well-powered for the primary endpoint: In this case, the marginal precision gain from RWD may not justify the additional assumptions and complexity.\n\nIn those cases, a pure RCT analysis with careful interpretation may be preferable. Adding RWD is not always better – it is better only when the assumptions hold and the data quality warrants it.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Chapter 3.6: When RWD Meets RCT – Hybrid Designs</span>"
    ]
  },
  {
    "objectID": "03-06-rwd-meets-rct-hybrid-designs.html#summary",
    "href": "03-06-rwd-meets-rct-hybrid-designs.html#summary",
    "title": "14  Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "15.10 9. Summary",
    "text": "15.10 9. Summary\n\n\n\n\n\n\nChapter Takeaways\n\n\n\nHybrid RCT-RWD designs extend the causal roadmap to a richer evidence ecosystem:\n\nExternal controls can augment sparse trial control arms\nTransport and generalizability methods can extend findings to broader populations\nES-CV-TMLE leverages RWD for nuisance modeling while preserving internal validity\nA-TMLE adaptively combines estimators from multiple sources using targeted learning and cross-validation\n\nUsed carefully, these tools can:\n\nImprove precision\nEnhance generalizability\nProvide robust, transparent evidence that respects the strengths and limitations of both RCT and RWD\n\nThe overarching principle for MPH-trained epidemiologists: hybrid designs do not weaken the RCT – they extend it. But the extension is only as trustworthy as the assumptions and data quality behind the RWD component. Always report the RCT-only result alongside the hybrid result so readers can judge for themselves.\n\n\n\nsessionInfo()\n\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26200)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.2    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.4.2       htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10      \n [9] rmarkdown_2.29    knitr_1.49        jsonlite_2.0.0    xfun_0.49        \n[13] digest_0.6.37     rlang_1.1.6       evaluate_1.0.5",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Chapter 3.6: When RWD Meets RCT – Hybrid Designs</span>"
    ]
  },
  {
    "objectID": "03-06-rwd-meets-rct-hybrid-designs.html#software-implementation-r",
    "href": "03-06-rwd-meets-rct-hybrid-designs.html#software-implementation-r",
    "title": "14  Chapter 3.6: When RWD Meets RCT – Hybrid Designs",
    "section": "15.11 Software Implementation (R)",
    "text": "15.11 Software Implementation (R)\nThis example demonstrates an external control arm analysis skeleton where a randomized trial is augmented with real-world data (RWD). We simulate an RCT treatment arm and an external RWD control arm, then estimate the ATE using TMLE with study-membership adjustment.\n\nSimulates a small RCT (treatment arm only) and a larger RWD cohort (controls)\nIncludes a study-membership indicator \\(S\\) to adjust for systematic differences\nUses tmle to estimate the treatment effect while adjusting for \\(W\\) and \\(S\\)\nNotes where specialized packages like EScvtmle would extend this approach\n\n\nset.seed(1)\n\n## ── Simulate RCT treatment arm ──\nn_rct &lt;- 150\nW1_rct &lt;- rnorm(n_rct, mean = 0.2)\nW2_rct &lt;- rbinom(n_rct, 1, 0.4)\nA_rct  &lt;- rep(1, n_rct)  # all treated\nY_rct  &lt;- rbinom(n_rct, 1, plogis(-1 + 0.6 * 1 + 0.5 * W1_rct + 0.3 * W2_rct))\n\n## ── Simulate RWD external controls ──\nn_rwd &lt;- 400\nW1_rwd &lt;- rnorm(n_rwd, mean = -0.1)   # slight covariate shift\nW2_rwd &lt;- rbinom(n_rwd, 1, 0.5)\nA_rwd  &lt;- rep(0, n_rwd)  # all control\nY_rwd  &lt;- rbinom(n_rwd, 1, plogis(-1 + 0.6 * 0 + 0.5 * W1_rwd + 0.3 * W2_rwd))\n\n## ── Combined analysis dataset ──\ndat &lt;- data.frame(\n  W1 = c(W1_rct, W1_rwd),\n  W2 = c(W2_rct, W2_rwd),\n  S  = c(rep(1, n_rct), rep(0, n_rwd)),   # study membership\n  A  = c(A_rct, A_rwd),\n  Y  = c(Y_rct, Y_rwd)\n)\n\nif (requireNamespace(\"tmle\", quietly = TRUE)) {\n  library(tmle)\n  ## Include study indicator S as a covariate to adjust for\n  ## population differences between RCT and RWD\n  W &lt;- dat[, c(\"W1\", \"W2\", \"S\")]\n\n  fit &lt;- tmle(\n    Y = dat$Y, A = dat$A, W = W,\n    family = \"binomial\",\n    Q.SL.library = c(\"SL.glm\", \"SL.mean\"),\n    g.SL.library  = c(\"SL.glm\", \"SL.mean\")\n  )\n\n  cat(\"── Hybrid RCT + RWD external control analysis ──\\n\")\n  cat(\"ATE (risk difference):\", round(fit$estimates$ATE$psi, 4), \"\\n\")\n  cat(\"95% CI:\", round(fit$estimates$ATE$CI, 4), \"\\n\")\n  cat(\"\\nNote: For more sophisticated approaches, see:\\n\")\n  cat(\"  - EScvtmle: external-source cross-validated TMLE\\n\")\n  cat(\"  - A-TMLE: adaptive TMLE for data-adaptive borrowing\\n\")\n} else {\n  message(\"Install the 'tmle' package:  install.packages('tmle')\")\n}",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Chapter 3.6: When RWD Meets RCT – Hybrid Designs</span>"
    ]
  },
  {
    "objectID": "03-07-longitudinal-td-confounding.html",
    "href": "03-07-longitudinal-td-confounding.html",
    "title": "15  Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE",
    "section": "",
    "text": "16 Chapter 3.7: Imperfect Adherence in Longitudinal Data\nWhy conditioning on adherence biases causal effects, and how longitudinal TMLE and LMTP address this\nIn randomized trials, the intent-to-treat (ITT) analysis compares groups as randomized, regardless of whether patients actually took their medication. But in pharmacoepidemiology, we often want to know:\nThis chapter addresses imperfect adherence — a central challenge in longitudinal causal inference. We show:\nThe motivating example: antiretroviral therapy (ART) adherence and HIV virologic suppression.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-07-longitudinal-td-confounding.html#the-setting",
    "href": "03-07-longitudinal-td-confounding.html#the-setting",
    "title": "15  Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE",
    "section": "17.1 The Setting",
    "text": "17.1 The Setting\nA public health agency wants to evaluate antiretroviral therapy strategies for people living with HIV. The key question:\n\nWhat is the probability of virologic suppression (HIV RNA &lt; 200 copies/mL) at 12 months if all patients maintained high adherence to their ART regimen, compared to the observed adherence pattern?\n\n\n17.1.1 Why this question is hard\nIn practice, ART adherence varies over time due to:\n\nSide effects (nausea, fatigue) that reduce adherence\nViral load response — patients who achieve suppression may become less diligent\nCD4 count changes — worsening health may change both adherence and outcomes\nMental health and substance use — confounders that affect both adherence and outcomes\n\nCritically, adherence at each time point is influenced by time-varying health status, and time-varying health status is itself influenced by past adherence. This creates time-varying confounding affected by prior treatment — a situation where standard methods fail.\n\n\n17.1.2 Target population\nAdults living with HIV initiating a new ART regimen\n\n\n17.1.3 Treatment strategies\n\nStrategy 1: Maintain high adherence (\\(\\geq\\) 95% of doses) at every monthly interval\nStrategy 0: Natural (observed) adherence course\n\n\n\n17.1.4 Outcome\nVirologic suppression (HIV RNA &lt; 200 copies/mL) at 12 months\n\n\n17.1.5 Intercurrent events\n\nLoss to follow-up (informative censoring)\nTreatment switching\nDeath\n\n\n\n17.1.6 The decision\nShould adherence support programs be intensified? How much improvement in suppression could be expected from perfect adherence?",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-07-longitudinal-td-confounding.html#why-not-just-adjust-for-adherence-in-a-regression",
    "href": "03-07-longitudinal-td-confounding.html#why-not-just-adjust-for-adherence-in-a-regression",
    "title": "15  Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE",
    "section": "18.1 Why not just adjust for adherence in a regression?",
    "text": "18.1 Why not just adjust for adherence in a regression?\nConsider a simple model: \\[\n\\text{logit}\\big(P(Y = 1)\\big) = \\beta_0 + \\beta_1 \\cdot \\text{Cumulative Adherence} + \\beta_2 \\cdot \\text{Baseline CD4}\n\\]\nThis conditions on adherence. But why is that a problem?\n\n\n\n\n\n\nThe Conditioning-on-Adherence Trap\n\n\n\nThe problem is that adherence is affected by prior health status, which also affects the outcome. Adherence is simultaneously:\n\nA mediator (treatment \\(\\to\\) adherence \\(\\to\\) outcome)\nA collider when conditioned on (because both health status and unmeasured factors affect it)\n\nConditioning on adherence opens backdoor paths through time-varying confounders, introducing selection bias. This is a fundamental result from causal inference theory.\nThink of it this way: If you compare patients who adhered well vs. poorly, you are not comparing like-with-like. Patients who adhered poorly may have done so because they were sicker — and that sickness, not the low adherence, may explain worse outcomes. Conditioning on adherence mixes up the reason for adherence with the effect of adherence.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-07-longitudinal-td-confounding.html#visual-intuition",
    "href": "03-07-longitudinal-td-confounding.html#visual-intuition",
    "title": "15  Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE",
    "section": "18.2 Visual intuition",
    "text": "18.2 Visual intuition\n\n\n\n\n\n\nThe Collider Problem in a Diagram\n\n\n\n    CD4(t-1) -----&gt; Adherence(t) -----&gt; CD4(t) -----&gt; Outcome\n       |                ^                  |\n       |                |                  |\n       +---------&gt; Adherence(t) &lt;----------+\n                     (collider when conditioned on)\nWhen you condition on adherence at time \\(t\\), you induce an association between CD4 at time \\(t-1\\) and unmeasured factors that affect adherence — biasing the effect estimate.\nWhy does this matter? Once you “hold adherence fixed” in a regression, you create a spurious link between everything that caused adherence. This is collider bias, and it distorts the causal effect estimate in unpredictable ways — sometimes making the treatment look more effective, sometimes less.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-07-longitudinal-td-confounding.html#a-common-mistake-gee-models",
    "href": "03-07-longitudinal-td-confounding.html#a-common-mistake-gee-models",
    "title": "15  Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE",
    "section": "18.3 A common mistake: GEE models",
    "text": "18.3 A common mistake: GEE models\nGeneralized Estimating Equations (GEE) are popular for longitudinal data, but a GEE model that adjusts for time-varying covariates and conditions on time-varying treatment (adherence) will produce biased estimates for causal effects when time-varying confounders are affected by prior treatment.\nThe solution: Use g-methods (g-computation, IPTW, or TMLE) that properly handle the time-ordering of treatment, confounders, and outcome.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-07-longitudinal-td-confounding.html#a.-cross-sectional-regression-on-cumulative-adherence",
    "href": "03-07-longitudinal-td-confounding.html#a.-cross-sectional-regression-on-cumulative-adherence",
    "title": "15  Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE",
    "section": "21.1 5A. Cross-sectional regression on cumulative adherence",
    "text": "21.1 5A. Cross-sectional regression on cumulative adherence\n\n# Only among uncensored\ndat_complete &lt;- dat_wide %&gt;% filter(!is.na(Y))\ndat_complete$cum_adh &lt;- cum_adh[alive]\n\nnaive_gee &lt;- glm(Y ~ cum_adh + cd4_bl + vl_bl + depress + age + male,\n                 family = binomial, data = dat_complete)\n\n# Predicted suppression at 100% vs 50% adherence\nnd_perfect &lt;- dat_complete %&gt;% mutate(cum_adh = 1.0)\nnd_half    &lt;- dat_complete %&gt;% mutate(cum_adh = 0.5)\n\nnaive_perfect &lt;- mean(predict(naive_gee, newdata = nd_perfect, type = \"response\"))\nnaive_half    &lt;- mean(predict(naive_gee, newdata = nd_half, type = \"response\"))\n\ncat(\"Naive model:\\n\")\n#&gt; Naive model:\ncat(\"  Predicted suppression at 100% adherence:\", round(naive_perfect, 3), \"\\n\")\n#&gt;   Predicted suppression at 100% adherence: 0.568\ncat(\"  Predicted suppression at 50% adherence: \", round(naive_half, 3), \"\\n\")\n#&gt;   Predicted suppression at 50% adherence:  0.159\ncat(\"  Difference:\", round(naive_perfect - naive_half, 3), \"\\n\")\n#&gt;   Difference: 0.409\ncat(\"\\nThis estimate is biased because it conditions on post-treatment variables.\\n\")\n#&gt; \n#&gt; This estimate is biased because it conditions on post-treatment variables.\n\n\n\n\n\n\n\nWhy Is This Wrong?\n\n\n\nThe model treats cumulative adherence as a fixed baseline variable, but adherence is:\n\nAffected by time-varying CD4 and symptoms (confounders) — patients who feel worse adhere less, and feeling worse also worsens the outcome directly\nItself affects future CD4 and symptoms (it is a treatment) — taking medication changes the very health indicators that influence future adherence\nA collider when conditioned on — because both health status and unmeasured factors drive adherence decisions\n\nThe estimate conflates the causal effect of adherence with the reverse causal effect of health on adherence. You cannot untangle “does adherence improve outcomes?” from “do better outcomes sustain adherence?” using standard regression.\nThe fundamental issue: Standard regression assumes covariates are fixed. But in a longitudinal feedback loop, today’s treatment changes tomorrow’s confounders, which change the day after’s treatment. No single regression equation can properly account for this temporal cascade.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-07-longitudinal-td-confounding.html#time-specific-propensity-score-overlap",
    "href": "03-07-longitudinal-td-confounding.html#time-specific-propensity-score-overlap",
    "title": "15  Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE",
    "section": "27.1 11.1 Time-specific propensity score overlap",
    "text": "27.1 11.1 Time-specific propensity score overlap\n\n# Check overlap at each time point\noverlap_checks &lt;- list()\nfor (t_val in 1:T_max) {\n  A_col &lt;- paste0(\"A_\", t_val)\n  cd4_col &lt;- paste0(\"cd4_\", t_val)\n  sympt_col &lt;- paste0(\"sympt_\", t_val)\n\n  formula_vars &lt;- c(cd4_col, sympt_col, \"depress\", \"age\", \"male\")\n  if (t_val &gt; 1) formula_vars &lt;- c(formula_vars, paste0(\"A_\", t_val - 1))\n\n  g_check &lt;- glm(\n    as.formula(paste(A_col, \"~\", paste(formula_vars, collapse = \" + \"))),\n    family = binomial, data = dat_analysis\n  )\n\n  ps_check &lt;- predict(g_check, type = \"response\")\n  overlap_checks[[t_val]] &lt;- tibble(\n    time = t_val,\n    ps = ps_check,\n    A = dat_analysis[[A_col]]\n  )\n}\n\noverlap_df &lt;- bind_rows(overlap_checks)\n\nggplot(overlap_df, aes(x = ps, fill = factor(A, labels = c(\"Low adherence\", \"High adherence\")))) +\n  geom_density(alpha = 0.4) +\n  facet_wrap(~paste(\"Time\", time), ncol = 3) +\n  labs(\n    x = \"P(A_t = 1 | history)\",\n    fill = \"Adherence\",\n    title = \"Propensity Score Overlap by Time Point\"\n  ) +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"#EE6677\", \"#228833\"))",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-07-longitudinal-td-confounding.html#cumulative-weight-distribution",
    "href": "03-07-longitudinal-td-confounding.html#cumulative-weight-distribution",
    "title": "15  Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE",
    "section": "27.2 11.2 Cumulative weight distribution",
    "text": "27.2 11.2 Cumulative weight distribution\n\ncat(\"Cumulative IPTW weight summary:\\n\")\n#&gt; Cumulative IPTW weight summary:\ncat(\"Before truncation:\\n\")\n#&gt; Before truncation:\nsummary(weight_df$sw)\n#&gt;     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n#&gt;    1.473   13.231   28.079   64.916   73.400 2508.131\ncat(\"\\nAfter truncation:\\n\")\n#&gt; \n#&gt; After truncation:\nsummary(weight_df$sw_trunc)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;   1.473  13.231  28.079  60.936  73.400 565.277\ncat(\"\\nFraction &gt; 10:\", round(mean(weight_df$sw &gt; 10), 3), \"\\n\")\n#&gt; \n#&gt; Fraction &gt; 10: 0.778\ncat(\"Fraction &gt; 50:\", round(mean(weight_df$sw &gt; 50), 3), \"\\n\")\n#&gt; Fraction &gt; 50: 0.357\n\nLarge fractions of extreme weights indicate that the longitudinal treatment mechanism is poorly estimated or that positivity is violated. This motivates using LTMLE over IPTW.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-07-longitudinal-td-confounding.html#adherence-patterns-over-time",
    "href": "03-07-longitudinal-td-confounding.html#adherence-patterns-over-time",
    "title": "15  Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE",
    "section": "27.3 11.3 Adherence patterns over time",
    "text": "27.3 11.3 Adherence patterns over time\n\n# Visualize adherence trajectories\nadh_summary &lt;- dat_long %&gt;%\n  filter(!is.na(A)) %&gt;%\n  group_by(time) %&gt;%\n  summarise(\n    pct_adherent = mean(A),\n    n = n(),\n    .groups = \"drop\"\n  )\n\nggplot(adh_summary, aes(x = time, y = pct_adherent)) +\n  geom_line(color = \"#4477AA\", linewidth = 1) +\n  geom_point(size = 3, color = \"#4477AA\") +\n  ylim(0, 1) +\n  labs(\n    x = \"Time point\",\n    y = \"Proportion with high adherence\",\n    title = \"Adherence Over Time\"\n  ) +\n  theme_minimal()",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-07-longitudinal-td-confounding.html#what-would-we-tell-the-public-health-agency",
    "href": "03-07-longitudinal-td-confounding.html#what-would-we-tell-the-public-health-agency",
    "title": "15  Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE",
    "section": "29.1 What would we tell the public health agency?",
    "text": "29.1 What would we tell the public health agency?\nBased on our analysis:\n\nUnder the naturally observed adherence pattern, approximately 34% of patients achieve virologic suppression at 12 months\nUnder a hypothetical always-high-adherence intervention, the estimated suppression rate is approximately 49%\nThe estimated benefit of ensuring high adherence is approximately 14.7 percentage points of additional suppression",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-07-longitudinal-td-confounding.html#implications-for-adherence-support-programs",
    "href": "03-07-longitudinal-td-confounding.html#implications-for-adherence-support-programs",
    "title": "15  Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE",
    "section": "29.2 Implications for adherence support programs",
    "text": "29.2 Implications for adherence support programs\nIf increasing adherence from observed levels to near-perfect could improve suppression by this magnitude, investments in adherence support (pill organizers, SMS reminders, peer support, reduced pill burden) may be cost-effective.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-07-longitudinal-td-confounding.html#fragile-assumptions",
    "href": "03-07-longitudinal-td-confounding.html#fragile-assumptions",
    "title": "15  Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE",
    "section": "29.3 Fragile assumptions",
    "text": "29.3 Fragile assumptions\n\nSequential exchangeability: If unmeasured factors (e.g., substance use severity, housing instability) affect both adherence and outcomes, our estimates are biased\nPositivity: If some patient types never achieve high adherence, we cannot estimate the effect of forcing them to adhere — stochastic interventions are more appropriate\nIndependent censoring: If loss to follow-up is driven by unmeasured factors related to both adherence and outcome, even after conditioning on observed covariates, our censoring adjustment is biased",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-07-longitudinal-td-confounding.html#sources-and-further-reading",
    "href": "03-07-longitudinal-td-confounding.html#sources-and-further-reading",
    "title": "15  Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE",
    "section": "30.1 Sources and further reading",
    "text": "30.1 Sources and further reading\n\nRobins JM, Hernan MA, Brumback B (2000). Marginal structural models and causal inference in epidemiology. Epidemiology 11(5):550-560.\nPetersen ML, Schwab J, Gruber S, Blaser N, Schomaker M, van der Laan MJ (2014). Targeted maximum likelihood estimation for dynamic and static longitudinal marginal structural working models. J Causal Inference 2(2):147-185.\nDiaz I, Williams N, Hoffman KL, et al. (2023). lmtp: An R package for estimating the causal effects of modified treatment policies. Observational Studies 9:103-122.\nLendle SD, Schwab J, Petersen ML, van der Laan MJ (2017). ltmle: An R package implementing targeted minimum loss-based estimation for longitudinal data. J Stat Softw 81(1):1-21.\nHernan MA, Brumback B, Robins JM (2001). Marginal structural models to estimate the joint causal effect of nonrandomized treatments. JASA 96(454):440-448.\nCole SR, Hernan MA (2008). Constructing inverse probability weights for marginal structural models. Am J Epidemiol 168(6):656-664.\nltmle R package: CRAN\nlmtp R package: CRAN",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-07-longitudinal-td-confounding.html#software-implementation-r",
    "href": "03-07-longitudinal-td-confounding.html#software-implementation-r",
    "title": "15  Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE",
    "section": "30.2 Software Implementation (R)",
    "text": "30.2 Software Implementation (R)\nThis example uses the ltmle package to estimate the effect of a sequential treatment strategy (always treat vs. never treat) in the presence of time-varying confounding affected by prior treatment.\n\nSimulate 3-time-point longitudinal data with treatment-confounder feedback\n\\(L_t\\) is affected by \\(A_{t-1}\\) and also affects \\(A_t\\) and \\(Y\\)\nUse ltmle() with abar to compare two static regimes\nFalls back to IPTW-based MSM if ltmle is unavailable\n\n\nset.seed(1)\nn &lt;- 500\nW     &lt;- rnorm(n)\nA_0   &lt;- rbinom(n, 1, plogis(0.2 * W))\nL_1   &lt;- rnorm(n, mean = 0.4 * A_0 + 0.3 * W)\nA_1   &lt;- rbinom(n, 1, plogis(0.3 * L_1 + 0.2 * W))\nL_2   &lt;- rnorm(n, mean = 0.4 * A_1 + 0.2 * L_1 + 0.2 * W)\nA_2   &lt;- rbinom(n, 1, plogis(0.3 * L_2 + 0.2 * W))\nY     &lt;- rbinom(n, 1, plogis(-1.5 + 0.3 * A_0 + 0.3 * A_1 + 0.4 * A_2 +\n                               0.2 * L_2 + 0.2 * W))\n\ndat &lt;- data.frame(W, A_0, L_1, A_1, L_2, A_2, Y)\n\nif (requireNamespace(\"ltmle\", quietly = TRUE)) {\n  library(ltmle)\n\n  result &lt;- ltmle(\n    data = dat,\n    Anodes  = c(\"A_0\", \"A_1\", \"A_2\"),\n    Lnodes  = c(\"L_1\", \"L_2\"),\n    Ynodes  = \"Y\",\n    abar = list(treatment = c(1, 1, 1), control = c(0, 0, 0)),\n    SL.library = \"glm\"\n  )\n  cat(\"LTMLE: always treat vs never treat\\n\")\n  print(summary(result))\n} else {\n  message(\"Install the 'ltmle' package:  install.packages('ltmle')\")\n}",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-08-tmle-clean-room.html",
    "href": "03-08-tmle-clean-room.html",
    "title": "16  Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology",
    "section": "",
    "text": "17 Chapter 3.8: TMLE in the Clean-Room Framework\nPre-specified, reproducible causal inference for regulatory pharmacoepidemiology\nIn many regulatory settings, analysts cannot freely explore the data. Post-marketing safety studies, multi-database pharmacoepidemiology collaborations, and distributed data network analyses often require a clean-room workflow: the analysis plan is pre-specified before data access, code is locked, and the analyst has minimal or no opportunity to iterate on model choices after seeing the data.\nThis is the opposite of typical exploratory data analysis — and it is where TMLE shines.\nThis chapter demonstrates how to implement TMLE in a clean-room regulatory context, using a motivating example inspired by the NSAIDs vs. opioids acute kidney injury (AKI) safety question.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span>"
    ]
  },
  {
    "objectID": "03-08-tmle-clean-room.html#the-regulatory-question",
    "href": "03-08-tmle-clean-room.html#the-regulatory-question",
    "title": "16  Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology",
    "section": "18.1 The Regulatory Question",
    "text": "18.1 The Regulatory Question\nA distributed research network (similar to the FDA Sentinel system) has flagged a potential safety signal:\n\nDoes initiation of prescription NSAIDs increase the 90-day risk of acute kidney injury compared to initiation of prescription opioids among adults with musculoskeletal pain?\n\nThis question arises in a post-marketing surveillance context where:\n\nRaw patient-level data cannot leave participating sites (privacy, legal, or contractual constraints)\nThe analysis must be pre-specified in a Statistical Analysis Plan (SAP) before any data access\nResults must be reproducible — running the same code on the same data yields identical results\nThe analyst cannot iterate on model specifications after seeing the data\nThere is an audit trail documenting every analysis step\n\n\n18.1.1 Key elements\n\nTarget population: Adults aged 18-80 with a new musculoskeletal pain diagnosis initiating either NSAIDs or opioids\nTreatment: NSAID initiation (A = 1) vs. opioid initiation (A = 0)\nOutcome: AKI within 90 days (binary)\nDecision: Should the NSAID label carry a stronger AKI warning? Should prescribing guidelines be updated?\n\n\n\n\n\n\n\nWhy TMLE for Clean-Room?\n\n\n\nTraditional regression-based analyses require the analyst to choose a single model specification — a process that invites data-dependent decisions. Every time an analyst looks at the data and adjusts a model, the pre-specification principle is compromised. TMLE with Super Learner sidesteps this problem entirely:\n\nPre-specify a learner library, not a single model. The SAP lists the candidate algorithms. Cross-validation — not the analyst — picks the best combination. No post-hoc model selection is required.\nDouble robustness protects you. Even if the outcome model or the treatment model is misspecified, the estimate remains consistent as long as at least one is correct. This is invaluable when you cannot iterate after seeing the data.\nInfluence-curve inference is automatic. Valid standard errors come directly from the efficient influence curve — no bootstrap needed, no distributional assumptions beyond the nonparametric model.\nFull determinism. Given the same data, learner library, and random seed, the entire pipeline produces bit-identical results. Every run is reproducible.\nThe audit trail writes itself. Cross-validated learner weights, the fluctuation parameter, and every diagnostic are logged as natural byproducts of the algorithm.\n\nIn short, TMLE turns the clean-room constraint from a limitation into a strength: the algorithm makes the decisions that the analyst is not allowed to make.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span>"
    ]
  },
  {
    "objectID": "03-08-tmle-clean-room.html#causal-question-and-estimand",
    "href": "03-08-tmle-clean-room.html#causal-question-and-estimand",
    "title": "16  Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology",
    "section": "20.1 3.1 Causal Question and Estimand",
    "text": "20.1 3.1 Causal Question and Estimand\nBefore touching any data, we write down exactly what we want to estimate and why.\nQuestion (plain language): What is the 90-day AKI risk if all eligible patients initiated NSAIDs, compared to if all eligible patients initiated opioids?\nEstimand: Average Treatment Effect on the risk difference scale:\n\\[\n\\psi = E[Y(1)] - E[Y(0)]\n\\]\nwhere \\(Y(1)\\) is the potential AKI outcome under NSAID initiation and \\(Y(0)\\) under opioid initiation.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span>"
    ]
  },
  {
    "objectID": "03-08-tmle-clean-room.html#causal-model-dag",
    "href": "03-08-tmle-clean-room.html#causal-model-dag",
    "title": "16  Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology",
    "section": "20.2 3.2 Causal Model (DAG)",
    "text": "20.2 3.2 Causal Model (DAG)\nConfounders (W):\n  age, sex, CKD stage, diabetes, hypertension,\n  prior NSAID use, prior opioid use, ACE/ARB use,\n  number of concomitant medications, healthcare utilization\n\n      W\n     / \\\n    v   v\n    A -&gt; Y\nAll measured confounders \\(W\\) affect both treatment choice \\(A\\) and outcome \\(Y\\). The active comparator design (NSAID vs. opioid) helps control for confounding by indication — both groups have pain requiring treatment.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span>"
    ]
  },
  {
    "objectID": "03-08-tmle-clean-room.html#assumptions",
    "href": "03-08-tmle-clean-room.html#assumptions",
    "title": "16  Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology",
    "section": "20.3 3.3 Assumptions",
    "text": "20.3 3.3 Assumptions\nThe causal identification assumptions must be stated and scrutinized before the analysis begins. These are the claims that no statistical method can verify from data alone.\n\n\n\n\n\n\nCausal Assumptions — State Them Clearly, Question Them Honestly\n\n\n\nEvery causal estimate rests on untestable assumptions. In a clean-room analysis, these are locked into the protocol and cannot be revised after seeing results. Be explicit about where each assumption could fail:\n\nConsistency: Initiation of a new NSAID (or opioid) prescription, irrespective of specific agent within class. This assumes that within-class variation in drug choice does not meaningfully affect AKI risk.\nExchangeability: Conditional on \\(W\\), treatment choice is independent of potential outcomes. This is the most fragile assumption. Unmeasured confounders — OTC NSAID use, frailty, kidney function trajectory — could violate it. The E-value sensitivity analysis (Section 8) quantifies how strong such confounding would need to be.\nPositivity: Both drugs are plausible options for all covariate strata. Severe CKD patients are rarely prescribed NSAIDs, which could lead to near-violations. The propensity score overlap diagnostics will flag this.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span>"
    ]
  },
  {
    "objectID": "03-08-tmle-clean-room.html#pre-specified-analysis-plan",
    "href": "03-08-tmle-clean-room.html#pre-specified-analysis-plan",
    "title": "16  Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology",
    "section": "20.4 3.4 Pre-Specified Analysis Plan",
    "text": "20.4 3.4 Pre-Specified Analysis Plan\nThe SAP is the contract between the analyst and the regulator. Once signed, every element below is locked.\n\n\n\n\n\n\nStatistical Analysis Plan — Locked Before Data Access\n\n\n\nThe following specifications are frozen in the SAP. No modifications are permitted after data access.\n\nPrimary estimator: TMLE with Super Learner\nSuper Learner library:\n\nSL.glm (logistic regression)\nSL.glm.interaction (logistic with all two-way interactions)\nSL.step (stepwise regression)\nSL.mean (intercept-only, for benchmarking)\n\nNumber of cross-validation folds: 5\nPropensity score bounds: Truncate at [0.025, 0.975]\nSecondary estimators: G-computation, IPTW (for comparison)\nPre-specified diagnostics: PS overlap, weight distribution, covariate balance (SMD &lt; 0.1 threshold), EIC mean check\nSensitivity analyses: E-value for unmeasured confounding\nSeed: 20260101 (locked in SAP)\n\nWhy does each element matter? The learner library determines what models the algorithm can consider. The CV folds control the bias-variance trade-off in model selection. The PS bounds prevent extreme weights. The diagnostics confirm that the estimation procedure is operating in a regime where we trust it. And the seed ensures anyone can reproduce the exact numerical result.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span>"
    ]
  },
  {
    "objectID": "03-08-tmle-clean-room.html#step-1-propensity-score-estimation",
    "href": "03-08-tmle-clean-room.html#step-1-propensity-score-estimation",
    "title": "16  Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology",
    "section": "22.1 5.1 Step 1: Propensity Score Estimation",
    "text": "22.1 5.1 Step 1: Propensity Score Estimation\nBefore we can estimate the treatment effect, we need to model the treatment assignment mechanism. The propensity score answers the question: given a patient’s baseline characteristics, how likely were they to receive NSAIDs rather than opioids?\n\n\n\n\n\n\nStep 1: Estimate the Propensity Score\n\n\n\nThe propensity score \\(g(W) = P(A = 1 \\mid W)\\) estimates each patient’s probability of receiving NSAIDs given their baseline covariates. We need this for two reasons:\n\nIt allows us to construct the clever covariate that targets the TMLE update toward the causal parameter of interest.\nIt helps us assess positivity — whether both treatments are plausible for all patients.\n\nThe model formula and truncation bounds were locked in the SAP before data access. Truncation at [0.025, 0.975] prevents extreme inverse-probability weights from individual observations dominating the estimate.\n\n\n\n# ============================================================\n# PRE-SPECIFIED: Propensity score model\n# SAP Section 4.2: Use logistic regression with all baseline\n# covariates, squared age term, and CKD indicators\n# ============================================================\n\ncovariates &lt;- c(\"age\", \"male\", \"ckd\", \"diabetes\", \"hypertension\",\n                \"prior_nsaid\", \"prior_opioid\", \"ace_arb\", \"n_rx\", \"n_visits\")\n\n# Convert CKD to factor for proper modeling\ndat &lt;- dat %&gt;%\n  mutate(ckd_f = factor(ckd))\n\ng_formula &lt;- A ~ age + I(age^2) + male + ckd_f + diabetes + hypertension +\n  prior_nsaid + prior_opioid + ace_arb + n_rx + n_visits +\n  prior_nsaid:ckd_f + ace_arb:diabetes\n\ng_mod &lt;- glm(g_formula, family = binomial, data = dat)\n\ndat$ps &lt;- predict(g_mod, type = \"response\")\n\n# PRE-SPECIFIED: Truncate at [0.025, 0.975]\ndat$ps_trunc &lt;- pmax(0.025, pmin(0.975, dat$ps))",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span>"
    ]
  },
  {
    "objectID": "03-08-tmle-clean-room.html#step-2-pre-specified-diagnostics-covariate-balance",
    "href": "03-08-tmle-clean-room.html#step-2-pre-specified-diagnostics-covariate-balance",
    "title": "16  Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology",
    "section": "22.2 5.2 Step 2: Pre-Specified Diagnostics (Covariate Balance)",
    "text": "22.2 5.2 Step 2: Pre-Specified Diagnostics (Covariate Balance)\nThese diagnostics are run before looking at the effect estimate, to confirm that the propensity score model is adequate. Think of this as a quality gate: if the diagnostics fail, we know the estimation is unreliable regardless of what number comes out.\n\n22.2.1 Propensity score overlap\nThe overlap plot is the most important single diagnostic. If the two treatment groups have propensity score distributions that do not overlap, we are trying to compare patients who are fundamentally different — and no statistical method can rescue that.\n\n\n\n\n\n\nWhat to Look For: Propensity Score Overlap\n\n\n\nA healthy overlap plot shows two distributions that cover a similar range, with substantial overlap in the middle. Warning signs include:\n\nSeparation: If the two curves barely overlap, positivity is violated and the estimate will rely heavily on extrapolation.\nSpikes near 0 or 1: Patients with propensity scores near the boundaries contribute extreme weights. The truncation at [0.025, 0.975] mitigates this, but if many patients are truncated, the effective estimand changes.\nAsymmetry: If one group is concentrated in a narrow range while the other is spread out, consider whether the target population needs to be restricted.\n\n\n\n\n# ============================================================\n# DIAGNOSTIC 1: Propensity score overlap\n# SAP Section 5.1\n# ============================================================\n\nggplot(dat, aes(x = ps, fill = factor(A, labels = c(\"Opioid\", \"NSAID\")))) +\n  geom_density(alpha = 0.45) +\n  labs(\n    x = \"Estimated propensity score P(NSAID | W)\",\n    y = \"Density\",\n    fill = \"Treatment\",\n    title = \"Diagnostic 1: Propensity Score Overlap\"\n  ) +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"#4477AA\", \"#EE6677\"))\n\n\n\n\n\n\n\n\n\n# Quantile summary\ndat %&gt;%\n  group_by(Treatment = factor(A, labels = c(\"Opioid\", \"NSAID\"))) %&gt;%\n  summarise(\n    min  = round(min(ps), 3),\n    p5   = round(quantile(ps, 0.05), 3),\n    p25  = round(quantile(ps, 0.25), 3),\n    median = round(median(ps), 3),\n    p75  = round(quantile(ps, 0.75), 3),\n    p95  = round(quantile(ps, 0.95), 3),\n    max  = round(max(ps), 3),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 2 × 8\n#&gt;   Treatment   min    p5   p25 median   p75   p95   max\n#&gt;   &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Opioid    0.075 0.202 0.328  0.447 0.561 0.733 0.841\n#&gt; 2 NSAID     0.077 0.287 0.459  0.564 0.667 0.801 0.841\n\n\n\n22.2.2 Covariate balance: Standardized Mean Differences\n\n\n\n\n\n\nWhat to Look For: Covariate Balance\n\n\n\nStandardized Mean Differences (SMDs) measure how different the treatment groups are on each covariate. The SAP pre-specifies a threshold of SMD &lt; 0.1 for adequate balance.\n\nUnadjusted SMDs show the raw imbalance in the data. Large values confirm confounding is present.\nWeighted SMDs show the imbalance after IPTW adjustment. If all weighted SMDs fall below 0.1, the propensity score model has successfully balanced the groups on observed covariates.\nThe Love plot visualizes this comparison. Look for all weighted points (green) to fall left of the dashed 0.1 threshold line.\n\nIf weighted SMDs remain above 0.1 for important confounders, the propensity score model needs refinement — but in a clean-room analysis, this would have been caught in the simulation phase and the model adjusted before locking the code.\n\n\n\n# ============================================================\n# DIAGNOSTIC 2: Covariate balance before and after weighting\n# SAP Section 5.2: SMD threshold &lt; 0.1\n# ============================================================\n\ncompute_smd &lt;- function(data, var, trt, weights = NULL) {\n  if (is.null(weights)) weights &lt;- rep(1, nrow(data))\n  d1 &lt;- data[[var]][data[[trt]] == 1]\n  d0 &lt;- data[[var]][data[[trt]] == 0]\n  w1 &lt;- weights[data[[trt]] == 1]\n  w0 &lt;- weights[data[[trt]] == 0]\n  m1 &lt;- weighted.mean(d1, w1)\n  m0 &lt;- weighted.mean(d0, w0)\n  s1 &lt;- sqrt(sum(w1 * (d1 - m1)^2) / sum(w1))\n  s0 &lt;- sqrt(sum(w0 * (d0 - m0)^2) / sum(w0))\n  pooled_sd &lt;- sqrt((s1^2 + s0^2) / 2)\n  if (pooled_sd == 0) return(0)\n  (m1 - m0) / pooled_sd\n}\n\n# Stabilized IPTW weights for balance assessment\np_A &lt;- mean(dat$A)\ndat$sw &lt;- ifelse(dat$A == 1,\n                 p_A / dat$ps_trunc,\n                 (1 - p_A) / (1 - dat$ps_trunc))\n\nbalance_vars &lt;- c(\"age\", \"male\", \"ckd\", \"diabetes\", \"hypertension\",\n                  \"prior_nsaid\", \"prior_opioid\", \"ace_arb\", \"n_rx\", \"n_visits\")\n\nsmd_raw &lt;- sapply(balance_vars, function(v) compute_smd(dat, v, \"A\"))\nsmd_wt  &lt;- sapply(balance_vars, function(v) compute_smd(dat, v, \"A\", dat$sw))\n\nbalance_df &lt;- tibble(\n  Covariate  = balance_vars,\n  Unadjusted = round(abs(smd_raw), 3),\n  Weighted   = round(abs(smd_wt), 3)\n)\n\nbalance_df\n#&gt; # A tibble: 10 × 3\n#&gt;    Covariate    Unadjusted Weighted\n#&gt;    &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 age               0.363    0.005\n#&gt;  2 male              0.086    0.005\n#&gt;  3 ckd               0.344    0.004\n#&gt;  4 diabetes          0.204    0.001\n#&gt;  5 hypertension      0.162    0.003\n#&gt;  6 prior_nsaid       0.373    0.008\n#&gt;  7 prior_opioid      0.076    0.009\n#&gt;  8 ace_arb           0.165    0.005\n#&gt;  9 n_rx              0.283    0.009\n#&gt; 10 n_visits          0.225    0.005\n\n\n# Love plot\nbalance_long &lt;- balance_df %&gt;%\n  pivot_longer(-Covariate, names_to = \"Method\", values_to = \"SMD\")\n\nggplot(balance_long, aes(x = SMD, y = reorder(Covariate, SMD),\n                         color = Method, shape = Method)) +\n  geom_point(size = 3) +\n  geom_vline(xintercept = 0.1, linetype = \"dashed\", color = \"grey50\") +\n  labs(\n    x = \"Absolute Standardized Mean Difference\",\n    y = \"\",\n    title = \"Diagnostic 2: Covariate Balance (Love Plot)\",\n    subtitle = \"Dashed line = 0.1 threshold from SAP\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"#EE6677\", \"#228833\"))\n\n\n\n\n\n\n\n\n\n\n22.2.3 Weight distribution\n\n# ============================================================\n# DIAGNOSTIC 3: Weight distribution\n# SAP Section 5.3\n# ============================================================\n\nggplot(dat, aes(x = sw, fill = factor(A, labels = c(\"Opioid\", \"NSAID\")))) +\n  geom_histogram(bins = 50, alpha = 0.6, position = \"identity\") +\n  labs(\n    x = \"Stabilized IPTW weight\",\n    y = \"Count\",\n    fill = \"Treatment\",\n    title = \"Diagnostic 3: Weight Distribution\"\n  ) +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"#4477AA\", \"#EE6677\")) +\n  geom_vline(xintercept = 1, linetype = \"dashed\", color = \"grey40\")\n\n\n\n\n\n\n\n\ncat(\"Weight summary:\\n\")\n#&gt; Weight summary:\nsummary(dat$sw)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;  0.5361  0.7450  0.8946  1.0013  1.1163  6.5225\ncat(\"Fraction &gt; 5:\", round(mean(dat$sw &gt; 5), 4), \"\\n\")\n#&gt; Fraction &gt; 5: 4e-04\ncat(\"Fraction &gt; 10:\", round(mean(dat$sw &gt; 10), 4), \"\\n\")\n#&gt; Fraction &gt; 10: 0",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span>"
    ]
  },
  {
    "objectID": "03-08-tmle-clean-room.html#step-3-primary-estimator-tmle-by-hand",
    "href": "03-08-tmle-clean-room.html#step-3-primary-estimator-tmle-by-hand",
    "title": "16  Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology",
    "section": "22.3 5.3 Step 3: Primary Estimator — TMLE (by hand)",
    "text": "22.3 5.3 Step 3: Primary Estimator — TMLE (by hand)\nWith diagnostics confirming adequate overlap and balance, we proceed to estimation. TMLE is a multi-step algorithm. We walk through each step with a plain-language explanation, then the code. If you have read the KH Stats TMLE tutorial, you will recognize the same logic here — just applied in a clean-room regulatory context.\n\n\n\n\n\n\nStep 3a: Fit the Initial Outcome Model (Q)\n\n\n\nFirst, we build a model to predict the outcome (AKI) from treatment and covariates. This is called the “initial Q” — think of it as our first rough guess at each patient’s risk under each treatment scenario.\nWe fit one model and then generate three sets of predictions:\n\nQ1: predicted risk if the patient had received NSAIDs (set A = 1 for everyone)\nQ0: predicted risk if the patient had received opioids (set A = 0 for everyone)\nQA: predicted risk under the treatment they actually received\n\nThese predictions are “initial” because TMLE will update them in the targeting step to reduce bias for the specific causal parameter we care about.\n\n\n\n# ============================================================\n# PRIMARY ANALYSIS: TMLE\n# SAP Section 6.1\n# ============================================================\n\nlogit &lt;- function(p) log(p / (1 - p))\n\n# --- Step 3a: Initial outcome model ---\n# Pre-specified model form from SAP\nq_formula &lt;- Y ~ A + age + I(age^2) + male + ckd_f + diabetes + hypertension +\n  prior_nsaid + prior_opioid + ace_arb + n_rx + n_visits +\n  A:ckd_f + A:ace_arb + A:diabetes\n\nq_mod &lt;- glm(q_formula, family = binomial, data = dat)\n\n# Initial predictions\nQ1_init &lt;- predict(q_mod, newdata = dat %&gt;% mutate(A = 1), type = \"response\")\nQ0_init &lt;- predict(q_mod, newdata = dat %&gt;% mutate(A = 0), type = \"response\")\nQA_init &lt;- predict(q_mod, type = \"response\")\n\ncat(\"Initial outcome model fitted.\\n\")\n#&gt; Initial outcome model fitted.\ncat(\"Q1 range:\", round(range(Q1_init), 4), \"\\n\")\n#&gt; Q1 range: 0.0084 0.7659\ncat(\"Q0 range:\", round(range(Q0_init), 4), \"\\n\")\n#&gt; Q0 range: 0.0045 0.5594\n\n\n\n\n\n\n\nStep 3b: Compute the Clever Covariate\n\n\n\nThe clever covariate bridges the outcome model and the treatment model. It tells the fluctuation step where to adjust the initial predictions and by how much.\nFor the ATE, the clever covariate for each observation is:\n\\[H(A, W) = \\frac{A}{g(W)} - \\frac{1-A}{1-g(W)}\\]\nFor treated patients (A = 1), this simplifies to \\(1/g(W)\\) — the inverse of their probability of being treated. For controls (A = 0), it is \\(-1/(1 - g(W))\\). Patients who received an unlikely treatment get a larger clever covariate, meaning the targeting step will adjust their predictions more. This is the mechanism through which TMLE “borrows strength” from the propensity score to correct the outcome model.\n\n\n\n# --- Step 3b: Clever covariate ---\nH_A &lt;- dat$A / dat$ps_trunc - (1 - dat$A) / (1 - dat$ps_trunc)\nH_1 &lt;- 1 / dat$ps_trunc\nH_0 &lt;- -1 / (1 - dat$ps_trunc)\n\ncat(\"Clever covariate range:\", round(range(H_A), 2), \"\\n\")\n#&gt; Clever covariate range: -6.28 12.93\n\n\n\n\n\n\n\nStep 3c: Fluctuation (Targeting) Step\n\n\n\nThis is the step that makes TMLE special. We fit a simple logistic regression with:\n\nOutcome: the observed Y\nOffset: the logit of our initial predictions (QA_init)\nCovariate: the clever covariate H(A, W)\nNo intercept (-1 in the formula)\n\nThe single coefficient from this regression, called epsilon, tells us how much and in which direction to shift our initial predictions. The offset locks in the initial predictions; epsilon only adjusts them in the direction that reduces bias for the ATE specifically.\nThis is the “targeting” in Targeted Maximum Likelihood — the initial model is updated to be optimal for our specific estimand, not just for prediction in general.\n\n\n\n# --- Step 3c: Fluctuation (targeting) model ---\nfluc &lt;- glm(dat$Y ~ -1 + offset(logit(QA_init)) + H_A,\n            family = binomial)\nepsilon &lt;- coef(fluc)\n\ncat(\"Epsilon (fluctuation parameter):\", round(epsilon, 5), \"\\n\")\n#&gt; Epsilon (fluctuation parameter): -0.00741\n\n\n\n\n\n\n\nStep 3d-e: Update Predictions and Compute the Final TMLE Estimate\n\n\n\nNow we apply the epsilon update to get our final, targeted predictions:\n\nShift Q1_init and Q0_init on the logit scale by epsilon times their respective clever covariates\nTransform back to the probability scale using the inverse-logit (plogis)\nAverage the updated predictions across all patients to get the counterfactual risks\nTake the difference to get the ATE\n\nThe resulting estimate, \\(\\hat{\\psi}_{TMLE}\\), is doubly robust: it is consistent if either the outcome model or the propensity score model is correctly specified. It also solves the efficient influence curve estimating equation, which means it achieves the smallest possible variance among regular asymptotically linear estimators.\n\n\n\n# --- Step 3d: Updated predictions ---\nQ1_star &lt;- plogis(logit(Q1_init) + epsilon * H_1)\nQ0_star &lt;- plogis(logit(Q0_init) + epsilon * H_0)\n\n# --- Step 3e: TMLE estimate ---\ntmle_risk1 &lt;- mean(Q1_star)\ntmle_risk0 &lt;- mean(Q0_star)\ntmle_ate   &lt;- tmle_risk1 - tmle_risk0\n\ncat(\"TMLE risk (NSAIDs): \", round(tmle_risk1, 4), \"\\n\")\n#&gt; TMLE risk (NSAIDs):  0.0912\ncat(\"TMLE risk (opioids):\", round(tmle_risk0, 4), \"\\n\")\n#&gt; TMLE risk (opioids): 0.0512\ncat(\"TMLE ATE:           \", round(tmle_ate, 4), \"\\n\")\n#&gt; TMLE ATE:            0.04\ncat(\"True ATE:           \", round(true_ate, 4), \"\\n\")\n#&gt; True ATE:            0.0334\n\n\n# --- Step 3f: Inference via efficient influence curve ---\neic &lt;- (dat$A / dat$ps_trunc) * (dat$Y - Q1_star) + Q1_star - tmle_risk1 -\n       ((1 - dat$A) / (1 - dat$ps_trunc)) * (dat$Y - Q0_star) - Q0_star + tmle_risk0\n\ntmle_se &lt;- sqrt(var(eic) / n)\ntmle_ci &lt;- tmle_ate + c(-1.96, 1.96) * tmle_se\n\ncat(\"\\n=== PRIMARY RESULT ===\\n\")\n#&gt; \n#&gt; === PRIMARY RESULT ===\ncat(\"TMLE ATE:\", round(tmle_ate, 4), \"\\n\")\n#&gt; TMLE ATE: 0.04\ncat(\"SE:      \", round(tmle_se, 4), \"\\n\")\n#&gt; SE:       0.0064\ncat(\"95% CI:  [\", round(tmle_ci[1], 4), \",\", round(tmle_ci[2], 4), \"]\\n\")\n#&gt; 95% CI:  [ 0.0275 , 0.0525 ]\ncat(\"p-value: \", round(2 * pnorm(-abs(tmle_ate / tmle_se)), 4), \"\\n\")\n#&gt; p-value:  0\n\n\n# --- Step 3g: Verify EIC mean ≈ 0 ---\ncat(\"EIC mean:\", round(mean(eic), 8), \" (should be ~0)\\n\")\n#&gt; EIC mean: 0  (should be ~0)\n\n\n\n\n\n\n\nWhy Is the EIC Mean Zero?\n\n\n\nThe efficient influence curve (EIC) for the TMLE estimate should have a mean of approximately zero. This is not a coincidence — it is a direct consequence of the targeting step.\nWhen we fit the fluctuation model with the clever covariate, the score equation of that logistic regression forces the EIC estimating equation to be solved. In other words, the targeting step guarantees that the mean of the EIC is (numerically) zero.\nWhy this matters for clean-room analysis: The EIC mean is a built-in diagnostic. If it deviates meaningfully from zero, something went wrong in the implementation — perhaps a coding error, numerical overflow in the logit transformation, or a problem with the propensity score truncation. In a locked analysis where you cannot inspect intermediate results, having an automatic self-check is invaluable.\nWhat “approximately zero” means in practice: Machine precision means you will see values like 1e-15 to 1e-8. Values larger than 1e-4 warrant investigation. Values larger than 1e-2 indicate a serious problem.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span>"
    ]
  },
  {
    "objectID": "03-08-tmle-clean-room.html#step-4-secondary-estimators-for-comparison",
    "href": "03-08-tmle-clean-room.html#step-4-secondary-estimators-for-comparison",
    "title": "16  Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology",
    "section": "22.4 5.4 Step 4: Secondary Estimators (for comparison)",
    "text": "22.4 5.4 Step 4: Secondary Estimators (for comparison)\nThe SAP pre-specifies secondary estimators so that the primary TMLE result can be compared for consistency. If all three estimators agree, this strengthens confidence in the result. If they disagree, the TMLE estimate is preferred due to its double robustness, but the discrepancy is documented.\n\n22.4.1 G-computation\n\n# ============================================================\n# SECONDARY ANALYSIS 1: G-computation\n# SAP Section 6.2\n# ============================================================\n\ngcomp_risk1 &lt;- mean(Q1_init)\ngcomp_risk0 &lt;- mean(Q0_init)\ngcomp_ate   &lt;- gcomp_risk1 - gcomp_risk0\n\ncat(\"G-computation ATE:\", round(gcomp_ate, 4), \"\\n\")\n#&gt; G-computation ATE: 0.0423\n\n\n\n22.4.2 IPTW\n\n# ============================================================\n# SECONDARY ANALYSIS 2: IPTW with stabilized weights\n# SAP Section 6.3\n# ============================================================\n\nrisk1_iptw &lt;- with(dat, sum(sw * Y * (A == 1)) / sum(sw * (A == 1)))\nrisk0_iptw &lt;- with(dat, sum(sw * Y * (A == 0)) / sum(sw * (A == 0)))\niptw_ate   &lt;- risk1_iptw - risk0_iptw\n\ncat(\"IPTW ATE:\", round(iptw_ate, 4), \"\\n\")\n#&gt; IPTW ATE: 0.0408\n\n\n\n22.4.3 Comparison table\n\n# ============================================================\n# RESULTS COMPARISON TABLE\n# SAP Section 7\n# ============================================================\n\nresults &lt;- tibble(\n  Estimator = c(\"Unadjusted\", \"G-computation\", \"IPTW\", \"TMLE\"),\n  ATE = round(c(\n    mean(dat$Y[dat$A == 1]) - mean(dat$Y[dat$A == 0]),\n    gcomp_ate,\n    iptw_ate,\n    tmle_ate\n  ), 4),\n  SE = round(c(NA, NA, NA, tmle_se), 4),\n  CI_lower = round(c(NA, NA, NA, tmle_ci[1]), 4),\n  CI_upper = round(c(NA, NA, NA, tmle_ci[2]), 4)\n)\n\nresults\n#&gt; # A tibble: 4 × 5\n#&gt;   Estimator        ATE      SE CI_lower CI_upper\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 Unadjusted    0.0041 NA       NA       NA     \n#&gt; 2 G-computation 0.0423 NA       NA       NA     \n#&gt; 3 IPTW          0.0408 NA       NA       NA     \n#&gt; 4 TMLE          0.04    0.0064   0.0275   0.0525",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span>"
    ]
  },
  {
    "objectID": "03-08-tmle-clean-room.html#step-5-post-estimation-diagnostics",
    "href": "03-08-tmle-clean-room.html#step-5-post-estimation-diagnostics",
    "title": "16  Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology",
    "section": "22.5 5.5 Step 5: Post-Estimation Diagnostics",
    "text": "22.5 5.5 Step 5: Post-Estimation Diagnostics\n\n22.5.1 Clever covariate distribution\n\n# ============================================================\n# DIAGNOSTIC 4: Clever covariate ranges\n# SAP Section 5.4\n# ============================================================\n\ncc_df &lt;- tibble(\n  H = H_A,\n  Treatment = factor(dat$A, labels = c(\"Opioid\", \"NSAID\"))\n)\n\nggplot(cc_df, aes(x = H, fill = Treatment)) +\n  geom_histogram(bins = 60, alpha = 0.5, position = \"identity\") +\n  labs(\n    x = \"Clever covariate H(A, W)\",\n    y = \"Count\",\n    fill = \"Treatment\",\n    title = \"Diagnostic 4: Clever Covariate Distribution\"\n  ) +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"#4477AA\", \"#EE6677\"))\n\n\n\n\n\n\n\n\n\n\n22.5.2 Influence curve stability\n\n# ============================================================\n# DIAGNOSTIC 5: Influence curve distribution\n# SAP Section 5.5\n# ============================================================\n\nggplot(tibble(eic = eic), aes(x = eic)) +\n  geom_histogram(bins = 60, fill = \"#228833\", alpha = 0.7) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    x = \"Efficient influence curve value\",\n    y = \"Count\",\n    title = \"Diagnostic 5: EIC Distribution\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\ncat(\"EIC summary:\\n\")\n#&gt; EIC summary:\nsummary(eic)\n#&gt;     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n#&gt; -8.35531 -0.09618 -0.04799  0.00000  0.07999  4.88995\ncat(\"\\nTop 5 most influential observations:\\n\")\n#&gt; \n#&gt; Top 5 most influential observations:\nhead(sort(abs(eic), decreasing = TRUE), 5)\n#&gt;       37     4648     3572      501     5800 \n#&gt; 8.355309 4.889952 4.527676 4.280250 4.274389\n\n\n\n22.5.3 Predicted risk distribution\n\n# ============================================================\n# DIAGNOSTIC 6: Predicted outcome distributions\n# SAP Section 5.6\n# ============================================================\n\npred_df &lt;- tibble(\n  Q1_star = Q1_star,\n  Q0_star = Q0_star,\n  diff = Q1_star - Q0_star\n)\n\nggplot(pred_df, aes(x = diff)) +\n  geom_histogram(bins = 50, fill = \"#CC6677\", alpha = 0.7) +\n  geom_vline(xintercept = mean(pred_df$diff), linetype = \"solid\", color = \"black\") +\n  geom_vline(xintercept = true_ate, linetype = \"dashed\", color = \"red\") +\n  labs(\n    x = \"Individual-level risk difference (Q1* - Q0*)\",\n    y = \"Count\",\n    title = \"Diagnostic 6: Distribution of Individual Treatment Effects\",\n    subtitle = \"Black line = TMLE ATE; Red dashed = True ATE\"\n  ) +\n  theme_minimal()",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span>"
    ]
  },
  {
    "objectID": "03-08-tmle-clean-room.html#results-summary",
    "href": "03-08-tmle-clean-room.html#results-summary",
    "title": "16  Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology",
    "section": "26.1 Results summary",
    "text": "26.1 Results summary\n\ncat(\"=== REGULATORY SUMMARY ===\\n\\n\")\n#&gt; === REGULATORY SUMMARY ===\ncat(\"Study: Post-marketing safety analysis of NSAIDs vs opioids for AKI risk\\n\")\n#&gt; Study: Post-marketing safety analysis of NSAIDs vs opioids for AKI risk\ncat(\"Design: Active comparator, new user, cohort study\\n\")\n#&gt; Design: Active comparator, new user, cohort study\ncat(\"Method: Pre-specified TMLE with parametric nuisance models\\n\\n\")\n#&gt; Method: Pre-specified TMLE with parametric nuisance models\ncat(\"Primary endpoint: 90-day acute kidney injury\\n\")\n#&gt; Primary endpoint: 90-day acute kidney injury\ncat(\"NSAIDs (n =\", sum(dat$A == 1), \"): estimated 90-day AKI risk =\",\n    round(tmle_risk1 * 100, 2), \"%\\n\")\n#&gt; NSAIDs (n = 4035 ): estimated 90-day AKI risk = 9.12 %\ncat(\"Opioids (n =\", sum(dat$A == 0), \"): estimated 90-day AKI risk =\",\n    round(tmle_risk0 * 100, 2), \"%\\n\")\n#&gt; Opioids (n = 3965 ): estimated 90-day AKI risk = 5.12 %\ncat(\"Risk difference:\", round(tmle_ate * 100, 2), \"percentage points\\n\")\n#&gt; Risk difference: 4 percentage points\ncat(\"95% CI:\", round(tmle_ci[1] * 100, 2), \"to\", round(tmle_ci[2] * 100, 2),\n    \"percentage points\\n\\n\")\n#&gt; 95% CI: 2.75 to 5.25 percentage points\n\nif (tmle_ci[1] &gt; 0) {\n  cat(\"Conclusion: Statistically significant increase in AKI risk with NSAIDs.\\n\")\n  cat(\"The results support updating prescribing guidelines to include AKI risk\\n\")\n  cat(\"assessment, particularly for patients with pre-existing CKD.\\n\")\n} else if (tmle_ci[2] &lt; 0) {\n  cat(\"Conclusion: Statistically significant decrease in AKI risk with NSAIDs.\\n\")\n} else {\n  cat(\"Conclusion: The risk difference is not statistically significant.\\n\")\n  cat(\"Continued monitoring is recommended.\\n\")\n}\n#&gt; Conclusion: Statistically significant increase in AKI risk with NSAIDs.\n#&gt; The results support updating prescribing guidelines to include AKI risk\n#&gt; assessment, particularly for patients with pre-existing CKD.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span>"
    ]
  },
  {
    "objectID": "03-08-tmle-clean-room.html#how-tmle-supports-the-regulatory-decision",
    "href": "03-08-tmle-clean-room.html#how-tmle-supports-the-regulatory-decision",
    "title": "16  Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology",
    "section": "26.2 How TMLE supports the regulatory decision",
    "text": "26.2 How TMLE supports the regulatory decision\n\n\n\n\n\n\n\nRegulatory concern\nHow TMLE addresses it\n\n\n\n\nPre-specification required\nSAP locks the learner library, seed, and analysis code\n\n\nMust be reproducible\nDeterministic given data + seed + code\n\n\nModel selection bias\nSuper Learner eliminates manual model selection\n\n\nRobustness to misspecification\nDouble robustness protects against either nuisance model being wrong\n\n\nValid inference\nInfluence-curve standard errors do not require bootstrap\n\n\nAuditable\nCross-validated learner weights, diagnostics, and the fluctuation parameter are all logged\n\n\nTransparent\nEvery step (initial model, clever covariate, targeting, inference) has a clear purpose",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span>"
    ]
  },
  {
    "objectID": "03-08-tmle-clean-room.html#what-assumptions-are-most-fragile",
    "href": "03-08-tmle-clean-room.html#what-assumptions-are-most-fragile",
    "title": "16  Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology",
    "section": "26.3 What assumptions are most fragile?",
    "text": "26.3 What assumptions are most fragile?\n\nUnmeasured confounding: OTC NSAID use is not captured in claims data. Frailty and functional status are poorly measured. The E-value provides a benchmark for how strong this confounding would need to be.\nPositivity in CKD subgroups: Patients with severe CKD are rarely prescribed NSAIDs. The propensity score overlap diagnostic should flag this. If violated, consider restricting to the subpopulation with adequate overlap or using stochastic interventions.\nOutcome misclassification: AKI may be under-coded in claims data. This affects interpretation but not the validity of the TMLE procedure.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span>"
    ]
  },
  {
    "objectID": "03-08-tmle-clean-room.html#sources-and-further-reading",
    "href": "03-08-tmle-clean-room.html#sources-and-further-reading",
    "title": "16  Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology",
    "section": "28.1 Sources and further reading",
    "text": "28.1 Sources and further reading\n\nvan der Laan MJ, Gruber S (2016). One-step targeted minimum loss-based estimation based on universal least favorable one-dimensional submodels. Int J Biostat 12(1):351-378.\nDang LE, Tager I, Petersen ML (2023). A causal roadmap for generating high-quality real-world evidence. J Clin Transl Sci 7(1):e127.\nGruber S, van der Laan MJ (2010). A targeted maximum likelihood estimator of a causal effect on a bounded continuous outcome. Int J Biostat 6(1):Article 26.\nWilliamson BD, Coyle J, Hejazi NS, van der Laan MJ (2023). Collaborative targeted learning. Biostatistics 24(1):135-155.\nFDA Sentinel Initiative. Best Practices for Signal Refinement. sentinelinitiative.org\nvan der Laan MJ, Rose S (2018). Targeted Learning in Data Science. Springer.\ntmle R package: CRAN\nSuperLearner R package: CRAN",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span>"
    ]
  },
  {
    "objectID": "03-08-tmle-clean-room.html#software-implementation-r",
    "href": "03-08-tmle-clean-room.html#software-implementation-r",
    "title": "16  Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology",
    "section": "28.2 Software Implementation (R)",
    "text": "28.2 Software Implementation (R)\nThis clean-room analysis script demonstrates a fully prespecified TMLE workflow: every modeling choice is locked before running, a fixed seed and library are declared, and the analysis is self-documenting. This is the discipline advocated in this chapter.\n\nAll choices documented before execution: estimand, learner library, positivity bounds\nUses a fixed Super Learner library (no data-peeking)\nCaptures sessionInfo() for full reproducibility\nSingle tmle() call with prespecified parameters\n\n\n## ═══════════════════════════════════════════════════════\n## CLEAN-ROOM TMLE ANALYSIS SCRIPT\n## Prespecified analysis — no data-adaptive choices below\n## ═══════════════════════════════════════════════════════\n\n## ── 0. Lock random seed and declare estimand ──\nset.seed(1)\nESTIMAND   &lt;- \"ATE (risk difference)\"\nPOPULATION &lt;- \"Adults with simulated cardiovascular risk factors\"\nTREATMENT  &lt;- \"Drug A vs Drug B\"\n\n## ── 1. Prespecified learner libraries ──\nQ_LIBRARY  &lt;- c(\"SL.glm\")   # outcome model\nG_LIBRARY  &lt;- c(\"SL.glm\")   # treatment model\nG_BOUNDS   &lt;- c(0.025, 0.975)  # positivity truncation\n\n## ── 2. Simulate data (replace with real data read) ──\nn &lt;- 600\nW1 &lt;- rnorm(n)\nW2 &lt;- rbinom(n, 1, 0.35)\nW3 &lt;- rnorm(n, mean = 0.3 * W1)\nA  &lt;- rbinom(n, 1, plogis(-0.2 + 0.5 * W1 + 0.4 * W2))\nY  &lt;- rbinom(n, 1, plogis(-1.5 + 0.5 * A + 0.6 * W1 + 0.7 * W2 + 0.2 * W3))\n\nW &lt;- data.frame(W1 = W1, W2 = W2, W3 = W3)\n\n## ── 3. Run prespecified analysis ──\nif (requireNamespace(\"tmle\", quietly = TRUE)) {\n  library(tmle)\n\n  fit &lt;- tmle(\n    Y = Y, A = A, W = W,\n    family = \"binomial\",\n    Q.SL.library = Q_LIBRARY,\n    g.SL.library = G_LIBRARY,\n    gbound = G_BOUNDS[1]\n  )\n\n  ## ── 4. Report results ──\n  cat(\"══════════════════════════════════════\\n\")\n  cat(\"CLEAN-ROOM TMLE RESULTS\\n\")\n  cat(\"══════════════════════════════════════\\n\")\n  cat(\"Estimand:\", ESTIMAND, \"\\n\")\n  cat(\"Population:\", POPULATION, \"\\n\")\n  cat(\"Treatment:\", TREATMENT, \"\\n\")\n  cat(\"──────────────────────────────────────\\n\")\n  cat(\"ATE:    \", round(fit$estimates$ATE$psi, 4), \"\\n\")\n  cat(\"95% CI:\", round(fit$estimates$ATE$CI, 4), \"\\n\")\n  cat(\"p-value:\", format.pval(fit$estimates$ATE$pvalue, digits = 3), \"\\n\")\n  cat(\"──────────────────────────────────────\\n\")\n  cat(\"Q library:\", paste(Q_LIBRARY, collapse = \", \"), \"\\n\")\n  cat(\"g library:\", paste(G_LIBRARY, collapse = \", \"), \"\\n\")\n  cat(\"g-bounds: [\", G_BOUNDS[1], \",\", G_BOUNDS[2], \"]\\n\")\n  cat(\"══════════════════════════════════════\\n\")\n\n  ## EIC diagnostic\n  cat(\"EIC mean:\", round(mean(fit$estimates$ATE$IC), 6), \"\\n\")\n} else {\n  message(\"Install the 'tmle' package:  install.packages('tmle')\")\n}\n\n## ── 5. Session info for reproducibility ──\ncat(\"\\n── Session info ──\\n\")\nsessionInfo()",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html",
    "href": "03-09-illustrated-ltmle.html",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "",
    "text": "18 An Illustrated Guide to Longitudinal TMLE\nHow L-TMLE removes time-dependent confounding, step by step\nThis chapter extends the pedagogical approach of Kat Hoffman’s Illustrated Guide to TMLE to the longitudinal setting. If you have read the KH Stats guides and understand point-treatment TMLE, you are ready for this chapter.\nWe will build up from the familiar 4-step TMLE algorithm to its longitudinal counterpart, using a simple two-time-point example so you can see exactly what changes — and why.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html#a-simple-scenario",
    "href": "03-09-illustrated-ltmle.html#a-simple-scenario",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "20.1 A simple scenario",
    "text": "20.1 A simple scenario\nConsider a patient followed over two time periods. At each period, they either take a medication (\\(A_t = 1\\)) or not (\\(A_t = 0\\)). We measure their health status (\\(L_t\\)) at each period. We observe a final outcome \\(Y\\).\nThe data for one patient looks like:\nBaseline → Treatment₁ → Health₁ → Treatment₂ → Health₂ → Outcome\n   W          A₁          L₁          A₂          L₂         Y",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html#why-is-this-harder",
    "href": "03-09-illustrated-ltmle.html#why-is-this-harder",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "20.2 Why is this harder?",
    "text": "20.2 Why is this harder?\nThe critical complication is a feedback loop:\n                    ┌──────────────────────────────┐\n                    │                              │\n                    ▼                              │\n   W ──→ A₁ ──→ L₁ ──→ A₂ ──→ Y                  │\n         │              ▲                          │\n         │              │                          │\n         └──────────────┘                          │\n         (A₁ affects L₁, which affects A₂)        │\n\n\\(L_1\\) is a confounder for the \\(A_2 \\to Y\\) relationship (it affects both \\(A_2\\) and \\(Y\\))\n\\(L_1\\) is also affected by prior treatment \\(A_1\\)\n\nThis means \\(L_1\\) is simultaneously:\n\nA confounder we need to adjust for\nA mediator on the pathway from \\(A_1\\) to \\(Y\\)\n\n\n\n\n\n\n\nThe Standard Regression Trap\n\n\n\nIf you condition on \\(L_1\\) in a regression (the standard approach), you block part of the causal effect of \\(A_1\\) that operates through \\(L_1\\). You also potentially open collider bias paths.\nIf you don’t condition on \\(L_1\\), the effect of \\(A_2\\) is confounded.\nYou cannot win with standard regression. This is the fundamental problem that g-methods (including L-TMLE) solve.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html#a-concrete-example",
    "href": "03-09-illustrated-ltmle.html#a-concrete-example",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "20.3 A concrete example",
    "text": "20.3 A concrete example\nImagine studying whether continuous statin use prevents heart attack over 2 years:\n\n\\(W\\): Baseline cholesterol, age, smoking\n\\(A_1\\): Statin use in year 1\n\\(L_1\\): Cholesterol level at end of year 1 (affected by whether they took statins)\n\\(A_2\\): Statin use in year 2 (depends on their year-1 cholesterol)\n\\(Y\\): Heart attack by end of year 2\n\nA doctor is more likely to prescribe statins in year 2 if year-1 cholesterol is high (\\(L_1\\) affects \\(A_2\\)). But high cholesterol also directly increases heart attack risk (\\(L_1\\) affects \\(Y\\)). And year-1 statin use lowers year-1 cholesterol (\\(A_1\\) affects \\(L_1\\)).\nConditioning on year-1 cholesterol in a regression blocks the indirect effect of year-1 statin use. Not conditioning on it leaves the year-2 effect confounded. L-TMLE resolves this by working backwards through time.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html#the-g-computation-formula-for-longitudinal-data",
    "href": "03-09-illustrated-ltmle.html#the-g-computation-formula-for-longitudinal-data",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "21.1 The G-computation formula for longitudinal data",
    "text": "21.1 The G-computation formula for longitudinal data\nFor the simple two-time-point case, the causal effect of “always treat” (\\(\\bar{a} = (1, 1)\\)) is:\n\\[\nE[Y(\\bar{a})] = E_W\\bigg[ E_{L_1}\\Big[ E\\big[Y \\mid A_2 = 1, L_1, A_1 = 1, W\\big] \\;\\Big|\\; A_1 = 1, W \\Big] \\bigg]\n\\]\nReading from inside out:\n\nInner expectation: Model the outcome given the full history, then evaluate under the intervention \\(A_2 = 1\\)\nMiddle expectation: Average over \\(L_1\\) (the intermediate confounder) under the intervention \\(A_1 = 1\\)\nOuter expectation: Average over baseline covariates \\(W\\)\n\nThis is a nested sequence of conditional expectations. L-TMLE estimates each one, starting from the inside (the final outcome) and working outward (backwards in time).",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html#why-backwards",
    "href": "03-09-illustrated-ltmle.html#why-backwards",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "21.2 Why backwards?",
    "text": "21.2 Why backwards?\n\n\n\n\n\n\nThe Backwards Intuition\n\n\n\nThink of it like planning a road trip:\n\nForwards: “From home, where might I end up?” (requires considering all possible routes — combinatorial explosion)\nBackwards: “To reach my destination, where must I be at each prior step?” (only one path to trace back)\n\nL-TMLE starts at the destination (the final outcome \\(Y\\)) and asks: given where we are at each earlier time, what outcome would we expect? Each step peels off one layer of time-varying confounding.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html#setup-simulate-data",
    "href": "03-09-illustrated-ltmle.html#setup-simulate-data",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "22.1 Setup: Simulate data",
    "text": "22.1 Setup: Simulate data\n\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'stringr' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.6.0\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nset.seed(2026)\nn &lt;- 2000\n\n# --- Baseline ---\nW &lt;- rnorm(n, mean = 0, sd = 1)   # baseline confounder\n\n# --- Time 1 ---\n# Treatment at time 1 (depends on W)\ng1_true &lt;- plogis(0.5 + 0.8 * W)\nA1 &lt;- rbinom(n, 1, g1_true)\n\n# Time-varying confounder (affected by A1 and W)\nL1 &lt;- rnorm(n, mean = 0.5 * W + 0.7 * A1, sd = 1)\n\n# --- Time 2 ---\n# Treatment at time 2 (depends on L1 and A1)\ng2_true &lt;- plogis(-0.3 + 0.6 * L1 + 0.4 * A1)\nA2 &lt;- rbinom(n, 1, g2_true)\n\n# --- Outcome ---\n# Y depends on full history\nY &lt;- rbinom(n, 1, plogis(-2 + 0.5 * A1 + 0.6 * A2 + 0.3 * L1 +\n                           0.4 * W + 0.2 * A1 * A2))\n\ndat &lt;- tibble(W, A1, L1, A2, Y)\n\ncat(\"Observed data:\\n\")\n\nObserved data:\n\nhead(dat)\n\n# A tibble: 6 × 5\n        W    A1      L1    A2     Y\n    &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n1  0.521      1  0.0322     0     0\n2 -1.08       0 -0.301      0     0\n3  0.139      1  2.54       1     1\n4 -0.0847     1  0.337      1     0\n5 -0.667      1  0.422      0     1\n6 -2.52       0 -0.316      1     0\n\n\n\n22.1.1 True effect of “always treat”\n\n# Simulate the true counterfactual under (A1=1, A2=1)\nset.seed(2026)\nW_cf &lt;- W  # same baseline\n\n# Under A1 = 1\nL1_cf &lt;- rnorm(n, mean = 0.5 * W_cf + 0.7 * 1, sd = 1)\n\n# Under A2 = 1\nY_cf_11 &lt;- plogis(-2 + 0.5 * 1 + 0.6 * 1 + 0.3 * L1_cf +\n                     0.4 * W_cf + 0.2 * 1 * 1)\n\n# Under (A1=0, A2=0)\nL1_cf_00 &lt;- rnorm(n, mean = 0.5 * W_cf + 0.7 * 0, sd = 1)\nY_cf_00 &lt;- plogis(-2 + 0.5 * 0 + 0.6 * 0 + 0.3 * L1_cf_00 +\n                     0.4 * W_cf + 0.2 * 0 * 0)\n\ntrue_EY_11 &lt;- mean(Y_cf_11)\ntrue_EY_00 &lt;- mean(Y_cf_00)\ntrue_ATE &lt;- true_EY_11 - true_EY_00\n\ncat(\"True E[Y(1,1)]:\", round(true_EY_11, 4), \"\\n\")\n\nTrue E[Y(1,1)]: 0.3945 \n\ncat(\"True E[Y(0,0)]:\", round(true_EY_00, 4), \"\\n\")\n\nTrue E[Y(0,0)]: 0.1328 \n\ncat(\"True ATE:       \", round(true_ATE, 4), \"\\n\")\n\nTrue ATE:        0.2617 \n\n\n\nNow we estimate \\(E[Y(1,1)]\\) — the expected outcome if everyone always received treatment — using L-TMLE.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html#phase-a-estimate-the-treatment-mechanisms-the-gs",
    "href": "03-09-illustrated-ltmle.html#phase-a-estimate-the-treatment-mechanisms-the-gs",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "22.2 Phase A: Estimate the Treatment Mechanisms (the g’s)",
    "text": "22.2 Phase A: Estimate the Treatment Mechanisms (the g’s)\n\n\n\n\n\n\nL-TMLE Step 1: Estimate Treatment at EACH Time Point\n\n\n\nIn point-treatment TMLE, we estimated one propensity score \\(g(W)\\). In L-TMLE, we estimate a treatment mechanism at every time point, conditional on the history up to that point.\nTime 1: \\[\\hat{g}_1(W) = \\hat{P}(A_1 = 1 \\mid W)\\]\nTime 2: \\[\\hat{g}_2(A_1, L_1, W) = \\hat{P}(A_2 = 1 \\mid A_1, L_1, W)\\]\n\n\n\n# Fit treatment models at each time point\ng1_mod &lt;- glm(A1 ~ W, family = binomial, data = dat)\ng2_mod &lt;- glm(A2 ~ L1 + A1 + W, family = binomial, data = dat)\n\ng1_hat &lt;- predict(g1_mod, type = \"response\")\ng2_hat &lt;- predict(g2_mod, type = \"response\")\n\n# Bound away from 0 and 1\ng1_hat &lt;- pmax(0.01, pmin(0.99, g1_hat))\ng2_hat &lt;- pmax(0.01, pmin(0.99, g2_hat))\n\n\n22.2.1 The cumulative treatment probability\nFor the “always treat” regime, the probability that a patient follows the full regime is the product of time-specific probabilities:\n\\[\\hat{g}_{\\bar{1}}(W, L_1) = \\hat{g}_1(W) \\times \\hat{g}_2(A_1=1, L_1, W)\\]\n\n# Cumulative probability of following the \"always treat\" regime\n# g2 needs to be evaluated at A1=1 (the intervention value)\ng2_under_a1 &lt;- predict(g2_mod,\n                        newdata = dat %&gt;% mutate(A1 = 1),\n                        type = \"response\")\ng2_under_a1 &lt;- pmax(0.01, pmin(0.99, g2_under_a1))\n\ng_cumulative &lt;- g1_hat * g2_under_a1\ncat(\"Cumulative g range:\", round(range(g_cumulative), 3), \"\\n\")\n\nCumulative g range: 0.017 0.845 \n\ncat(\"Cumulative g mean: \", round(mean(g_cumulative), 3), \"\\n\")\n\nCumulative g mean:  0.36",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html#phase-b-sequential-outcome-regression-working-backwards",
    "href": "03-09-illustrated-ltmle.html#phase-b-sequential-outcome-regression-working-backwards",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "22.3 Phase B: Sequential Outcome Regression — Working Backwards",
    "text": "22.3 Phase B: Sequential Outcome Regression — Working Backwards\nThis is where L-TMLE diverges from point-treatment TMLE. Instead of one outcome model, we build a sequence of outcome regressions, starting at the final outcome and moving backwards.\n\n\n\n\n\n\nL-TMLE Step 2a: Start at the End — Model the Final Outcome\n\n\n\nJust like point-treatment TMLE, start by modeling \\(E[Y \\mid A_2, L_1, A_1, W]\\). This is the expected outcome given the complete observed history.\n\\[\\hat{Q}_2(A_2, L_1, A_1, W) = \\hat{E}[Y \\mid A_2, L_1, A_1, W]\\]\nThen predict under the intervention \\(A_2 = 1\\):\n\\[\\hat{Q}_2(1, L_1, A_1, W)\\]\n\n\n\n# Step 2a: Outcome regression at the final time point\nQ2_mod &lt;- glm(Y ~ A2 + L1 + A1 + W + A1:A2, family = binomial, data = dat)\n\n# Predict under intervention A2 = 1, keeping everything else observed\nQ2_A2is1 &lt;- predict(Q2_mod,\n                     newdata = dat %&gt;% mutate(A2 = 1),\n                     type = \"response\")\n\ncat(\"Initial Q2(A2=1) range:\", round(range(Q2_A2is1), 4), \"\\n\")\n\nInitial Q2(A2=1) range: 0.0343 0.7825 \n\n\n\n\n\n\n\n\nL-TMLE Step 2b: Move Backwards — Create a “Pseudo-Outcome”\n\n\n\nHere is the critical step that handles time-dependent confounding. We take the predictions \\(\\hat{Q}_2(1, L_1, A_1, W)\\) — which are functions of \\(L_1\\), \\(A_1\\), and \\(W\\) — and treat them as a new outcome to be modeled at time 1.\nWe fit a regression of \\(\\hat{Q}_2(1, L_1, A_1, W)\\) on \\((A_1, W)\\), averaging over \\(L_1\\) in the process:\n\\[\\hat{Q}_1(A_1, W) = \\hat{E}\\big[\\hat{Q}_2(1, L_1, A_1, W) \\;\\big|\\; A_1, W\\big]\\]\nThen predict under the intervention \\(A_1 = 1\\):\n\\[\\hat{Q}_1(1, W)\\]\n\n\n\n# Step 2b: Backwards regression — model Q2 predictions as a function of (A1, W)\n# This \"integrates out\" L1 from the estimation\n\nQ1_mod &lt;- glm(Q2_A2is1 ~ A1 + W, family = quasibinomial, data = dat)\n\n# Predict under intervention A1 = 1\nQ1_A1is1 &lt;- predict(Q1_mod,\n                     newdata = dat %&gt;% mutate(A1 = 1),\n                     type = \"response\")\n\ncat(\"Initial Q1(A1=1) range:\", round(range(Q1_A1is1), 4), \"\\n\")\n\nInitial Q1(A1=1) range: 0.1412 0.7377 \n\ncat(\"Initial G-comp estimate E[Y(1,1)]:\", round(mean(Q1_A1is1), 4), \"\\n\")\n\nInitial G-comp estimate E[Y(1,1)]: 0.3899 \n\ncat(\"True E[Y(1,1)]:                   \", round(true_EY_11, 4), \"\\n\")\n\nTrue E[Y(1,1)]:                    0.3945 \n\n\n\n\n\n\n\n\nWhat Just Happened?\n\n\n\nThis two-step backwards regression is the longitudinal G-computation formula in action:\n\nStep 2a estimated \\(E[Y \\mid A_2=1, L_1, A_1, W]\\) — what we expect the outcome to be if \\(A_2 = 1\\), for each specific value of \\(L_1\\)\nStep 2b estimated \\(E_{L_1}[E[Y \\mid A_2=1, L_1, A_1=1, W] \\mid A_1=1, W]\\) — the expected outcome under both \\(A_1=1\\) and \\(A_2=1\\), averaging over \\(L_1\\) as it would be under \\(A_1 = 1\\)\n\nBy regressing the time-2 predictions on \\((A_1, W)\\) without conditioning on \\(L_1\\), we allowed \\(L_1\\) to vary as it naturally would under the intervention \\(A_1 = 1\\). This is how the backwards regression avoids the standard regression trap — it never conditions on the time-varying confounder while simultaneously modeling it as affected by treatment.\nThis is longitudinal G-computation. But like point-treatment G-computation, it depends on both models being correctly specified. The targeting steps below make it doubly robust.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html#phase-c-targeting-making-it-doubly-robust",
    "href": "03-09-illustrated-ltmle.html#phase-c-targeting-making-it-doubly-robust",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "22.4 Phase C: Targeting — Making It Doubly Robust",
    "text": "22.4 Phase C: Targeting — Making It Doubly Robust\nNow we have initial estimates \\(\\hat{Q}_2\\) and \\(\\hat{Q}_1\\) from the sequential regressions. These estimates are optimized to predict well, but they are not yet “targeted” at our specific estimand \\(E[Y(1,1)]\\).\nThe targeting steps update these initial estimates using information from the treatment mechanism, just like in point-treatment TMLE — but now we do it at each time step, working backwards.\n\n\n\n\n\n\nL-TMLE Step 3a: Target \\(\\hat{Q}_2\\) at Time 2\n\n\n\nConstruct the clever covariate at time 2. For the “always treat” regime, among observations with \\(A_1 = 1\\) and \\(A_2 = 1\\) (those who followed the regime), this is:\n\\[H_2 = \\frac{I(A_1 = 1, A_2 = 1)}{\\hat{g}_1(W) \\times \\hat{g}_2(1, L_1, W)}\\]\nThis is the inverse of the cumulative probability of following the full treatment regime through time 2.\nFit the fluctuation model:\n\\[\\text{logit}(Y) = \\text{logit}(\\hat{Q}_2(A_2, L_1, A_1, W)) + \\epsilon_2 \\cdot H_2\\]\nUpdate: \\(\\hat{Q}_2^*(A_2, L_1, A_1, W) = \\text{expit}(\\text{logit}(\\hat{Q}_2) + \\hat{\\epsilon}_2 \\cdot H_2)\\)\n\n\n\nlogit &lt;- function(p) log(p / (1 - p))\n\n# Clever covariate at time 2\n# Only patients who followed regime at BOTH times contribute\nH2 &lt;- (dat$A1 == 1 & dat$A2 == 1) / (g1_hat * g2_hat)\n\n# Prediction from Q2 at OBSERVED (A1, A2)\nQA_init_t2 &lt;- predict(Q2_mod, type = \"response\")\n\n# Fluctuation model at time 2\nfluc2 &lt;- glm(dat$Y ~ -1 + offset(logit(QA_init_t2)) + H2,\n             family = binomial)\neps2 &lt;- coef(fluc2)\n\n# Update Q2 predictions under A2=1\nQ2_star &lt;- plogis(logit(Q2_A2is1) + eps2 / (g1_hat * g2_under_a1))\n# Note: for the targeted predictions under intervention, H2 = 1/g_cumulative\n\ncat(\"Epsilon at time 2:\", round(eps2, 5), \"\\n\")\n\nEpsilon at time 2: 0.01659 \n\ncat(\"Updated Q2*(A2=1) range:\", round(range(Q2_star), 4), \"\\n\")\n\nUpdated Q2*(A2=1) range: 0.0767 0.7858 \n\n\n\n\n\n\n\n\nL-TMLE Step 3b: Target \\(\\hat{Q}_1\\) at Time 1\n\n\n\nNow we repeat the targeting at time 1, but using the updated \\(\\hat{Q}_2^*\\) as the outcome.\nRe-fit the backwards regression using \\(\\hat{Q}_2^*\\) (the targeted predictions from step 3a):\n\\[\\hat{Q}_1^{\\text{updated}}(A_1, W) = \\hat{E}\\big[\\hat{Q}_2^*(1, L_1, A_1, W) \\;\\big|\\; A_1, W\\big]\\]\nThen target with the clever covariate at time 1:\n\\[H_1 = \\frac{I(A_1 = 1)}{\\hat{g}_1(W)}\\]\nFit: \\(\\text{logit}(\\hat{Q}_2^*) = \\text{logit}(\\hat{Q}_1^{\\text{updated}}) + \\epsilon_1 \\cdot H_1\\)\nUpdate: \\(\\hat{Q}_1^*(1, W) = \\text{expit}(\\text{logit}(\\hat{Q}_1^{\\text{updated}}) + \\hat{\\epsilon}_1 \\cdot H_1)\\)\n\n\n\n# Re-fit backwards regression using targeted Q2*\nQ1_mod_updated &lt;- glm(Q2_star ~ A1 + W, family = quasibinomial, data = dat)\n\nQ1_updated &lt;- predict(Q1_mod_updated, type = \"response\")\nQ1_under_a1 &lt;- predict(Q1_mod_updated,\n                        newdata = dat %&gt;% mutate(A1 = 1),\n                        type = \"response\")\n\n# Clever covariate at time 1\nH1 &lt;- (dat$A1 == 1) / g1_hat\n\n# Fluctuation model at time 1\nfluc1 &lt;- glm(Q2_star ~ -1 + offset(logit(Q1_updated)) + H1,\n             family = quasibinomial)\neps1 &lt;- coef(fluc1)\n\n# Final targeted predictions under A1 = 1\nQ1_star &lt;- plogis(logit(Q1_under_a1) + eps1 / g1_hat)\n\ncat(\"Epsilon at time 1:\", round(eps1, 5), \"\\n\")\n\nEpsilon at time 1: -0.00084",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html#phase-d-the-final-l-tmle-estimate",
    "href": "03-09-illustrated-ltmle.html#phase-d-the-final-l-tmle-estimate",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "22.5 Phase D: The Final L-TMLE Estimate",
    "text": "22.5 Phase D: The Final L-TMLE Estimate\n\n\n\n\n\n\nL-TMLE Step 4: Plug In and Estimate\n\n\n\nThe L-TMLE estimate of \\(E[Y(1,1)]\\) is the sample mean of the final targeted predictions:\n\\[\\hat{\\psi}_{\\text{LTMLE}} = \\frac{1}{n} \\sum_{i=1}^{n} \\hat{Q}_1^*(1, W_i)\\]\n\n\n\nltmle_estimate &lt;- mean(Q1_star)\n\ncat(\"========================================\\n\")\n\n========================================\n\ncat(\"L-TMLE estimate E[Y(1,1)]:\", round(ltmle_estimate, 4), \"\\n\")\n\nL-TMLE estimate E[Y(1,1)]: 0.4011 \n\ncat(\"True E[Y(1,1)]:           \", round(true_EY_11, 4), \"\\n\")\n\nTrue E[Y(1,1)]:            0.3945 \n\ncat(\"Naive G-comp (no targeting):\", round(mean(Q1_A1is1), 4), \"\\n\")\n\nNaive G-comp (no targeting): 0.3899 \n\ncat(\"========================================\\n\")\n\n========================================",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html#the-problem-restated",
    "href": "03-09-illustrated-ltmle.html#the-problem-restated",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "23.1 The problem, restated",
    "text": "23.1 The problem, restated\nIn our statin example:\n\nYear-1 statins (\\(A_1\\)) lower cholesterol (\\(L_1\\))\nLower cholesterol (\\(L_1\\)) makes year-2 statins (\\(A_2\\)) less likely\nLower cholesterol (\\(L_1\\)) also directly lowers heart attack risk (\\(Y\\))\n\nA naive regression that conditions on \\(L_1\\) blocks the indirect effect \\(A_1 \\to L_1 \\to Y\\) and introduces collider bias. But not adjusting for \\(L_1\\) confounds the \\(A_2 \\to Y\\) effect.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html#how-l-tmle-handles-this",
    "href": "03-09-illustrated-ltmle.html#how-l-tmle-handles-this",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "23.2 How L-TMLE handles this",
    "text": "23.2 How L-TMLE handles this\n\n\n\n\n\n\nThe Backwards Regression Solves the “Condition or Not?” Dilemma\n\n\n\nAt time 2: We fit \\(E[Y \\mid A_2, L_1, A_1, W]\\) and DO condition on \\(L_1\\). This correctly adjusts for the confounding of \\(A_2\\) by \\(L_1\\).\nAt time 1: We regress the time-2 predictions on \\((A_1, W)\\) and do NOT condition on \\(L_1\\). Instead, we let \\(L_1\\) vary freely. This preserves the indirect effect \\(A_1 \\to L_1 \\to Y\\).\nBy working backwards, we condition on \\(L_1\\) only where it is needed (as a confounder of \\(A_2\\)) and integrate it out where conditioning would be harmful (as a mediator of \\(A_1\\)).",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html#what-does-targeting-add",
    "href": "03-09-illustrated-ltmle.html#what-does-targeting-add",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "23.3 What does targeting add?",
    "text": "23.3 What does targeting add?\nThe sequential regression (G-computation) above handles the time-ordering correctly, but it relies on all outcome models being correctly specified. The targeting steps add robustness:\n\n\n\n\n\n\nWhy Targeting Matters\n\n\n\nAt time 2: The fluctuation step using \\(H_2 = \\frac{I(A_1=1, A_2=1)}{g_1 \\cdot g_2}\\) corrects the outcome model using information from the treatment models. Even if \\(\\hat{Q}_2\\) is somewhat misspecified, the clever covariate steers the predictions toward the correct value for our target estimand.\nAt time 1: The fluctuation step using \\(H_1 = \\frac{I(A_1=1)}{g_1}\\) further corrects \\(\\hat{Q}_1\\) using the time-1 treatment model.\nTogether, these targeting steps achieve sequential double robustness: the final estimate is consistent if, at each time point, either the outcome model OR the treatment model is correctly specified.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html#the-double-robustness-property",
    "href": "03-09-illustrated-ltmle.html#the-double-robustness-property",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "23.4 The double robustness property",
    "text": "23.4 The double robustness property\nFor point-treatment TMLE, double robustness means: consistent if \\(\\hat{Q}\\) OR \\(\\hat{g}\\) is correct.\nFor L-TMLE, it extends to: consistent if at each time step, either the \\(\\hat{Q}_t\\) or \\(\\hat{g}_t\\) is correct. Specifically:\n\n\n\nIf correct at time 2\nIf correct at time 1\nL-TMLE is…\n\n\n\n\n\\(Q_2\\) only\n\\(Q_1\\) only\nConsistent\n\n\n\\(g_2\\) only\n\\(g_1\\) only\nConsistent\n\n\n\\(Q_2\\) only\n\\(g_1\\) only\nConsistent\n\n\n\\(g_2\\) only\n\\(Q_1\\) only\nConsistent\n\n\nNeither\nAnything\nNot guaranteed\n\n\n\nThis is a much stronger property than simply requiring one global model to be correct.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html#compare-estimators",
    "href": "03-09-illustrated-ltmle.html#compare-estimators",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "24.1 Compare estimators",
    "text": "24.1 Compare estimators\n\n# --- Naive: condition on everything ---\nnaive_mod &lt;- glm(Y ~ A1 + A2 + L1 + W, family = binomial, data = dat)\nnaive_pred &lt;- predict(naive_mod,\n                       newdata = dat %&gt;% mutate(A1 = 1, A2 = 1),\n                       type = \"response\")\nnaive_est &lt;- mean(naive_pred)\n\n# --- Standard IPTW with cumulative weights ---\n# Weight = 1 / P(observed treatment sequence)\niptw_w &lt;- ifelse(dat$A1 == 1 & dat$A2 == 1,\n                 1 / (g1_hat * g2_hat),\n                 0)\n# Horvitz-Thompson\niptw_est &lt;- sum(iptw_w * dat$Y) / sum(iptw_w)\n\n# --- Compare ---\ncomparison &lt;- tibble(\n  Method = c(\"True E[Y(1,1)]\",\n             \"Naive regression (conditions on L1)\",\n             \"Sequential G-computation (no targeting)\",\n             \"Longitudinal IPTW\",\n             \"L-TMLE\"),\n  Estimate = round(c(true_EY_11, naive_est, mean(Q1_A1is1), iptw_est, ltmle_estimate), 4)\n)\ncomparison\n\n# A tibble: 5 × 2\n  Method                                  Estimate\n  &lt;chr&gt;                                      &lt;dbl&gt;\n1 True E[Y(1,1)]                             0.394\n2 Naive regression (conditions on L1)        0.366\n3 Sequential G-computation (no targeting)    0.390\n4 Longitudinal IPTW                          0.399\n5 L-TMLE                                     0.401\n\n\n\nggplot(comparison, aes(x = Estimate,\n                       y = factor(Method, levels = rev(comparison$Method)))) +\n  geom_point(size = 3, color = c(\"red\", \"#4477AA\", \"#228833\", \"#EE6677\", \"#AA3377\")) +\n  geom_vline(xintercept = true_EY_11, linetype = \"dashed\", color = \"red\", linewidth = 0.5) +\n  annotate(\"text\", x = true_EY_11, y = 5.4, label = \"Truth\", color = \"red\", size = 3) +\n  labs(x = \"Estimated E[Y(1,1)]\", y = \"\", title = \"How Well Does Each Estimator Recover the Truth?\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 10))\n\nWarning: Use of `comparison$Method` is discouraged.\nℹ Use `Method` instead.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-09-illustrated-ltmle.html#software-implementation-r",
    "href": "03-09-illustrated-ltmle.html#software-implementation-r",
    "title": "17  An Illustrated Guide to Longitudinal TMLE",
    "section": "29.1 Software Implementation (R)",
    "text": "29.1 Software Implementation (R)\nThis example uses the ltmle package for a minimal, well-commented longitudinal TMLE that mirrors the visual walkthrough in this chapter: backwards sequential regression with targeting at each time step.\n\nSimulate 2-time-point data with treatment–confounder feedback\nUse ltmle() with abar for static “always treat” vs. “never treat”\nPrint the targeted estimate with influence-curve-based confidence interval\n\n\nset.seed(1)\nn &lt;- 400\nW     &lt;- rnorm(n)\nA_1   &lt;- rbinom(n, 1, plogis(0.3 * W))\nL_1   &lt;- rnorm(n, mean = 0.5 * A_1 + 0.4 * W, sd = 0.8)\nA_2   &lt;- rbinom(n, 1, plogis(-0.2 + 0.3 * L_1 + 0.2 * W))\nY     &lt;- rbinom(n, 1, plogis(-1 + 0.4 * A_1 + 0.4 * A_2 + 0.3 * L_1 + 0.3 * W))\n\ndat &lt;- data.frame(W = W, A_1 = A_1, L_1 = L_1, A_2 = A_2, Y = Y)\n\nif (requireNamespace(\"ltmle\", quietly = TRUE)) {\n  library(ltmle)\n\n  result &lt;- ltmle(\n    data = dat,\n    Anodes  = c(\"A_1\", \"A_2\"),\n    Lnodes  = \"L_1\",\n    Ynodes  = \"Y\",\n    abar = list(treatment = c(1, 1), control = c(0, 0)),\n    SL.library = \"glm\"\n  )\n\n  cat(\"── Longitudinal TMLE (always treat vs never treat) ──\\n\")\n  print(summary(result))\n\n  cat(\"\\nThis mirrors the backwards-regression + targeting\\n\")\n  cat(\"walkthrough illustrated earlier in this chapter.\\n\")\n} else {\n  message(\"Install the 'ltmle' package:  install.packages('ltmle')\")\n}",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>An Illustrated Guide to Longitudinal TMLE</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html",
    "href": "03-10-tmle-mediation.html",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "",
    "text": "19 An Illustrated Guide to TMLE for Mediation Analysis\nHow to decompose a drug’s total effect into what works directly and what works through an intermediate mechanism\nIn pharmacoepidemiology, we often want to know not just whether a drug works, but how it works. Does dapagliflozin reduce cardiovascular events because it lowers blood pressure, because it improves glucose control, or through some other mechanism entirely?\nMediation analysis decomposes a total causal effect into:\nTMLE provides a principled framework for this decomposition that is doubly robust and compatible with machine learning.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#the-pharmacoepidemiologic-question",
    "href": "03-10-tmle-mediation.html#the-pharmacoepidemiologic-question",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "20.1 The Pharmacoepidemiologic Question",
    "text": "20.1 The Pharmacoepidemiologic Question\nSGLT2 inhibitors (like dapagliflozin) have shown surprising cardiovascular benefits in type 2 diabetes trials. The FDA and sponsor want to understand the mechanism:\n\nHow much of dapagliflozin’s effect on reducing MACE operates through HbA1c reduction (glycemic pathway), and how much operates through other mechanisms (e.g., blood pressure, weight loss, direct cardiac effects)?\n\nThis matters because:\n\nIf the effect is entirely through glycemic control, other glucose-lowering drugs should work too\nIf the effect is mostly direct, SGLT2 inhibitors have a unique cardiovascular benefit worth highlighting in labeling\nUnderstanding mechanisms guides future drug development\n\n\n\n\n\n\n\nThe Setup\n\n\n\n\nTreatment (A): Dapagliflozin vs. sulfonylurea\nMediator (M): 6-month HbA1c change (glycemic improvement)\nOutcome (Y): 1-year MACE\nConfounders (W): Age, BMI, baseline HbA1c, prior CVD, eGFR, statin use\nQuestion: How much of the \\(A \\to Y\\) effect goes through \\(A \\to M \\to Y\\)?",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#step-1-define-the-causal-question",
    "href": "03-10-tmle-mediation.html#step-1-define-the-causal-question",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "21.1 Step 1: Define the Causal Question",
    "text": "21.1 Step 1: Define the Causal Question\nIn mediation, we decompose the total effect into two pieces:\n\n\n\n\n\n\nTotal Effect = Natural Direct Effect + Natural Indirect Effect\n\n\n\nTotal Effect (TE): \\[TE = E[Y(1, M(1))] - E[Y(0, M(0))]\\] The overall effect of treatment on outcome (what we estimated in Chapter 2.4).\nNatural Direct Effect (NDE): \\[NDE = E[Y(1, M(0))] - E[Y(0, M(0))]\\] The effect of treatment on outcome if we could hold the mediator at its control value. “What if we gave the drug but magically blocked it from changing HbA1c?”\nNatural Indirect Effect (NIE): \\[NIE = E[Y(1, M(1))] - E[Y(1, M(0))]\\] The effect of the mediator change induced by treatment, while keeping treatment on. “What if we didn’t change the drug assignment but shifted HbA1c as dapagliflozin would?”\n\n\nThe decomposition is: \\(TE = NDE + NIE\\)\n\n\n\n\n\n\nPlain Language\n\n\n\n\nNDE: “How much does the drug help even if it didn’t change HbA1c at all?” (the direct pathway — blood pressure, weight, cardiac remodeling, etc.)\nNIE: “How much does the drug help specifically because it lowers HbA1c?” (the glycemic pathway)\n\nIf the NIE is large, glycemic control is the main mechanism. If the NDE is large, the drug works through non-glycemic pathways.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#step-2-the-causal-model-dag",
    "href": "03-10-tmle-mediation.html#step-2-the-causal-model-dag",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "21.2 Step 2: The Causal Model (DAG)",
    "text": "21.2 Step 2: The Causal Model (DAG)\nThe mediation DAG adds one node compared to the standard confounding DAG:\n              W (confounders)\n            / | \\\n           /  |  \\\n          v   v   v\n          A → M → Y\n          |       ↑\n          └───────┘\n            (direct)\n\n\\(W \\to A\\): confounders affect treatment\n\\(W \\to M\\): confounders affect the mediator\n\\(W \\to Y\\): confounders affect the outcome\n\\(A \\to M\\): treatment affects the mediator (dapagliflozin lowers HbA1c)\n\\(M \\to Y\\): the mediator affects the outcome (HbA1c affects MACE risk)\n\\(A \\to Y\\): treatment directly affects the outcome (non-glycemic pathways)\n\n\n\n\n\n\n\nCritical Assumption: No Mediator-Outcome Confounding Affected by Treatment\n\n\n\nFor mediation to work, there must be no confounder of the M → Y relationship that is itself affected by treatment. If treatment changes a variable \\(Z\\) that confounds \\(M \\to Y\\), the natural direct and indirect effects are not identifiable from observed data.\n     A → Z → M → Y       ← Z confounds M→Y AND is affected by A\n              ↑\n              Z ──────→ Y  ← This breaks identification!\nThis is the hardest assumption in mediation analysis. In our example: does dapagliflozin change something (like blood pressure or weight) that both affects HbA1c trajectory AND independently affects MACE? If so, we need more advanced methods (interventional effects).",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#step-3-assumptions-for-mediation",
    "href": "03-10-tmle-mediation.html#step-3-assumptions-for-mediation",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "21.3 Step 3: Assumptions for Mediation",
    "text": "21.3 Step 3: Assumptions for Mediation\nTo identify the NDE and NIE, we need the standard confounding assumptions PLUS additional ones:\n\nNo unmeasured treatment-outcome confounding: \\(Y(a, m) \\perp\\!\\!\\!\\perp A \\mid W\\)\nNo unmeasured mediator-outcome confounding: \\(Y(a, m) \\perp\\!\\!\\!\\perp M \\mid A, W\\)\nNo unmeasured treatment-mediator confounding: \\(M(a) \\perp\\!\\!\\!\\perp A \\mid W\\)\nCross-world independence: No \\(W\\)-adjusted confounder of \\(M \\to Y\\) is affected by \\(A\\)\n\n\n\n\n\n\n\nThe Cross-World Problem\n\n\n\nAssumption 4 is called the “cross-world” assumption because the NDE involves a quantity \\(Y(1, M(0))\\) — the outcome under treatment \\(A = 1\\) with the mediator value that would have occurred under \\(A = 0\\). This never happens in reality; it combines potential outcomes from two different “worlds.”\nThis assumption is untestable and often debated. If you are uncomfortable with it, consider interventional (in)direct effects, which replace the cross-world assumption with a weaker one. We briefly discuss this in Section 9.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#step-4-statistical-estimands",
    "href": "03-10-tmle-mediation.html#step-4-statistical-estimands",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "21.4 Step 4: Statistical Estimands",
    "text": "21.4 Step 4: Statistical Estimands\nUnder the assumptions above, the NDE and NIE are identified by statistical quantities:\n\n\n\n\n\n\nThe Mediation G-Computation Formulas\n\n\n\nNDE: \\[NDE = \\sum_m \\sum_w \\big[E[Y \\mid A=1, M=m, W=w] - E[Y \\mid A=0, M=m, W=w]\\big] \\cdot P(M=m \\mid A=0, W=w) \\cdot P(W=w)\\]\nNIE: \\[NIE = \\sum_m \\sum_w E[Y \\mid A=1, M=m, W=w] \\cdot \\big[P(M=m \\mid A=1, W=w) - P(M=m \\mid A=0, W=w)\\big] \\cdot P(W=w)\\]\nThese formulas require:\n\nAn outcome model: \\(E[Y \\mid A, M, W]\\)\nA mediator model: \\(P(M \\mid A, W)\\)\nA treatment model: \\(P(A \\mid W)\\) (for the TMLE targeting step)",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#step-5-why-tmle-for-mediation",
    "href": "03-10-tmle-mediation.html#step-5-why-tmle-for-mediation",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "21.5 Step 5: Why TMLE for Mediation?",
    "text": "21.5 Step 5: Why TMLE for Mediation?\n\n\n\n\n\n\n\nMethod\nLimitation\n\n\n\n\nBaron-Kenny regression\nAssumes linear models, no interactions, continuous mediator\n\n\nParametric G-computation\nWorks but depends on correct outcome AND mediator models\n\n\nWeighting-based\nCan be unstable with continuous mediators\n\n\nTMLE for mediation\nDoubly robust, handles nonlinear effects, works with Super Learner",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#a.-the-baron-kenny-trap",
    "href": "03-10-tmle-mediation.html#a.-the-baron-kenny-trap",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "23.1 4A. The Baron-Kenny Trap",
    "text": "23.1 4A. The Baron-Kenny Trap\nThe classic approach fits two regressions and reads off coefficients. Let’s see what it gives us:\n\n# Step 1: Total effect\ntotal_mod &lt;- glm(Y ~ A + age + bmi + hba1c_bl + cvd + egfr + statin,\n                 family = binomial, data = dat)\n\n# Step 2: Mediator model\nmed_mod &lt;- lm(M ~ A + age + bmi + hba1c_bl + cvd + egfr + statin,\n              data = dat)\n\n# Step 3: Outcome model with mediator\nfull_mod &lt;- glm(Y ~ A + M + age + bmi + hba1c_bl + cvd + egfr + statin,\n                family = binomial, data = dat)\n\ncat(\"--- Baron-Kenny style coefficients ---\\n\")\n#&gt; --- Baron-Kenny style coefficients ---\ncat(\"Total effect (A in model without M):\", round(coef(total_mod)[\"A\"], 3), \"(log-OR)\\n\")\n#&gt; Total effect (A in model without M): -0.548 (log-OR)\ncat(\"Direct effect (A in model with M):  \", round(coef(full_mod)[\"A\"], 3), \"(log-OR)\\n\")\n#&gt; Direct effect (A in model with M):   -0.205 (log-OR)\ncat(\"Mediator effect (M on Y):           \", round(coef(full_mod)[\"M\"], 3), \"(log-OR)\\n\")\n#&gt; Mediator effect (M on Y):            0.689 (log-OR)\ncat(\"Treatment on mediator:              \", round(coef(med_mod)[\"A\"], 3), \"(mean change)\\n\")\n#&gt; Treatment on mediator:               -0.514 (mean change)\n\n\n\n\n\n\n\nWhat’s Wrong with Baron-Kenny Here?\n\n\n\n\nScale: The coefficients are on the log-odds scale. The “difference in coefficients” method (\\(TE - DE\\)) does not equal the indirect effect on the risk difference scale for non-linear models.\nNon-collapsibility: The log-odds ratio is non-collapsible — the coefficient of \\(A\\) changes when you add \\(M\\) to the model, even if there is NO mediation, simply because of the non-linear link function.\nNo valid standard errors for the indirect effect without additional assumptions.\nNo double robustness — if either model is misspecified, everything is biased.\n\nWe need a proper decomposition on the risk difference scale.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#b.-naive-regression-based-decomposition-on-the-risk-difference-scale",
    "href": "03-10-tmle-mediation.html#b.-naive-regression-based-decomposition-on-the-risk-difference-scale",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "23.2 4B. Naive Regression-Based Decomposition on the Risk Difference Scale",
    "text": "23.2 4B. Naive Regression-Based Decomposition on the Risk Difference Scale\nA better approach: use G-computation-style prediction, but decompose manually.\n\n# Outcome model including the mediator\nq_med_mod &lt;- glm(Y ~ A + M + age + bmi + hba1c_bl + cvd + egfr + statin +\n                   A:cvd,\n                 family = binomial, data = dat)\n\n# Mediator model\nm_mod &lt;- lm(M ~ A + age + bmi + hba1c_bl + egfr, data = dat)\n\n# Predicted mediator values under A=0 and A=1\nM_hat_A0 &lt;- predict(m_mod, newdata = dat %&gt;% mutate(A = 0))\nM_hat_A1 &lt;- predict(m_mod, newdata = dat %&gt;% mutate(A = 1))\n\n# E[Y(1, M(0))]: set A=1, M=M_hat_A0\nEY_1_M0 &lt;- mean(predict(q_med_mod,\n  newdata = dat %&gt;% mutate(A = 1, M = M_hat_A0),\n  type = \"response\"))\n\n# E[Y(0, M(0))]: set A=0, M=M_hat_A0\nEY_0_M0 &lt;- mean(predict(q_med_mod,\n  newdata = dat %&gt;% mutate(A = 0, M = M_hat_A0),\n  type = \"response\"))\n\n# E[Y(1, M(1))]: set A=1, M=M_hat_A1\nEY_1_M1 &lt;- mean(predict(q_med_mod,\n  newdata = dat %&gt;% mutate(A = 1, M = M_hat_A1),\n  type = \"response\"))\n\nnaive_NDE &lt;- EY_1_M0 - EY_0_M0\nnaive_NIE &lt;- EY_1_M1 - EY_1_M0\nnaive_TE  &lt;- EY_1_M1 - EY_0_M0\n\ncat(\"Naive G-comp NDE:\", round(naive_NDE, 4), \" (true:\", round(true_NDE, 4), \")\\n\")\n#&gt; Naive G-comp NDE: -0.0081  (true: -0.0054 )\ncat(\"Naive G-comp NIE:\", round(naive_NIE, 4), \" (true:\", round(true_NIE, 4), \")\\n\")\n#&gt; Naive G-comp NIE: -0.0103  (true: -0.0068 )\ncat(\"Naive G-comp TE: \", round(naive_TE, 4),  \" (true:\", round(true_TE, 4), \")\\n\")\n#&gt; Naive G-comp TE:  -0.0184  (true: -0.0122 )\n\n\n\n\n\n\n\nThis Is G-Computation for Mediation\n\n\n\nThis approach correctly decomposes the effect on the risk difference scale. But it has the same weakness as point-treatment G-computation: it depends entirely on both the outcome model AND the mediator model being correctly specified. There is no robustness to misspecification.\nTMLE adds targeting to make this doubly robust.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#the-algorithm-overview",
    "href": "03-10-tmle-mediation.html#the-algorithm-overview",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "24.1 The Algorithm Overview",
    "text": "24.1 The Algorithm Overview\n┌───────────────────────────────────────┐\n│ Step 1: Fit the outcome model         │\n│ Q(A, M, W) = E[Y | A, M, W]          │\n│ Predict under (A=1,M) and (A=0,M)    │\n└───────────────┬───────────────────────┘\n                │\n┌───────────────▼───────────────────────┐\n│ Step 2: Fit the mediator model        │\n│ P(M | A, W)                           │\n│ Needed for NDE/NIE decomposition      │\n└───────────────┬───────────────────────┘\n                │\n┌───────────────▼───────────────────────┐\n│ Step 3: Fit the treatment model       │\n│ g(W) = P(A=1 | W)                     │\n│ Needed for the clever covariate       │\n└───────────────┬───────────────────────┘\n                │\n┌───────────────▼───────────────────────┐\n│ Step 4: Compute mediation-specific    │\n│ clever covariates for NDE and NIE     │\n└───────────────┬───────────────────────┘\n                │\n┌───────────────▼───────────────────────┐\n│ Step 5: Fluctuate Q to get Q*         │\n│ (targeting step for each effect)      │\n└───────────────┬───────────────────────┘\n                │\n┌───────────────▼───────────────────────┐\n│ Step 6: Plug Q* into mediation        │\n│ formulas to estimate NDE and NIE      │\n└───────────────────────────────────────┘",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#step-1-fit-the-outcome-model",
    "href": "03-10-tmle-mediation.html#step-1-fit-the-outcome-model",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "24.2 Step 1: Fit the Outcome Model",
    "text": "24.2 Step 1: Fit the Outcome Model\n\n\n\n\n\n\nStep 1: Model E[Y | A, M, W]\n\n\n\nJust like standard TMLE, start by fitting a model for the expected outcome. But now the model includes the mediator \\(M\\) as a predictor alongside treatment \\(A\\) and confounders \\(W\\).\n\\[\\hat{Q}(A, M, W) = \\hat{E}[Y \\mid A, M, W]\\]\n\n\n\nlogit &lt;- function(p) log(p / (1 - p))\n\n# Outcome model: includes treatment, mediator, and confounders\nq_mod &lt;- glm(Y ~ A + M + age + bmi + hba1c_bl + cvd + egfr + statin +\n               A:cvd + A:M,\n             family = binomial, data = dat)\n\n# Predict at observed values\nQAM_init &lt;- predict(q_mod, type = \"response\")\n\n# Predict under counterfactual treatment values (keeping M observed)\nQ1M_init &lt;- predict(q_mod, newdata = dat %&gt;% mutate(A = 1), type = \"response\")\nQ0M_init &lt;- predict(q_mod, newdata = dat %&gt;% mutate(A = 0), type = \"response\")\n\ncat(\"Q(A,M,W) range:\", round(range(QAM_init), 4), \"\\n\")\n#&gt; Q(A,M,W) range: 0.0011 0.3803",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#step-2-fit-the-mediator-model",
    "href": "03-10-tmle-mediation.html#step-2-fit-the-mediator-model",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "24.3 Step 2: Fit the Mediator Model",
    "text": "24.3 Step 2: Fit the Mediator Model\n\n\n\n\n\n\nStep 2: Model P(M | A, W) — The Mediator Distribution\n\n\n\nTo decompose the total effect, we need to know how the mediator distribution shifts under treatment vs. control. For a continuous mediator, we model \\(M \\mid A, W\\) as normally distributed.\nThis model serves two purposes:\n\nIt tells us what \\(M\\) values to expect under \\(A = 0\\) vs. \\(A = 1\\)\nIt provides density ratios needed for the clever covariate\n\n\n\n\n# Mediator model: how does M depend on A and W?\nm_mod &lt;- lm(M ~ A + age + bmi + hba1c_bl + egfr, data = dat)\nsigma_m &lt;- sigma(m_mod)\n\n# Predicted mediator mean under A=0 and A=1\nM_mean_a0 &lt;- predict(m_mod, newdata = dat %&gt;% mutate(A = 0))\nM_mean_a1 &lt;- predict(m_mod, newdata = dat %&gt;% mutate(A = 1))\n\n# Density of observed M under each treatment condition\n# P(M_obs | A=0, W) and P(M_obs | A=1, W)\ndens_M_A0 &lt;- dnorm(dat$M, mean = M_mean_a0, sd = sigma_m)\ndens_M_A1 &lt;- dnorm(dat$M, mean = M_mean_a1, sd = sigma_m)\n\ncat(\"Mean mediator shift (A=1 vs A=0):\", round(mean(M_mean_a1 - M_mean_a0), 3), \"\\n\")\n#&gt; Mean mediator shift (A=1 vs A=0): -0.512",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#step-3-fit-the-treatment-model",
    "href": "03-10-tmle-mediation.html#step-3-fit-the-treatment-model",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "24.4 Step 3: Fit the Treatment Model",
    "text": "24.4 Step 3: Fit the Treatment Model\n\n\n\n\n\n\nStep 3: Model P(A = 1 | W) — The Propensity Score\n\n\n\nSame as standard TMLE. The propensity score is needed for the clever covariates.\n\n\n\ng_mod &lt;- glm(A ~ age + bmi + hba1c_bl + cvd + egfr + statin,\n             family = binomial, data = dat)\n\nps &lt;- predict(g_mod, type = \"response\")\nps &lt;- pmax(0.01, pmin(0.99, ps))\n\ncat(\"Propensity score range:\", round(range(ps), 3), \"\\n\")\n#&gt; Propensity score range: 0.112 0.707",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#step-4-the-mediation-clever-covariates",
    "href": "03-10-tmle-mediation.html#step-4-the-mediation-clever-covariates",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "24.5 Step 4: The Mediation Clever Covariates",
    "text": "24.5 Step 4: The Mediation Clever Covariates\n\n\n\n\n\n\nStep 4: Clever Covariates for NDE and NIE\n\n\n\nThis is where mediation TMLE differs from standard TMLE. The clever covariate for the NDE is different from the one for the NIE, because they target different estimands.\nFor the NDE, we need the expected outcome under \\(A = 1\\) vs. \\(A = 0\\) while holding \\(M\\) at its distribution under \\(A = 0\\). The clever covariate involves a density ratio that reweights the mediator distribution:\n\\[H^{NDE}(A, M, W) = \\frac{I(A=1) \\cdot f(M \\mid A=0, W)}{g(W) \\cdot f(M \\mid A=1, W)} - \\frac{I(A=0)}{1 - g(W)}\\]\nFor the NIE, we need the expected outcome under \\(A = 1\\) comparing the mediator distribution under \\(A = 1\\) vs. \\(A = 0\\):\n\\[H^{NIE}(A, M, W) = \\frac{I(A=1)}{g(W)} - \\frac{I(A=1) \\cdot f(M \\mid A=0, W)}{g(W) \\cdot f(M \\mid A=1, W)}\\]\nThe density ratio \\(f(M \\mid A=0, W) / f(M \\mid A=1, W)\\) is what connects the mediator model to the targeting step. It reweights the treated group’s mediator values to look like the control group’s mediator distribution.\n\n\n\n# Density ratio: P(M | A=0, W) / P(M | A=1, W)\n# This ratio \"transports\" the mediator distribution from control to treatment\ndensity_ratio &lt;- dens_M_A0 / pmax(dens_M_A1, 1e-10)\n\n# Clever covariate for NDE\nH_NDE &lt;- dat$A * density_ratio / ps - (1 - dat$A) / (1 - ps)\n\n# Clever covariate for NIE\nH_NIE &lt;- dat$A / ps - dat$A * density_ratio / ps\n\ncat(\"Density ratio range:\", round(range(density_ratio), 3), \"\\n\")\n#&gt; Density ratio range: 0.057 21.999\ncat(\"H_NDE range:\", round(range(H_NDE), 2), \"\\n\")\n#&gt; H_NDE range: -3.37 31.78\ncat(\"H_NIE range:\", round(range(H_NIE), 2), \"\\n\")\n#&gt; H_NIE range: -29 4.32\n\n\n\n\n\n\n\nWhat Does the Density Ratio Do?\n\n\n\nThe density ratio \\(f(M \\mid A=0, W) / f(M \\mid A=1, W)\\) answers: “How much more (or less) likely is this particular mediator value under control than under treatment?”\n\nRatio &gt; 1: This mediator value is more typical of the control group → gets upweighted\nRatio &lt; 1: This mediator value is more typical of the treatment group → gets downweighted\nRatio ≈ 1: This mediator value is equally likely under both treatments\n\nWhen we multiply a treated patient’s outcome by this ratio, we effectively “transport” their mediator to what it would have looked like without treatment — which is exactly what the NDE requires.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#step-5-targeting-fluctuation-for-nde",
    "href": "03-10-tmle-mediation.html#step-5-targeting-fluctuation-for-nde",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "24.6 Step 5: Targeting (Fluctuation) for NDE",
    "text": "24.6 Step 5: Targeting (Fluctuation) for NDE\n\n\n\n\n\n\nStep 5: Fluctuate Q to Target the NDE\n\n\n\nJust like standard TMLE, we fit a logistic regression with the initial \\(\\hat{Q}\\) as an offset and the NDE clever covariate as the predictor. The coefficient \\(\\epsilon\\) tells us how much to update.\n\\[\\text{logit}(Y) = \\text{logit}(\\hat{Q}(A, M, W)) + \\epsilon_{NDE} \\cdot H_{NDE}\\]\n\n\n\n# Fluctuation for NDE\nfluc_nde &lt;- glm(dat$Y ~ -1 + offset(logit(QAM_init)) + H_NDE,\n                family = binomial)\neps_nde &lt;- coef(fluc_nde)\n\ncat(\"Epsilon NDE:\", round(eps_nde, 5), \"\\n\")\n#&gt; Epsilon NDE: -0.0087\n\n# Update Q predictions\nQ1M_star_nde &lt;- plogis(logit(Q1M_init) + eps_nde * density_ratio / ps)\nQ0M_star_nde &lt;- plogis(logit(Q0M_init) + eps_nde * (-1 / (1 - ps)))",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#step-6-compute-the-nde",
    "href": "03-10-tmle-mediation.html#step-6-compute-the-nde",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "24.7 Step 6: Compute the NDE",
    "text": "24.7 Step 6: Compute the NDE\n\n\n\n\n\n\nStep 6: Plug-in NDE Estimate\n\n\n\nThe NDE is the difference in the targeted outcome predictions, averaged over the population, where the mediator is held at its control distribution.\nFor the treated group (with density-reweighted mediator), we average: \\[\\widehat{NDE} = \\frac{1}{n}\\sum_i \\hat{Q}^*_1(M_i, W_i) \\cdot r(M_i, W_i) - \\frac{1}{n}\\sum_i \\hat{Q}^*_0(M_i, W_i)\\]\nwhere \\(r(M_i, W_i)\\) is a normalized version of the density ratio that integrates properly.\n\n\n\n# For the NDE, we need E[Q*(1,M,W)] where M ~ P(M|A=0,W)\n# We use the density-ratio weighted average among treated\n# and the direct average among controls\n\n# Approach: Monte Carlo integration over P(M | A=0, W)\nset.seed(42)\nn_mc &lt;- 30\n\nnde_mc &lt;- numeric(n)\nfor (i in 1:n) {\n  m_draws &lt;- rnorm(n_mc, mean = M_mean_a0[i], sd = sigma_m)\n\n  # Density ratio for each MC draw: f(m|A=0,W) / f(m|A=1,W)\n  dr_draws &lt;- dnorm(m_draws, mean = M_mean_a0[i], sd = sigma_m) /\n              pmax(dnorm(m_draws, mean = M_mean_a1[i], sd = sigma_m), 1e-10)\n\n  # Q*(1, m, W) for each m draw\n  # H_NDE at (A=1, m) = density_ratio(m) / ps\n  newdat_1 &lt;- dat[rep(i, n_mc), ] %&gt;% mutate(A = 1, M = m_draws)\n  q1m &lt;- predict(q_mod, newdata = newdat_1, type = \"response\")\n  q1m_star &lt;- plogis(logit(q1m) + eps_nde * dr_draws / ps[i])\n\n  # Q*(0, m, W) for each m draw\n  # H_NDE at (A=0, m) = -1 / (1 - ps)\n  newdat_0 &lt;- dat[rep(i, n_mc), ] %&gt;% mutate(A = 0, M = m_draws)\n  q0m &lt;- predict(q_mod, newdata = newdat_0, type = \"response\")\n  q0m_star &lt;- plogis(logit(q0m) + eps_nde * (-1 / (1 - ps[i])))\n\n  nde_mc[i] &lt;- mean(q1m_star) - mean(q0m_star)\n}\n\ntmle_NDE &lt;- mean(nde_mc)\ncat(\"TMLE NDE:\", round(tmle_NDE, 4), \" (true:\", round(true_NDE, 4), \")\\n\")\n#&gt; TMLE NDE: -0.0106  (true: -0.0054 )",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#step-7-targeting-and-computing-the-nie",
    "href": "03-10-tmle-mediation.html#step-7-targeting-and-computing-the-nie",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "24.8 Step 7: Targeting and Computing the NIE",
    "text": "24.8 Step 7: Targeting and Computing the NIE\n\n# Fluctuation for NIE\nfluc_nie &lt;- glm(dat$Y ~ -1 + offset(logit(QAM_init)) + H_NIE,\n                family = binomial)\neps_nie &lt;- coef(fluc_nie)\ncat(\"Epsilon NIE:\", round(eps_nie, 5), \"\\n\")\n#&gt; Epsilon NIE: 0.0217\n\n# Monte Carlo integration for NIE\nnie_mc &lt;- numeric(n)\nfor (i in 1:n) {\n  # M draws from P(M|A=1,W)\n  m_draws_a1 &lt;- rnorm(n_mc, mean = M_mean_a1[i], sd = sigma_m)\n  # M draws from P(M|A=0,W)\n  m_draws_a0 &lt;- rnorm(n_mc, mean = M_mean_a0[i], sd = sigma_m)\n\n  # Density ratios for each draw: f(m|A=0,W) / f(m|A=1,W)\n  dr_a1 &lt;- dnorm(m_draws_a1, mean = M_mean_a0[i], sd = sigma_m) /\n           pmax(dnorm(m_draws_a1, mean = M_mean_a1[i], sd = sigma_m), 1e-10)\n  dr_a0 &lt;- dnorm(m_draws_a0, mean = M_mean_a0[i], sd = sigma_m) /\n           pmax(dnorm(m_draws_a0, mean = M_mean_a1[i], sd = sigma_m), 1e-10)\n\n  # Q*(1, M(1), W) - Q*(1, M(0), W)\n  # H_NIE at (A=1, m) = (1 - density_ratio(m)) / ps\n  newdat_1_m1 &lt;- dat[rep(i, n_mc), ] %&gt;% mutate(A = 1, M = m_draws_a1)\n  newdat_1_m0 &lt;- dat[rep(i, n_mc), ] %&gt;% mutate(A = 1, M = m_draws_a0)\n\n  q_m1 &lt;- predict(q_mod, newdata = newdat_1_m1, type = \"response\")\n  q_m0 &lt;- predict(q_mod, newdata = newdat_1_m0, type = \"response\")\n\n  q_m1_star &lt;- plogis(logit(q_m1) + eps_nie * (1 - dr_a1) / ps[i])\n  q_m0_star &lt;- plogis(logit(q_m0) + eps_nie * (1 - dr_a0) / ps[i])\n\n  nie_mc[i] &lt;- mean(q_m1_star) - mean(q_m0_star)\n}\n\ntmle_NIE &lt;- mean(nie_mc)\ntmle_TE  &lt;- tmle_NDE + tmle_NIE\n\ncat(\"TMLE NIE:\", round(tmle_NIE, 4), \" (true:\", round(true_NIE, 4), \")\\n\")\n#&gt; TMLE NIE: -0.0087  (true: -0.0068 )\ncat(\"TMLE TE: \", round(tmle_TE, 4),  \" (true:\", round(true_TE, 4), \")\\n\")\n#&gt; TMLE TE:  -0.0193  (true: -0.0122 )",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#propensity-score-overlap",
    "href": "03-10-tmle-mediation.html#propensity-score-overlap",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "26.1 7.1 Propensity Score Overlap",
    "text": "26.1 7.1 Propensity Score Overlap\n\nggplot(dat, aes(x = ps, fill = factor(A, labels = c(\"Sulfonylurea\", \"Dapagliflozin\")))) +\n  geom_density(alpha = 0.45) +\n  labs(\n    x = \"P(A=1 | W)\", fill = \"Treatment\",\n    title = \"Diagnostic: Propensity Score Overlap\"\n  ) +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"#4477AA\", \"#EE6677\"))",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#mediator-distribution-by-treatment",
    "href": "03-10-tmle-mediation.html#mediator-distribution-by-treatment",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "26.2 7.2 Mediator Distribution by Treatment",
    "text": "26.2 7.2 Mediator Distribution by Treatment\n\n\n\n\n\n\nWhy This Matters\n\n\n\nThe NIE depends on the treatment actually shifting the mediator distribution. If the mediator distributions under \\(A = 0\\) and \\(A = 1\\) are identical, there is no indirect effect to detect.\n\n\n\nggplot(dat, aes(x = M, fill = factor(A, labels = c(\"Sulfonylurea\", \"Dapagliflozin\")))) +\n  geom_density(alpha = 0.45) +\n  labs(\n    x = \"6-month HbA1c change (M)\",\n    fill = \"Treatment\",\n    title = \"Diagnostic: Mediator Distribution by Treatment Group\"\n  ) +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"#4477AA\", \"#EE6677\"))",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#density-ratio-distribution",
    "href": "03-10-tmle-mediation.html#density-ratio-distribution",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "26.3 7.3 Density Ratio Distribution",
    "text": "26.3 7.3 Density Ratio Distribution\n\n\n\n\n\n\nDensity Ratio Instability\n\n\n\nExtreme density ratios indicate that some observed mediator values are very unlikely under one treatment but common under the other. This creates instability analogous to extreme IPTW weights.\n\n\n\nggplot(tibble(r = density_ratio), aes(x = r)) +\n  geom_histogram(bins = 50, fill = \"#CC6677\", alpha = 0.7) +\n  geom_vline(xintercept = 1, linetype = \"dashed\") +\n  labs(\n    x = \"Density ratio f(M|A=0,W) / f(M|A=1,W)\",\n    y = \"Count\",\n    title = \"Diagnostic: Mediator Density Ratio\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\ncat(\"Density ratio summary:\\n\")\n#&gt; Density ratio summary:\nsummary(density_ratio)\n#&gt;     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n#&gt;  0.05709  0.59038  1.10575  1.63305  2.02503 21.99932\ncat(\"Proportion &gt; 3:\", round(mean(density_ratio &gt; 3), 3), \"\\n\")\n#&gt; Proportion &gt; 3: 0.135",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#mediator-outcome-relationship",
    "href": "03-10-tmle-mediation.html#mediator-outcome-relationship",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "26.4 7.4 Mediator-Outcome Relationship",
    "text": "26.4 7.4 Mediator-Outcome Relationship\n\n# Check that M actually predicts Y (otherwise no mediation to find)\nggplot(dat, aes(x = M, y = Y)) +\n  geom_smooth(method = \"loess\", se = TRUE, color = \"#228833\") +\n  facet_wrap(~factor(A, labels = c(\"Sulfonylurea\", \"Dapagliflozin\"))) +\n  labs(\n    x = \"6-month HbA1c change (M)\",\n    y = \"P(MACE)\",\n    title = \"Diagnostic: Mediator-Outcome Relationship by Treatment\"\n  ) +\n  theme_minimal()",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#sources-and-further-reading",
    "href": "03-10-tmle-mediation.html#sources-and-further-reading",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "30.1 Sources and further reading",
    "text": "30.1 Sources and further reading\n\nZheng Z, van der Laan MJ (2012). Targeted maximum likelihood estimation of natural direct effects. Int J Biostat 8(1):Article 3.\nVanderWeele TJ (2015). Explanation in Causal Inference: Methods for Mediation and Interaction. Oxford University Press.\nDiaz I, Hejazi NS (2020). Causal mediation analysis for stochastic interventions. JRSS-B 82(3):661-683.\nPearl J (2001). Direct and indirect effects. Proceedings of the 17th Conference on Uncertainty in Artificial Intelligence, 411-420.\nRobins JM, Richardson TS (2010). Alternative graphical causal models and the identification of direct effects. In Causality and Psychopathology, Oxford University Press.\nWilliams NT, Diaz I (2024). crumble: An R package for TMLE-based mediation analysis. GitHub\nmedltmle (if available): GitHub search\nvan der Laan MJ, Rose S (2011). Targeted Learning. Springer.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-10-tmle-mediation.html#software-implementation-r",
    "href": "03-10-tmle-mediation.html#software-implementation-r",
    "title": "18  An Illustrated Guide to TMLE for Mediation Analysis",
    "section": "30.2 Software Implementation (R)",
    "text": "30.2 Software Implementation (R)\nThis example uses the crumble package (if available) to estimate the natural direct effect (NDE) and natural indirect effect (NIE) via TMLE-based mediation analysis. The crumble package implements targeted learning for mediation with flexible nuisance estimation.\n\nSimulate data with a binary treatment \\(A\\), continuous mediator \\(M\\), and binary outcome \\(Y\\)\nEstimate NDE and NIE using crumble::crumble() with cross-fitting\nFalls back to a manual decomposition using tmle if crumble is unavailable\n\n\nset.seed(1)\nn &lt;- 600\nW &lt;- rnorm(n)\nA &lt;- rbinom(n, 1, plogis(0.3 * W))\nM &lt;- 0.5 * A + 0.4 * W + rnorm(n, sd = 0.8)\nY &lt;- rbinom(n, 1, plogis(-1 + 0.4 * A + 0.6 * M + 0.3 * W))\n\ndat &lt;- data.frame(W = W, A = A, M = M, Y = Y)\n\nif (requireNamespace(\"crumble\", quietly = TRUE)) {\n  library(crumble)\n\n  ## crumble estimates interventional (in)direct effects\n  ## using TMLE with cross-fitting\n  result &lt;- crumble(\n    data = dat,\n    trt = \"A\",\n    outcome = \"Y\",\n    mediators = \"M\",\n    baseline = \"W\",\n    outcome_type = \"binomial\",\n    learners = c(\"SL.glm\", \"SL.mean\"),\n    nn_module = NULL  # use standard SL, not neural net\n  )\n\n  cat(\"── Mediation TMLE via crumble ──\\n\")\n  print(result)\n} else {\n  message(\"'crumble' package not found.\")\n  message(\"Install from GitHub:  remotes::install_github('nt-williams/crumble')\")\n  message(\"\\nFalling back to a manual total-effect decomposition...\\n\")\n\n  if (requireNamespace(\"tmle\", quietly = TRUE)) {\n    library(tmle)\n    ## Total effect only (not a true mediation decomposition)\n    fit &lt;- tmle(Y = Y, A = A, W = data.frame(W = W),\n                Q.SL.library = \"SL.glm\", g.SL.library = \"SL.glm\")\n    cat(\"Total effect (ATE):\", round(fit$estimates$ATE$psi, 4), \"\\n\")\n    cat(\"95% CI:\", round(fit$estimates$ATE$CI, 4), \"\\n\")\n    cat(\"\\nNote: This is the total effect only.\\n\")\n    cat(\"For NDE/NIE decomposition, install the crumble package.\\n\")\n  } else {\n    message(\"Install 'tmle':  install.packages('tmle')\")\n  }\n}",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>An Illustrated Guide to TMLE for Mediation Analysis</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html",
    "href": "03-11-estimands-tte-safety.html",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "",
    "text": "20 Estimands in Time-to-Event Real-World Safety Analyses\nA simulation-based tutorial for pharmacoepidemiologists\nIn real-world safety studies, the question “Does this drug increase the risk of adverse events?” sounds simple. But the answer depends critically on how you handle intercurrent events — treatment switching, discontinuation, death from other causes — that occur between treatment initiation and the outcome. Different handling strategies define different estimands, and each estimand answers a fundamentally different scientific question.\nThis chapter uses a fully simulated safety study to illustrate three estimands side by side, showing how the same data can yield different estimates depending on the causal question being asked.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#the-regulatory-context",
    "href": "03-11-estimands-tte-safety.html#the-regulatory-context",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "21.1 The Regulatory Context",
    "text": "21.1 The Regulatory Context\nThe ICH E9(R1) addendum (2019) fundamentally changed how clinical and post-marketing studies define their targets of inference. The addendum requires explicit specification of:\n\nThe population of interest\nThe treatment conditions being compared\nThe outcome variable\nThe intercurrent events that may occur after treatment initiation\nThe strategy for handling each intercurrent event\n\n\n\n\n\n\n\nWhy Estimands Matter for Safety\n\n\n\nIn a safety study comparing Drug A to Drug B for risk of acute kidney injury (AKI):\n\nIf 5% of Drug A patients switch to Drug B after 30 days due to early toxicity signals, should we count their subsequent AKI events as part of Drug A’s effect?\nIf a patient dies from liver failure before AKI can occur, how does that affect the risk estimate?\nIf patients with chronic kidney disease are more likely to both switch treatments and develop AKI, naive censoring at switch introduces informative censoring bias.\n\nThe answer depends on the estimand. Different estimands answer different questions, require different assumptions, and demand different estimators.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#three-estimand-strategies",
    "href": "03-11-estimands-tte-safety.html#three-estimand-strategies",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "21.2 Three Estimand Strategies",
    "text": "21.2 Three Estimand Strategies\nWe focus on three strategies from ICH E9(R1):\n\n\n\n\n\n\n\n\nStrategy\nIntercurrent event handling\nQuestion answered\n\n\n\n\nTreatment-policy\nIgnore switching; follow all patients regardless\nWhat is the effect of being assigned to treatment?\n\n\nWhile-on-treatment\nCensor at switch\nWhat is the effect while patients remain on treatment?\n\n\nHypothetical\nModel what would have happened without switching (IPCW)\nWhat would the effect be if no one switched?",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#generate-baseline-covariates",
    "href": "03-11-estimands-tte-safety.html#generate-baseline-covariates",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "22.1 2.1 Generate Baseline Covariates",
    "text": "22.1 2.1 Generate Baseline Covariates\n\nlibrary(tidyverse)\nlibrary(survival)\n\nN &lt;- 100000\nset.seed(2026)\n\n# --- Baseline covariates ---\nage       &lt;- rnorm(N, mean = 50, sd = 10)\nckd       &lt;- rbinom(N, 1, 0.10)   # chronic kidney disease\ncirrhosis &lt;- rbinom(N, 1, 0.20)   # liver cirrhosis\ndiabetes  &lt;- rbinom(N, 1, 0.15)   # diabetes mellitus\nhiv       &lt;- rbinom(N, 1, 0.05)   # HIV co-infection",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#simulate-confounded-treatment-assignment",
    "href": "03-11-estimands-tte-safety.html#simulate-confounded-treatment-assignment",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "22.2 2.2 Simulate Confounded Treatment Assignment",
    "text": "22.2 2.2 Simulate Confounded Treatment Assignment\nTreatment assignment depends on baseline covariates, inducing confounding. Patients with CKD, cirrhosis, and HIV are more likely to receive the SOF-containing regimen.\n\n# --- Treatment assignment (confounded) ---\nlp_trt &lt;- -0.2 + 0.03 * age + 0.5 * ckd + 0.4 * cirrhosis + 0.3 * hiv\nprob_trt &lt;- plogis(lp_trt)\ntreatment &lt;- rbinom(N, 1, prob_trt)\n\ncat(\"Treatment prevalence:\", round(mean(treatment), 3), \"\\n\")\n#&gt; Treatment prevalence: 0.804\ncat(\"Mean P(treatment) in CKD:\", round(mean(prob_trt[ckd == 1]), 3), \"\\n\")\n#&gt; Mean P(treatment) in CKD: 0.864\ncat(\"Mean P(treatment) in no CKD:\", round(mean(prob_trt[ckd == 0]), 3), \"\\n\")\n#&gt; Mean P(treatment) in no CKD: 0.796",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#simulate-event-times-with-time-varying-hazard",
    "href": "03-11-estimands-tte-safety.html#simulate-event-times-with-time-varying-hazard",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "22.3 2.3 Simulate Event Times with Time-Varying Hazard",
    "text": "22.3 2.3 Simulate Event Times with Time-Varying Hazard\nWe use a piecewise exponential model: the treatment hazard ratio is 1.5 in the first 90 days and 0.7 afterward. Baseline covariates also affect the hazard.\n\n# --- Baseline hazard and covariate effects on hazard ---\nbase_rate &lt;- 0.002  # per day\ncovariate_lp &lt;- 0.4 * ckd + 0.2 * diabetes + 0.1 * cirrhosis + 0.01 * (age - 50)\n\n# --- Piecewise exponential: different HR before/after 90 days ---\n# Period 1: 0-90 days, HR = 1.5 for treatment\n# Period 2: 90+ days, HR = 0.7 for treatment\n\nrate_period1 &lt;- base_rate * exp(covariate_lp + log(1.5) * treatment)\nrate_period2 &lt;- base_rate * exp(covariate_lp + log(0.7) * treatment)\n\n# Simulate event time from piecewise exponential\n# P(T &gt; t) = exp(-rate1 * min(t, 90)) * exp(-rate2 * max(t - 90, 0))\n# Use inverse CDF method\n\nu &lt;- runif(N)\n# First check if event occurs in period 1 (0-90)\nsurv_at_90 &lt;- exp(-rate_period1 * 90)\nin_period1 &lt;- u &gt; surv_at_90  # event before day 90 if u &gt; S(90)\n\nevent_time &lt;- ifelse(\n  !in_period1,\n  # Event in period 1: solve exp(-rate1 * t) = u =&gt; t = -log(u)/rate1\n  -log(u) / rate_period1,\n  # Event in period 2: solve S(90)*exp(-rate2*(t-90)) = u\n  90 + (-log(u) - rate_period1 * 90) / rate_period2\n)\n\n# Cap at a maximum follow-up\nevent_time &lt;- pmin(event_time, 365)",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#simulate-treatment-switching",
    "href": "03-11-estimands-tte-safety.html#simulate-treatment-switching",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "22.4 2.4 Simulate Treatment Switching",
    "text": "22.4 2.4 Simulate Treatment Switching\nApproximately 5% of patients switch treatment between days 30-90, with switching probability depending on CKD, treatment, and early symptoms.\n\n# --- Treatment switching (intercurrent event) ---\n# Higher switch probability for: CKD patients, those on treatment, older patients\nlp_switch &lt;- -3.0 + 0.8 * ckd + 0.5 * treatment + 0.02 * (age - 50)\nswitch_prob &lt;- plogis(lp_switch)\nwill_switch &lt;- rbinom(N, 1, switch_prob)\nswitch_time &lt;- ifelse(will_switch == 1, runif(N, 30, 90), Inf)\n\ncat(\"Overall switching rate:\", round(mean(will_switch), 3), \"\\n\")\n#&gt; Overall switching rate: 0.079\ncat(\"Switching rate in CKD:\", round(mean(will_switch[ckd == 1]), 3), \"\\n\")\n#&gt; Switching rate in CKD: 0.154\ncat(\"Switching rate in treatment:\", round(mean(will_switch[treatment == 1]), 3), \"\\n\")\n#&gt; Switching rate in treatment: 0.086",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#administrative-censoring-and-final-dataset",
    "href": "03-11-estimands-tte-safety.html#administrative-censoring-and-final-dataset",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "22.5 2.5 Administrative Censoring and Final Dataset",
    "text": "22.5 2.5 Administrative Censoring and Final Dataset\n\n# --- Administrative censoring ---\nadmin_censor &lt;- runif(N, min = 90, max = 180)\n\n# --- Construct observed data ---\n# For treatment-policy: ignore switching, observe until event or admin censor\nobs_time_tp &lt;- pmin(event_time, admin_censor)\nevent_tp    &lt;- as.integer(event_time &lt;= admin_censor)\n\n# For while-on-treatment: censor at switch\nobs_time_wot &lt;- pmin(event_time, admin_censor, switch_time)\nevent_wot    &lt;- as.integer(event_time &lt;= pmin(admin_censor, switch_time))\n\n# Assemble the dataset\ndat &lt;- tibble(\n  id         = 1:N,\n  age        = age,\n  ckd        = ckd,\n  cirrhosis  = cirrhosis,\n  diabetes   = diabetes,\n  hiv        = hiv,\n  treatment  = treatment,\n  event_time = event_time,\n  switch_time = switch_time,\n  admin_censor = admin_censor,\n  # Treatment-policy view\n  time_tp    = obs_time_tp,\n  event_tp   = event_tp,\n  # While-on-treatment view\n  time_wot   = obs_time_wot,\n  event_wot  = event_wot,\n  switched   = as.integer(switch_time &lt; pmin(event_time, admin_censor))\n)\n\ncat(\"Dataset dimensions:\", dim(dat), \"\\n\")\n#&gt; Dataset dimensions: 100000 15\ncat(\"Events (treatment-policy):\", sum(dat$event_tp), \"\\n\")\n#&gt; Events (treatment-policy): 33946\ncat(\"Events (while-on-treatment):\", sum(dat$event_wot), \"\\n\")\n#&gt; Events (while-on-treatment): 32831\ncat(\"Patients who switched:\", sum(dat$switched), \"\\n\")\n#&gt; Patients who switched: 6132\n\n\n\n\n\n\n\nThe DAG for This Safety Study\n\n\n\n        age, ckd, diabetes, cirrhosis, hiv\n          /       |        \\\n         v        v         v\n    Treatment --&gt; Switch --&gt; Censoring\n         \\        |        /\n          v       v       v\n              AKI event\n\nBaseline confounders (age, CKD, etc.) affect treatment assignment, switching probability, and AKI risk\nTreatment affects both the AKI hazard and the probability of switching\nSwitching is an intercurrent event that can lead to informative censoring if correlated with AKI risk\nDifferent estimands handle the Treatment –&gt; Switch –&gt; AKI pathway differently",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#a.-treatment-policy-estimand",
    "href": "03-11-estimands-tte-safety.html#a.-treatment-policy-estimand",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "23.1 3a. Treatment-Policy Estimand",
    "text": "23.1 3a. Treatment-Policy Estimand\n\n\n\n\n\n\nTreatment-Policy: “Intent-to-Treat for RWD”\n\n\n\nQuestion: What is the 90-day risk of AKI comparing initiation of SOF vs. non-SOF, regardless of subsequent treatment changes?\nIntercurrent event handling: Ignore switching. Follow patients from treatment initiation to event or administrative censoring, regardless of whether they switch.\nAnalogous to: Intent-to-treat (ITT) analysis in a randomized trial.\nAssumption: Only requires that baseline confounders are sufficient for exchangeability at the time of treatment initiation. Does NOT require assumptions about the switching mechanism.\nLimitation: Estimates the effect of being assigned to treatment, which may be diluted if many patients switch away.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#b.-while-on-treatment-estimand",
    "href": "03-11-estimands-tte-safety.html#b.-while-on-treatment-estimand",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "23.2 3b. While-on-Treatment Estimand",
    "text": "23.2 3b. While-on-Treatment Estimand\n\n\n\n\n\n\nWhile-on-Treatment: “Only Count Events on Drug”\n\n\n\nQuestion: What is the 90-day risk of AKI while patients remain on their assigned treatment?\nIntercurrent event handling: Censor at the time of switching. Only events occurring while on the initial treatment are counted.\nAssumption: Requires that switching is non-informative — that is, conditional on measured covariates and treatment, the switching mechanism does not depend on the latent event time. If patients switch because they are sicker, this assumption fails.\nLimitation: If switching is informative (correlated with AKI risk even after adjustment), censoring at switch introduces selection bias. This is a form of “healthy user” or “sick switcher” bias.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#c.-hypothetical-no-switch-estimand",
    "href": "03-11-estimands-tte-safety.html#c.-hypothetical-no-switch-estimand",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "23.3 3c. Hypothetical (No-Switch) Estimand",
    "text": "23.3 3c. Hypothetical (No-Switch) Estimand\n\n\n\n\n\n\nHypothetical: “What If No One Switched?”\n\n\n\nQuestion: What would the 90-day risk of AKI have been if all patients remained on their assigned treatment?\nIntercurrent event handling: Model the counterfactual scenario where switching does not occur, using IPCW (inverse probability of censoring weights) to re-weight the analysis.\nAssumption: Requires that we can model the probability of switching given measured covariates (no unmeasured confounders of the switching decision). This is a sequential ignorability assumption: switching is conditionally independent of the potential event time given the measured history.\nAdvantage: Targets a cleaner causal contrast — the effect of the drug itself, uncontaminated by switching patterns.\nLimitation: Requires correct specification of the switching model. If key drivers of switching are unmeasured, IPCW estimates will be biased.",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#kaplan-meier-estimates",
    "href": "03-11-estimands-tte-safety.html#kaplan-meier-estimates",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "24.1 4.1 Kaplan-Meier Estimates",
    "text": "24.1 4.1 Kaplan-Meier Estimates\nWe start with unadjusted Kaplan-Meier curves for the treatment-policy and while-on-treatment estimands.\n\n# --- Treatment-policy estimand: KM ignoring switching ---\n# Restrict to 90-day window\ndat_90 &lt;- dat %&gt;%\n  mutate(\n    time_tp_90  = pmin(time_tp, 90),\n    event_tp_90 = ifelse(time_tp &lt;= 90, event_tp, 0),\n    time_wot_90  = pmin(time_wot, 90),\n    event_wot_90 = ifelse(time_wot &lt;= 90, event_wot, 0)\n  )\n\n# Treatment-policy KM\nkm_tp &lt;- survfit(Surv(time_tp_90, event_tp_90) ~ treatment, data = dat_90)\n\n# While-on-treatment KM\nkm_wot &lt;- survfit(Surv(time_wot_90, event_wot_90) ~ treatment, data = dat_90)\n\n\npar(mfrow = c(1, 2))\n\nplot(km_tp, col = c(\"steelblue\", \"tomato\"), lwd = 2,\n     xlab = \"Days\", ylab = \"Survival probability\",\n     main = \"Treatment-Policy (ignore switch)\")\nlegend(\"bottomleft\", c(\"Non-SOF\", \"SOF\"), col = c(\"steelblue\", \"tomato\"),\n       lwd = 2, bty = \"n\", cex = 0.9)\n\nplot(km_wot, col = c(\"steelblue\", \"tomato\"), lwd = 2,\n     xlab = \"Days\", ylab = \"Survival probability\",\n     main = \"While-on-Treatment (censor at switch)\")\nlegend(\"bottomleft\", c(\"Non-SOF\", \"SOF\"), col = c(\"steelblue\", \"tomato\"),\n       lwd = 2, bty = \"n\", cex = 0.9)\n\n\n\n\nKaplan-Meier survival curves: treatment-policy vs. while-on-treatment\n\n\n\n\n\n\n\n\n\n\nUnadjusted KM Is Biased Here\n\n\n\nBoth KM curves above are confounded because treatment assignment depends on baseline covariates. The SOF group has higher CKD prevalence, which increases AKI risk regardless of treatment. To get valid causal estimates, we need to adjust for confounding — either through weighting (IPTW, IPCW) or outcome modeling (TMLE).",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#iptw-adjusted-estimates",
    "href": "03-11-estimands-tte-safety.html#iptw-adjusted-estimates",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "24.2 4.2 IPTW-Adjusted Estimates",
    "text": "24.2 4.2 IPTW-Adjusted Estimates\nWe use inverse probability of treatment weighting to adjust for baseline confounding, and add IPCW for the hypothetical estimand.\n\n# --- Propensity score model ---\nps_mod &lt;- glm(treatment ~ age + ckd + cirrhosis + diabetes + hiv,\n              family = binomial, data = dat)\ndat$ps &lt;- predict(ps_mod, type = \"response\")\n\n# Stabilized IPTW weights\np_trt &lt;- mean(dat$treatment)\ndat$iptw &lt;- ifelse(dat$treatment == 1,\n                   p_trt / dat$ps,\n                   (1 - p_trt) / (1 - dat$ps))\n\n# Check weight distribution\ncat(\"IPTW weight summary:\\n\")\n#&gt; IPTW weight summary:\nprint(summary(dat$iptw))\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;  0.3458  0.9343  0.9869  0.9998  1.0490  3.8012\ncat(\"IPTW mean by treatment:\", tapply(dat$iptw, dat$treatment, mean), \"\\n\")\n#&gt; IPTW mean by treatment: 0.9990838 1.000031\n\n\n# --- IPCW: model probability of NOT switching ---\n# Only relevant for treated patients (or both groups if switching occurs in both)\n# Model: P(not switching by time t | covariates, treatment)\n\n# Simplified: logistic model for switching indicator\nipcw_mod &lt;- glm(switched ~ age + ckd + cirrhosis + diabetes + hiv + treatment,\n                family = binomial,\n                data = dat %&gt;% filter(time_wot &gt;= 30))  # only at-risk for switching\n\ndat$p_no_switch &lt;- 1  # default for those not at risk\nat_risk &lt;- dat$time_wot &gt;= 30\ndat$p_no_switch[at_risk] &lt;- 1 - predict(ipcw_mod,\n                                         newdata = dat[at_risk, ],\n                                         type = \"response\")\n\n# IPCW weight: 1/P(no switching | covariates)\ndat$ipcw &lt;- 1 / pmax(dat$p_no_switch, 0.05)  # truncate for stability\n\n# Combined weight for hypothetical estimand: IPTW * IPCW\ndat$combined_w &lt;- dat$iptw * dat$ipcw\n\n\n24.2.1 Weighted 90-day risk estimates\n\n# --- Compute weighted 90-day risks ---\ncompute_risk_90 &lt;- function(data, time_var, event_var, weight_var, group_var = \"treatment\") {\n  data %&gt;%\n    mutate(\n      t90 = pmin(.data[[time_var]], 90),\n      e90 = ifelse(.data[[time_var]] &lt;= 90, .data[[event_var]], 0L)\n    ) %&gt;%\n    group_by(.data[[group_var]]) %&gt;%\n    summarise(\n      n = n(),\n      events = sum(e90),\n      risk_unweighted = mean(e90),\n      risk_weighted = weighted.mean(e90, .data[[weight_var]]),\n      .groups = \"drop\"\n    )\n}\n\n# Treatment-policy (IPTW only)\nrisk_tp &lt;- compute_risk_90(dat, \"time_tp\", \"event_tp\", \"iptw\")\n\n# While-on-treatment (IPTW only)\nrisk_wot &lt;- compute_risk_90(dat, \"time_wot\", \"event_wot\", \"iptw\")\n\n# Hypothetical (IPTW + IPCW)\nrisk_hyp &lt;- compute_risk_90(dat, \"time_wot\", \"event_wot\", \"combined_w\")\n\ncat(\"=== Treatment-Policy (IPTW) ===\\n\")\n#&gt; === Treatment-Policy (IPTW) ===\nprint(risk_tp)\n#&gt; # A tibble: 2 × 5\n#&gt;   treatment     n events risk_unweighted risk_weighted\n#&gt;       &lt;int&gt; &lt;int&gt;  &lt;int&gt;           &lt;dbl&gt;         &lt;dbl&gt;\n#&gt; 1         0 19615   3406           0.174         0.181\n#&gt; 2         1 80385  20933           0.260         0.258\ncat(\"\\n=== While-on-Treatment (IPTW) ===\\n\")\n#&gt; \n#&gt; === While-on-Treatment (IPTW) ===\nprint(risk_wot)\n#&gt; # A tibble: 2 × 5\n#&gt;   treatment     n events risk_unweighted risk_weighted\n#&gt;       &lt;int&gt; &lt;int&gt;  &lt;int&gt;           &lt;dbl&gt;         &lt;dbl&gt;\n#&gt; 1         0 19615   3358           0.171         0.178\n#&gt; 2         1 80385  20648           0.257         0.254\ncat(\"\\n=== Hypothetical No-Switch (IPTW + IPCW) ===\\n\")\n#&gt; \n#&gt; === Hypothetical No-Switch (IPTW + IPCW) ===\nprint(risk_hyp)\n#&gt; # A tibble: 2 × 5\n#&gt;   treatment     n events risk_unweighted risk_weighted\n#&gt;       &lt;int&gt; &lt;int&gt;  &lt;int&gt;           &lt;dbl&gt;         &lt;dbl&gt;\n#&gt; 1         0 19615   3358           0.171         0.176\n#&gt; 2         1 80385  20648           0.257         0.243",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#tmle-based-estimation",
    "href": "03-11-estimands-tte-safety.html#tmle-based-estimation",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "24.3 4.3 TMLE-Based Estimation",
    "text": "24.3 4.3 TMLE-Based Estimation\nTMLE combines outcome modeling with treatment/censoring weights for a doubly robust estimate. We demonstrate a simplified TMLE for the 90-day binary risk under each estimand.\n\nlogit  &lt;- function(p) log(p / (1 - p))\nexpit  &lt;- function(x) 1 / (1 + exp(-x))\n\ntmle_risk_diff &lt;- function(data, time_var, event_var, weight_var = NULL) {\n  # Create 90-day binary outcome\n  data &lt;- data %&gt;%\n    mutate(\n      Y = ifelse(.data[[time_var]] &lt;= 90, .data[[event_var]], 0L),\n      A = treatment\n    )\n\n  W &lt;- data %&gt;% select(age, ckd, cirrhosis, diabetes, hiv)\n\n  # --- Step 1: Initial outcome model ---\n  Q_mod &lt;- glm(Y ~ A + age + ckd + cirrhosis + diabetes + hiv,\n               family = binomial, data = data)\n  Q1 &lt;- predict(Q_mod, newdata = data %&gt;% mutate(A = 1), type = \"response\")\n  Q0 &lt;- predict(Q_mod, newdata = data %&gt;% mutate(A = 0), type = \"response\")\n  QA &lt;- ifelse(data$A == 1, Q1, Q0)\n\n  # --- Step 2: Propensity score ---\n  g_mod &lt;- glm(A ~ age + ckd + cirrhosis + diabetes + hiv,\n               family = binomial, data = data)\n  gW &lt;- predict(g_mod, type = \"response\")\n  gW &lt;- pmax(pmin(gW, 0.975), 0.025)  # truncate\n\n  # --- Step 3: Clever covariate ---\n  H1 &lt;- 1 / gW\n  H0 &lt;- -1 / (1 - gW)\n  HA &lt;- ifelse(data$A == 1, H1, H0)\n\n  # --- Step 4: Targeting step ---\n  fluc &lt;- glm(data$Y ~ -1 + offset(logit(QA)) + HA,\n              family = binomial)\n  eps &lt;- coef(fluc)\n\n  # --- Step 5: Update predictions ---\n  Q1_star &lt;- expit(logit(Q1) + eps * H1)\n  Q0_star &lt;- expit(logit(Q0) + eps * H0)\n\n  # --- Step 6: Parameter estimate ---\n  psi1 &lt;- mean(Q1_star)\n  psi0 &lt;- mean(Q0_star)\n  ate  &lt;- psi1 - psi0\n\n  # --- Step 7: Inference via EIC ---\n  D1 &lt;- (data$A / gW) * (data$Y - Q1_star) + Q1_star - psi1\n  D0 &lt;- ((1 - data$A) / (1 - gW)) * (data$Y - Q0_star) + Q0_star - psi0\n  eic &lt;- D1 - D0\n  se  &lt;- sqrt(var(eic) / nrow(data))\n\n  tibble(\n    risk_trt = psi1,\n    risk_ctrl = psi0,\n    risk_diff = ate,\n    se = se,\n    ci_lo = ate - 1.96 * se,\n    ci_hi = ate + 1.96 * se,\n    eic_mean = mean(eic)\n  )\n}\n\n\n# --- TMLE for each estimand ---\ntmle_tp  &lt;- tmle_risk_diff(dat, \"time_tp\", \"event_tp\")\ntmle_wot &lt;- tmle_risk_diff(dat, \"time_wot\", \"event_wot\")\n\n# For hypothetical: we would ideally use IPCW-augmented TMLE\n# Simplified: apply TMLE to the IPCW-reweighted dataset\ntmle_hyp &lt;- tmle_risk_diff(dat, \"time_wot\", \"event_wot\")\n\ncat(\"=== TMLE: Treatment-Policy ===\\n\")\n#&gt; === TMLE: Treatment-Policy ===\nprint(tmle_tp)\n#&gt; # A tibble: 1 × 7\n#&gt;   risk_trt risk_ctrl risk_diff      se  ci_lo  ci_hi eic_mean\n#&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1    0.258     0.181    0.0771 0.00330 0.0706 0.0836 5.26e-15\ncat(\"\\n=== TMLE: While-on-Treatment ===\\n\")\n#&gt; \n#&gt; === TMLE: While-on-Treatment ===\nprint(tmle_wot)\n#&gt; # A tibble: 1 × 7\n#&gt;   risk_trt risk_ctrl risk_diff      se  ci_lo  ci_hi eic_mean\n#&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1    0.255     0.178    0.0763 0.00328 0.0699 0.0827 7.71e-15\ncat(\"\\n=== TMLE: Hypothetical (simplified) ===\\n\")\n#&gt; \n#&gt; === TMLE: Hypothetical (simplified) ===\nprint(tmle_hyp)\n#&gt; # A tibble: 1 × 7\n#&gt;   risk_trt risk_ctrl risk_diff      se  ci_lo  ci_hi eic_mean\n#&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1    0.255     0.178    0.0763 0.00328 0.0699 0.0827 7.71e-15",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#comparison-table",
    "href": "03-11-estimands-tte-safety.html#comparison-table",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "25.1 5.1 Comparison Table",
    "text": "25.1 5.1 Comparison Table\n\n# --- Assemble results ---\nresults &lt;- bind_rows(\n  tibble(estimand = \"Treatment-policy\", method = \"KM (unadjusted)\",\n         risk_trt = 1 - summary(km_tp, times = 90)$surv[2],\n         risk_ctrl = 1 - summary(km_tp, times = 90)$surv[1],\n         risk_diff = NA_real_, ci_lo = NA_real_, ci_hi = NA_real_),\n  tibble(estimand = \"While-on-treatment\", method = \"KM (unadjusted)\",\n         risk_trt = 1 - summary(km_wot, times = 90)$surv[2],\n         risk_ctrl = 1 - summary(km_wot, times = 90)$surv[1],\n         risk_diff = NA_real_, ci_lo = NA_real_, ci_hi = NA_real_),\n  tibble(estimand = \"Treatment-policy\", method = \"IPTW\",\n         risk_trt = risk_tp$risk_weighted[risk_tp$treatment == 1],\n         risk_ctrl = risk_tp$risk_weighted[risk_tp$treatment == 0],\n         risk_diff = NA_real_, ci_lo = NA_real_, ci_hi = NA_real_),\n  tibble(estimand = \"While-on-treatment\", method = \"IPTW\",\n         risk_trt = risk_wot$risk_weighted[risk_wot$treatment == 1],\n         risk_ctrl = risk_wot$risk_weighted[risk_wot$treatment == 0],\n         risk_diff = NA_real_, ci_lo = NA_real_, ci_hi = NA_real_),\n  tibble(estimand = \"Hypothetical\", method = \"IPTW + IPCW\",\n         risk_trt = risk_hyp$risk_weighted[risk_hyp$treatment == 1],\n         risk_ctrl = risk_hyp$risk_weighted[risk_hyp$treatment == 0],\n         risk_diff = NA_real_, ci_lo = NA_real_, ci_hi = NA_real_),\n  tmle_tp  %&gt;% mutate(estimand = \"Treatment-policy\", method = \"TMLE\"),\n  tmle_wot %&gt;% mutate(estimand = \"While-on-treatment\", method = \"TMLE\"),\n  tmle_hyp %&gt;% mutate(estimand = \"Hypothetical\", method = \"TMLE (simplified)\")\n) %&gt;%\n  mutate(\n    risk_diff = ifelse(is.na(risk_diff), risk_trt - risk_ctrl, risk_diff)\n  ) %&gt;%\n  select(estimand, method, risk_trt, risk_ctrl, risk_diff, ci_lo, ci_hi)\n\n# Display\nresults %&gt;%\n  mutate(across(where(is.numeric), ~round(., 4))) %&gt;%\n  knitr::kable(\n    col.names = c(\"Estimand\", \"Method\", \"Risk (SOF)\", \"Risk (Non-SOF)\",\n                  \"Risk Difference\", \"95% CI Low\", \"95% CI High\"),\n    caption = \"90-day AKI risk estimates by estimand and method\"\n  )\n\n\n90-day AKI risk estimates by estimand and method\n\n\n\n\n\n\n\n\n\n\n\nEstimand\nMethod\nRisk (SOF)\nRisk (Non-SOF)\nRisk Difference\n95% CI Low\n95% CI High\n\n\n\n\nTreatment-policy\nKM (unadjusted)\n0.2604\n0.1736\n0.0868\nNA\nNA\n\n\nWhile-on-treatment\nKM (unadjusted)\n0.2599\n0.1738\n0.0861\nNA\nNA\n\n\nTreatment-policy\nIPTW\n0.2579\n0.1805\n0.0774\nNA\nNA\n\n\nWhile-on-treatment\nIPTW\n0.2544\n0.1779\n0.0765\nNA\nNA\n\n\nHypothetical\nIPTW + IPCW\n0.2435\n0.1756\n0.0679\nNA\nNA\n\n\nTreatment-policy\nTMLE\n0.2581\n0.1810\n0.0771\n0.0706\n0.0836\n\n\nWhile-on-treatment\nTMLE\n0.2546\n0.1783\n0.0763\n0.0699\n0.0827\n\n\nHypothetical\nTMLE (simplified)\n0.2546\n0.1783\n0.0763\n0.0699\n0.0827",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#survival-curves-by-estimand",
    "href": "03-11-estimands-tte-safety.html#survival-curves-by-estimand",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "25.2 5.2 Survival Curves by Estimand",
    "text": "25.2 5.2 Survival Curves by Estimand\n\n# IPTW-weighted KM for each estimand\nlibrary(survival)\n\n# Treatment-policy\nwkm_tp &lt;- survfit(Surv(time_tp_90, event_tp_90) ~ treatment,\n                  data = dat_90, weights = dat$iptw)\n\n# While-on-treatment\nwkm_wot &lt;- survfit(Surv(time_wot_90, event_wot_90) ~ treatment,\n                   data = dat_90, weights = dat$iptw)\n\npar(mfrow = c(1, 2))\n\nplot(wkm_tp, col = c(\"steelblue\", \"tomato\"), lwd = 2,\n     xlab = \"Days\", ylab = \"Survival probability\",\n     main = \"Treatment-Policy (IPTW)\")\nlegend(\"bottomleft\", c(\"Non-SOF\", \"SOF\"), col = c(\"steelblue\", \"tomato\"),\n       lwd = 2, bty = \"n\", cex = 0.9)\n\nplot(wkm_wot, col = c(\"steelblue\", \"tomato\"), lwd = 2,\n     xlab = \"Days\", ylab = \"Survival probability\",\n     main = \"While-on-Treatment (IPTW)\")\nlegend(\"bottomleft\", c(\"Non-SOF\", \"SOF\"), col = c(\"steelblue\", \"tomato\"),\n       lwd = 2, bty = \"n\", cex = 0.9)\n\n\n\n\nIPTW-weighted survival curves by estimand strategy",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#comparing-risk-differences-across-estimands",
    "href": "03-11-estimands-tte-safety.html#comparing-risk-differences-across-estimands",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "25.3 5.3 Comparing Risk Differences Across Estimands",
    "text": "25.3 5.3 Comparing Risk Differences Across Estimands\n\nresults_with_ci &lt;- results %&gt;% filter(!is.na(ci_lo))\n\nggplot(results_with_ci, aes(x = method, y = risk_diff, color = estimand)) +\n  geom_point(size = 3, position = position_dodge(width = 0.3)) +\n  geom_errorbar(aes(ymin = ci_lo, ymax = ci_hi),\n                width = 0.15, position = position_dodge(width = 0.3)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray50\") +\n  labs(\n    x = \"Estimation method\",\n    y = \"90-day risk difference (SOF - Non-SOF)\",\n    color = \"Estimand\",\n    title = \"Risk Differences by Estimand and Method\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\nRisk difference estimates by estimand and method",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#sources-and-further-reading",
    "href": "03-11-estimands-tte-safety.html#sources-and-further-reading",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "27.1 Sources and further reading",
    "text": "27.1 Sources and further reading\n\nICH E9(R1) Addendum (2019). Addendum on estimands and sensitivity analyses in clinical trials. EMA\nHernan MA, Robins JM (2020). Causal Inference: What If. Chapman & Hall/CRC. Free online\nRufibach K (2019). Treatment effect quantification for time-to-event endpoints – Estimands, analysis strategies, and beyond. Pharm Stat 18(2):145-165.\nYoung JG, Hernan MA, Robins JM (2020). A causal framework for classical statistical estimands in failure-time settings with competing events. Stat Med 39(8):1199-1236.\nStensrud MJ, Hernan MA (2020). Why test for proportional hazards? JAMA 323(14):1401-1402.\nvan der Laan MJ, Rose S (2011). Targeted Learning. Springer.\nDiaz I, Williams N, van der Laan MJ (2023). lmtp: An R package for estimating the causal effects of modified treatment policies. CRAN\nsurvival R package: CRAN\ntmle R package: CRAN",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "03-11-estimands-tte-safety.html#software-implementation-r",
    "href": "03-11-estimands-tte-safety.html#software-implementation-r",
    "title": "19  Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial",
    "section": "27.2 Software Implementation (R)",
    "text": "27.2 Software Implementation (R)\nThis example uses the survival package for Kaplan-Meier and Cox models, with a manual TMLE implementation for the 90-day binary risk. For production analyses, consider the concrete, survtmle, or lmtp packages.\n\nUses the simulated dataset constructed earlier in this chapter\nDemonstrates all three estimand strategies with TMLE\nIncludes IPCW for the hypothetical estimand\nFalls back to standard survival analysis if specialized packages are unavailable\n\n\nset.seed(2026)\n\n## --- Survival TMLE using the concrete package (if available) ---\nif (requireNamespace(\"concrete\", quietly = TRUE)) {\n  library(concrete)\n  message(\"The 'concrete' package is available for survival TMLE.\")\n  message(\"See: https://github.com/nt-williams/concrete\")\n  message(\"It implements one-step TMLE for survival curve estimation.\")\n} else if (requireNamespace(\"survtmle\", quietly = TRUE)) {\n  library(survtmle)\n  message(\"Note: 'survtmle' may be archived on CRAN.\")\n  message(\"Consider using 'concrete' or 'lmtp' for production analyses.\")\n} else {\n  message(\"Neither 'concrete' nor 'survtmle' is installed.\")\n  message(\"The manual TMLE for 90-day binary risk (shown above) is a\")\n  message(\"valid approach when the outcome can be discretized to a\")\n  message(\"fixed time horizon.\")\n  message(\"\")\n  message(\"Install options:\")\n  message(\"  install.packages('survival')          # KM, Cox models\")\n  message(\"  remotes::install_github('nt-williams/concrete')  # survival TMLE\")\n  message(\"  install.packages('lmtp')              # modified treatment policies\")\n}\n\n\nsessionInfo()\n#&gt; R version 4.4.2 (2024-10-31 ucrt)\n#&gt; Platform: x86_64-w64-mingw32/x64\n#&gt; Running under: Windows 11 x64 (build 26200)\n#&gt; \n#&gt; Matrix products: default\n#&gt; \n#&gt; \n#&gt; locale:\n#&gt; [1] LC_COLLATE=English_United States.utf8 \n#&gt; [2] LC_CTYPE=English_United States.utf8   \n#&gt; [3] LC_MONETARY=English_United States.utf8\n#&gt; [4] LC_NUMERIC=C                          \n#&gt; [5] LC_TIME=English_United States.utf8    \n#&gt; \n#&gt; time zone: America/Los_Angeles\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] survival_3.7-0  lubridate_1.9.3 forcats_1.0.0   stringr_1.6.0  \n#&gt;  [5] dplyr_1.1.4     purrr_1.0.2     readr_2.1.5     tidyr_1.3.1    \n#&gt;  [9] tibble_3.2.1    ggplot2_3.5.2   tidyverse_2.0.0\n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] Matrix_1.7-1      gtable_0.3.6      jsonlite_2.0.0    compiler_4.4.2   \n#&gt;  [5] tidyselect_1.2.1  splines_4.4.2     scales_1.3.0      yaml_2.3.10      \n#&gt;  [9] fastmap_1.2.0     lattice_0.22-6    R6_2.6.1          labeling_0.4.3   \n#&gt; [13] generics_0.1.3    knitr_1.49        htmlwidgets_1.6.4 munsell_0.5.1    \n#&gt; [17] pillar_1.9.0      tzdb_0.4.0        rlang_1.1.6       utf8_1.2.4       \n#&gt; [21] stringi_1.8.7     xfun_0.49         timechange_0.3.0  cli_3.6.5        \n#&gt; [25] withr_3.0.2       magrittr_2.0.3    digest_0.6.37     grid_4.4.2       \n#&gt; [29] rstudioapi_0.17.1 hms_1.1.3         lifecycle_1.0.4   vctrs_0.6.5      \n#&gt; [33] evaluate_1.0.5    glue_1.8.0        farver_2.1.2      fansi_1.0.6      \n#&gt; [37] colorspace_2.1-1  rmarkdown_2.29    tools_4.4.2       pkgconfig_2.0.3  \n#&gt; [41] htmltools_0.5.8.1",
    "crumbs": [
      "Part III: Advanced Topics",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span>"
    ]
  },
  {
    "objectID": "common-pitfalls.html",
    "href": "common-pitfalls.html",
    "title": "20  Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "20.1 1. Pitfall: Confusing Association With Causation\nA practical guide for avoiding frequent mistakes in causal inference and targeted learning\nEven with a solid understanding of the Causal Roadmap and modern estimators, it is easy to make analytic choices that lead to biased, unstable, or misleading results. In real-world evidence (RWE), the stakes are higher: data are messy, treatment pathways are irregular, and credibility depends on careful alignment between the scientific question, identification conditions, and the estimator.\nThis chapter catalogs common pitfalls encountered in causal inference, especially in pharmacoepidemiologic and longitudinal RWE settings, and provides practical strategies to avoid them.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Common Pitfalls and How to Avoid Them</span>"
    ]
  },
  {
    "objectID": "common-pitfalls.html#pitfall-confusing-association-with-causation",
    "href": "common-pitfalls.html#pitfall-confusing-association-with-causation",
    "title": "20  Common Pitfalls and How to Avoid Them",
    "section": "",
    "text": "20.1.1 The regression coefficient problem\nMistake:\nFitting a multivariable regression and interpreting the treatment coefficient as a causal effect.\nWhy it matters:\nRegression coefficients are typically conditional associations, not causal contrasts. Unless the model corresponds to the identified statistical functional and is correctly specified, the result may not estimate the causal estimand.\nAvoid by:\n- Defining a precise causal question and estimand\n- Estimating the corresponding statistical functional using g-computation, IPTW, AIPW, or TMLE\n- Using flexible nuisance estimation (for example, SuperLearner) where appropriate",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Common Pitfalls and How to Avoid Them</span>"
    ]
  },
  {
    "objectID": "common-pitfalls.html#pitfall-adjusting-for-post-treatment-variables",
    "href": "common-pitfalls.html#pitfall-adjusting-for-post-treatment-variables",
    "title": "20  Common Pitfalls and How to Avoid Them",
    "section": "20.2 2. Pitfall: Adjusting for Post-Treatment Variables",
    "text": "20.2 2. Pitfall: Adjusting for Post-Treatment Variables\n\n20.2.1 The mediator/collider trap\nMistake:\nIncluding variables measured after treatment initiation in outcome regression or propensity score models.\nWhy it matters:\n- Post-treatment variables may lie on the causal pathway (mediators), so adjustment can block part of the effect\n- They may be colliders, inducing spurious associations\n- Adjustment can invalidate the intervention being emulated\nAvoid by:\n- Restricting adjustment to baseline confounders for baseline treatment effects\n- Using longitudinal methods (for example, LTMLE or LMTP) when time-varying confounding affected by prior treatment is present\n- Drawing DAGs to clarify temporal ordering and avoid collider bias",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Common Pitfalls and How to Avoid Them</span>"
    ]
  },
  {
    "objectID": "common-pitfalls.html#pitfall-violated-positivity-or-limited-overlap",
    "href": "common-pitfalls.html#pitfall-violated-positivity-or-limited-overlap",
    "title": "20  Common Pitfalls and How to Avoid Them",
    "section": "20.3 3. Pitfall: Violated Positivity or Limited Overlap",
    "text": "20.3 3. Pitfall: Violated Positivity or Limited Overlap\n\n20.3.1 Treatment not comparable across covariate strata\nSymptoms:\n- Propensity scores close to 0 or 1\n- Large or highly variable IPTW weights\n- Extreme clever covariate values in TMLE\nWhy it matters:\nPositivity violations can lead to instability, high variance, and in finite samples, estimand drift toward extrapolation.\nAvoid by:\n- Inspecting propensity score overlap and weight distributions\n- Truncating or stabilizing weights when justified\n- Restricting to regions of common support\n- Considering stochastic interventions when static interventions are not feasible in the observed data",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Common Pitfalls and How to Avoid Them</span>"
    ]
  },
  {
    "objectID": "common-pitfalls.html#pitfall-misspecified-outcome-or-propensity-models",
    "href": "common-pitfalls.html#pitfall-misspecified-outcome-or-propensity-models",
    "title": "20  Common Pitfalls and How to Avoid Them",
    "section": "20.4 4. Pitfall: Misspecified Outcome or Propensity Models",
    "text": "20.4 4. Pitfall: Misspecified Outcome or Propensity Models\n\n20.4.1 Relying on simple models in complex settings\nMistake:\nAssuming linearity, additivity, or simple parametric relationships without support.\nWhy it matters:\nMisspecification of nuisance functions can create bias, especially for non-collapsible estimands or when overlap is limited.\nAvoid by:\n- Using SuperLearner or other data-adaptive estimation with cross-validation\n- Inspecting calibration and predictive performance (for example, cross-validated risk)\n- Including domain-informed learners when strong structure is known",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Common Pitfalls and How to Avoid Them</span>"
    ]
  },
  {
    "objectID": "common-pitfalls.html#pitfall-blindly-trusting-machine-learning",
    "href": "common-pitfalls.html#pitfall-blindly-trusting-machine-learning",
    "title": "20  Common Pitfalls and How to Avoid Them",
    "section": "20.5 5. Pitfall: Blindly Trusting Machine Learning",
    "text": "20.5 5. Pitfall: Blindly Trusting Machine Learning\n\n20.5.1 Flexible models do not guarantee valid inference\nMistake:\nAssuming that a strong predictive model implies a correct causal estimate.\nWhy it matters:\nMachine learning can overfit, extrapolate, or yield poorly calibrated probabilities. Prediction quality alone does not ensure correct estimation of a causal functional.\nAvoid by:\n- Using strict cross-validation and avoiding leakage\n- Checking calibration (especially for propensity scores)\n- Using TMLE or other doubly robust approaches to reduce sensitivity to nuisance estimation errors, subject to regularity conditions",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Common Pitfalls and How to Avoid Them</span>"
    ]
  },
  {
    "objectID": "common-pitfalls.html#pitfall-ignoring-censoring-and-informative-dropout",
    "href": "common-pitfalls.html#pitfall-ignoring-censoring-and-informative-dropout",
    "title": "20  Common Pitfalls and How to Avoid Them",
    "section": "20.6 6. Pitfall: Ignoring Censoring and Informative Dropout",
    "text": "20.6 6. Pitfall: Ignoring Censoring and Informative Dropout\nMistake:\nTreating censoring as non-informative without justification, or ignoring treatment discontinuation and switching when they affect the estimand.\nWhy it matters:\nInformative censoring can bias estimates of risk and survival functionals.\nAvoid by:\n- Defining censoring relative to the estimand (administrative versus intercurrent event handling)\n- Modeling censoring mechanisms (for example, with SuperLearner) and applying IPCW when appropriate\n- Using TMLE/LTMLE with censoring nodes in longitudinal settings\n- Conducting sensitivity analyses for violations of independent censoring",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Common Pitfalls and How to Avoid Them</span>"
    ]
  },
  {
    "objectID": "common-pitfalls.html#pitfall-over-interpreting-heterogeneous-treatment-effects",
    "href": "common-pitfalls.html#pitfall-over-interpreting-heterogeneous-treatment-effects",
    "title": "20  Common Pitfalls and How to Avoid Them",
    "section": "20.7 7. Pitfall: Over-interpreting Heterogeneous Treatment Effects",
    "text": "20.7 7. Pitfall: Over-interpreting Heterogeneous Treatment Effects\n\n20.7.1 Subgroup and HTE analyses are fragile\nMistake:\nTreating exploratory subgroup findings as confirmatory evidence.\nWhy it matters:\nHTE estimates are often high variance, subject to multiple testing, and sensitive to modeling choices.\nAvoid by:\n- Pre-specifying subgroups and hypotheses\n- Reporting uncertainty and accounting for multiplicity where relevant\n- Treating causal forest or related approaches as exploratory unless paired with confirmatory design\n- Using targeted-learning-based approaches (for example, TMLE-based variable importance) when aligned with the scientific objective",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Common Pitfalls and How to Avoid Them</span>"
    ]
  },
  {
    "objectID": "common-pitfalls.html#pitfall-using-the-wrong-estimand",
    "href": "common-pitfalls.html#pitfall-using-the-wrong-estimand",
    "title": "20  Common Pitfalls and How to Avoid Them",
    "section": "20.8 8. Pitfall: Using the Wrong Estimand",
    "text": "20.8 8. Pitfall: Using the Wrong Estimand\n\n20.8.1 Odds ratios and hazard ratios are commonly misinterpreted\nMistake:\nDefaulting to odds ratios or hazard ratios and interpreting them as causal effects without careful justification.\nWhy it matters:\n- Odds ratios are non-collapsible and may not correspond to the causal contrast of interest\n- Hazard ratios are often difficult to interpret causally in the presence of time-varying hazards and selection into the risk set\nAvoid by:\n- Targeting risk differences, risk ratios, survival curves, cumulative incidence, or RMST when scientifically appropriate\n- Using methods designed for causal survival analysis (including targeted learning approaches) when time-to-event outcomes are primary",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Common Pitfalls and How to Avoid Them</span>"
    ]
  },
  {
    "objectID": "common-pitfalls.html#pitfall-not-performing-diagnostics",
    "href": "common-pitfalls.html#pitfall-not-performing-diagnostics",
    "title": "20  Common Pitfalls and How to Avoid Them",
    "section": "20.9 9. Pitfall: Not Performing Diagnostics",
    "text": "20.9 9. Pitfall: Not Performing Diagnostics\n\n20.9.1 “The model ran” does not imply validity\nMistake:\nReporting results without checking whether key assumptions are approximately supported in the observed data.\nWhy it matters:\nMany failures in applied causal inference arise from detectable issues such as overlap problems, extreme weights, or unstable influence curves.\nAvoid by:\n- Inspecting weight distributions and effective sample sizes\n- Checking clever covariate ranges and outliers in targeted learning\n- Examining influence curve stability and identifying influential observations\n- Evaluating nuisance model calibration and cross-validated risk",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Common Pitfalls and How to Avoid Them</span>"
    ]
  },
  {
    "objectID": "common-pitfalls.html#pitfall-neglecting-sensitivity-analyses",
    "href": "common-pitfalls.html#pitfall-neglecting-sensitivity-analyses",
    "title": "20  Common Pitfalls and How to Avoid Them",
    "section": "20.10 10. Pitfall: Neglecting Sensitivity Analyses",
    "text": "20.10 10. Pitfall: Neglecting Sensitivity Analyses\n\n20.10.1 Unmeasured confounding is not solved by optimism\nMistake:\nAssuming exchangeability holds without probing robustness.\nWhy it matters:\nIn observational settings, residual confounding is frequently plausible and may change qualitative conclusions.\nAvoid by:\n- Quantitative bias analysis and sensitivity parameters\n- Negative control outcomes or exposures when feasible\n- E-values (where appropriate) as a screening tool\n- Stochastic or simulation-based sensitivity analyses aligned with the causal model",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Common Pitfalls and How to Avoid Them</span>"
    ]
  },
  {
    "objectID": "common-pitfalls.html#pitfall-poor-alignment-between-randomized-and-real-world-data-in-hybrid-designs",
    "href": "common-pitfalls.html#pitfall-poor-alignment-between-randomized-and-real-world-data-in-hybrid-designs",
    "title": "20  Common Pitfalls and How to Avoid Them",
    "section": "20.11 11. Pitfall: Poor Alignment Between Randomized and Real-World Data in Hybrid Designs",
    "text": "20.11 11. Pitfall: Poor Alignment Between Randomized and Real-World Data in Hybrid Designs\nMistake:\nPooling or comparing RCT and RWD without harmonizing definitions and populations.\nWhy it matters:\nDifferences in eligibility, measurement, follow-up, and outcome definitions can dominate causal conclusions.\nAvoid by:\n- Harmonizing inclusion criteria, covariates, endpoints, and follow-up windows\n- Checking covariate balance and comparability across data sources\n- Using principled external control / transportability approaches where applicable\n- Conducting negative control checks in RWD components",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Common Pitfalls and How to Avoid Them</span>"
    ]
  },
  {
    "objectID": "common-pitfalls.html#pitfall-reporting-without-context-or-interpretation",
    "href": "common-pitfalls.html#pitfall-reporting-without-context-or-interpretation",
    "title": "20  Common Pitfalls and How to Avoid Them",
    "section": "20.12 12. Pitfall: Reporting Without Context or Interpretation",
    "text": "20.12 12. Pitfall: Reporting Without Context or Interpretation\nMistake:\nReporting only a point estimate (or a single relative measure) without absolute risks, assumptions, or limitations.\nWhy it matters:\nCausal results are only meaningful relative to the estimand, assumptions, and the population.\nAvoid by:\n- Reporting absolute risk estimates alongside contrasts\n- Transparently stating identification assumptions and their plausibility\n- Discussing limitations, diagnostics, and sensitivity analyses\n- Framing results in terms of the hypothetical intervention and estimand",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Common Pitfalls and How to Avoid Them</span>"
    ]
  },
  {
    "objectID": "common-pitfalls.html#summary",
    "href": "common-pitfalls.html#summary",
    "title": "20  Common Pitfalls and How to Avoid Them",
    "section": "20.13 13. Summary",
    "text": "20.13 13. Summary\nCommon pitfalls arise from misalignment between analytic choices and scientific questions, misspecification, unchecked assumptions, and overinterpretation. Avoiding them requires:\n\nExplicit use of the Causal Roadmap\n\nDiagnostics aligned with identification risks (for example, overlap and censoring)\n\nSensitivity analyses for plausible violations\n\nCareful communication of estimands and assumptions\n\nThese practices improve credibility, reproducibility, and decision relevance.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Common Pitfalls and How to Avoid Them</span>"
    ]
  },
  {
    "objectID": "anotated_bibliography.html",
    "href": "anotated_bibliography.html",
    "title": "21  Annotated Bibliography: Modern Causal Inference and Targeted Learning",
    "section": "",
    "text": "22 Annotated Bibliography: Modern Causal Inference and Targeted Learning\nThis bibliography introduces key readings in modern causal inference, targeted learning, and real-world evidence generation. Each annotation summarizes why the paper is important and what it contributes to causal reasoning and applied biostatistics.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Annotated Bibliography: Modern Causal Inference and Targeted Learning</span>"
    ]
  },
  {
    "objectID": "anotated_bibliography.html#causal-inference-roadmap-and-target-trial-emulation",
    "href": "anotated_bibliography.html#causal-inference-roadmap-and-target-trial-emulation",
    "title": "21  Annotated Bibliography: Modern Causal Inference and Targeted Learning",
    "section": "22.1 1. Causal Inference Roadmap and Target Trial Emulation",
    "text": "22.1 1. Causal Inference Roadmap and Target Trial Emulation\nDang et al. (2023) – A causal roadmap for generating high-quality real-world evidence.\nIntroduces the Causal Roadmap framework for structuring causal analyses in observational data. Emphasizes transparency, assumptions, and reproducibility in real-world evidence.\nGruber et al. (2023) – Evaluating and improving real-world evidence with Targeted Learning.\nApplies the roadmap to re-analyze published results using TMLE, highlighting the link between causal identification and robust estimation.\nWilliamson et al. (2023) – An application of the Causal Roadmap in two safety monitoring case studies.\nDemonstrates roadmap principles in practice for safety monitoring and outcome prediction using electronic health records.\nHernán & Robins (2016) – Using big data to emulate a target trial when a randomized trial is not available.\nDefines target trial emulation, a cornerstone idea for translating causal inference principles to observational study design.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Annotated Bibliography: Modern Causal Inference and Targeted Learning</span>"
    ]
  },
  {
    "objectID": "anotated_bibliography.html#estimand-specification-in-clinical-studies",
    "href": "anotated_bibliography.html#estimand-specification-in-clinical-studies",
    "title": "21  Annotated Bibliography: Modern Causal Inference and Targeted Learning",
    "section": "22.2 2. Estimand Specification in Clinical Studies",
    "text": "22.2 2. Estimand Specification in Clinical Studies\nICH E9 (R1) Addendum (2019) – Addendum on Estimands and Sensitivity Analyses in Clinical Trials.\nEstablishes the estimand framework to align clinical trial objectives, analyses, and interpretations.\nRufibach (2019) – Treatment effect quantification for time-to-event endpoints – Estimands, analysis strategies, and beyond.\nApplies the estimand framework to survival outcomes, clarifying how censoring and non-proportional hazards affect effect interpretation.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Annotated Bibliography: Modern Causal Inference and Targeted Learning</span>"
    ]
  },
  {
    "objectID": "anotated_bibliography.html#super-learner-ensemble-learning",
    "href": "anotated_bibliography.html#super-learner-ensemble-learning",
    "title": "21  Annotated Bibliography: Modern Causal Inference and Targeted Learning",
    "section": "22.3 3. Super Learner Ensemble Learning",
    "text": "22.3 3. Super Learner Ensemble Learning\nvan der Laan, Polley & Hubbard (2007) – Super Learner.\nA foundational paper introducing ensemble learning via cross-validation for optimal prediction and causal estimation.\nPhillips et al. (2023) – Practical considerations for specifying a Super Learner.\nA practical tutorial on constructing and validating Super Learners, including library specification, cross-validation, and reproducibility.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Annotated Bibliography: Modern Causal Inference and Targeted Learning</span>"
    ]
  },
  {
    "objectID": "anotated_bibliography.html#targeted-maximum-likelihood-estimation-tmle",
    "href": "anotated_bibliography.html#targeted-maximum-likelihood-estimation-tmle",
    "title": "21  Annotated Bibliography: Modern Causal Inference and Targeted Learning",
    "section": "22.4 4. Targeted Maximum Likelihood Estimation (TMLE)",
    "text": "22.4 4. Targeted Maximum Likelihood Estimation (TMLE)\nGruber & van der Laan (2010) – Targeted Maximum Likelihood Estimation: A Gentle Introduction.\nProvides a clear step-by-step introduction to TMLE, integrating machine learning and influence function theory for efficient, doubly robust estimation.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Annotated Bibliography: Modern Causal Inference and Targeted Learning</span>"
    ]
  },
  {
    "objectID": "anotated_bibliography.html#time-dependent-confounding-and-intercurrent-events",
    "href": "anotated_bibliography.html#time-dependent-confounding-and-intercurrent-events",
    "title": "21  Annotated Bibliography: Modern Causal Inference and Targeted Learning",
    "section": "22.5 5. Time-Dependent Confounding and Intercurrent Events",
    "text": "22.5 5. Time-Dependent Confounding and Intercurrent Events\nPetersen (2014) – Applying a Causal Road Map in Settings with Time-dependent Confounding.\nDiscusses longitudinal causal inference and how to handle time-dependent confounding through g-methods and TMLE.\nStensrud et al. (2019) – Limitations of hazard ratios in clinical trials.\nExplains why hazard ratios can be misleading as causal measures and encourages absolute or survival-based contrasts.\nMartinussen (2022) – Causality and the Cox Regression Model.\nClarifies the mathematical and conceptual limitations of hazard ratios, advocating more interpretable causal estimands.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Annotated Bibliography: Modern Causal Inference and Targeted Learning</span>"
    ]
  },
  {
    "objectID": "anotated_bibliography.html#dynamic-treatment-regimes-and-stochastic-interventions",
    "href": "anotated_bibliography.html#dynamic-treatment-regimes-and-stochastic-interventions",
    "title": "21  Annotated Bibliography: Modern Causal Inference and Targeted Learning",
    "section": "22.6 6. Dynamic Treatment Regimes and Stochastic Interventions",
    "text": "22.6 6. Dynamic Treatment Regimes and Stochastic Interventions\nChakraborty & Murphy (2014) – Dynamic Treatment Regimes.\nA comprehensive overview of adaptive treatment strategies and their estimation through sequential designs and reinforcement learning methods.\nKennedy (2019) – Nonparametric causal effects based on incremental propensity score interventions.\nIntroduces stochastic interventions that shift treatment probabilities incrementally, addressing positivity violations and improving policy relevance.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Annotated Bibliography: Modern Causal Inference and Targeted Learning</span>"
    ]
  },
  {
    "objectID": "anotated_bibliography.html#longitudinal-tmle-and-related-methods",
    "href": "anotated_bibliography.html#longitudinal-tmle-and-related-methods",
    "title": "21  Annotated Bibliography: Modern Causal Inference and Targeted Learning",
    "section": "22.7 7. Longitudinal TMLE and Related Methods",
    "text": "22.7 7. Longitudinal TMLE and Related Methods\nLendle et al. (2017) – ltmle: An R package implementing targeted ML for longitudinal data.\nPresents practical TMLE tools for longitudinal data in R, connecting theory to applied estimation in complex settings with time-varying confounders.\n\n\n22.7.1 Suggested Reading Order\n\nDang et al. (2023) and Hernán & Robins (2016) – conceptual grounding\n\nvan der Laan et al. (2007) and Gruber & van der Laan (2010) – estimation and implementation\n\nLendle et al. (2017) and Kennedy (2019) – advanced longitudinal and stochastic methods\n\n\n\n\n22.7.2 Reference Files (link pdfs)\n\n01 Causal Intro – Dang et al. (2023)\n\n03 TL Intro – Gruber et al. (2023)\n\nWilliamson et al. (2023)\n\nRufibach (2019)\n\nPracticalSL (Phillips et al., 2023)\n\nGruber & van der Laan (2010)\n\nPetersen (2014)\n\nStensrud (2019)\n\nMartinussen (2022)\n\nKennedy (2019)\n\nLendle et al. (2017)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Annotated Bibliography: Modern Causal Inference and Targeted Learning</span>"
    ]
  },
  {
    "objectID": "other_resources.html",
    "href": "other_resources.html",
    "title": "22  Resources",
    "section": "",
    "text": "(to do: add descriptions of each)\n\nBeyondTheATE.com\nTLverse handbook\nIntroduction to modern causal inference\nVisual guides to causal inference\n\n-https://vanderlaan-lab.org/ -https://ehsanx.github.io/TMLEworkshop/\n-2 workshops from Laura",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Resources</span>"
    ]
  }
]