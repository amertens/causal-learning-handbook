[["index.html", "Resources Chapter 1 Welcome!", " Resources Chapter 1 Welcome! This site introduces the Causal Roadmap, Targeted Maximum Likelihood Estimation (TMLE), and Super Learner for modern causal inference in epidemiology, with an emphasis on pharmacoepidemiology and clinical trial analysis. "],["chapter-2.4-superlearner-and-machine-learning-for-causal-inference.html", "Chapter 2 Chapter 2.4: SuperLearner and Machine Learning for Causal Inference 2.1 1. Why Use SuperLearner in Causal Inference? 2.2 2. Conceptual Overview of SuperLearner 2.3 3. A Minimal Working Example 2.4 4. Using the SuperLearner Package 2.5 5. Choosing a Loss Function: MSE vs Log-Likelihood vs AUC 2.6 6. Interpreting CV-Risk and Coefficient Weights 2.7 7. Customizing the Library and Tuning Learners 2.8 8. Cross-Validated SuperLearner (CV.SuperLearner) 2.9 9. Integrating SuperLearner into Causal Inference 2.10 10. Practical Tips for Using SuperLearner 2.11 11. Summary", " Chapter 2 Chapter 2.4: SuperLearner and Machine Learning for Causal Inference Flexible prediction to strengthen causal effect estimation Modern causal inference relies on estimating nuisance functions (outcome regressions and treatment / censoring mechanisms) that are as accurate as possible. If these models are mis-specified, even sophisticated causal estimators can be biased. Rather than gambling on a single model (e.g., logistic regression), we can stack many candidate learners and let the data decide how to combine them. This is what SuperLearner does. In this chapter you will learn: The intuition behind SuperLearner (SL) and stacking How cross-validation is used to avoid overfitting How to build and interpret SuperLearner models in R When and why to choose different loss functions (MSE, log-likelihood, AUC) How to customize SL libraries and tune algorithms How SL integrates with TMLE and other causal estimators This chapter leans heavily on the excellent visual tutorial by Katherine Hoffman and the SuperLearner demo by David Benkeser (both provided as PDFs), and recasts them in a causal-inference focused Quarto format. 2.1 1. Why Use SuperLearner in Causal Inference? Causal estimators such as g-computation, IPTW, AIPW, and TMLE rely on estimating: The outcome regression: \\(Q(W, A) = E[Y \\mid W, A]\\) The treatment (or censoring) mechanism: \\(g(W) = P(A = 1 \\mid W)\\) In traditional practice, both are often modeled with simple GLMs. This is dangerous when: Relationships are nonlinear Interactions are present There are many covariates We are unsure about which variables to include or in what functional form SuperLearner helps by: Combining multiple algorithms (GLM, random forests, LASSO, boosted trees, etc.) Using K-fold cross-validation to evaluate and weight each algorithm Producing an ensemble predictor with theoretical guarantees (an “oracle inequality”): asymptotically, SL performs nearly as well as the best algorithm in the library In causal inference, we rarely care about prediction for its own sake, but good prediction of nuisance functions leads to better causal effect estimation. 2.2 2. Conceptual Overview of SuperLearner At a high level, SuperLearner does the following: Pick a set of candidate learners (the library). Split the data into K folds. For each learner: Fit on K-1 folds (training data), Predict on the held-out fold (validation data). Collect cross-validated predictions for every observation and every learner. Fit a metalearner (often a linear regression) that finds the optimal weighted combination of the learners’ predictions to minimize a chosen loss function (e.g., mean squared error, negative log-likelihood). Refit each base learner on the full dataset. Use the metalearner and the refit base learners to form the final ensemble and obtain predictions for new data. This is exactly the workflow illustrated in the “VISUAL GUIDE TO SUPERLEARNING” figure in the KHstats tutorial. 2.3 3. A Minimal Working Example We’ll start with a simple prediction problem, then connect it back to causal inference later. 2.3.1 3.1 Simulated data library(tidyverse) library(SuperLearner) set.seed(7) n &lt;- 2000 obs &lt;- tibble( id = 1:n, x1 = rnorm(n), x2 = rbinom(n, 1, plogis(10 * x1)), x3 = rbinom(n, 1, plogis(x1 * x2 + 0.5 * x2)), x4 = rnorm(n, mean = x1 * x2, sd = 0.5 * x3), y = x1 + x2 + x2 * x3 + sin(x4) + rnorm(n, sd = 0.2) ) glimpse(obs) ## Rows: 2,000 ## Columns: 6 ## $ id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, … ## $ x1 &lt;dbl&gt; 2.287247161, -1.196771682, -0.694292510, -0.412292951, -0.970673341, -0.947279945, 0.748139340, -0.116955226, 0.1526576… ## $ x2 &lt;int&gt; 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,… ## $ x3 &lt;int&gt; 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,… ## $ x4 &lt;dbl&gt; 1.50283924, 0.04260947, 0.00000000, 0.00000000, 0.00000000, 1.07555690, 0.90481789, 0.03292026, 0.15265763, 3.04174063,… ## $ y &lt;dbl&gt; 5.03669124, -1.13306036, -0.38284042, -0.28671230, -0.87539307, -0.23969890, 3.82052213, -0.25644487, 1.43066246, 3.979… The outcome y is a nonlinear function of the covariates, with interactions and a sine term. GLMs will struggle here. 2.4 4. Using the SuperLearner Package 2.4.1 4.1 Basic call We’ll start with a small library for illustration. set.seed(1234) X &lt;- obs %&gt;% select(x1:x4) %&gt;% as.data.frame() Y &lt;- obs$y SL.lib &lt;- c(&quot;SL.glm&quot;, # simple GLM &quot;SL.mean&quot;, # intercept-only &quot;SL.earth&quot;, # multivariate adaptive regression splines (MARS) &quot;SL.ranger&quot;) # random forest sl_fit &lt;- SuperLearner( Y = Y, X = X, newX = NULL, family = gaussian(), SL.library = SL.lib, method = &quot;method.NNLS&quot;, # non-negative least squares metalearner cvControl = list(V = 10L) ) sl_fit ## ## Call: ## SuperLearner(Y = Y, X = X, newX = NULL, family = gaussian(), SL.library = SL.lib, method = &quot;method.NNLS&quot;, cvControl = list(V = 10L)) ## ## ## ## Risk Coef ## SL.glm_All 0.15038334 0.0000000 ## SL.mean_All 4.52716718 0.0000000 ## SL.earth_All 0.04408952 0.8593302 ## SL.ranger_All 0.05735981 0.1406698 Key outputs: Risk: cross-validated risk (e.g., MSE) for each learner Coef: weight given to each learner in the ensemble The learner with the smallest CV-risk often gets the largest weight, but SL can combine learners. We can access the ensemble predictions: head(sl_fit$SL.predict) ## [,1] ## 1 5.36960217 ## 2 -1.15651994 ## 3 -0.66557910 ## 4 -0.39653932 ## 5 -0.94879355 ## 6 -0.04451723 and predictions from individual learners: head(sl_fit$library.predict) ## SL.glm_All SL.mean_All SL.earth_All SL.ranger_All ## 1 4.9119003 1.145784 5.44169210 4.9292158 ## 2 -0.9619611 1.145784 -1.14585410 -1.2216759 ## 3 -0.8907976 1.145784 -0.67326080 -0.6186528 ## 4 -0.6300543 1.145784 -0.40211488 -0.3624791 ## 5 -1.1463457 1.145784 -0.94947428 -0.9446351 ## 6 -0.1673960 1.145784 -0.01723667 -0.2111701 2.5 5. Choosing a Loss Function: MSE vs Log-Likelihood vs AUC SuperLearner allows different loss functions, which define what we mean by “best” prediction. 2.5.1 5.1 Mean Squared Error (MSE) Default for family = gaussian() Appropriate for continuous outcomes when we care about squared error: \\[ L(y, \\hat{y}) = (y - \\hat{y})^2 \\] Good when we want well-calibrated mean predictions Example (already used above): method = \"method.NNLS\" with family = gaussian() 2.5.2 5.2 Negative Log-Likelihood (Binomial deviance) Natural choice for binary outcomes when we care about probability calibration: \\[ L(y, \\hat{p}) = -[y \\log(\\hat{p}) + (1-y) \\log(1-\\hat{p})] \\] Strongly penalizes confident but wrong predictions Recommended for: Outcome models (Y binary) Treatment models (A binary) in causal inference Use method = \"method.NNloglik\" with family = binomial(). Example: # suppose Y is binary Y_bin &lt;- rbinom(n, 1, plogis(X$x1 + X$x2)) sl_loglik &lt;- SuperLearner( Y = Y_bin, X = X, family = binomial(), SL.library = c(&quot;SL.glm&quot;, &quot;SL.mean&quot;, &quot;SL.ranger&quot;), method = &quot;method.NNloglik&quot; ) sl_loglik ## ## Call: ## SuperLearner(Y = Y_bin, X = X, family = binomial(), SL.library = c(&quot;SL.glm&quot;, &quot;SL.mean&quot;, &quot;SL.ranger&quot;), method = &quot;method.NNloglik&quot;) ## ## ## ## Risk Coef ## SL.glm_All 0.5286216 0.8914129 ## SL.mean_All 0.6818619 0.0000000 ## SL.ranger_All 0.5537130 0.1085871 2.5.3 5.3 AUC / Rank Loss For classification problems where the ranking of probabilities matters more than calibration Common when choosing a threshold later (e.g., risk stratification) SuperLearner implementation: method = \"method.AUC\" Particularly useful when interested in discriminatory ability (e.g., disease risk scores) Example: library(cvAUC) # required by method.AUC sl_auc &lt;- SuperLearner( Y = Y_bin, X = X, family = binomial(), SL.library = c(&quot;SL.glm&quot;, &quot;SL.mean&quot;, &quot;SL.ranger&quot;), method = &quot;method.AUC&quot; ) ## Warning in method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames, : optim didn&#39;t converge when estimating the super learner ## coefficients, reason (see ?optim): 52 optim message: ERROR: ABNORMAL_TERMINATION_IN_LNSRCH sl_auc ## ## Call: ## SuperLearner(Y = Y_bin, X = X, family = binomial(), SL.library = c(&quot;SL.glm&quot;, &quot;SL.mean&quot;, &quot;SL.ranger&quot;), method = &quot;method.AUC&quot;) ## ## ## Risk Coef ## SL.glm_All 0.1938743 0.9988292700 ## SL.mean_All 0.5268196 0.0006672332 ## SL.ranger_All 0.2104779 0.0005034968 2.5.4 5.4 Which loss should I choose? For outcome models in TMLE/AIPW: If binary → log-likelihood (binomial deviance) If continuous → MSE or other appropriate distribution-based loss For treatment / censoring models in causal inference: Typically log-likelihood (because we want accurate estimates of P(A | W)) For pure classification (no causal estimation): Consider AUC loss (method.AUC) if ranking is the priority 2.6 6. Interpreting CV-Risk and Coefficient Weights sl_fit$cvRisk ## SL.glm_All SL.mean_All SL.earth_All SL.ranger_All ## 0.15038334 4.52716718 0.04408952 0.05735981 sl_fit$coef ## SL.glm_All SL.mean_All SL.earth_All SL.ranger_All ## 0.0000000 0.0000000 0.8593302 0.1406698 cvRisk shows cross-validated risk for each algorithm coef gives the ensemble weights (metalearner solution) An algorithm might have: Low risk → high weight High risk → weight near zero (effectively excluded) This matches the demonstration in the Benkeser notes where GLM dominates mean-only models when predicting MI. 2.7 7. Customizing the Library and Tuning Learners 2.7.1 7.1 Adding tuned versions of a learner (e.g., Random Forest) We can define bounded random forest variants with different hyperparameters. SL.ranger_mtry3 &lt;- function(..., mtry = 3){ SL.ranger(..., mtry = mtry) } SL.ranger_mtry4 &lt;- function(..., mtry = 4){ SL.ranger(..., mtry = mtry) } SL.lib_tuned &lt;- c(&quot;SL.glm&quot;, &quot;SL.earth&quot;, &quot;SL.ranger_mtry3&quot;, &quot;SL.ranger_mtry4&quot;) Then run: set.seed(123) sl_tuned &lt;- SuperLearner( Y = Y, X = X, family = gaussian(), SL.library = SL.lib_tuned, method = &quot;method.NNLS&quot; ) sl_tuned$cvRisk ## SL.glm_All SL.earth_All SL.ranger_mtry3_All SL.ranger_mtry4_All ## 0.15062184 0.04401740 0.05044671 0.05242569 sl_tuned$coef ## SL.glm_All SL.earth_All SL.ranger_mtry3_All SL.ranger_mtry4_All ## 0.0000000 0.7318382 0.2681618 0.0000000 SuperLearner automatically picks which tuned version (or combination) works best. 2.8 8. Cross-Validated SuperLearner (CV.SuperLearner) CV.SuperLearner adds an outer layer of cross-validation to evaluate SL versus its components objectively. set.seed(123) cv_sl &lt;- CV.SuperLearner( Y = Y, X = X, V = 5, family = gaussian(), SL.library = SL.lib ) cv_sl ## ## Call: CV.SuperLearner(Y = Y, X = X, V = 5, family = gaussian(), SL.library = SL.lib) ## ## ## Cross-validated predictions from the SuperLearner: SL.predict ## ## Cross-validated predictions from the discrete super learner (cross-validation selector): discreteSL.predict ## ## Which library algorithm was the discrete super learner: whichDiscreteSL ## ## Cross-validated prediction for all algorithms in the library: library.predict plot(cv_sl) The plot shows: Cross-validated risks and confidence intervals for each learner Performance of the discrete and continuous SuperLearner This step is particularly helpful when you want to justify using SL rather than a single, simpler algorithm. 2.9 9. Integrating SuperLearner into Causal Inference So far we focused on prediction. How does this relate to causal inference? For a point-treatment ATE, a TMLE analysis might look like: # Example skeleton (you will flesh this out later with your own data) library(tmle) tmle_fit &lt;- tmle( Y = Y_bin, # binary outcome A = A, # treatment W = X, # covariates family = &quot;binomial&quot;, Q.SL.library = c(&quot;SL.glm&quot;, &quot;SL.ranger&quot;, &quot;SL.earth&quot;), g.SL.library = c(&quot;SL.glm&quot;, &quot;SL.ranger&quot;, &quot;SL.mean&quot;) ) tmle_fit$estimates$ATE Here: Q.SL.library is used to estimate outcome regression E[Y|A,W] g.SL.library is used to estimate propensity scores P(A|W) TMLE combines these with targeting to produce an efficient, doubly robust estimate Key advantages: You no longer need to guess the “right” model for Y or A You can include many flexible learners without overfitting (thanks to SL + CV) Your causal inference relies less on arbitrary parametric modeling choices 2.10 10. Practical Tips for Using SuperLearner Start with a modest but diverse library GLM (SL.glm) Random forest (SL.ranger or SL.randomForest) MARS (SL.earth) Penalized regression (SL.glmnet) Pick loss functions that match your problem Binary → log-likelihood (for calibration) or AUC (for ranking) Continuous → MSE Watch computation time SL is more expensive than a single GLM, especially with many learners and CV folds. Use SL primarily on nuisance functions Don’t use SL to directly estimate the causal effect; instead, use SL to estimate Q and g and feed these into TMLE, AIPW, etc. Inspect SL outputs Which learners are getting weight? Are any learners consistently poor performers? Do you need to adjust your library? 2.11 11. Summary In this chapter you learned How SuperLearner combines multiple algorithms using cross-validation and a metalearner The role of loss functions (MSE, log-likelihood, AUC) and when to choose each How to implement SuperLearner in R, inspect CV-risk and weights, and customize the library How SuperLearner supports reliable causal inference by improving nuisance function estimation and integrating seamlessly with TMLE and other estimators Next, we move to Module 3, where we tackle longitudinal data, dynamic treatment regimes, and modified treatment policies, often using SuperLearner as a core building block. "],["chapter-x-common-pitfalls-and-how-to-avoid-them.html", "Chapter 3 Chapter X: Common Pitfalls and How to Avoid Them 3.1 1. Pitfall: Confusing Association With Causation 3.2 2. Pitfall: Adjusting for Post-Treatment Variables 3.3 3. Pitfall: Violated Positivity or Limited Overlap 3.4 4. Pitfall: Misspecified Outcome or Propensity Models 3.5 5. Pitfall: Blindly Trusting Machine Learning 3.6 6. Pitfall: Ignoring Censoring and Informative Dropout 3.7 7. Pitfall: Over-interpreting Heterogeneous Treatment Effects 3.8 8. Pitfall: Using the Wrong Estimand 3.9 9. Pitfall: Not Performing Diagnostics 3.10 10. Pitfall: Neglecting Sensitivity Analyses 3.11 11. Pitfall: Poor Alignment Between Randomized and Real-World Data in Hybrid Designs 3.12 12. Pitfall: Reporting Without Context or Interpretation 3.13 13. Summary", " Chapter 3 Chapter X: Common Pitfalls and How to Avoid Them A practical guide for avoiding frequent mistakes in causal inference and targeted learning Even with a solid understanding of the Causal Roadmap and modern estimators, it is easy to make analytic choices that lead to biased, unstable, or misleading results. In real-world evidence (RWE), the stakes are higher: data are messy, treatment pathways are irregular, and credibility depends on careful alignment between the scientific question, identification conditions, and the estimator. This chapter catalogs common pitfalls encountered in causal inference, especially in pharmacoepidemiologic and longitudinal RWE settings, and provides practical strategies to avoid them. 3.1 1. Pitfall: Confusing Association With Causation 3.1.1 The regression coefficient problem Mistake: Fitting a multivariable regression and interpreting the treatment coefficient as a causal effect. Why it matters: Regression coefficients are typically conditional associations, not causal contrasts. Unless the model corresponds to the identified statistical functional and is correctly specified, the result may not estimate the causal estimand. Avoid by: - Defining a precise causal question and estimand - Estimating the corresponding statistical functional using g-computation, IPTW, AIPW, or TMLE - Using flexible nuisance estimation (for example, SuperLearner) where appropriate 3.2 2. Pitfall: Adjusting for Post-Treatment Variables 3.2.1 The mediator/collider trap Mistake: Including variables measured after treatment initiation in outcome regression or propensity score models. Why it matters: - Post-treatment variables may lie on the causal pathway (mediators), so adjustment can block part of the effect - They may be colliders, inducing spurious associations - Adjustment can invalidate the intervention being emulated Avoid by: - Restricting adjustment to baseline confounders for baseline treatment effects - Using longitudinal methods (for example, LTMLE or LMTP) when time-varying confounding affected by prior treatment is present - Drawing DAGs to clarify temporal ordering and avoid collider bias 3.3 3. Pitfall: Violated Positivity or Limited Overlap 3.3.1 Treatment not comparable across covariate strata Symptoms: - Propensity scores close to 0 or 1 - Large or highly variable IPTW weights - Extreme clever covariate values in TMLE Why it matters: Positivity violations can lead to instability, high variance, and in finite samples, estimand drift toward extrapolation. Avoid by: - Inspecting propensity score overlap and weight distributions - Truncating or stabilizing weights when justified - Restricting to regions of common support - Considering stochastic interventions when static interventions are not feasible in the observed data 3.4 4. Pitfall: Misspecified Outcome or Propensity Models 3.4.1 Relying on simple models in complex settings Mistake: Assuming linearity, additivity, or simple parametric relationships without support. Why it matters: Misspecification of nuisance functions can create bias, especially for non-collapsible estimands or when overlap is limited. Avoid by: - Using SuperLearner or other data-adaptive estimation with cross-validation - Inspecting calibration and predictive performance (for example, cross-validated risk) - Including domain-informed learners when strong structure is known 3.5 5. Pitfall: Blindly Trusting Machine Learning 3.5.1 Flexible models do not guarantee valid inference Mistake: Assuming that a strong predictive model implies a correct causal estimate. Why it matters: Machine learning can overfit, extrapolate, or yield poorly calibrated probabilities. Prediction quality alone does not ensure correct estimation of a causal functional. Avoid by: - Using strict cross-validation and avoiding leakage - Checking calibration (especially for propensity scores) - Using TMLE or other doubly robust approaches to reduce sensitivity to nuisance estimation errors, subject to regularity conditions 3.6 6. Pitfall: Ignoring Censoring and Informative Dropout Mistake: Treating censoring as non-informative without justification, or ignoring treatment discontinuation and switching when they affect the estimand. Why it matters: Informative censoring can bias estimates of risk and survival functionals. Avoid by: - Defining censoring relative to the estimand (administrative versus intercurrent event handling) - Modeling censoring mechanisms (for example, with SuperLearner) and applying IPCW when appropriate - Using TMLE/LTMLE with censoring nodes in longitudinal settings - Conducting sensitivity analyses for violations of independent censoring 3.7 7. Pitfall: Over-interpreting Heterogeneous Treatment Effects 3.7.1 Subgroup and HTE analyses are fragile Mistake: Treating exploratory subgroup findings as confirmatory evidence. Why it matters: HTE estimates are often high variance, subject to multiple testing, and sensitive to modeling choices. Avoid by: - Pre-specifying subgroups and hypotheses - Reporting uncertainty and accounting for multiplicity where relevant - Treating causal forest or related approaches as exploratory unless paired with confirmatory design - Using targeted-learning-based approaches (for example, TMLE-based variable importance) when aligned with the scientific objective 3.8 8. Pitfall: Using the Wrong Estimand 3.8.1 Odds ratios and hazard ratios are commonly misinterpreted Mistake: Defaulting to odds ratios or hazard ratios and interpreting them as causal effects without careful justification. Why it matters: - Odds ratios are non-collapsible and may not correspond to the causal contrast of interest - Hazard ratios are often difficult to interpret causally in the presence of time-varying hazards and selection into the risk set Avoid by: - Targeting risk differences, risk ratios, survival curves, cumulative incidence, or RMST when scientifically appropriate - Using methods designed for causal survival analysis (including targeted learning approaches) when time-to-event outcomes are primary 3.9 9. Pitfall: Not Performing Diagnostics 3.9.1 “The model ran” does not imply validity Mistake: Reporting results without checking whether key assumptions are approximately supported in the observed data. Why it matters: Many failures in applied causal inference arise from detectable issues such as overlap problems, extreme weights, or unstable influence curves. Avoid by: - Inspecting weight distributions and effective sample sizes - Checking clever covariate ranges and outliers in targeted learning - Examining influence curve stability and identifying influential observations - Evaluating nuisance model calibration and cross-validated risk 3.10 10. Pitfall: Neglecting Sensitivity Analyses 3.10.1 Unmeasured confounding is not solved by optimism Mistake: Assuming exchangeability holds without probing robustness. Why it matters: In observational settings, residual confounding is frequently plausible and may change qualitative conclusions. Avoid by: - Quantitative bias analysis and sensitivity parameters - Negative control outcomes or exposures when feasible - E-values (where appropriate) as a screening tool - Stochastic or simulation-based sensitivity analyses aligned with the causal model 3.11 11. Pitfall: Poor Alignment Between Randomized and Real-World Data in Hybrid Designs Mistake: Pooling or comparing RCT and RWD without harmonizing definitions and populations. Why it matters: Differences in eligibility, measurement, follow-up, and outcome definitions can dominate causal conclusions. Avoid by: - Harmonizing inclusion criteria, covariates, endpoints, and follow-up windows - Checking covariate balance and comparability across data sources - Using principled external control / transportability approaches where applicable - Conducting negative control checks in RWD components 3.12 12. Pitfall: Reporting Without Context or Interpretation Mistake: Reporting only a point estimate (or a single relative measure) without absolute risks, assumptions, or limitations. Why it matters: Causal results are only meaningful relative to the estimand, assumptions, and the population. Avoid by: - Reporting absolute risk estimates alongside contrasts - Transparently stating identification assumptions and their plausibility - Discussing limitations, diagnostics, and sensitivity analyses - Framing results in terms of the hypothetical intervention and estimand 3.13 13. Summary Common pitfalls arise from misalignment between analytic choices and scientific questions, misspecification, unchecked assumptions, and overinterpretation. Avoiding them requires: Explicit use of the Causal Roadmap Diagnostics aligned with identification risks (for example, overlap and censoring) Sensitivity analyses for plausible violations Careful communication of estimands and assumptions These practices improve credibility, reproducibility, and decision relevance. "],["annotated-bibliography-modern-causal-inference-and-targeted-learning.html", "Chapter 4 Annotated Bibliography: Modern Causal Inference and Targeted Learning 4.1 1. Causal Inference Roadmap and Target Trial Emulation 4.2 2. Estimand Specification in Clinical Studies 4.3 3. Super Learner Ensemble Learning 4.4 4. Targeted Maximum Likelihood Estimation (TMLE) 4.5 5. Time-Dependent Confounding and Intercurrent Events 4.6 6. Dynamic Treatment Regimes and Stochastic Interventions 4.7 7. Longitudinal TMLE and Related Methods", " Chapter 4 Annotated Bibliography: Modern Causal Inference and Targeted Learning This bibliography introduces key readings in modern causal inference, targeted learning, and real-world evidence generation. Each annotation summarizes why the paper is important and what it contributes to causal reasoning and applied biostatistics. 4.0.1 to add: Targeted learning in real-world comparative effectiveness research with time-varying interventions https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6099 4.1 1. Causal Inference Roadmap and Target Trial Emulation Dang et al. (2023) – A causal roadmap for generating high-quality real-world evidence. Introduces the Causal Roadmap framework for structuring causal analyses in observational data. Emphasizes transparency, assumptions, and reproducibility in real-world evidence. Gruber et al. (2023) – Evaluating and improving real-world evidence with Targeted Learning. Applies the roadmap to re-analyze published results using TMLE, highlighting the link between causal identification and robust estimation. Williamson et al. (2023) – An application of the Causal Roadmap in two safety monitoring case studies. Demonstrates roadmap principles in practice for safety monitoring and outcome prediction using electronic health records. Hernán &amp; Robins (2016) – Using big data to emulate a target trial when a randomized trial is not available. Defines target trial emulation, a cornerstone idea for translating causal inference principles to observational study design. 4.2 2. Estimand Specification in Clinical Studies ICH E9 (R1) Addendum (2019) – Addendum on Estimands and Sensitivity Analyses in Clinical Trials. Establishes the estimand framework to align clinical trial objectives, analyses, and interpretations. Rufibach (2019) – Treatment effect quantification for time-to-event endpoints – Estimands, analysis strategies, and beyond. Applies the estimand framework to survival outcomes, clarifying how censoring and non-proportional hazards affect effect interpretation. 4.3 3. Super Learner Ensemble Learning van der Laan, Polley &amp; Hubbard (2007) – Super Learner. A foundational paper introducing ensemble learning via cross-validation for optimal prediction and causal estimation. Phillips et al. (2023) – Practical considerations for specifying a Super Learner. A practical tutorial on constructing and validating Super Learners, including library specification, cross-validation, and reproducibility. 4.4 4. Targeted Maximum Likelihood Estimation (TMLE) Gruber &amp; van der Laan (2010) – Targeted Maximum Likelihood Estimation: A Gentle Introduction. Provides a clear step-by-step introduction to TMLE, integrating machine learning and influence function theory for efficient, doubly robust estimation. 4.5 5. Time-Dependent Confounding and Intercurrent Events Petersen (2014) – Applying a Causal Road Map in Settings with Time-dependent Confounding. Discusses longitudinal causal inference and how to handle time-dependent confounding through g-methods and TMLE. Stensrud et al. (2019) – Limitations of hazard ratios in clinical trials. Explains why hazard ratios can be misleading as causal measures and encourages absolute or survival-based contrasts. Martinussen (2022) – Causality and the Cox Regression Model. Clarifies the mathematical and conceptual limitations of hazard ratios, advocating more interpretable causal estimands. 4.6 6. Dynamic Treatment Regimes and Stochastic Interventions Chakraborty &amp; Murphy (2014) – Dynamic Treatment Regimes. A comprehensive overview of adaptive treatment strategies and their estimation through sequential designs and reinforcement learning methods. Kennedy (2019) – Nonparametric causal effects based on incremental propensity score interventions. Introduces stochastic interventions that shift treatment probabilities incrementally, addressing positivity violations and improving policy relevance. 4.7 7. Longitudinal TMLE and Related Methods Lendle et al. (2017) – ltmle: An R package implementing targeted ML for longitudinal data. Presents practical TMLE tools for longitudinal data in R, connecting theory to applied estimation in complex settings with time-varying confounders. 4.7.1 Suggested Reading Order Dang et al. (2023) and Hernán &amp; Robins (2016) – conceptual grounding van der Laan et al. (2007) and Gruber &amp; van der Laan (2010) – estimation and implementation Lendle et al. (2017) and Kennedy (2019) – advanced longitudinal and stochastic methods 4.7.2 Reference Files (link pdfs) 01 Causal Intro – Dang et al. (2023) 03 TL Intro – Gruber et al. (2023) Williamson et al. (2023) Rufibach (2019) PracticalSL (Phillips et al., 2023) Gruber &amp; van der Laan (2010) Petersen (2014) Stensrud (2019) Martinussen (2022) Kennedy (2019) Lendle et al. (2017) (to do: add descriptions of each) BeyondTheATE.com TLverse handbook Introduction to modern causal inference Visual guides to causal inference -https://vanderlaan-lab.org/ -https://ehsanx.github.io/TMLEworkshop/ -2 workshops from Laura "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
