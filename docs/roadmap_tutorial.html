<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="A practical guide to the Causal Roadmap, Targeted Maximum Likelihood Estimation (TMLE), and Super Learner for modern causal inference in epidemiology, with emphasis on pharmacoepidemiology and clinical trial analysis.">

<title>5&nbsp; Causal Roadmap for Real-world Evidence Generation: A Tutorial – Causal Learning Handbook</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./02-01-gcomputation.html" rel="next">
<link href="./01-03-identification-estimands.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-b343bb23504f009ddf7b24643a6af19a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-01-regression-vs-causal.html">Part I: Foundations</a></li><li class="breadcrumb-item"><a href="./roadmap_tutorial.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Causal Roadmap for Real-world Evidence Generation: A Tutorial</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Causal Learning Handbook</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/amertens/causal-learning-handbook" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Causal Learning Handbook</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Part I: Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-01-regression-vs-causal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Chapter 1.1: Limitations of Standard Regression Analyses</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-02-causal-roadmap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Chapter 1.2: The Causal Roadmap</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-03-identification-estimands.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./roadmap_tutorial.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Causal Roadmap for Real-world Evidence Generation: A Tutorial</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Part II: Estimation Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-01-gcomputation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Chapter 2.1: Outcome Modeling and Standardization (G-Computation)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-02-iptw.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Chapter 2.2: Inverse Probability of Treatment Weighting (IPTW)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-03-doubly-robust-tmle.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Chapter 2.3: Doubly Robust Estimators and Targeted Learning (AIPW + TMLE)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-04-tmle-teaching-examples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Chapter 2.4: From Question to Estimate — TMLE in Practice</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./superlearner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Chapter 2.4: SuperLearner and Machine Learning for Causal Inference</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Part III: Advanced Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-03-longitudinal-case-study.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chapter 3.3: Case Study – Real-World Application in Longitudinal Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-04-effect-modification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Chapter 3.4: Effect Modification and Heterogeneous Treatment Effects</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-05-advanced-diagnostics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Chapter 3.5: Advanced Diagnostics and Sensitivity Analyses</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-06-rwd-meets-rct-hybrid-designs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Chapter 3.6: When RWD Meets RCT – Hybrid Designs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-07-longitudinal-td-confounding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Chapter 3.7: Imperfect Adherence, Time-Varying Confounding, and Longitudinal TMLE</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-08-tmle-clean-room.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Chapter 3.8: TMLE in the Clean-Room Framework for Pharmacoepidemiology</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-09-illustrated-ltmle.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">An Illustrated Guide to Longitudinal TMLE</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-10-tmle-mediation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">An Illustrated Guide to TMLE for Mediation Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-11-estimands-tte-safety.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Estimands in Time-to-Event Real-World Safety Analyses: A Simulation-Based Tutorial</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./common-pitfalls.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Common Pitfalls and How to Avoid Them</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./anotated_bibliography.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Annotated Bibliography: Modern Causal Inference and Targeted Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./other_resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Resources</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#to-do" id="toc-to-do" class="nav-link active" data-scroll-target="#to-do"><span class="header-section-number">5.1</span> To do</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"><span class="header-section-number">5.2</span> Introduction</a></li>
  <li><a href="#why-venture-down-a-new-path" id="toc-why-venture-down-a-new-path" class="nav-link" data-scroll-target="#why-venture-down-a-new-path"><span class="header-section-number">5.3</span> Why venture down a new path?</a></li>
  <li><a href="#motivation" id="toc-motivation" class="nav-link" data-scroll-target="#motivation"><span class="header-section-number">5.4</span> Motivation</a></li>
  <li><a href="#the-causal-roadmap" id="toc-the-causal-roadmap" class="nav-link" data-scroll-target="#the-causal-roadmap"><span class="header-section-number">5.5</span> The Causal Roadmap</a></li>
  <li><a href="#notation" id="toc-notation" class="nav-link" data-scroll-target="#notation"><span class="header-section-number">5.6</span> Notation</a></li>
  <li><a href="#step-0-state-the-question" id="toc-step-0-state-the-question" class="nav-link" data-scroll-target="#step-0-state-the-question"><span class="header-section-number">5.7</span> Step 0: State the question</a>
  <ul class="collapse">
  <li><a href="#target-trial-emulation" id="toc-target-trial-emulation" class="nav-link" data-scroll-target="#target-trial-emulation"><span class="header-section-number">5.7.1</span> Target Trial Emulation</a></li>
  </ul></li>
  <li><a href="#step-1-define-the-causal-model" id="toc-step-1-define-the-causal-model" class="nav-link" data-scroll-target="#step-1-define-the-causal-model"><span class="header-section-number">5.8</span> Step 1: Define the causal model</a></li>
  <li><a href="#step-2-define-the-causal-parameter-of-interest" id="toc-step-2-define-the-causal-parameter-of-interest" class="nav-link" data-scroll-target="#step-2-define-the-causal-parameter-of-interest"><span class="header-section-number">5.9</span> Step 2: Define the causal parameter of interest</a>
  <ul class="collapse">
  <li><a href="#estimand-specification" id="toc-estimand-specification" class="nav-link" data-scroll-target="#estimand-specification"><span class="header-section-number">5.9.1</span> Estimand Specification</a></li>
  <li><a href="#treatment-policy-versus-hypothetical-estimands" id="toc-treatment-policy-versus-hypothetical-estimands" class="nav-link" data-scroll-target="#treatment-policy-versus-hypothetical-estimands"><span class="header-section-number">5.9.2</span> Treatment-Policy versus Hypothetical Estimands</a></li>
  <li><a href="#intercurrent-events" id="toc-intercurrent-events" class="nav-link" data-scroll-target="#intercurrent-events"><span class="header-section-number">5.9.3</span> Intercurrent Events</a></li>
  <li><a href="#time-to-event-outcomes-and-risk-based-estimands" id="toc-time-to-event-outcomes-and-risk-based-estimands" class="nav-link" data-scroll-target="#time-to-event-outcomes-and-risk-based-estimands"><span class="header-section-number">5.9.4</span> Time-to-Event Outcomes and Risk-Based Estimands</a></li>
  </ul></li>
  <li><a href="#step-3-link-to-observed-data" id="toc-step-3-link-to-observed-data" class="nav-link" data-scroll-target="#step-3-link-to-observed-data"><span class="header-section-number">5.10</span> Step 3: Link to observed data</a>
  <ul class="collapse">
  <li><a href="#observed-data-censoring-rules" id="toc-observed-data-censoring-rules" class="nav-link" data-scroll-target="#observed-data-censoring-rules"><span class="header-section-number">5.10.1</span> Observed-Data Censoring Rules</a></li>
  </ul></li>
  <li><a href="#step-4-assess-identifiablity" id="toc-step-4-assess-identifiablity" class="nav-link" data-scroll-target="#step-4-assess-identifiablity"><span class="header-section-number">5.11</span> Step 4: Assess Identifiablity</a></li>
  <li><a href="#step-5-choose-and-apply-the-estimator" id="toc-step-5-choose-and-apply-the-estimator" class="nav-link" data-scroll-target="#step-5-choose-and-apply-the-estimator"><span class="header-section-number">5.12</span> Step 5: Choose and apply the estimator</a>
  <ul class="collapse">
  <li><a href="#simple-substitution-estimator-g-computation" id="toc-simple-substitution-estimator-g-computation" class="nav-link" data-scroll-target="#simple-substitution-estimator-g-computation"><span class="header-section-number">5.12.1</span> Simple substitution estimator (g-computation)</a></li>
  <li><a href="#iptw--inverse-probability-of-treatment-weighting-estimator" id="toc-iptw--inverse-probability-of-treatment-weighting-estimator" class="nav-link" data-scroll-target="#iptw--inverse-probability-of-treatment-weighting-estimator"><span class="header-section-number">5.12.2</span> IPTW- Inverse Probability of Treatment Weighting estimator</a></li>
  <li><a href="#tmle--targeted-maximum-likelihood-estimation" id="toc-tmle--targeted-maximum-likelihood-estimation" class="nav-link" data-scroll-target="#tmle--targeted-maximum-likelihood-estimation"><span class="header-section-number">5.12.3</span> TMLE- targeted maximum likelihood estimation</a></li>
  <li><a href="#estimator-properties" id="toc-estimator-properties" class="nav-link" data-scroll-target="#estimator-properties"><span class="header-section-number">5.12.4</span> Estimator Properties</a></li>
  </ul></li>
  <li><a href="#step-6-statistical-uncertainty" id="toc-step-6-statistical-uncertainty" class="nav-link" data-scroll-target="#step-6-statistical-uncertainty"><span class="header-section-number">5.13</span> Step 6: Statistical Uncertainty</a></li>
  <li><a href="#step-7-interpret-findings" id="toc-step-7-interpret-findings" class="nav-link" data-scroll-target="#step-7-interpret-findings"><span class="header-section-number">5.14</span> Step 7: Interpret findings</a></li>
  <li><a href="#summary-and-discussion" id="toc-summary-and-discussion" class="nav-link" data-scroll-target="#summary-and-discussion"><span class="header-section-number">5.15</span> Summary and Discussion</a></li>
  <li><a href="#caution-use-your-tools-well." id="toc-caution-use-your-tools-well." class="nav-link" data-scroll-target="#caution-use-your-tools-well."><span class="header-section-number">5.16</span> Caution: Use your tools well.</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-01-regression-vs-causal.html">Part I: Foundations</a></li><li class="breadcrumb-item"><a href="./roadmap_tutorial.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Causal Roadmap for Real-world Evidence Generation: A Tutorial</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Causal Roadmap for Real-world Evidence Generation: A Tutorial</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="to-do" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="to-do"><span class="header-section-number">5.1</span> To do</h2>
<p>(This workshop is in progress- updates to be made:)</p>
<ul>
<li>Make example data simulated within sheet for reproducibility, and make Y binary</li>
<li>Add webr implementation</li>
<li>Add more details on inference (step 6)</li>
<li>Add TMLE and LMTP code at the end</li>
<li></li>
</ul>
</section>
<section id="introduction" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="introduction"><span class="header-section-number">5.2</span> Introduction</h2>
<p>This tutorial provides a gentle introduction to the Causal Roadmap and its applications in pharmaco-epidemiologic research. It is designed for a broad audience, including learners from both academia and industry. We systematically walk through each step of the Causal Roadmap—from explicitly formulating a research question, to translating it into a formal causal estimand, to identifying and estimating that estimand from observed data, and finally to drawing valid inferences and interpreting results. Each step is illustrated using a working example from a pharmaco-epidemiology setting, accompanied by interactive, built-in code to facilitate hands-on learning. The structure and content of this tutorial are informed by the Introduction to Causal Inference and Causal Roadmap course developed by Maya Petersen and Laura Balzer (UC Berkeley Biostatistics): <a href="http://www.ucbbiostat.com/">http://www.ucbbiostat.com/</a>.</p>
</section>
<section id="why-venture-down-a-new-path" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="why-venture-down-a-new-path"><span class="header-section-number">5.3</span> Why venture down a new path?</h2>
<p>Adopting the Causal Roadmap in our approach to research in causal inference enables us to clearly state a scientific question and select an analytic approach that matches the question being asked while ensuring systematic assessment of our ability/feasibility to answer this question from the data we observe (identifiability). Comparing candidate estimators under a shared estimand supports principled method selection.</p>
</section>
<section id="motivation" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="motivation"><span class="header-section-number">5.4</span> Motivation</h2>
<ul>
<li>Suppose we are interested in the impact of Drug A vs Drug B on risk of cardiovascular disease among postmenopausal women with osteoporosis.</li>
<li>Our usual approach would be to collect data on the intervention, outcome (cardiovascular disease ) and some covariates.</li>
</ul>
<p>A common default is logistic regression, which targets a conditional odds ratio by exponentiating the regression coefficient on the intervention (treatment).. However, this conditional odds ratio is often not the estimand that matches the scientific question in real-world evidence settings. * The problem with this approach is that it allows the tool i.e.&nbsp;logistic regression to define the question we answer rather than starting with the question and picking amongst tools that allow us to answer the question. * To address this problem, we introduce the Causal Roadmap!</p>
</section>
<section id="the-causal-roadmap" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="the-causal-roadmap"><span class="header-section-number">5.5</span> The Causal Roadmap</h2>
<p>The Causal Roadmap is a framework that provides a systematic process to move from a research question to estimation and interpretation which guides investigators on how to design and analyse their studies a priori. This framework has the following steps;</p>
<ul>
<li>Stating the research question and hypothetical experiment</li>
<li>Defining the causal model and parameter of interest</li>
<li>Linking the causal model to the observed data and defining the statistical model</li>
<li>Assessing identifiability: linking the causal effect to a parameter estimable from the observed data</li>
<li>Selecting and applying the estimator</li>
<li>Deriving an estimate of the sampling distribution (statistical uncertainty)</li>
<li>Making inference (interpreting findings)</li>
</ul>
<p>We shall now delve into each of these steps in details after we go over some notation!</p>
</section>
<section id="notation" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="notation"><span class="header-section-number">5.6</span> Notation</h2>
<ul>
<li><strong><em>A</em></strong>: Exposure/Treatment
<ul>
<li>The term treatment is often used in causal inference even with exposures that are not medical treatments. We shall use A=1 for exposed (treated) and A=0 for unexposed (untreated)</li>
</ul></li>
<li><strong><em>Y</em></strong>: outcome</li>
<li><strong><em>W</em></strong>: set of measured confounding variables</li>
<li><strong><em>U</em></strong>: set of unmeasured factors</li>
<li><span class="math inline">\(\mathbb{E}[Y|A=a]\)</span>: expected outcome Y among those who experience exposure A=a in our population. This is a descriptive measure</li>
<li><span class="math inline">\(\mathbb{E}[Y_{a}]\)</span>: expected counterfactual outcome <span class="math inline">\(Y_a\)</span> when all experience exposure A=a in our population. This is a causal quantity. Generally <span class="math inline">\(\mathbb{E}[Y|A=a]\)</span> does not equal to <span class="math inline">\(\mathbb{E}[Y_{a}]\)</span> and this is the fundamental problem of causal inference</li>
<li><span class="math inline">\(\mathbb{E}[Y|A=a,W=w]\)</span>: expected outcome Y among those who expereince exposure A=a and have covariates W=w, in our population. For example this can be the mean outcome among exposed men. These conditional expectations are often estimated using multivariable regression models.</li>
<li><span class="math inline">\(\mathbb{E}[\mathbb{E}[Y|A=a,W=w]]\)</span>:expected outcome Y among those who experience exposure A=a and have covariates W=w,averaged across covariate strata in the population. This is a marginal expectation.</li>
</ul>
</section>
<section id="step-0-state-the-question" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="step-0-state-the-question"><span class="header-section-number">5.7</span> Step 0: State the question</h2>
<ul>
<li>This is the very first step of the roadmap. A helpful way to be clear about the scientific question is to explicitly state the experiment that would unambiguously yield estimates of the causal effect of interest.</li>
<li>For example: What is the effect of a certain medication on the incidence of cardiovascular disease among postmenopausal women who initiated Drug A vs Drug B in the United States?</li>
<li>We can consider a hypothetical experiment where we ask what would be the the difference in CVD incidence if patients received the intervention drug A vs if all patients received the control drug B (or standard of care).</li>
<li>To sharply frame our research question, we want to be more specific about;
<ul>
<li>The target population (What age group? where?)</li>
<li>The exposure (What dosage? Frequency?)</li>
<li>The outcome (over what timeframe?)</li>
<li>Ways to change the exposure and their plausibility</li>
</ul></li>
<li>Other interesting hypothetical experiments could include:
<ul>
<li>What would be the difference in CVD incidence if patients were initiated on drug A once they reached a certain risk threshold vs if all patients are initiated on Drug A regardless of their risk profile?</li>
<li>What would be the difference in CVD incidence if an additional 10% of patients received the intervention compared to if the intervention uptake remained as observed?</li>
</ul></li>
<li>We note that there is massive flexibility in how we can define our desired hypothetical experiments.</li>
</ul>
<section id="target-trial-emulation" class="level3" data-number="5.7.1">
<h3 data-number="5.7.1" class="anchored" data-anchor-id="target-trial-emulation"><span class="header-section-number">5.7.1</span> Target Trial Emulation</h3>
<p>The hypothetical experiment defined in Step 0 can be viewed as a target trial.</p>
<p>Observational studies aim to emulate this trial by aligning eligibility criteria, treatment assignment, follow-up, outcome definitions, and estimands.</p>
<p>The Causal Roadmap provides the formal structure for conducting such emulations transparently.</p>
</section>
</section>
<section id="step-1-define-the-causal-model" class="level2" data-number="5.8">
<h2 data-number="5.8" class="anchored" data-anchor-id="step-1-define-the-causal-model"><span class="header-section-number">5.8</span> Step 1: Define the causal model</h2>
<ul>
<li>Causal modeling formalizes our knowledge however limited. We are able to explore which variables affect each other, examine the role of unmeasured factors and the functional form of the relationships between variables.</li>
<li>In this tutorial, we shall focus on structural causal models and corresponding causal graphs (Pearl 2000). However, we do note that there are many other causal frameworks.</li>
<li>The figure 1 below corresponds to a simple causal graph with corresponding structural causal model as follows;
<ul>
<li><span class="math inline">\(W= f_w(U_w)\)</span></li>
<li><span class="math inline">\(A= f_A(W,U_A)\)</span></li>
<li><span class="math inline">\(Y = f_Y(W,A,U_Y)\)</span></li>
</ul></li>
<li>We make no assumptions on the background factors <span class="math inline">\((U_w,U_A,U_Y)\)</span> or on the functional forms of functions <span class="math inline">\((f_w,f_A,f_Y)\)</span></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="cm1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>If you believed no unmeasured confounding, a possible causal model and graph (figure 2) would be: * <span class="math inline">\(W= f_w(U_w)\)</span> * <span class="math inline">\(A= f_A(W,U_A)\)</span> * <span class="math inline">\(Y = f_Y(W,A,U_Y)\)</span></p>
<p>Here we assume that the background factors are all independent but still make no assumption on the functional forms of <span class="math inline">\((f_w,f_A,f_Y)\)</span>. However, keep in mind that this is an assumption we are making, and</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="cm2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="step-2-define-the-causal-parameter-of-interest" class="level2" data-number="5.9">
<h2 data-number="5.9" class="anchored" data-anchor-id="step-2-define-the-causal-parameter-of-interest"><span class="header-section-number">5.9</span> Step 2: Define the causal parameter of interest</h2>
<ul>
<li>We now define counterfactuals by intervening on the causal model. We can do this by setting the exposure to a specific level e.g A=1 for all units.
<ul>
<li><span class="math inline">\(W= f_w(U_w)\)</span></li>
<li><span class="math inline">\(A= 1\)</span></li>
<li><span class="math inline">\(Y_1 = f_Y(W,1,U_Y)\)</span> where <span class="math inline">\(Y_1\)</span> is the outcome if possibly-contrary to fact, the unit was exposed (A=1)</li>
</ul></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="cm3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>Analogously, we can intervene on the causal model by setting A=0
<ul>
<li><span class="math inline">\(W= f_w(U_w)\)</span></li>
<li><span class="math inline">\(A= 0\)</span></li>
<li><span class="math inline">\(Y_0 = f_Y(W,0,U_Y)\)</span> where <span class="math inline">\(Y_0\)</span> is the outcome if possibly-contrary to fact, the unit was exposed (A=0)</li>
</ul></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="cm5.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>We use counterfactuals to define the causal parameter:</p>
<ul>
<li>For example, the difference between the expected counterfactual outcomes under these two interventions i.e <span class="math inline">\(\mathbb{E}[Y_1]-\mathbb{E}[Y_0]\)</span> which is known as the average treatment effect(ATE)</li>
<li>For a binary outcome, like in this example. we define the causal risk difference (CRD) as <span class="math inline">\(\mathbb{P}(Y_1=1)-\mathbb{P}(Y_0=1)\)</span>.</li>
</ul>
<p>Many other causal parameters are possible!!</p>
<section id="estimand-specification" class="level3" data-number="5.9.1">
<h3 data-number="5.9.1" class="anchored" data-anchor-id="estimand-specification"><span class="header-section-number">5.9.1</span> Estimand Specification</h3>
<p>An estimand precisely defines the treatment effect of interest by specifying all attributes of the causal question.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 40%">
<col style="width: 60%">
</colgroup>
<thead>
<tr class="header">
<th>Attribute</th>
<th>Specification</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Population</td>
<td>Eligible individuals meeting study inclusion criteria</td>
</tr>
<tr class="even">
<td>Treatment Strategies</td>
<td>Intervention A versus comparator B</td>
</tr>
<tr class="odd">
<td>Endpoint</td>
<td>Binary or time-to-event outcome within a fixed horizon</td>
</tr>
<tr class="even">
<td>Intercurrent Events</td>
<td>Addressed via treatment-policy or hypothetical strategy</td>
</tr>
<tr class="odd">
<td>Summary Measure</td>
<td>Risk difference, risk ratio, or mean difference</td>
</tr>
</tbody>
</table>
<p>Explicit estimand specification ensures alignment between the scientific question, identification assumptions, and estimation strategy.</p>
<p><em>NOTE: cite ICH E9[R1] Framework here</em></p>
</section>
<section id="treatment-policy-versus-hypothetical-estimands" class="level3" data-number="5.9.2">
<h3 data-number="5.9.2" class="anchored" data-anchor-id="treatment-policy-versus-hypothetical-estimands"><span class="header-section-number">5.9.2</span> Treatment-Policy versus Hypothetical Estimands</h3>
<p>A treatment-policy estimand contrasts outcomes under initial treatment assignment regardless of subsequent treatment changes (i.e., intention-to-treat estimates as presented in this workshop).</p>
<p>A hypothetical estimand contrasts outcomes under a counterfactual world in which intercurrent events (e.g., switching or discontinuation) do not occur.</p>
<p>The choice between these estimands reflects different scientific questions and determines how intercurrent events are handled during analysis.</p>
</section>
<section id="intercurrent-events" class="level3" data-number="5.9.3">
<h3 data-number="5.9.3" class="anchored" data-anchor-id="intercurrent-events"><span class="header-section-number">5.9.3</span> Intercurrent Events</h3>
<p>Intercurrent events are post-treatment events that affect the interpretation or existence of the outcome, such as treatment switching, discontinuation, or death.</p>
<p>Handling of intercurrent events must be specified at the estimand stage, not deferred to estimation. Common strategies include:</p>
<ul>
<li>Treatment-policy: ignore the intercurrent event</li>
<li>Hypothetical: censor or reweight to eliminate its occurrence</li>
<li>Composite: redefine the outcome to include the event</li>
</ul>
<p>This choice determines the causal question being answered.</p>
</section>
<section id="time-to-event-outcomes-and-risk-based-estimands" class="level3" data-number="5.9.4">
<h3 data-number="5.9.4" class="anchored" data-anchor-id="time-to-event-outcomes-and-risk-based-estimands"><span class="header-section-number">5.9.4</span> Time-to-Event Outcomes and Risk-Based Estimands</h3>
<p>In many applications, outcomes occur over time and are subject to censoring.</p>
<p>Rather than targeting hazard ratios, the Causal Roadmap naturally accommodates risk-based estimands, such as cumulative incidence at a fixed time horizon.</p>
<p>For example, the causal risk difference at 90 days compares the probability of experiencing the event by day 90 under each treatment strategy.</p>
</section>
</section>
<section id="step-3-link-to-observed-data" class="level2" data-number="5.10">
<h2 data-number="5.10" class="anchored" data-anchor-id="step-3-link-to-observed-data"><span class="header-section-number">5.10</span> Step 3: Link to observed data</h2>
<ul>
<li>Observed data are denoted O=(W,A,Y) where W reprensents measured covariates, A is the exposure and Y is the outcome.</li>
<li>We assume that the causal model provides a description of our study under existing conditions(i.e.&nbsp;the real world) and under interventions (i.e.the counterfactual world)</li>
<li>This provides a link between the causal world and the real (observed) world and therefore our causal model implies our statistical model which is the set of possible distributions of observed data.</li>
<li>The causal model may but often does not place any restrictions on the statistical model in which case the statistical model is <strong><em>non parametric</em></strong>.</li>
<li>For example our model says that A is a function of W and <span class="math inline">\(U_A\)</span> but does not specify the form of that function: A= <span class="math inline">\(f_A(W,U_A)\)</span>. However, if we know the form, that should be specified in the causal model.</li>
</ul>
<section id="observed-data-censoring-rules" class="level3" data-number="5.10.1">
<h3 data-number="5.10.1" class="anchored" data-anchor-id="observed-data-censoring-rules"><span class="header-section-number">5.10.1</span> Observed-Data Censoring Rules</h3>
<p>The observed data structure must specify which events terminate follow-up and how they relate to the estimand.</p>
<p>Censoring may occur due to administrative end of follow-up, loss to follow-up, or treatment switching.</p>
<p>Whether censoring is causal or administrative depends on the estimand and must be addressed through design or analysis.</p>
</section>
</section>
<section id="step-4-assess-identifiablity" class="level2" data-number="5.11">
<h2 data-number="5.11" class="anchored" data-anchor-id="step-4-assess-identifiablity"><span class="header-section-number">5.11</span> Step 4: Assess Identifiablity</h2>
<ul>
<li>This process involves linking the causal effect to the parameter estimable from observed data. This requires some assumptions as follows:
<ul>
<li>Temporality: exposure precedes the outcome. This is indicated by an arrow on the causal graph from A to Y</li>
<li>Consistency: <span class="math inline">\(Y_a\)</span>=Y where A=a. If an individual received treatment A=a, then their observed outcome Y is equal to their potential outcome under that treatment <span class="math inline">\(Y_a\)</span>.</li>
<li>Stability: We require no interference between units. This is indicated by the fact that the outcomes Y are only a function of each unit’s exposure A in the causal model and graph.</li>
<li>Randomization:No unmeasured confounding such that <span class="math inline">\(Y_a \perp A \mid W\)</span></li>
<li>Positivity: We require sufficient variability in exposure within confounder values i.e.&nbsp;<span class="math inline">\(0 &lt; \mathbb{P}(A=1|W)&lt;1\)</span>.</li>
</ul></li>
<li>With these assumptions, we can express our causal target parameter which is a function of counterfactuals in terms of our observed data i.e</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\mathbb{E}(Y_a)
    &amp;= \mathbb{E}\big[ \mathbb{E}(Y_a \mid W) \big] \\
    &amp;= \mathbb{E}\big[ \mathbb{E}(Y_a \mid A=a, W) \big]  under \ randomization\\
    &amp;= \mathbb{E}\big[ \mathbb{E}(Y \mid A=a, W) \big] under \ consistency
\end{aligned}
\]</span></p>
<ul>
<li>Again wishing for something does not make it true.</li>
<li>Under the above assumptions we can have the G-computation identifiability result (Robins 1986) as
<ul>
<li><span class="math inline">\(\mathbb{E}[Y_1-Y_0] = \mathbb{E}\big[\mathbb{E}(Y\mid A=1,W)-\mathbb{E}(Y\mid A=0,W)]\)</span> where the right handside is our parameter of interest a.k.a our statistical estimand. <strong>Connection to estimation:</strong> The g-computation (simple substitution) estimator in Step 5 directly implements this identified functional by estimating (E[Y A, W]), predicting under (A=1) and (A=0), and averaging over (W). In other words, Step 5 begins by turning the Step 4 identification formula into an explicit computational procedure.</li>
<li>For a binary outcome, we have the marginal risk difference as $. This is marginal because the outer expectation averages over the confounder distribution.</li>
</ul></li>
</ul>
<p>What if the assumptions are not all met? For example one might be worried about unmeasured confounders or that the data structure does not assure temporality.Possible options include: * Giving up!! * Changing the research question, the exposure, the outcome or the target population * Proceeding to do the best job possible estimating the target parameter provided the question is still well-defined and interpretable and that we can still get as close as possible to the wished for causal parameter given the limitations in the data.</p>
<p><em>Assessing Assumptions in Real-World Data</em> The plausibility of identification assumptions depends on the data source. For example, claims data may offer rich information on diagnoses and procedures but limited clinical detail.Explicitly discussing data limitations strengthens interpretation and guides sensitivity analyses.</p>
<p>Having established the causal estimand, the observed-data structure, and the assumptions under which the estimand is identified, we now turn to estimation. At this stage of the Causal Roadmap, the scientific question has been translated into a well-defined statistical target, and the remaining tasks concern how best to estimate this target from finite data, assess precision, and diagnose potential threats such as model misspecification or practical violations of assumptions. The choice of estimator should therefore be guided by the estimand and identification results, rather than driving them.</p>
</section>
<section id="step-5-choose-and-apply-the-estimator" class="level2" data-number="5.12">
<h2 data-number="5.12" class="anchored" data-anchor-id="step-5-choose-and-apply-the-estimator"><span class="header-section-number">5.12</span> Step 5: Choose and apply the estimator</h2>
<ul>
<li>An estimator is an algorithm that when applied to the data generates an estimate of the parameter of interest.</li>
<li>There are several estimators available for the statistical parameter (which equals the ATE if the identifiability assumptions hold). Among these are:
<ul>
<li>Substitution estimators (e.g.&nbsp;paramteric G-computation)</li>
<li>Propensity score based estimators (e.g.&nbsp;IPTW, matching)</li>
<li>Double robust estimators (e.g.TMLE, A-IPTW)</li>
</ul></li>
<li>But before we dive into these estimators, let us pause to recall the usual approach. One would usually run a logistic regression of the outcome Y( risk of Cardiovasicular disease) on exposure (drug A or B) and baseline confounders W:</li>
</ul>
<p><span class="math display">\[
\text{logit}\big( \mathbb{E}(Y \mid A, W) \big)
    = \beta_0 + \beta_1 A + \beta_2 W_1 + \cdots + \beta_{19} W_{18}.
\]</span></p>
<ul>
<li>They would then exponentiate the coefficient on the exposure and interpret the association in terms of an odds ratio.
<ul>
<li>Conditional OR: “While holding other factors constant”</li>
</ul></li>
<li>The problem here is that our target parameter (ATE) does not equal <span class="math inline">\(e^{\beta_{1}}\)</span>. Rather we are letting the estimation approach drive the question. Additionally, this estimation approach relies on the main terms logisitic regression being correct.</li>
<li>A <strong>parametric</strong> estimation approach assumes we know the relationship between covariates W, the exposure A and the outcome Y and have correctly specified this relation with a finite set of constants called “parameters”.
<ul>
<li>For example, we can specify a regression with main terms for covaritaes and a few interactions or squared terms that we think are reasonable.</li>
<li>If we had this knowledge, we should encode it in our causal model so we avoid introducing new assumptions during estimation.</li>
<li>With parametric regression models, we are likely assuming we know more than we actually know.</li>
</ul></li>
<li>A <strong>non-parametric</strong> estimation approach acknowledges that we do not know the form of the relations beetween the covariates W, the exposure A and the outcome Y.
<ul>
<li>For example, one could divide the data into all combinations of (A,W), calculate and average the stratum specific A and Y relations.</li>
<li>Unfortunately we typically have too many covariates and/or continuous covariates which would result into empty cells. This is known as the curse of dimensionality as the number of strata increases exponentially with dimension of W!</li>
</ul></li>
<li>In a <strong>semi parametric</strong> estimation approach, we often “know nothing” (i.e.&nbsp;have a non-paramteric statistical model) but also need to smooth over data with weak support during estimation.
<ul>
<li>We utilize “data-adaptive estimation” or “machine learning”.</li>
<li>One could choose an algorithm (e.g.&nbsp;stepwise regression, loess or polynomial splines), but we have no basis for choosing one over the other.</li>
<li>Instead we allow a large class of algorthims to compete and we select the best algorithm with cross-validation. This is the basis of <strong><em>Super Learner</em></strong> which we will focus on in this tutorial.</li>
</ul></li>
</ul>
<p>Recall our statistical parameter is <span class="math inline">\(\mathbb{E}\big[\mathbb{E}(Y\mid A=1,W)-\mathbb{E}(Y\mid A=0,W)\big]\)</span> which equals the ATE if the identifiability results hold.</p>
<p>We shall now discuss the following estimators with example implementation code in R: * Simple substitution estimator a.k.a paramteric G-computation or parametric g-formula * Inverse probability of treatment weighting (IPTW) * Targeted maximum likelihood estimation (TMLE) with Super Learner</p>
<section id="simple-substitution-estimator-g-computation" class="level3" data-number="5.12.1">
<h3 data-number="5.12.1" class="anchored" data-anchor-id="simple-substitution-estimator-g-computation"><span class="header-section-number">5.12.1</span> Simple substitution estimator (g-computation)</h3>
<p><em>Why start with g-computation?</em> G-computation (outcome modeling and standardization) is often the most intuitive entry point for causal estimation because it does not interpret a regression coefficient as a causal effect. Instead, it implements the identification formula by estimating the conditional mean outcome (E[Y A, W]), predicting counterfactual outcomes under (A=1) and (A=0) for each individual, and then standardizing (averaging) those predictions over the empirical distribution of (W). The resulting contrast is a marginal (population-level) estimand, such as a risk difference.</p>
<p>To get some intuition behind this estimator, let us think of causal inference as a problem of missing information where we know the outcome under the observed exposure but are missing the outcome under the other exposure condition. We therefore use parametric regression to estimate outcomes for all under both exposed and unexposed conditions after controlling for the measured confounders. We then average and compare predicted outcomes. The algorithm is as follows. First we shall load in our simulated dataset “CausalWorkshop.csv” and set the random seed.</p>
<p><strong>Algorithm (standardization / g-computation):</strong></p>
<ol type="1">
<li>Fit an outcome model (Q(A,W) = E[Y A, W]).<br>
</li>
<li>Create two counterfactual datasets by setting (A=1) for everyone and (A=0) for everyone.<br>
</li>
<li>Predict outcomes under each intervention and average predictions over the observed (W) distribution:</li>
</ol>
<p><span class="math display">\[
E[Y^a] = E_W\{E[Y \mid A=a, W]\}.
\]</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'ggplot2' was built under R version 4.4.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'stringr' was built under R version 4.4.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.6.0
✔ ggplot2   3.5.2     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.1
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">read_csv</span>(<span class="st">"CausalWorkshop.csv"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Rows: 200 Columns: 6
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (6): W1, W2, W3, W4, A, Y

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  W1        W2         W3         W4 A          Y
1  1 0.7040728  0.3122141  0.4414994 0 0.04669768
2  0 0.6962875  0.4380506  1.3836186 0 0.07710665
3  0 0.3938895 -0.5381666 -1.4355267 0 0.17743687
4  0 0.6422344  0.7668415  1.2486485 0 0.03303451
5  1 0.4257656 -0.2033714 -0.1459042 0 0.10488589
6  1 0.4578941  1.5954809  0.7091765 0 0.02280160</code></pre>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tail</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    W1         W2         W3          W4 A           Y
195  0 0.85578904  1.1663078  2.10450450 1 0.002777352
196  0 0.43430486  0.5446386 -0.23810871 0 0.046925226
197  1 0.24331831 -1.7955021 -0.76891635 0 0.067511199
198  0 0.62919489 -0.2291413  0.07503677 1 0.109081662
199  0 0.09132161 -0.1004926  0.76101300 0 0.116936200
200  1 0.54266527 -1.4793356 -0.79376429 0 0.053090261</code></pre>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 200   6</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># set.seed(1)</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># n &lt;- 2000</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># data &lt;- tibble(</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co">#   # Baseline covariates (W): representative of postmenopausal osteoporosis patients</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co">#   age = pmin(pmax(rnorm(n, mean = 72, sd = 7), 50), 90),             # years</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co">#   prior_cvd = rbinom(n, 1, plogis((age - 70) / 8 - 1.2)),            # prior cardiovascular disease</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co">#   frailty = rnorm(n, mean = 0, sd = 1),                              # latent frailty proxy</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co">#   smoke = rbinom(n, 1, plogis(-0.5 + 0.02 * (age - 70) + 0.4 * frailty)),</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co">#   sbp = rnorm(n, mean = 130 + 8 * prior_cvd + 3 * smoke, sd = 12),   # systolic BP</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co">#   bmd_t = rnorm(n, mean = -2.5 - 0.3 * frailty, sd = 0.6)            # bone mineral density T-score</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co"># ) %&gt;%</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co">#   mutate(</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co">#     # Treatment assignment A: Drug A (1) vs Drug B (0), confounded by baseline risk and severity</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co">#     # More frail / higher CVD risk patients are more likely to be given Drug B (A=0), for example.</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co">#     ps_true = plogis(</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="co">#       0.4 - 0.06 * (age - 70) - 0.7 * prior_cvd - 0.25 * frailty + 0.35 * (bmd_t &lt; -2.8) - 0.15 * smoke</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="co">#     ),</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="co">#     A = rbinom(n, 1, ps_true)</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="co">#   ) %&gt;%</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="co">#   mutate(</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="co">#     # Outcome model (truth): binary 1-year CVD event</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="co">#     # Includes (i) nonlinearity in age and (ii) an A-by-prior_cvd interaction.</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="co">#     # This makes a main-terms logistic regression for Y misspecified.</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="co">#     lp_y_true =</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="co">#       -3.4 +</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="co">#       0.06 * (age - 70) +</span></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a><span class="co">#       0.02 * (age - 70)^2 / 10 +           # mild nonlinearity</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="co">#       0.9 * prior_cvd +</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a><span class="co">#       0.35 * smoke +</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a><span class="co">#       0.015 * (sbp - 130) +</span></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a><span class="co">#       0.25 * frailty +</span></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a><span class="co">#       0.10 * (bmd_t &lt; -2.8) +</span></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a><span class="co">#       (-0.25) * A +                         # average protective effect</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a><span class="co">#       (-0.55) * A * prior_cvd,              # stronger protection among those with prior CVD</span></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a><span class="co">#     p_y_true = plogis(lp_y_true),</span></span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a><span class="co">#     Y = rbinom(n, 1, p_y_true)</span></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a><span class="co">#   ) %&gt;%</span></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a><span class="co">#   select(</span></span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a><span class="co">#     # Keep W as W1-W4 to minimize changes downstream, plus keep interpretable versions for teaching</span></span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a><span class="co">#     W1 = age, W2 = prior_cvd, W3 = sbp, W4 = bmd_t, A, Y,</span></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a><span class="co">#     age, prior_cvd, sbp, bmd_t, frailty, smoke</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a><span class="co">#   )</span></span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a><span class="co"># # View data</span></span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a><span class="co"># glimpse(data)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol type="1">
<li><p>We the estimate the mean outcome Y as a function of exposure (treatment) A and measured confounders W. In this example we run a main terms logistic regression.</p></li>
<li><p>We estimate the conditional mean outcome <span class="math inline">\(Q(A,W)=E(Y∣A,W)\)</span> using a main-terms logistic regression. In the simulated osteoporosis example, the true outcome mechanism includes nonlinearity in age and an A × prior CVD interaction, so this main-terms logistic regression is intentionally misspecified.</p></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>outcome.regression <span class="ot">&lt;-</span> <span class="fu">glm</span>(Y <span class="sc">~</span> A <span class="sc">+</span> W1<span class="sc">+</span>W2<span class="sc">+</span>W3<span class="sc">+</span>W4, <span class="at">family=</span><span class="st">'binomial'</span>, <span class="at">data=</span>data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in eval(family$initialize): non-integer #successes in a binomial glm!</code></pre>
</div>
</div>
<p><strong>Key point:</strong> Regression coefficients (for example, an odds ratio from a logistic model) are typically <strong>conditional</strong> measures given (W). The Roadmap target in this workshop is a <strong>marginal</strong> contrast (for example, a risk difference). Standardization (g-computation) converts an outcome regression into a marginal estimand by averaging predicted outcomes over the covariate distribution.</p>
<ol start="2" type="1">
<li>We use estimates from 1 above to predict outcomes for each unit while “setting” the exposure to different values e.g.&nbsp;A=1 and A=0</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>data.A1 <span class="ot">&lt;-</span> data.A0 <span class="ot">&lt;-</span> data</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>data.A1<span class="sc">$</span>A <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>data.A0<span class="sc">$</span>A <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(data.A1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         W1          W2          W3          W4           A           Y 
 0.52000000  0.51459003  0.02187934 -0.01958053  1.00000000  0.06244803 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(data.A0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         W1          W2          W3          W4           A           Y 
 0.52000000  0.51459003  0.02187934 -0.01958053  0.00000000  0.06244803 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>predict.outcome.A1 <span class="ot">&lt;-</span> <span class="fu">predict</span>( outcome.regression, <span class="at">newdata=</span>data.A1, </span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>                               <span class="at">type=</span><span class="st">'response'</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>predict.outcome.A0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(outcome.regression, <span class="at">newdata=</span>data.A0, </span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>                              <span class="at">type=</span><span class="st">'response'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="3" type="1">
<li>Average predictions to estimate the marginal risks in the population under exposure and no exposure. To compare estimates, take the difference in means.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(predict.outcome.A1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.03877997</code></pre>
</div>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(predict.outcome.A0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.07258282</code></pre>
</div>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>Simple.Subs <span class="ot">&lt;-</span> <span class="fu">mean</span>(predict.outcome.A1 <span class="sc">-</span> predict.outcome.A0)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>Simple.Subs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.03380285</code></pre>
</div>
</div>
<section id="when-can-g-computation-fail" class="level4" data-number="5.12.1.1">
<h4 data-number="5.12.1.1" class="anchored" data-anchor-id="when-can-g-computation-fail"><span class="header-section-number">5.12.1.1</span> When can g-computation fail?</h4>
<ul>
<li><strong>Outcome model misspecification:</strong> If (E[Y A, W]) is misspecified (wrong functional form, missing interactions), the standardized estimate can be biased. Here, we missed a true interaction in the data-generating process.</li>
<li><strong>Practical positivity violations:</strong> If some covariate strata rarely receive one treatment, g-computation must extrapolate to regions with little or no support.</li>
<li><strong>Unmeasured confounding:</strong> No outcome-modeling approach can correct for confounders that are not measured.</li>
</ul>
<p>These failure modes motivate (i) overlap diagnostics, (ii) flexible nuisance estimation (for example, SuperLearner), and (iii) doubly robust estimators such as TMLE.</p>
<p><strong>Preview:</strong> One way to reduce reliance on parametric assumptions is to estimate (Q(A,W)) with flexible learners (for example, generalized additive models, random forests, boosting) or an ensemble via SuperLearner. In the next sections, we use SuperLearner first for nuisance estimation and then integrate it with TMLE, which targets the causal estimand while retaining a basis for statistical inference.</p>
</section>
</section>
<section id="iptw--inverse-probability-of-treatment-weighting-estimator" class="level3" data-number="5.12.2">
<h3 data-number="5.12.2" class="anchored" data-anchor-id="iptw--inverse-probability-of-treatment-weighting-estimator"><span class="header-section-number">5.12.2</span> IPTW- Inverse Probability of Treatment Weighting estimator</h3>
<p><strong>Intuition (pseudo-population):</strong> IPTW treats confounding as a form of biased sampling. Units who received a treatment that was unlikely given their covariates receive larger weights, and units who received an expected treatment receive smaller weights. In the resulting weighted pseudo-population, treatment is approximately independent of measured covariates (if the propensity score model is correct), mimicking a randomized experiment.</p>
<p>The intuition behind this estimation approach is to think of confounding as a problem of biased sampling, where certain exposure–covariate subgroups are overrepresented relative to what we would observe in a randomized trial, while others are underrepresented. We apply weights to up-weight under-represented units and down-weight over-represented units We then average and compare weighted outcomes. The algorithm is as follows;</p>
<ol type="1">
<li>Estimate the probability of being exposed/treated A as a function of measured confounders W:<span class="math inline">\(\mathbb{P}(A=1\mid W)\)</span>. This is often referred to as the propensity score. We can estimate the propensity score by running a main terms logistic regression as illustrated below</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>pscore.regression <span class="ot">&lt;-</span> <span class="fu">glm</span>(A<span class="sc">~</span> W1<span class="sc">+</span>W2<span class="sc">+</span>W3<span class="sc">+</span>W4, <span class="at">family=</span><span class="fu">binomial</span>(), <span class="at">data=</span>data)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pscore.regression)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = A ~ W1 + W2 + W3 + W4, family = binomial(), data = data)

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -1.3445     0.3821  -3.519 0.000433 ***
W1            0.4637     0.3130   1.482 0.138399    
W2            0.5113     0.5629   0.908 0.363744    
W3            0.4483     0.3208   1.397 0.162360    
W4           -0.2676     0.3095  -0.865 0.387227    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 247.64  on 199  degrees of freedom
Residual deviance: 241.99  on 195  degrees of freedom
AIC: 251.99

Number of Fisher Scoring iterations: 4</code></pre>
</div>
</div>
<p><strong>Identification link:</strong> Under consistency, exchangeability given (W), and positivity, we can write <span class="math display">\[
E\{Y(1)\} = E\left[\frac{\mathbb{I}(A=1)Y}{e(W)}\right], \qquad
E\{Y(0)\} = E\left[\frac{\mathbb{I}(A=0)Y}{1-e(W)}\right],
\]</span></p>
<p>where (e(W)=P(A=1W)). IPTW replaces the expectation with a sample average and replaces (e(W)) with an estimate.</p>
<ol start="2" type="1">
<li>We then use estimates from 1 above to calculate exposed/treated weights: 1/<span class="math inline">\(\mathbb{P}(A=1\mid W)\)</span> and unexposed/untreated weights:1/<span class="math inline">\(\mathbb{P}(A=0\mid W)\)</span></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>predict.prob.A1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(pscore.regression, <span class="at">type=</span><span class="st">'response'</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(predict.prob.A1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.1555  0.2521  0.3034  0.3100  0.3658  0.5145 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>predict.prob.A0 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> predict.prob.A1</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>wt1 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>( data<span class="sc">$</span>A<span class="sc">==</span><span class="dv">1</span>)<span class="sc">/</span>predict.prob.A1</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>wt0 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>( data<span class="sc">$</span>A<span class="sc">==</span><span class="dv">0</span>)<span class="sc">/</span>predict.prob.A0</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">data.frame</span>(<span class="fu">cbind</span>(<span class="at">A=</span>data<span class="sc">$</span>A, <span class="dv">1</span><span class="sc">/</span>predict.prob.A1, wt1, wt0)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  A       V2 wt1      wt0
1 0 2.646982   0 1.607171
2 0 4.197342   0 1.312760
3 0 3.718918   0 1.367793
4 0 3.735871   0 1.365514
5 0 3.044577   0 1.489099
6 0 2.128806   0 1.885892</code></pre>
</div>
</div>
<ol start="3" type="1">
<li>We then apply the weights and average the weighted outcomes to estimate the marginal risks in the population under A=1 and A=0. To compare estimates, we take the difference in weighted means.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(wt1<span class="sc">*</span>data<span class="sc">$</span>Y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.03973564</code></pre>
</div>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(wt0<span class="sc">*</span>data<span class="sc">$</span>Y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.07234258</code></pre>
</div>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>IPW <span class="ot">&lt;-</span> <span class="fu">mean</span>(wt1<span class="sc">*</span>data<span class="sc">$</span>Y) <span class="sc">-</span> <span class="fu">mean</span>(wt0<span class="sc">*</span>data<span class="sc">$</span>Y)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>IPW</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.03260694</code></pre>
</div>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>( (wt1<span class="sc">-</span>wt0)<span class="sc">*</span>data<span class="sc">$</span>Y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.03260694</code></pre>
</div>
</div>
<section id="stabilized-weights-optional-but-common-in-practice" class="level4" data-number="5.12.2.1">
<h4 data-number="5.12.2.1" class="anchored" data-anchor-id="stabilized-weights-optional-but-common-in-practice"><span class="header-section-number">5.12.2.1</span> Stabilized weights (optional but common in practice)</h4>
<p>Unstabilized weights can be variable in finite samples. A common alternative is to use stabilized weights, which multiply by the marginal probability of observed treatment:</p>
<p><span class="math display">\[
SW_i =
\begin{cases}
\frac{P(A=1)}{e(W_i)}, &amp; A_i=1 \\
\frac{P(A=0)}{1-e(W_i)}, &amp; A_i=0.
\end{cases}
\]</span></p>
<p>Stabilized weights often reduce variance and improve numerical stability without changing the large-sample target under correct specification.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>pA <span class="ot">&lt;-</span> <span class="fu">mean</span>(data<span class="sc">$</span>A)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>sw1 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(data<span class="sc">$</span>A<span class="sc">==</span><span class="dv">1</span>) <span class="sc">*</span> pA <span class="sc">/</span> predict.prob.A1</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>sw0 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(data<span class="sc">$</span>A<span class="sc">==</span><span class="dv">0</span>) <span class="sc">*</span> (<span class="dv">1</span><span class="sc">-</span>pA) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> predict.prob.A1)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>sw  <span class="ot">&lt;-</span> sw1 <span class="sc">+</span> sw0</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(sw)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.6025  0.8991  0.9700  1.0013  1.0937  1.9930 </code></pre>
</div>
</div>
<p><strong>Implementation note:</strong> IPTW can be implemented either by directly computing weighted means of (Y) within treatment groups (as shown here) or by fitting a weighted regression of (Y) on (A) using robust standard errors. These approaches target the same marginal contrast when implemented consistently.</p>
</section>
<section id="diagnostics-and-practical-tips-iptw" class="level4" data-number="5.12.2.2">
<h4 data-number="5.12.2.2" class="anchored" data-anchor-id="diagnostics-and-practical-tips-iptw"><span class="header-section-number">5.12.2.2</span> Diagnostics and practical tips (IPTW)</h4>
<ul>
<li><strong>Overlap:</strong> Inspect the distribution of (e(W)) by treatment group. Limited overlap indicates practical positivity problems and increases variance.</li>
<li><strong>Weight tails:</strong> Summarize weights (mean, sd, extreme quantiles). A heavy right tail indicates instability and sensitivity to a small number of observations.</li>
<li><strong>Truncation:</strong> Truncating weights (for example, at the 1st and 99th percentiles) can reduce variance at the cost of potential bias. In finite samples, truncation can improve mean squared error, but it should be reported transparently as a sensitivity analysis.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> wt1 <span class="sc">+</span> wt0</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>lo <span class="ot">&lt;-</span> <span class="fu">quantile</span>(w, <span class="fl">0.01</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>hi <span class="ot">&lt;-</span> <span class="fu">quantile</span>(w, <span class="fl">0.99</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>w_trunc <span class="ot">&lt;-</span> <span class="fu">pmin</span>(<span class="fu">pmax</span>(w, lo), hi)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(w_trunc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  1.212   1.359   1.525   1.993   2.455   4.885 </code></pre>
</div>
</div>
</section>
</section>
<section id="tmle--targeted-maximum-likelihood-estimation" class="level3" data-number="5.12.3">
<h3 data-number="5.12.3" class="anchored" data-anchor-id="tmle--targeted-maximum-likelihood-estimation"><span class="header-section-number">5.12.3</span> TMLE- targeted maximum likelihood estimation</h3>
<section id="why-doubly-robust-estimators" class="level4" data-number="5.12.3.1">
<h4 data-number="5.12.3.1" class="anchored" data-anchor-id="why-doubly-robust-estimators"><span class="header-section-number">5.12.3.1</span> Why doubly robust estimators?</h4>
<p>Both g-computation and IPTW rely on strong modeling assumptions: g-computation requires a correct outcome model, while IPTW requires a correct treatment model. Doubly robust estimators combine both approaches and are consistent if <strong>either</strong> the outcome model or the treatment model is correctly specified. This property is particularly valuable in real-world data settings, where all models are approximations.</p>
<ul>
<li>For intuition here, we again think of causal inference as a problem of missing information.</li>
<li>We predict the outcomes for all units under both exposed and unexposed conditions. We use a flexible estimation approach e.g.&nbsp;Super Learner to avoid assuming regression models that are not known or we use parametric knowledge if known.</li>
<li>We incorporate information on the covariate-exposure relation to <strong><em>improve</em></strong> the initial estimator. Why TMLE?
<ul>
<li>Again here we use a flexible estimation approach or parameteric knowledge if available.</li>
<li>We have a second chance to control for confounding hence this method is doubly robust</li>
<li>We are able to hone our estimator towards the parameter of interest.</li>
<li>This estimator is asymptotically linear and therefore we can obtain normal curve inference</li>
</ul></li>
<li>Finally, we average and compare the targeted predictions under exposure and no exposure.</li>
</ul>
</section>
<section id="what-is-super-learner" class="level4" data-number="5.12.3.2">
<h4 data-number="5.12.3.2" class="anchored" data-anchor-id="what-is-super-learner"><span class="header-section-number">5.12.3.2</span> What is Super Learner?</h4>
<ul>
<li>This is a supervised machine learning algorithm that offers a flexible and data daptive approach to learn complex relationships from data.</li>
<li>This algorithm uses cross-validation(sample splitting) to evaluate the performance of a library of candidate estimators.
<ul>
<li>The library should be diverse including simple (e.g expert informed parametric regressions) and more adaptive algorithms (e.g penalized regressions, stepwise regression, adaptive splines)</li>
<li>Performance is measured by a loss function e.g squared prediction error</li>
</ul></li>
<li>Cross-validation allows us to compare algorithms based on how they perform on independent data. Here we partition data in “folds”, fit each algorithm on the training set and evaluate its performance (called “risk”) on the validation set. We rotate through the folds and average the cross-validated risk estimates across the folds to obtain one measure of performance for each algorithm.</li>
<li>We could choose the algorithm with the best performance (e.g the lowest cross-validated MSE)</li>
<li>Instead, Super Learner builds the best combination of algorithm- specific predictions. We now illustrate below how to fit a Super Learner.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">'SuperLearner'</span>)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>SL.library <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"SL.glm"</span>, <span class="st">"SL.step.interaction"</span>, <span class="st">"SL.gam"</span>)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>X_Q <span class="ot">&lt;-</span> <span class="fu">select</span>(data, A, W1, W2, W3, W4)</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>Y_Q <span class="ot">&lt;-</span> data<span class="sc">$</span>Y</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>SL.outcome.regression <span class="ot">&lt;-</span> <span class="fu">suppressWarnings</span>(</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">SuperLearner</span>(<span class="at">Y =</span> Y_Q, <span class="at">X =</span> X_Q, <span class="at">SL.library =</span> SL.library, <span class="at">family =</span> <span class="fu">binomial</span>())</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>SL.outcome.regression</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:  
SuperLearner(Y = Y_Q, X = X_Q, family = binomial(), SL.library = SL.library) 

                               Risk       Coef
SL.glm_All              0.002778865 0.00000000
SL.step.interaction_All 0.001459048 0.07867521
SL.gam_All              0.001182814 0.92132479</code></pre>
</div>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>SL.predict.outcome <span class="ot">&lt;-</span> <span class="fu">predict</span>(SL.outcome.regression, </span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>                              <span class="at">newdata=</span><span class="fu">subset</span>(data, <span class="at">select=</span><span class="sc">-</span>Y))<span class="sc">$</span>pred</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(SL.predict.outcome)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           [,1]
[1,] 0.06091060
[2,] 0.03514467
[3,] 0.09372118
[4,] 0.02939087
[5,] 0.08990822
[6,] 0.01237438</code></pre>
</div>
</div>
</section>
<section id="why-do-i-need-to-target" class="level4" data-number="5.12.3.3">
<h4 data-number="5.12.3.3" class="anchored" data-anchor-id="why-do-i-need-to-target"><span class="header-section-number">5.12.3.3</span> Why do I need to target?</h4>
<ul>
<li>We could use Super Learner to predict the outcomes for each unit while “setting” the exposure to different levels and then average and contrast the predictions.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>SL.predict.outcome.A1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(SL.outcome.regression, </span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">newdata=</span><span class="fu">subset</span>(data.A1, <span class="at">select=</span><span class="sc">-</span>Y))<span class="sc">$</span>pred</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(SL.predict.outcome.A1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            [,1]
[1,] 0.038035992
[2,] 0.021723371
[3,] 0.059333993
[4,] 0.018101507
[5,] 0.056817294
[6,] 0.007565834</code></pre>
</div>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>SL.predict.outcome.A0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(SL.outcome.regression, <span class="at">newdata=</span><span class="fu">subset</span>(data.A0, <span class="at">select=</span><span class="sc">-</span>Y))<span class="sc">$</span>pred</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="co"># simple subst estimator</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(SL.predict.outcome.A1) <span class="sc">-</span> <span class="fu">mean</span>(SL.predict.outcome.A0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.02534228</code></pre>
</div>
</div>
<ul>
<li>But Super Learner is focused on <span class="math inline">\(\mathbb{E}(Y\mid A,W)\)</span> and not our parameter of interest. It makes the wrong bias-variance trade-off and specifically incurs too much bias.</li>
<li>There is also no reliable way to obtain statistical inference (i.e create 95% confidence intervals)</li>
</ul>
</section>
<section id="what-is-targeting" class="level4" data-number="5.12.3.4">
<h4 data-number="5.12.3.4" class="anchored" data-anchor-id="what-is-targeting"><span class="header-section-number">5.12.3.4</span> What is targeting?</h4>
<ul>
<li>Targeting involves using information in the estimated propensity score <span class="math inline">\(\mathbb{P}(A=1\mid W)\)</span> to update the initial (Super Learner) estimator of <span class="math inline">\(\mathbb{E}(Y\mid A,W)\)</span>.</li>
<li>It involves running a univariate regression of the outcome Y on a clever covariate with offset the initial estimator. Why “clever”? It ensures that the targeting step moves the initial estimator in a direction that removes bias.</li>
<li>We then use the estimated coefficient to update our initial predictions of the outcome under the exposure and no exposure.</li>
</ul>
</section>
<section id="how-do-i-target-one-approach" class="level4" data-number="5.12.3.5">
<h4 data-number="5.12.3.5" class="anchored" data-anchor-id="how-do-i-target-one-approach"><span class="header-section-number">5.12.3.5</span> How do i target? (One approach)</h4>
<ol type="1">
<li>Use Super Learner to estimate the propensity score <span class="math inline">\(\mathbb{P}(A=1\mid W)\)</span></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>SL.pscore <span class="ot">&lt;-</span> <span class="fu">SuperLearner</span>(<span class="at">Y=</span>data<span class="sc">$</span>A, <span class="at">X=</span><span class="fu">subset</span>(data, <span class="at">select=</span><span class="sc">-</span><span class="fu">c</span>(A,Y)),</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>                          <span class="at">SL.library=</span>SL.library, <span class="at">family=</span><span class="fu">binomial</span>())</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>SL.pscore</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:  
SuperLearner(Y = data$A, X = subset(data, select = -c(A, Y)), family = binomial(),  
    SL.library = SL.library) 

                             Risk      Coef
SL.glm_All              0.2153962 0.0000000
SL.step.interaction_All 0.2096272 0.1167303
SL.gam_All              0.2050174 0.8832697</code></pre>
</div>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>SL.predict.prob.A1 <span class="ot">&lt;-</span> SL.pscore<span class="sc">$</span>SL.predict</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(SL.predict.prob.A1 <span class="sc">-</span> <span class="fu">predict</span>(SL.pscore, <span class="at">newdata=</span><span class="fu">subset</span>(data,<span class="at">select=</span><span class="sc">-</span><span class="fu">c</span>(A,Y)))<span class="sc">$</span>pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       V1   
 Min.   :0  
 1st Qu.:0  
 Median :0  
 Mean   :0  
 3rd Qu.:0  
 Max.   :0  </code></pre>
</div>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(SL.predict.prob.A1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       V1        
 Min.   :0.1537  
 1st Qu.:0.2331  
 Median :0.2764  
 Mean   :0.3100  
 3rd Qu.:0.3589  
 Max.   :0.9152  </code></pre>
</div>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>SL.predict.prob.A0 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> SL.predict.prob.A1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong><em>Note</em></strong>: As you run this code you might encounter a warning “non-integer #successes in a binomial glm!”. This simply means that our outcome Y is not binary much as it’s bounded between 0 and 1. This is okay and can be ignored.</p>
<ol start="2" type="1">
<li>Calculate the “clever covariate”</li>
</ol>
<p><span class="math display">\[H(A,W)= \frac{\mathbb{I}(A=1)}{\mathbb{P}(A=1\mid W)}- \frac{\mathbb{I}(A=0)}{\mathbb{P}(A=0\mid W)}\]</span></p>
<p>Here’s code to evaluate the “clever covariate”</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>H.AW <span class="ot">&lt;-</span> (data<span class="sc">$</span>A<span class="sc">==</span><span class="dv">1</span>)<span class="sc">/</span>SL.predict.prob.A1 <span class="sc">-</span> (data<span class="sc">$</span>A<span class="sc">==</span><span class="dv">0</span>)<span class="sc">/</span>SL.predict.prob.A0</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(H.AW)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       V1           
 Min.   :-2.207960  
 1st Qu.:-1.411579  
 Median :-1.302509  
 Mean   : 0.004165  
 3rd Qu.: 1.955975  
 Max.   : 5.893745  </code></pre>
</div>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>H<span class="fl">.1</span>W <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>SL.predict.prob.A1</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>H<span class="fl">.0</span>W <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span>SL.predict.prob.A0</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="fu">tail</span>(<span class="fu">data.frame</span>(<span class="at">A=</span>data<span class="sc">$</span>A, H.AW, H<span class="fl">.1</span>W, H<span class="fl">.0</span>W))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    A      H.AW     H.1W      H.0W
195 1  2.563149 2.563149 -1.639734
196 0 -1.385142 3.596447 -1.385142
197 0 -1.352029 3.840674 -1.352029
198 1  5.448316 5.448316 -1.224804
199 0 -1.181615 6.506164 -1.181615
200 0 -1.360020 3.777621 -1.360020</code></pre>
</div>
</div>
<p>3.Run logistic regression of the outcome on this covariate using logit of the initial estimator <span class="math inline">\(\mathbb{E}(Y\mid A,W)\)</span> as offset where logit(x)= log[x/(1-x)]</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>logitUpdate <span class="ot">&lt;-</span> <span class="fu">glm</span>( data<span class="sc">$</span>Y <span class="sc">~</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span><span class="fu">offset</span>( <span class="fu">qlogis</span>(SL.predict.outcome)) <span class="sc">+</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>                      H.AW, <span class="at">family=</span><span class="st">'binomial'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in eval(family$initialize): non-integer #successes in a binomial glm!</code></pre>
</div>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>epsilon <span class="ot">&lt;-</span> logitUpdate<span class="sc">$</span>coef</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>epsilon</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       H.AW 
0.003211247 </code></pre>
</div>
</div>
<ol start="4" type="1">
<li>Plug in the estimated coefficient <span class="math inline">\(\epsilon\)</span> to yield our targeted estimator <span class="math inline">\(\mathbb{E^*}(Y\mid A,W)\)</span> and use the targeted estimator <span class="math inline">\(\mathbb{E^*}(Y\mid A,W)\)</span> to predict outcomes for all under A=1 and A=0</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>target.predict.outcome.A1 <span class="ot">&lt;-</span> <span class="fu">plogis</span>( <span class="fu">qlogis</span>(SL.predict.outcome.A1)<span class="sc">+</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>                                       epsilon<span class="sc">*</span>H<span class="fl">.1</span>W)</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>target.predict.outcome.A0 <span class="ot">&lt;-</span> <span class="fu">plogis</span>( <span class="fu">qlogis</span>(SL.predict.outcome.A0)<span class="sc">+</span></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>                                      epsilon<span class="sc">*</span>H<span class="fl">.0</span>W)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="5" type="1">
<li>Average the predictions to estimate the marginal risks in the population under exposure and no exposure. Compare the estimates by taking the difference.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>TMLE <span class="ot">&lt;-</span> <span class="fu">mean</span>( target.predict.outcome.A1 <span class="sc">-</span> target.predict.outcome.A0)</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>TMLE</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.02453077</code></pre>
</div>
</div>
</section>
</section>
<section id="estimator-properties" class="level3" data-number="5.12.4">
<h3 data-number="5.12.4" class="anchored" data-anchor-id="estimator-properties"><span class="header-section-number">5.12.4</span> Estimator Properties</h3>
<ul>
<li>We have discussed three estimators and gone through their implementation. We shall now go over the properties and each of them and points of consideration.</li>
<li>Simple substitution estimator
<ul>
<li>Relies on consistently estimating the mean outcome <span class="math inline">\(\mathbb{E^*}(Y\mid A,W)\)</span>. Sometimes we have a lot of knowledge about how the relationship between the outcome Y and the exposure-covariates (A,W) but other times, our knowldege is limited and assuming a parametric regression model can result in bias and misleading inferences.</li>
</ul></li>
<li>IPTW
<ul>
<li>Relies on consistently estimating the propensity score <span class="math inline">\(\mathbb{P}(A=1\mid W)\)</span>. While sometimes we have a lot of knowledge about how the exposure was assigned, other times our knowledge is limited and assuming a parametric regression model can result in bias and misleading inference.</li>
<li>This estimator is unstable under positivity violations. When covariate groups only have a few exposed or unexposed observations, weights can blow up!!. When there are covariate groups with 0 exposed or unexposed observations, weights will not blow up but the estimator will likely be biased and varaince will be underestimated.</li>
</ul></li>
<li>TMLE
<ul>
<li>This estimator is doubly robust i.e.&nbsp;yields a consistent estimate if either the conditional mean <span class="math inline">\(\mathbb{E^*}(Y\mid A,W)\)</span> or the propensity score <span class="math inline">\(\mathbb{P}(A=1\mid W)\)</span> is consistently estimated. We get two chances to get it right !!</li>
<li>It is also semi-parametric efficient which means it achieves the lowest asymptotic variance (most precision) among a large class of estimators if both the conditional mean and propensity score are consistently estimated at reasonable rates.</li>
<li>This estimator has formal theory to support valid statistical inference under mild conditions even when using machine learning.</li>
<li>Being a substitution estimator (plug-in), it is robust under positivity violations,strong confounding and rare outcomes.</li>
<li>There is readily available software to implement this estimator e.g.&nbsp;ltmle package, lmptp package in R among others</li>
</ul></li>
<li>We have now come to the end of our estimation exercise assuming we have selected an estimating approach and estimated our parameter of interest. We now move back to the general Roadmap.</li>
</ul>
</section>
</section>
<section id="step-6-statistical-uncertainty" class="level2" data-number="5.13">
<h2 data-number="5.13" class="anchored" data-anchor-id="step-6-statistical-uncertainty"><span class="header-section-number">5.13</span> Step 6: Statistical Uncertainty</h2>
<ul>
<li>To do statistical inference, we need to derive an estimate of the sampling distribution.</li>
<li>We can consider doing a non-parametric bootstrap where we re-sample the observed data with replacement, apply the entire estimation process (including machine learning algorithms) to the re-sampled data, repeat X times and estimate the variance with the bootstrapped point estimates.</li>
<li>Alternatively, we can use influence curve based inference. We shall not discuss this here but this form of inference is available in the R packages.</li>
</ul>
</section>
<section id="step-7-interpret-findings" class="level2" data-number="5.14">
<h2 data-number="5.14" class="anchored" data-anchor-id="step-7-interpret-findings"><span class="header-section-number">5.14</span> Step 7: Interpret findings</h2>
<ul>
<li><p>The final step of the Causal Roadmap is to interpret the findings. At this stage, we evaluate whether and to what extent the underlying assumptions have been met in order to determine the strength of interpretation.</p></li>
<li><p>Findings support a statistical interpretation if (1) the statistical estimator has negligible bias and its variance is well estimated</p></li>
<li><p>Findings support a causal interpretation if 1 holds and (2) if the non testable identifiability assumptions hold.</p></li>
<li><p>Can be interpreted as if implemented in the real-world if 1 and 2 hold and if (3) the intervention is feasible and applicable to the real world population.</p></li>
<li><p>Findings can be interpreted as if we had emulated a randomized trial if 1-3 hold and the exposure could have been randomized to that population.</p></li>
<li><p>If there are concerns about causal assumptions (e.g.&nbsp;temporal odering is unclear, unmeasured confounding), the results can be interpreted as <strong><em>associational</em></strong>. In this case the estimand, <span class="math inline">\(\mathbb{E}\big[\mathbb{E}(Y\mid A=1,W)-\mathbb{E}(Y\mid A=0,W)]\)</span> can be interpreted as;</p>
<ul>
<li>The marginal difference in the expected outcome associated with the exposure, after accounting for the measured confounders</li>
<li>The difference in the mean outcome between persons exposed versus unexposed but with the same values of the adjustment covariates (averaged with respect to the distribution of those covariates in the population).e.g The difference in the risk of cardiovascular disease with intervention A vs B is X, accounting for region,age,sex,SES etc</li>
<li>Alternatively one can report that this is as close as we can get to the causal effet of A on Y given the limitations of the data detailing all limitations and including a causal graph to empower the reader to assess the plausibility of assumptions.</li>
</ul></li>
<li><p>If the authors believe causal assumptions are met, the parameter can be interpreted as the population average treatment effect <span class="math inline">\(\mathbb{E}\big[Y_1-Y_0\big]\)</span>.</p>
<ul>
<li>In words, this would be the difference in the expected outcome if everyone were exposed compared if everyone were unexposed. For example, there would be an X difference in the risk of cardiovascular disease if all patients in the population received intervention A vs B.</li>
</ul></li>
</ul>
</section>
<section id="summary-and-discussion" class="level2" data-number="5.15">
<h2 data-number="5.15" class="anchored" data-anchor-id="summary-and-discussion"><span class="header-section-number">5.15</span> Summary and Discussion</h2>
<ul>
<li>Congratulations!! You have successfully gone through the causal roadmap tutorial and successfully implemented the simple substitution, IPTW and TMLE estimators.</li>
<li>Hopefully, you have increased your intuitive and technical understanding of these estimators.</li>
</ul>
</section>
<section id="caution-use-your-tools-well." class="level2" data-number="5.16">
<h2 data-number="5.16" class="anchored" data-anchor-id="caution-use-your-tools-well."><span class="header-section-number">5.16</span> Caution: Use your tools well.</h2>
<ul>
<li><p>Use TMLE with Super Learner as part of a toolbox. Recall, fancy estimation tools cannot replace careful thinking throughout the rest of the Roadmap.</p></li>
<li><p>Remember to formally derive adjustment sets and the statistical parameter.</p>
<ul>
<li>Avoid errors of “causal model neglect”, occuring when estimating something differing meaningfully from any interpretable causal effect.</li>
</ul></li>
<li><p>Doubly robust estimators (e.g TMLE or A-IPW) can incorporate machine learning while maintaining basis for valid statistical inference. This helps us avoid errors of “statistical model neglect”, occurring when relying on unsubstantiated (parametric) assumptions during estimation. However, not without conditions.</p>
<ul>
<li>Specify the Super Learner library with care.</li>
<li>Diversity is key</li>
<li>Avoid overfitting by using sample splitting</li>
</ul></li>
<li><p>Practical positivity violations can happen. This can result from poor support for exposures of interest and can lead to bias and/or underestimates of variance. Some solutions to this include;</p>
<ul>
<li>Using a substitution estimator (G-comp,TMLE)</li>
<li>Doing targeting in TMLE through weighted regression instead of a clever covariate</li>
<li>Using a robust variance estimator e.g Tran et al.(2018), Benkeser et al.&nbsp;(2017)</li>
<li>Bounding the estimated propensity score away from O</li>
</ul></li>
<li><p>Run a simulation study mimicking key patterns of the observed data for example sample size, confounding structure, missing data mechanisms, practical violations, sparsity of the exposure and/or outcome, dependence structure etc and use results to guide analyses.</p></li>
<li><p>You have also survived a high speed tour through the Roadmap, and hopefully can appreciate some of its strengths.</p>
<ul>
<li>It necessitates clearly defined research questions, and ensures the parameters estimated will match the questions posed.</li>
<li>Elaborates what assumptions are necessary to interpret estimates as a causal effect</li>
<li>When assumptions are not met, the unmet assumptions provide clear guidance on how future research must be improved to increase the potential of causal interpretation.</li>
<li>Working in this framework can improve interpretability and relevance of epidemiologic research.</li>
<li>Despite focusing on the ATE, this framework is applicable to other causal questions and data structures such as estimating effects among treated/untreated, mediation, longitudinal interventions, dynamic regimes etc.</li>
</ul></li>
<li><p>If you are interested in learning about more advanced settings, here are some links to other resources.</p></li>
</ul>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/amertens\.github\.io\/causal-learning-handbook\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./01-03-identification-estimands.html" class="pagination-link" aria-label="Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Chapter 1.3: From Causal Questions to Analysis — Identification, Estimands, and Statistical Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./02-01-gcomputation.html" class="pagination-link" aria-label="Chapter 2.1: Outcome Modeling and Standardization (G-Computation)">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Chapter 2.1: Outcome Modeling and Standardization (G-Computation)</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb71" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Causal Roadmap for Real-world Evidence Generation: A Tutorial</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="in">```{r setup, include=FALSE}</span></span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a><span class="in">knitr::opts_chunk$set(echo = TRUE)</span></span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a><span class="fu">## To do</span></span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a>(This workshop is in progress- updates to be made:)</span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a><span class="ss"> * </span>Make example data simulated within sheet for reproducibility, and make Y binary</span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a><span class="ss"> * </span>Add webr implementation</span>
<span id="cb71-14"><a href="#cb71-14" aria-hidden="true" tabindex="-1"></a><span class="ss"> * </span>Add more details on inference (step 6)</span>
<span id="cb71-15"><a href="#cb71-15" aria-hidden="true" tabindex="-1"></a><span class="ss"> * </span>Add TMLE and LMTP code at the end</span>
<span id="cb71-16"><a href="#cb71-16" aria-hidden="true" tabindex="-1"></a> *</span>
<span id="cb71-17"><a href="#cb71-17" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb71-18"><a href="#cb71-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-19"><a href="#cb71-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-20"><a href="#cb71-20" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb71-21"><a href="#cb71-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-22"><a href="#cb71-22" aria-hidden="true" tabindex="-1"></a>This tutorial provides a gentle introduction to the Causal Roadmap and its applications in pharmaco-epidemiologic research. It is designed for a broad audience, including learners from both academia and industry. We systematically walk through each step of the Causal Roadmap—from explicitly formulating a research question, to translating it into a formal causal estimand, to identifying and estimating that estimand from observed data, and finally to drawing valid inferences and interpreting results. Each step is illustrated using a working example from a pharmaco-epidemiology setting, accompanied by interactive, built-in code to facilitate hands-on learning. The structure and content of this tutorial are informed by the Introduction to Causal Inference and Causal Roadmap course developed by Maya Petersen and Laura Balzer (UC Berkeley Biostatistics): <span class="co">[</span><span class="ot">http://www.ucbbiostat.com/</span><span class="co">](http://www.ucbbiostat.com/)</span>. </span>
<span id="cb71-23"><a href="#cb71-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-24"><a href="#cb71-24" aria-hidden="true" tabindex="-1"></a><span class="fu">## Why venture down a new path?</span></span>
<span id="cb71-25"><a href="#cb71-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-26"><a href="#cb71-26" aria-hidden="true" tabindex="-1"></a>Adopting the Causal Roadmap in our approach to research in causal inference enables us to clearly state a scientific question and select an analytic approach that matches the question being asked while ensuring systematic assessment of our ability/feasibility  to answer this question from the data we observe (identifiability). Comparing candidate estimators under a shared estimand supports principled method selection.</span>
<span id="cb71-27"><a href="#cb71-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-28"><a href="#cb71-28" aria-hidden="true" tabindex="-1"></a><span class="fu">## Motivation</span></span>
<span id="cb71-29"><a href="#cb71-29" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Suppose we are interested in the impact of Drug A vs Drug B on risk of cardiovascular disease among postmenopausal women with osteoporosis. </span>
<span id="cb71-30"><a href="#cb71-30" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Our usual approach would be to collect data on the intervention, outcome (cardiovascular disease ) and some covariates. </span>
<span id="cb71-31"><a href="#cb71-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-32"><a href="#cb71-32" aria-hidden="true" tabindex="-1"></a>A common default is logistic regression, which targets a conditional odds ratio by exponentiating the regression coefficient on the intervention (treatment).. However, this conditional odds ratio is often not the estimand that matches the scientific question in real-world evidence settings.</span>
<span id="cb71-33"><a href="#cb71-33" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The problem with this approach is that it allows the tool i.e. logistic regression to define the question we answer rather than starting with the question and picking amongst tools that allow us to answer the question.</span>
<span id="cb71-34"><a href="#cb71-34" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>To address this problem, we introduce the Causal Roadmap!</span>
<span id="cb71-35"><a href="#cb71-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-36"><a href="#cb71-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-37"><a href="#cb71-37" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Causal Roadmap</span></span>
<span id="cb71-38"><a href="#cb71-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-39"><a href="#cb71-39" aria-hidden="true" tabindex="-1"></a>The Causal Roadmap is a framework that provides a systematic process to move from a research question to estimation and interpretation which guides investigators on how to design and analyse their studies a priori. This framework has the following steps;</span>
<span id="cb71-40"><a href="#cb71-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-41"><a href="#cb71-41" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Stating the research question and hypothetical experiment</span>
<span id="cb71-42"><a href="#cb71-42" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Defining the causal model and parameter of interest</span>
<span id="cb71-43"><a href="#cb71-43" aria-hidden="true" tabindex="-1"></a><span class="ss">+  </span>Linking the causal model to the observed data and defining the statistical model</span>
<span id="cb71-44"><a href="#cb71-44" aria-hidden="true" tabindex="-1"></a><span class="ss">+  </span>Assessing identifiability: linking the causal effect to a parameter estimable from the observed data</span>
<span id="cb71-45"><a href="#cb71-45" aria-hidden="true" tabindex="-1"></a><span class="ss">+  </span>Selecting and applying the estimator</span>
<span id="cb71-46"><a href="#cb71-46" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Deriving an estimate of the sampling distribution (statistical uncertainty)</span>
<span id="cb71-47"><a href="#cb71-47" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Making inference (interpreting findings)</span>
<span id="cb71-48"><a href="#cb71-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-49"><a href="#cb71-49" aria-hidden="true" tabindex="-1"></a>We shall now delve into each of these steps in details after we go over some notation!</span>
<span id="cb71-50"><a href="#cb71-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-51"><a href="#cb71-51" aria-hidden="true" tabindex="-1"></a><span class="fu">## Notation</span></span>
<span id="cb71-52"><a href="#cb71-52" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>***A***: Exposure/Treatment</span>
<span id="cb71-53"><a href="#cb71-53" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>The term treatment is often used in causal inference even with exposures that are not medical treatments. We shall use A=1 for exposed (treated) and A=0 for unexposed (untreated)</span>
<span id="cb71-54"><a href="#cb71-54" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>***Y***: outcome </span>
<span id="cb71-55"><a href="#cb71-55" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>***W***: set of measured confounding variables</span>
<span id="cb71-56"><a href="#cb71-56" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>***U***: set of unmeasured factors</span>
<span id="cb71-57"><a href="#cb71-57" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\mathbb{E}<span class="co">[</span><span class="ot">Y|A=a</span><span class="co">]</span>$: expected outcome Y among those who experience exposure A=a in our population. This is a descriptive measure</span>
<span id="cb71-58"><a href="#cb71-58" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\mathbb{E}<span class="co">[</span><span class="ot">Y_{a}</span><span class="co">]</span>$: expected counterfactual outcome $Y_a$ when all experience exposure A=a in our population. This is a causal quantity. Generally $\mathbb{E}[Y|A=a]$ does not equal to $\mathbb{E}[Y_{a}]$ and this is the fundamental problem of causal inference</span>
<span id="cb71-59"><a href="#cb71-59" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\mathbb{E}<span class="co">[</span><span class="ot">Y|A=a,W=w</span><span class="co">]</span>$: expected outcome Y among those who expereince exposure A=a and have covariates W=w,  in our population. For example this can be the mean outcome among exposed men. These conditional expectations are often estimated using multivariable regression models.</span>
<span id="cb71-60"><a href="#cb71-60" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$\mathbb{E}<span class="co">[</span><span class="ot">\mathbb{E}[Y|A=a,W=w]</span><span class="co">]</span>$:expected outcome Y among those who experience exposure A=a and have covariates W=w,averaged across covariate strata in the population. This is a marginal expectation.</span>
<span id="cb71-61"><a href="#cb71-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-62"><a href="#cb71-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-63"><a href="#cb71-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-64"><a href="#cb71-64" aria-hidden="true" tabindex="-1"></a><span class="fu">## Step 0: State the question</span></span>
<span id="cb71-65"><a href="#cb71-65" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>This is the very first step of the roadmap. A helpful way to be clear about the scientific question is to  explicitly state the experiment that would unambiguously yield estimates of the causal effect of interest. </span>
<span id="cb71-66"><a href="#cb71-66" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>For example: What is the effect of a certain medication  on the incidence of cardiovascular disease  among postmenopausal women who initiated Drug A vs Drug B in the United States?</span>
<span id="cb71-67"><a href="#cb71-67" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We can consider a hypothetical experiment where we ask what would be the the difference in CVD incidence if patients received the intervention drug A vs if all patients received the control drug B (or standard of care).</span>
<span id="cb71-68"><a href="#cb71-68" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>To sharply frame our research question, we want to be more specific about;</span>
<span id="cb71-69"><a href="#cb71-69" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>The target population (What age group? where?)</span>
<span id="cb71-70"><a href="#cb71-70" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>The exposure (What dosage? Frequency?)</span>
<span id="cb71-71"><a href="#cb71-71" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>The outcome (over what timeframe?)</span>
<span id="cb71-72"><a href="#cb71-72" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Ways to change the exposure and their plausibility</span>
<span id="cb71-73"><a href="#cb71-73" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Other interesting hypothetical experiments could include:</span>
<span id="cb71-74"><a href="#cb71-74" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>What would be the difference in CVD incidence if patients were initiated on drug A once they reached a certain risk threshold vs if all patients are initiated on Drug A regardless of their risk profile? </span>
<span id="cb71-75"><a href="#cb71-75" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>What would be the difference in CVD incidence if an additional 10% of patients received the intervention compared to if the intervention uptake remained as observed? </span>
<span id="cb71-76"><a href="#cb71-76" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb71-77"><a href="#cb71-77" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We note that there is massive flexibility in how we can define our desired hypothetical experiments. </span>
<span id="cb71-78"><a href="#cb71-78" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb71-79"><a href="#cb71-79" aria-hidden="true" tabindex="-1"></a><span class="fu">### Target Trial Emulation</span></span>
<span id="cb71-80"><a href="#cb71-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-81"><a href="#cb71-81" aria-hidden="true" tabindex="-1"></a>The hypothetical experiment defined in Step 0 can be viewed as a target trial.</span>
<span id="cb71-82"><a href="#cb71-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-83"><a href="#cb71-83" aria-hidden="true" tabindex="-1"></a>Observational studies aim to emulate this trial by aligning eligibility criteria, treatment assignment, follow-up, outcome definitions, and estimands.</span>
<span id="cb71-84"><a href="#cb71-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-85"><a href="#cb71-85" aria-hidden="true" tabindex="-1"></a>The Causal Roadmap provides the formal structure for conducting such emulations transparently.</span>
<span id="cb71-86"><a href="#cb71-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-87"><a href="#cb71-87" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb71-88"><a href="#cb71-88" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb71-89"><a href="#cb71-89" aria-hidden="true" tabindex="-1"></a><span class="fu">## Step 1: Define the causal model </span></span>
<span id="cb71-90"><a href="#cb71-90" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Causal modeling formalizes our knowledge however limited. We are able to explore which variables affect each other, examine the role of unmeasured factors and the functional form of the relationships between variables. </span>
<span id="cb71-91"><a href="#cb71-91" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>In this tutorial, we shall focus on structural causal models and corresponding causal graphs (Pearl 2000). However, we do note that there are many other causal frameworks. </span>
<span id="cb71-92"><a href="#cb71-92" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The figure 1 below corresponds to a simple  causal graph with corresponding structural causal model as follows;</span>
<span id="cb71-93"><a href="#cb71-93" aria-hidden="true" tabindex="-1"></a><span class="ss">  *  </span>$W= f_w(U_w)$</span>
<span id="cb71-94"><a href="#cb71-94" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>$A= f_A(W,U_A)$</span>
<span id="cb71-95"><a href="#cb71-95" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>$Y = f_Y(W,A,U_Y)$</span>
<span id="cb71-96"><a href="#cb71-96" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We make no assumptions on the background factors $(U_w,U_A,U_Y)$ or on the functional forms of functions $(f_w,f_A,f_Y)$</span>
<span id="cb71-97"><a href="#cb71-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-98"><a href="#cb71-98" aria-hidden="true" tabindex="-1"></a><span class="in">```{r include-image, echo=FALSE, out.width="70%", fig.align="center"}</span></span>
<span id="cb71-99"><a href="#cb71-99" aria-hidden="true" tabindex="-1"></a><span class="in">knitr::include_graphics("cm1.png")</span></span>
<span id="cb71-100"><a href="#cb71-100" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-101"><a href="#cb71-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-102"><a href="#cb71-102" aria-hidden="true" tabindex="-1"></a>If you believed no unmeasured confounding, a possible causal model and graph (figure 2) would be:</span>
<span id="cb71-103"><a href="#cb71-103" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>$W= f_w(U_w)$</span>
<span id="cb71-104"><a href="#cb71-104" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>$A= f_A(W,U_A)$</span>
<span id="cb71-105"><a href="#cb71-105" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>$Y = f_Y(W,A,U_Y)$</span>
<span id="cb71-106"><a href="#cb71-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-107"><a href="#cb71-107" aria-hidden="true" tabindex="-1"></a>Here we assume that the background factors are all independent but still make no assumption on the functional forms of $(f_w,f_A,f_Y)$. However, keep in mind that this is an assumption we are making, and </span>
<span id="cb71-108"><a href="#cb71-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-109"><a href="#cb71-109" aria-hidden="true" tabindex="-1"></a><span class="in">```{r echo=FALSE, out.width="70%", fig.align="center"}</span></span>
<span id="cb71-110"><a href="#cb71-110" aria-hidden="true" tabindex="-1"></a><span class="in">knitr::include_graphics("cm2.png")</span></span>
<span id="cb71-111"><a href="#cb71-111" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-112"><a href="#cb71-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-113"><a href="#cb71-113" aria-hidden="true" tabindex="-1"></a><span class="fu">## Step 2: Define the causal parameter of interest</span></span>
<span id="cb71-114"><a href="#cb71-114" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We now define counterfactuals by intervening on the causal model.  We can do this by setting the exposure to a specific level e.g A=1 for all units.</span>
<span id="cb71-115"><a href="#cb71-115" aria-hidden="true" tabindex="-1"></a><span class="ss">  *  </span>$W= f_w(U_w)$</span>
<span id="cb71-116"><a href="#cb71-116" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>$A= 1$</span>
<span id="cb71-117"><a href="#cb71-117" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>$Y_1 = f_Y(W,1,U_Y)$ where $Y_1$ is the outcome if possibly-contrary to fact, the unit was exposed (A=1)</span>
<span id="cb71-118"><a href="#cb71-118" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb71-119"><a href="#cb71-119" aria-hidden="true" tabindex="-1"></a><span class="in">```{r echo=FALSE, out.width="70%", fig.align="center"}</span></span>
<span id="cb71-120"><a href="#cb71-120" aria-hidden="true" tabindex="-1"></a><span class="in">knitr::include_graphics("cm3.png")</span></span>
<span id="cb71-121"><a href="#cb71-121" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-122"><a href="#cb71-122" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb71-123"><a href="#cb71-123" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Analogously, we can intervene on the causal model by setting A=0</span>
<span id="cb71-124"><a href="#cb71-124" aria-hidden="true" tabindex="-1"></a><span class="ss">  *  </span>$W= f_w(U_w)$</span>
<span id="cb71-125"><a href="#cb71-125" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>$A= 0$</span>
<span id="cb71-126"><a href="#cb71-126" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>$Y_0 = f_Y(W,0,U_Y)$ where $Y_0$ is the outcome if possibly-contrary to fact, the unit was exposed (A=0)</span>
<span id="cb71-127"><a href="#cb71-127" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb71-128"><a href="#cb71-128" aria-hidden="true" tabindex="-1"></a><span class="in">```{r echo=FALSE, out.width="70%", fig.align="center"}</span></span>
<span id="cb71-129"><a href="#cb71-129" aria-hidden="true" tabindex="-1"></a><span class="in">knitr::include_graphics("cm5.png")</span></span>
<span id="cb71-130"><a href="#cb71-130" aria-hidden="true" tabindex="-1"></a><span class="in">```</span>  </span>
<span id="cb71-131"><a href="#cb71-131" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb71-132"><a href="#cb71-132" aria-hidden="true" tabindex="-1"></a>We use counterfactuals to define the causal parameter:</span>
<span id="cb71-133"><a href="#cb71-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-134"><a href="#cb71-134" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>For example, the difference between the expected counterfactual outcomes under these two interventions i.e $\mathbb{E}<span class="co">[</span><span class="ot">Y_1</span><span class="co">]</span>-\mathbb{E}<span class="co">[</span><span class="ot">Y_0</span><span class="co">]</span>$ which is known as the average treatment effect(ATE)</span>
<span id="cb71-135"><a href="#cb71-135" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>For a binary outcome, like in this example. we define the causal risk difference (CRD) as $\mathbb{P}(Y_1=1)-\mathbb{P}(Y_0=1)$.</span>
<span id="cb71-136"><a href="#cb71-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-137"><a href="#cb71-137" aria-hidden="true" tabindex="-1"></a>Many other causal parameters are possible!! </span>
<span id="cb71-138"><a href="#cb71-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-139"><a href="#cb71-139" aria-hidden="true" tabindex="-1"></a><span class="fu">### Estimand Specification </span></span>
<span id="cb71-140"><a href="#cb71-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-141"><a href="#cb71-141" aria-hidden="true" tabindex="-1"></a>An estimand precisely defines the treatment effect of interest by specifying all attributes of the causal question.</span>
<span id="cb71-142"><a href="#cb71-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-143"><a href="#cb71-143" aria-hidden="true" tabindex="-1"></a>| Attribute | Specification |</span>
<span id="cb71-144"><a href="#cb71-144" aria-hidden="true" tabindex="-1"></a>|----------|---------------|</span>
<span id="cb71-145"><a href="#cb71-145" aria-hidden="true" tabindex="-1"></a>| Population | Eligible individuals meeting study inclusion criteria |</span>
<span id="cb71-146"><a href="#cb71-146" aria-hidden="true" tabindex="-1"></a>| Treatment Strategies | Intervention A versus comparator B |</span>
<span id="cb71-147"><a href="#cb71-147" aria-hidden="true" tabindex="-1"></a>| Endpoint | Binary or time-to-event outcome within a fixed horizon |</span>
<span id="cb71-148"><a href="#cb71-148" aria-hidden="true" tabindex="-1"></a>| Intercurrent Events | Addressed via treatment-policy or hypothetical strategy |</span>
<span id="cb71-149"><a href="#cb71-149" aria-hidden="true" tabindex="-1"></a>| Summary Measure | Risk difference, risk ratio, or mean difference |</span>
<span id="cb71-150"><a href="#cb71-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-151"><a href="#cb71-151" aria-hidden="true" tabindex="-1"></a>Explicit estimand specification ensures alignment between the scientific question, identification assumptions, and estimation strategy.</span>
<span id="cb71-152"><a href="#cb71-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-153"><a href="#cb71-153" aria-hidden="true" tabindex="-1"></a>*NOTE: cite ICH E9[R1] Framework here*</span>
<span id="cb71-154"><a href="#cb71-154" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb71-155"><a href="#cb71-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-156"><a href="#cb71-156" aria-hidden="true" tabindex="-1"></a><span class="fu">### Treatment-Policy versus Hypothetical Estimands</span></span>
<span id="cb71-157"><a href="#cb71-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-158"><a href="#cb71-158" aria-hidden="true" tabindex="-1"></a>A treatment-policy estimand contrasts outcomes under initial treatment assignment regardless of subsequent treatment changes (i.e., intention-to-treat estimates as presented in this workshop).</span>
<span id="cb71-159"><a href="#cb71-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-160"><a href="#cb71-160" aria-hidden="true" tabindex="-1"></a>A hypothetical estimand contrasts outcomes under a counterfactual world in which intercurrent events (e.g., switching or discontinuation) do not occur.</span>
<span id="cb71-161"><a href="#cb71-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-162"><a href="#cb71-162" aria-hidden="true" tabindex="-1"></a>The choice between these estimands reflects different scientific questions and determines how intercurrent events are handled during analysis.</span>
<span id="cb71-163"><a href="#cb71-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-164"><a href="#cb71-164" aria-hidden="true" tabindex="-1"></a><span class="fu">### Intercurrent Events</span></span>
<span id="cb71-165"><a href="#cb71-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-166"><a href="#cb71-166" aria-hidden="true" tabindex="-1"></a>Intercurrent events are post-treatment events that affect the interpretation or existence of the outcome, such as treatment switching, discontinuation, or death.</span>
<span id="cb71-167"><a href="#cb71-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-168"><a href="#cb71-168" aria-hidden="true" tabindex="-1"></a>Handling of intercurrent events must be specified at the estimand stage, not deferred to estimation. Common strategies include:</span>
<span id="cb71-169"><a href="#cb71-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-170"><a href="#cb71-170" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Treatment-policy: ignore the intercurrent event</span>
<span id="cb71-171"><a href="#cb71-171" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Hypothetical: censor or reweight to eliminate its occurrence</span>
<span id="cb71-172"><a href="#cb71-172" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Composite: redefine the outcome to include the event</span>
<span id="cb71-173"><a href="#cb71-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-174"><a href="#cb71-174" aria-hidden="true" tabindex="-1"></a>This choice determines the causal question being answered.</span>
<span id="cb71-175"><a href="#cb71-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-176"><a href="#cb71-176" aria-hidden="true" tabindex="-1"></a><span class="fu">### Time-to-Event Outcomes and Risk-Based Estimands</span></span>
<span id="cb71-177"><a href="#cb71-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-178"><a href="#cb71-178" aria-hidden="true" tabindex="-1"></a>In many applications, outcomes occur over time and are subject to censoring.</span>
<span id="cb71-179"><a href="#cb71-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-180"><a href="#cb71-180" aria-hidden="true" tabindex="-1"></a>Rather than targeting hazard ratios, the Causal Roadmap naturally accommodates risk-based estimands, such as cumulative incidence at a fixed time horizon.</span>
<span id="cb71-181"><a href="#cb71-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-182"><a href="#cb71-182" aria-hidden="true" tabindex="-1"></a>For example, the causal risk difference at 90 days compares the probability of experiencing the event by day 90 under each treatment strategy.</span>
<span id="cb71-183"><a href="#cb71-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-184"><a href="#cb71-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-185"><a href="#cb71-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-186"><a href="#cb71-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-187"><a href="#cb71-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-188"><a href="#cb71-188" aria-hidden="true" tabindex="-1"></a><span class="fu">## Step 3: Link to observed data</span></span>
<span id="cb71-189"><a href="#cb71-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-190"><a href="#cb71-190" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Observed data are denoted O=(W,A,Y) where W reprensents measured covariates, A is the exposure and Y is the outcome. </span>
<span id="cb71-191"><a href="#cb71-191" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We assume that the causal model provides a description of our study under existing conditions(i.e. the real world) and under interventions (i.e.the counterfactual world)</span>
<span id="cb71-192"><a href="#cb71-192" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>This provides a link between the causal world and the real (observed) world and therefore our causal model implies our statistical model which is the set of possible distributions of observed data.</span>
<span id="cb71-193"><a href="#cb71-193" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The causal model may but often does not place any restrictions on the statistical model in which case the statistical model is ***non parametric***.</span>
<span id="cb71-194"><a href="#cb71-194" aria-hidden="true" tabindex="-1"></a><span class="ss"> * </span>For example our model says that A is a function of W and $U_A$ but does not specify the form of that function: A= $f_A(W,U_A)$. However, if we know the form, that should be specified in the causal model. </span>
<span id="cb71-195"><a href="#cb71-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-196"><a href="#cb71-196" aria-hidden="true" tabindex="-1"></a><span class="fu">### Observed-Data Censoring Rules</span></span>
<span id="cb71-197"><a href="#cb71-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-198"><a href="#cb71-198" aria-hidden="true" tabindex="-1"></a>The observed data structure must specify which events terminate follow-up and how they relate to the estimand.</span>
<span id="cb71-199"><a href="#cb71-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-200"><a href="#cb71-200" aria-hidden="true" tabindex="-1"></a>Censoring may occur due to administrative end of follow-up, loss to follow-up, or treatment switching.</span>
<span id="cb71-201"><a href="#cb71-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-202"><a href="#cb71-202" aria-hidden="true" tabindex="-1"></a>Whether censoring is causal or administrative depends on the estimand and must be addressed through design or analysis.</span>
<span id="cb71-203"><a href="#cb71-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-204"><a href="#cb71-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-205"><a href="#cb71-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-206"><a href="#cb71-206" aria-hidden="true" tabindex="-1"></a><span class="fu">## Step 4: Assess Identifiablity</span></span>
<span id="cb71-207"><a href="#cb71-207" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>This process involves linking the causal effect to the parameter estimable from observed data. This requires some assumptions as follows:</span>
<span id="cb71-208"><a href="#cb71-208" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Temporality: exposure precedes the outcome. This is indicated by an arrow on the causal graph from A to Y</span>
<span id="cb71-209"><a href="#cb71-209" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Consistency: $Y_a$=Y where A=a. If an individual received treatment A=a, then their observed outcome Y is equal to their potential outcome under that treatment $Y_a$.</span>
<span id="cb71-210"><a href="#cb71-210" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Stability: We require no interference between units. This is indicated by the fact that the outcomes Y are only a function of each unit's exposure A in the causal model and graph.</span>
<span id="cb71-211"><a href="#cb71-211" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Randomization:No unmeasured confounding such that $Y_a \perp A \mid W$ </span>
<span id="cb71-212"><a href="#cb71-212" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Positivity: We require sufficient variability in exposure within confounder values i.e. $0 &lt; \mathbb{P}(A=1|W)&lt;1$. </span>
<span id="cb71-213"><a href="#cb71-213" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>With these assumptions, we can express our causal target parameter which is a function of counterfactuals in terms of our observed data i.e</span>
<span id="cb71-214"><a href="#cb71-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-215"><a href="#cb71-215" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb71-216"><a href="#cb71-216" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb71-217"><a href="#cb71-217" aria-hidden="true" tabindex="-1"></a>\mathbb{E}(Y_a)</span>
<span id="cb71-218"><a href="#cb71-218" aria-hidden="true" tabindex="-1"></a>    &amp;= \mathbb{E}\big<span class="co">[</span><span class="ot"> \mathbb{E}(Y_a \mid W) \big</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb71-219"><a href="#cb71-219" aria-hidden="true" tabindex="-1"></a>    &amp;= \mathbb{E}\big<span class="co">[</span><span class="ot"> \mathbb{E}(Y_a \mid A=a, W) \big</span><span class="co">]</span>  under \ randomization<span class="sc">\\</span> </span>
<span id="cb71-220"><a href="#cb71-220" aria-hidden="true" tabindex="-1"></a>    &amp;= \mathbb{E}\big<span class="co">[</span><span class="ot"> \mathbb{E}(Y \mid A=a, W) \big</span><span class="co">]</span> under \ consistency</span>
<span id="cb71-221"><a href="#cb71-221" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb71-222"><a href="#cb71-222" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb71-223"><a href="#cb71-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-224"><a href="#cb71-224" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Again wishing for something does not make it true.</span>
<span id="cb71-225"><a href="#cb71-225" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Under the above assumptions we can have the G-computation identifiability result (Robins 1986) as</span>
<span id="cb71-226"><a href="#cb71-226" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>$\mathbb{E}<span class="co">[</span><span class="ot">Y_1-Y_0</span><span class="co">]</span> = \mathbb{E}\big<span class="co">[</span><span class="ot">\mathbb{E}(Y\mid A=1,W)-\mathbb{E}(Y\mid A=0,W)</span><span class="co">]</span>$ where the right handside is our parameter of interest a.k.a our statistical estimand. **Connection to estimation:** The g-computation (simple substitution) estimator in Step 5 directly implements this identified functional by estimating <span class="sc">\(</span>E<span class="co">[</span><span class="ot">Y \mid A, W</span><span class="co">]</span><span class="sc">\)</span>, predicting under <span class="sc">\(</span>A=1<span class="sc">\)</span> and <span class="sc">\(</span>A=0<span class="sc">\)</span>, and averaging over <span class="sc">\(</span>W<span class="sc">\)</span>. In other words, Step 5 begins by turning the Step 4 identification formula into an explicit computational procedure.</span>
<span id="cb71-227"><a href="#cb71-227" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>For a binary outcome, we have the marginal risk difference as \mathbb{E}\big<span class="co">[</span><span class="ot">\mathbb{P}(Y=1\mid A=1,W)-\mathbb{P}(Y=1\mid A=0,W)</span><span class="co">]</span>$. This is marginal because the outer expectation averages over the confounder distribution. </span>
<span id="cb71-228"><a href="#cb71-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-229"><a href="#cb71-229" aria-hidden="true" tabindex="-1"></a>What if the assumptions are not all met? For example one might be worried about unmeasured confounders or that the data structure does not assure temporality.Possible options include:</span>
<span id="cb71-230"><a href="#cb71-230" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Giving up!!</span>
<span id="cb71-231"><a href="#cb71-231" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Changing the research question, the exposure, the outcome or the target population</span>
<span id="cb71-232"><a href="#cb71-232" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Proceeding to do the best job possible estimating the target parameter provided the question is still well-defined and interpretable and that we  can still get as close as possible to the wished for causal parameter given the limitations in the data. </span>
<span id="cb71-233"><a href="#cb71-233" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb71-234"><a href="#cb71-234" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb71-235"><a href="#cb71-235" aria-hidden="true" tabindex="-1"></a>*Assessing Assumptions in Real-World Data* The plausibility of identification assumptions depends on the data source. For example, claims data may offer rich information on diagnoses and procedures but limited clinical detail.Explicitly discussing data limitations strengthens interpretation and guides sensitivity analyses.</span>
<span id="cb71-236"><a href="#cb71-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-237"><a href="#cb71-237" aria-hidden="true" tabindex="-1"></a>Having established the causal estimand, the observed-data structure, and the assumptions under which the estimand is identified, we now turn to estimation. At this stage of the Causal Roadmap, the scientific question has been translated into a well-defined statistical target, and the remaining tasks concern how best to estimate this target from finite data, assess precision, and diagnose potential threats such as model misspecification or practical violations of assumptions. The choice of estimator should therefore be guided by the estimand and identification results, rather than driving them.</span>
<span id="cb71-238"><a href="#cb71-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-239"><a href="#cb71-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-240"><a href="#cb71-240" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb71-241"><a href="#cb71-241" aria-hidden="true" tabindex="-1"></a><span class="fu">## Step 5: Choose and apply the estimator</span></span>
<span id="cb71-242"><a href="#cb71-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-243"><a href="#cb71-243" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>An estimator is an algorithm that when applied to the data generates an estimate of the parameter of interest. </span>
<span id="cb71-244"><a href="#cb71-244" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>There are several estimators available for the statistical parameter (which equals the ATE if the identifiability assumptions hold). Among these are:</span>
<span id="cb71-245"><a href="#cb71-245" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Substitution estimators (e.g. paramteric G-computation)</span>
<span id="cb71-246"><a href="#cb71-246" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Propensity score based estimators (e.g. IPTW, matching)</span>
<span id="cb71-247"><a href="#cb71-247" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Double robust estimators (e.g.TMLE, A-IPTW)</span>
<span id="cb71-248"><a href="#cb71-248" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>But before we dive into these estimators,  let us pause to recall the usual approach. One would usually run a logistic regression of the outcome Y( risk of Cardiovasicular disease) on exposure (drug A or B) and baseline confounders W:</span>
<span id="cb71-249"><a href="#cb71-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-250"><a href="#cb71-250" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb71-251"><a href="#cb71-251" aria-hidden="true" tabindex="-1"></a>\text{logit}\big( \mathbb{E}(Y \mid A, W) \big)</span>
<span id="cb71-252"><a href="#cb71-252" aria-hidden="true" tabindex="-1"></a>    = \beta_0 + \beta_1 A + \beta_2 W_1 + \cdots + \beta_{19} W_{18}.</span>
<span id="cb71-253"><a href="#cb71-253" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb71-254"><a href="#cb71-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-255"><a href="#cb71-255" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>They would then exponentiate the coefficient on the exposure and interpret the association in terms of an odds ratio.</span>
<span id="cb71-256"><a href="#cb71-256" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>Conditional OR: "While holding other factors constant"</span>
<span id="cb71-257"><a href="#cb71-257" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The problem here is that our target parameter (ATE) does not equal $e^{\beta_{1}}$. Rather we are letting the estimation approach drive the question. Additionally, this estimation approach relies on the main terms logisitic regression being correct. </span>
<span id="cb71-258"><a href="#cb71-258" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>A **parametric** estimation approach assumes we know the relationship between covariates W, the exposure A and the outcome Y and have correctly specified this relation with a finite set of constants called "parameters".</span>
<span id="cb71-259"><a href="#cb71-259" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>For example, we can specify a regression with main terms for covaritaes and a few interactions or squared terms that we think are reasonable. </span>
<span id="cb71-260"><a href="#cb71-260" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>If we had this knowledge, we should encode it in our causal model so we avoid introducing new assumptions during estimation. </span>
<span id="cb71-261"><a href="#cb71-261" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>With parametric regression models, we are likely assuming we know more than we actually know.</span>
<span id="cb71-262"><a href="#cb71-262" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>A **non-parametric** estimation approach acknowledges that we do not know the form of the relations beetween the covariates W, the exposure A and the outcome Y. </span>
<span id="cb71-263"><a href="#cb71-263" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>For example, one could divide the data into all combinations of (A,W), calculate and average the stratum specific A and Y relations. </span>
<span id="cb71-264"><a href="#cb71-264" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Unfortunately we typically have too many covariates and/or continuous covariates which would result into empty cells.  This is known as the curse of dimensionality as the number of strata increases exponentially with dimension of W!</span>
<span id="cb71-265"><a href="#cb71-265" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>In a  **semi parametric** estimation approach, we often "know nothing" (i.e. have a non-paramteric statistical model) but also need to smooth over data with weak support during estimation.</span>
<span id="cb71-266"><a href="#cb71-266" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>We utilize "data-adaptive estimation" or "machine learning". </span>
<span id="cb71-267"><a href="#cb71-267" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>One could choose an algorithm (e.g. stepwise regression, loess or polynomial splines), but we have no basis for choosing one over the other.</span>
<span id="cb71-268"><a href="#cb71-268" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Instead we allow a large class of algorthims to compete and we select the best algorithm with cross-validation. This is the basis of ***Super Learner*** which we will focus on in this tutorial. </span>
<span id="cb71-269"><a href="#cb71-269" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb71-270"><a href="#cb71-270" aria-hidden="true" tabindex="-1"></a>Recall our statistical parameter is $\mathbb{E}\big<span class="co">[</span><span class="ot">\mathbb{E}(Y\mid A=1,W)-\mathbb{E}(Y\mid A=0,W)\big</span><span class="co">]</span>$ which equals the ATE if the identifiability results hold. </span>
<span id="cb71-271"><a href="#cb71-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-272"><a href="#cb71-272" aria-hidden="true" tabindex="-1"></a>We shall now discuss the following estimators with example implementation code in R:</span>
<span id="cb71-273"><a href="#cb71-273" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Simple substitution estimator a.k.a paramteric G-computation or parametric g-formula</span>
<span id="cb71-274"><a href="#cb71-274" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Inverse probability of treatment weighting (IPTW)</span>
<span id="cb71-275"><a href="#cb71-275" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Targeted maximum likelihood estimation (TMLE) with Super Learner</span>
<span id="cb71-276"><a href="#cb71-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-277"><a href="#cb71-277" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simple substitution estimator (g-computation)</span></span>
<span id="cb71-278"><a href="#cb71-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-279"><a href="#cb71-279" aria-hidden="true" tabindex="-1"></a>*Why start with g-computation?* G-computation (outcome modeling and standardization) is often the most intuitive entry point for causal estimation because it does not interpret a regression coefficient as a causal effect. Instead, it implements the identification formula by estimating the conditional mean outcome <span class="sc">\(</span>E<span class="co">[</span><span class="ot">Y \mid A, W</span><span class="co">]</span><span class="sc">\)</span>, predicting counterfactual outcomes under <span class="sc">\(</span>A=1<span class="sc">\)</span> and <span class="sc">\(</span>A=0<span class="sc">\)</span> for each individual, and then standardizing (averaging) those predictions over the empirical distribution of <span class="sc">\(</span>W<span class="sc">\)</span>. The resulting contrast is a marginal (population-level) estimand, such as a risk difference.</span>
<span id="cb71-280"><a href="#cb71-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-281"><a href="#cb71-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-282"><a href="#cb71-282" aria-hidden="true" tabindex="-1"></a>To get some intuition behind this estimator, let us think of causal inference as a problem of missing information where we know the outcome under the observed exposure but are missing the outcome under the other exposure condition. We therefore use parametric regression to estimate outcomes for all under both exposed and unexposed conditions after controlling for the measured confounders. We then average and compare predicted outcomes. The algorithm is as follows. First we shall load in our simulated dataset "CausalWorkshop.csv" and set the random seed.</span>
<span id="cb71-283"><a href="#cb71-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-284"><a href="#cb71-284" aria-hidden="true" tabindex="-1"></a>**Algorithm (standardization / g-computation):**</span>
<span id="cb71-285"><a href="#cb71-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-286"><a href="#cb71-286" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Fit an outcome model <span class="sc">\(</span>Q(A,W) = E<span class="co">[</span><span class="ot">Y \mid A, W</span><span class="co">]</span><span class="sc">\)</span>.  </span>
<span id="cb71-287"><a href="#cb71-287" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Create two counterfactual datasets by setting <span class="sc">\(</span>A=1<span class="sc">\)</span> for everyone and <span class="sc">\(</span>A=0<span class="sc">\)</span> for everyone.  </span>
<span id="cb71-288"><a href="#cb71-288" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Predict outcomes under each intervention and average predictions over the observed <span class="sc">\(</span>W<span class="sc">\)</span> distribution:</span>
<span id="cb71-289"><a href="#cb71-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-290"><a href="#cb71-290" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb71-291"><a href="#cb71-291" aria-hidden="true" tabindex="-1"></a>E<span class="co">[</span><span class="ot">Y^a</span><span class="co">]</span> = E_W<span class="sc">\{</span>E<span class="co">[</span><span class="ot">Y \mid A=a, W</span><span class="co">]</span><span class="sc">\}</span>.</span>
<span id="cb71-292"><a href="#cb71-292" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb71-293"><a href="#cb71-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-294"><a href="#cb71-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-297"><a href="#cb71-297" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb71-298"><a href="#cb71-298" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb71-299"><a href="#cb71-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-300"><a href="#cb71-300" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb71-301"><a href="#cb71-301" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">read_csv</span>(<span class="st">"CausalWorkshop.csv"</span>))</span>
<span id="cb71-302"><a href="#cb71-302" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(data)</span>
<span id="cb71-303"><a href="#cb71-303" aria-hidden="true" tabindex="-1"></a><span class="fu">tail</span>(data)</span>
<span id="cb71-304"><a href="#cb71-304" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(data)</span>
<span id="cb71-305"><a href="#cb71-305" aria-hidden="true" tabindex="-1"></a><span class="co"># set.seed(1)</span></span>
<span id="cb71-306"><a href="#cb71-306" aria-hidden="true" tabindex="-1"></a><span class="co"># n &lt;- 2000</span></span>
<span id="cb71-307"><a href="#cb71-307" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb71-308"><a href="#cb71-308" aria-hidden="true" tabindex="-1"></a><span class="co"># data &lt;- tibble(</span></span>
<span id="cb71-309"><a href="#cb71-309" aria-hidden="true" tabindex="-1"></a><span class="co">#   # Baseline covariates (W): representative of postmenopausal osteoporosis patients</span></span>
<span id="cb71-310"><a href="#cb71-310" aria-hidden="true" tabindex="-1"></a><span class="co">#   age = pmin(pmax(rnorm(n, mean = 72, sd = 7), 50), 90),             # years</span></span>
<span id="cb71-311"><a href="#cb71-311" aria-hidden="true" tabindex="-1"></a><span class="co">#   prior_cvd = rbinom(n, 1, plogis((age - 70) / 8 - 1.2)),            # prior cardiovascular disease</span></span>
<span id="cb71-312"><a href="#cb71-312" aria-hidden="true" tabindex="-1"></a><span class="co">#   frailty = rnorm(n, mean = 0, sd = 1),                              # latent frailty proxy</span></span>
<span id="cb71-313"><a href="#cb71-313" aria-hidden="true" tabindex="-1"></a><span class="co">#   smoke = rbinom(n, 1, plogis(-0.5 + 0.02 * (age - 70) + 0.4 * frailty)),</span></span>
<span id="cb71-314"><a href="#cb71-314" aria-hidden="true" tabindex="-1"></a><span class="co">#   sbp = rnorm(n, mean = 130 + 8 * prior_cvd + 3 * smoke, sd = 12),   # systolic BP</span></span>
<span id="cb71-315"><a href="#cb71-315" aria-hidden="true" tabindex="-1"></a><span class="co">#   bmd_t = rnorm(n, mean = -2.5 - 0.3 * frailty, sd = 0.6)            # bone mineral density T-score</span></span>
<span id="cb71-316"><a href="#cb71-316" aria-hidden="true" tabindex="-1"></a><span class="co"># ) %&gt;%</span></span>
<span id="cb71-317"><a href="#cb71-317" aria-hidden="true" tabindex="-1"></a><span class="co">#   mutate(</span></span>
<span id="cb71-318"><a href="#cb71-318" aria-hidden="true" tabindex="-1"></a><span class="co">#     # Treatment assignment A: Drug A (1) vs Drug B (0), confounded by baseline risk and severity</span></span>
<span id="cb71-319"><a href="#cb71-319" aria-hidden="true" tabindex="-1"></a><span class="co">#     # More frail / higher CVD risk patients are more likely to be given Drug B (A=0), for example.</span></span>
<span id="cb71-320"><a href="#cb71-320" aria-hidden="true" tabindex="-1"></a><span class="co">#     ps_true = plogis(</span></span>
<span id="cb71-321"><a href="#cb71-321" aria-hidden="true" tabindex="-1"></a><span class="co">#       0.4 - 0.06 * (age - 70) - 0.7 * prior_cvd - 0.25 * frailty + 0.35 * (bmd_t &lt; -2.8) - 0.15 * smoke</span></span>
<span id="cb71-322"><a href="#cb71-322" aria-hidden="true" tabindex="-1"></a><span class="co">#     ),</span></span>
<span id="cb71-323"><a href="#cb71-323" aria-hidden="true" tabindex="-1"></a><span class="co">#     A = rbinom(n, 1, ps_true)</span></span>
<span id="cb71-324"><a href="#cb71-324" aria-hidden="true" tabindex="-1"></a><span class="co">#   ) %&gt;%</span></span>
<span id="cb71-325"><a href="#cb71-325" aria-hidden="true" tabindex="-1"></a><span class="co">#   mutate(</span></span>
<span id="cb71-326"><a href="#cb71-326" aria-hidden="true" tabindex="-1"></a><span class="co">#     # Outcome model (truth): binary 1-year CVD event</span></span>
<span id="cb71-327"><a href="#cb71-327" aria-hidden="true" tabindex="-1"></a><span class="co">#     # Includes (i) nonlinearity in age and (ii) an A-by-prior_cvd interaction.</span></span>
<span id="cb71-328"><a href="#cb71-328" aria-hidden="true" tabindex="-1"></a><span class="co">#     # This makes a main-terms logistic regression for Y misspecified.</span></span>
<span id="cb71-329"><a href="#cb71-329" aria-hidden="true" tabindex="-1"></a><span class="co">#     lp_y_true =</span></span>
<span id="cb71-330"><a href="#cb71-330" aria-hidden="true" tabindex="-1"></a><span class="co">#       -3.4 +</span></span>
<span id="cb71-331"><a href="#cb71-331" aria-hidden="true" tabindex="-1"></a><span class="co">#       0.06 * (age - 70) +</span></span>
<span id="cb71-332"><a href="#cb71-332" aria-hidden="true" tabindex="-1"></a><span class="co">#       0.02 * (age - 70)^2 / 10 +           # mild nonlinearity</span></span>
<span id="cb71-333"><a href="#cb71-333" aria-hidden="true" tabindex="-1"></a><span class="co">#       0.9 * prior_cvd +</span></span>
<span id="cb71-334"><a href="#cb71-334" aria-hidden="true" tabindex="-1"></a><span class="co">#       0.35 * smoke +</span></span>
<span id="cb71-335"><a href="#cb71-335" aria-hidden="true" tabindex="-1"></a><span class="co">#       0.015 * (sbp - 130) +</span></span>
<span id="cb71-336"><a href="#cb71-336" aria-hidden="true" tabindex="-1"></a><span class="co">#       0.25 * frailty +</span></span>
<span id="cb71-337"><a href="#cb71-337" aria-hidden="true" tabindex="-1"></a><span class="co">#       0.10 * (bmd_t &lt; -2.8) +</span></span>
<span id="cb71-338"><a href="#cb71-338" aria-hidden="true" tabindex="-1"></a><span class="co">#       (-0.25) * A +                         # average protective effect</span></span>
<span id="cb71-339"><a href="#cb71-339" aria-hidden="true" tabindex="-1"></a><span class="co">#       (-0.55) * A * prior_cvd,              # stronger protection among those with prior CVD</span></span>
<span id="cb71-340"><a href="#cb71-340" aria-hidden="true" tabindex="-1"></a><span class="co">#     p_y_true = plogis(lp_y_true),</span></span>
<span id="cb71-341"><a href="#cb71-341" aria-hidden="true" tabindex="-1"></a><span class="co">#     Y = rbinom(n, 1, p_y_true)</span></span>
<span id="cb71-342"><a href="#cb71-342" aria-hidden="true" tabindex="-1"></a><span class="co">#   ) %&gt;%</span></span>
<span id="cb71-343"><a href="#cb71-343" aria-hidden="true" tabindex="-1"></a><span class="co">#   select(</span></span>
<span id="cb71-344"><a href="#cb71-344" aria-hidden="true" tabindex="-1"></a><span class="co">#     # Keep W as W1-W4 to minimize changes downstream, plus keep interpretable versions for teaching</span></span>
<span id="cb71-345"><a href="#cb71-345" aria-hidden="true" tabindex="-1"></a><span class="co">#     W1 = age, W2 = prior_cvd, W3 = sbp, W4 = bmd_t, A, Y,</span></span>
<span id="cb71-346"><a href="#cb71-346" aria-hidden="true" tabindex="-1"></a><span class="co">#     age, prior_cvd, sbp, bmd_t, frailty, smoke</span></span>
<span id="cb71-347"><a href="#cb71-347" aria-hidden="true" tabindex="-1"></a><span class="co">#   )</span></span>
<span id="cb71-348"><a href="#cb71-348" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb71-349"><a href="#cb71-349" aria-hidden="true" tabindex="-1"></a><span class="co"># # View data</span></span>
<span id="cb71-350"><a href="#cb71-350" aria-hidden="true" tabindex="-1"></a><span class="co"># glimpse(data)</span></span>
<span id="cb71-351"><a href="#cb71-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-352"><a href="#cb71-352" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-353"><a href="#cb71-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-354"><a href="#cb71-354" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>We the estimate the mean outcome Y as a function of exposure (treatment) A and measured confounders W. In this example we run a main terms logistic regression. </span>
<span id="cb71-355"><a href="#cb71-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-356"><a href="#cb71-356" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>We estimate the conditional mean outcome  $Q(A,W)=E(Y∣A,W)$ using a main-terms logistic regression. In the simulated osteoporosis example, the true outcome mechanism includes nonlinearity in age and an A × prior CVD interaction, so this main-terms logistic regression is intentionally misspecified.</span>
<span id="cb71-357"><a href="#cb71-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-360"><a href="#cb71-360" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb71-361"><a href="#cb71-361" aria-hidden="true" tabindex="-1"></a>outcome.regression <span class="ot">&lt;-</span> <span class="fu">glm</span>(Y <span class="sc">~</span> A <span class="sc">+</span> W1<span class="sc">+</span>W2<span class="sc">+</span>W3<span class="sc">+</span>W4, <span class="at">family=</span><span class="st">'binomial'</span>, <span class="at">data=</span>data)</span>
<span id="cb71-362"><a href="#cb71-362" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-363"><a href="#cb71-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-364"><a href="#cb71-364" aria-hidden="true" tabindex="-1"></a>**Key point:** Regression coefficients (for example, an odds ratio from a logistic model) are typically **conditional** measures given \(W\). The Roadmap target in this workshop is a **marginal** contrast (for example, a risk difference). Standardization (g-computation) converts an outcome regression into a marginal estimand by averaging predicted outcomes over the covariate distribution.</span>
<span id="cb71-365"><a href="#cb71-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-366"><a href="#cb71-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-367"><a href="#cb71-367" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>We use estimates from 1 above to predict outcomes for each unit while "setting" the exposure to different values e.g. A=1 and A=0</span>
<span id="cb71-370"><a href="#cb71-370" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb71-371"><a href="#cb71-371" aria-hidden="true" tabindex="-1"></a>data.A1 <span class="ot">&lt;-</span> data.A0 <span class="ot">&lt;-</span> data</span>
<span id="cb71-372"><a href="#cb71-372" aria-hidden="true" tabindex="-1"></a>data.A1<span class="sc">$</span>A <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb71-373"><a href="#cb71-373" aria-hidden="true" tabindex="-1"></a>data.A0<span class="sc">$</span>A <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb71-374"><a href="#cb71-374" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(data.A1)</span>
<span id="cb71-375"><a href="#cb71-375" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(data.A0)</span>
<span id="cb71-376"><a href="#cb71-376" aria-hidden="true" tabindex="-1"></a>predict.outcome.A1 <span class="ot">&lt;-</span> <span class="fu">predict</span>( outcome.regression, <span class="at">newdata=</span>data.A1, </span>
<span id="cb71-377"><a href="#cb71-377" aria-hidden="true" tabindex="-1"></a>                               <span class="at">type=</span><span class="st">'response'</span>)</span>
<span id="cb71-378"><a href="#cb71-378" aria-hidden="true" tabindex="-1"></a>predict.outcome.A0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(outcome.regression, <span class="at">newdata=</span>data.A0, </span>
<span id="cb71-379"><a href="#cb71-379" aria-hidden="true" tabindex="-1"></a>                              <span class="at">type=</span><span class="st">'response'</span>)</span>
<span id="cb71-380"><a href="#cb71-380" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-381"><a href="#cb71-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-382"><a href="#cb71-382" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Average predictions to estimate the marginal risks in the population under exposure and no exposure. To compare estimates, take the difference in means.</span>
<span id="cb71-385"><a href="#cb71-385" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb71-386"><a href="#cb71-386" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(predict.outcome.A1)</span>
<span id="cb71-387"><a href="#cb71-387" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(predict.outcome.A0)</span>
<span id="cb71-388"><a href="#cb71-388" aria-hidden="true" tabindex="-1"></a>Simple.Subs <span class="ot">&lt;-</span> <span class="fu">mean</span>(predict.outcome.A1 <span class="sc">-</span> predict.outcome.A0)</span>
<span id="cb71-389"><a href="#cb71-389" aria-hidden="true" tabindex="-1"></a>Simple.Subs</span>
<span id="cb71-390"><a href="#cb71-390" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-391"><a href="#cb71-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-392"><a href="#cb71-392" aria-hidden="true" tabindex="-1"></a><span class="fu">#### When can g-computation fail?</span></span>
<span id="cb71-393"><a href="#cb71-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-394"><a href="#cb71-394" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Outcome model misspecification:** If <span class="sc">\(</span>E<span class="co">[</span><span class="ot">Y \mid A, W</span><span class="co">]</span><span class="sc">\)</span> is misspecified (wrong functional form, missing interactions), the standardized estimate can be biased. Here, we missed a true interaction in the data-generating process.</span>
<span id="cb71-395"><a href="#cb71-395" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Practical positivity violations:** If some covariate strata rarely receive one treatment, g-computation must extrapolate to regions with little or no support.</span>
<span id="cb71-396"><a href="#cb71-396" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Unmeasured confounding:** No outcome-modeling approach can correct for confounders that are not measured. </span>
<span id="cb71-397"><a href="#cb71-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-398"><a href="#cb71-398" aria-hidden="true" tabindex="-1"></a>These failure modes motivate (i) overlap diagnostics, (ii) flexible nuisance estimation (for example, SuperLearner), and (iii) doubly robust estimators such as TMLE.</span>
<span id="cb71-399"><a href="#cb71-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-400"><a href="#cb71-400" aria-hidden="true" tabindex="-1"></a>**Preview:** One way to reduce reliance on parametric assumptions is to estimate <span class="sc">\(</span>Q(A,W)<span class="sc">\)</span> with flexible learners (for example, generalized additive models, random forests, boosting) or an ensemble via SuperLearner. In the next sections, we use SuperLearner first for nuisance estimation and then integrate it with TMLE, which targets the causal estimand while retaining a basis for statistical inference.</span>
<span id="cb71-401"><a href="#cb71-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-402"><a href="#cb71-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-403"><a href="#cb71-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-404"><a href="#cb71-404" aria-hidden="true" tabindex="-1"></a><span class="fu">### IPTW- Inverse Probability of Treatment Weighting estimator</span></span>
<span id="cb71-405"><a href="#cb71-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-406"><a href="#cb71-406" aria-hidden="true" tabindex="-1"></a>**Intuition (pseudo-population):** IPTW treats confounding as a form of biased sampling. Units who received a treatment that was unlikely given their covariates receive larger weights, and units who received an expected treatment receive smaller weights. In the resulting weighted pseudo-population, treatment is approximately independent of measured covariates (if the propensity score model is correct), mimicking a randomized experiment.</span>
<span id="cb71-407"><a href="#cb71-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-408"><a href="#cb71-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-409"><a href="#cb71-409" aria-hidden="true" tabindex="-1"></a>The intuition behind this estimation approach is to think of confounding as a problem of biased sampling, where certain exposure–covariate subgroups are overrepresented relative to what we would observe in a randomized trial, while others are underrepresented. We apply weights to up-weight under-represented units and down-weight over-represented units We then average and compare weighted outcomes. The algorithm is as follows;</span>
<span id="cb71-410"><a href="#cb71-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-411"><a href="#cb71-411" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Estimate the probability of being exposed/treated A as a function of measured confounders W:$\mathbb{P}(A=1\mid W)$. This is often referred to as the propensity score. We can estimate the propensity score by running a main terms logistic regression as illustrated below</span>
<span id="cb71-412"><a href="#cb71-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-415"><a href="#cb71-415" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb71-416"><a href="#cb71-416" aria-hidden="true" tabindex="-1"></a>pscore.regression <span class="ot">&lt;-</span> <span class="fu">glm</span>(A<span class="sc">~</span> W1<span class="sc">+</span>W2<span class="sc">+</span>W3<span class="sc">+</span>W4, <span class="at">family=</span><span class="fu">binomial</span>(), <span class="at">data=</span>data)</span>
<span id="cb71-417"><a href="#cb71-417" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pscore.regression)</span>
<span id="cb71-418"><a href="#cb71-418" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-419"><a href="#cb71-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-420"><a href="#cb71-420" aria-hidden="true" tabindex="-1"></a>**Identification link:** Under consistency, exchangeability given <span class="sc">\(</span>W<span class="sc">\)</span>, and positivity, we can write</span>
<span id="cb71-421"><a href="#cb71-421" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb71-422"><a href="#cb71-422" aria-hidden="true" tabindex="-1"></a>E<span class="sc">\{</span>Y(1)<span class="sc">\}</span> = E\left<span class="co">[</span><span class="ot">\frac{\mathbb{I}(A=1)Y}{e(W)}\right</span><span class="co">]</span>, \qquad</span>
<span id="cb71-423"><a href="#cb71-423" aria-hidden="true" tabindex="-1"></a>E<span class="sc">\{</span>Y(0)<span class="sc">\}</span> = E\left<span class="co">[</span><span class="ot">\frac{\mathbb{I}(A=0)Y}{1-e(W)}\right</span><span class="co">]</span>,</span>
<span id="cb71-424"><a href="#cb71-424" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb71-425"><a href="#cb71-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-426"><a href="#cb71-426" aria-hidden="true" tabindex="-1"></a>where <span class="sc">\(</span>e(W)=P(A=1\mid W)<span class="sc">\)</span>. IPTW replaces the expectation with a sample average and replaces <span class="sc">\(</span>e(W)<span class="sc">\)</span> with an estimate.</span>
<span id="cb71-427"><a href="#cb71-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-428"><a href="#cb71-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-429"><a href="#cb71-429" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>We then use estimates from 1 above to calculate exposed/treated weights: 1/$\mathbb{P}(A=1\mid W)$ and unexposed/untreated weights:1/$\mathbb{P}(A=0\mid W)$</span>
<span id="cb71-430"><a href="#cb71-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-433"><a href="#cb71-433" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb71-434"><a href="#cb71-434" aria-hidden="true" tabindex="-1"></a>predict.prob.A1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(pscore.regression, <span class="at">type=</span><span class="st">'response'</span>)</span>
<span id="cb71-435"><a href="#cb71-435" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(predict.prob.A1)</span>
<span id="cb71-436"><a href="#cb71-436" aria-hidden="true" tabindex="-1"></a>predict.prob.A0 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> predict.prob.A1</span>
<span id="cb71-437"><a href="#cb71-437" aria-hidden="true" tabindex="-1"></a>wt1 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>( data<span class="sc">$</span>A<span class="sc">==</span><span class="dv">1</span>)<span class="sc">/</span>predict.prob.A1</span>
<span id="cb71-438"><a href="#cb71-438" aria-hidden="true" tabindex="-1"></a>wt0 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>( data<span class="sc">$</span>A<span class="sc">==</span><span class="dv">0</span>)<span class="sc">/</span>predict.prob.A0</span>
<span id="cb71-439"><a href="#cb71-439" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">data.frame</span>(<span class="fu">cbind</span>(<span class="at">A=</span>data<span class="sc">$</span>A, <span class="dv">1</span><span class="sc">/</span>predict.prob.A1, wt1, wt0)))</span>
<span id="cb71-440"><a href="#cb71-440" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-441"><a href="#cb71-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-442"><a href="#cb71-442" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>We then apply the weights and average the weighted outcomes to estimate the marginal risks in the population under A=1 and A=0. To compare estimates, we take the difference in weighted means.</span>
<span id="cb71-443"><a href="#cb71-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-446"><a href="#cb71-446" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb71-447"><a href="#cb71-447" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(wt1<span class="sc">*</span>data<span class="sc">$</span>Y)</span>
<span id="cb71-448"><a href="#cb71-448" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(wt0<span class="sc">*</span>data<span class="sc">$</span>Y)</span>
<span id="cb71-449"><a href="#cb71-449" aria-hidden="true" tabindex="-1"></a>IPW <span class="ot">&lt;-</span> <span class="fu">mean</span>(wt1<span class="sc">*</span>data<span class="sc">$</span>Y) <span class="sc">-</span> <span class="fu">mean</span>(wt0<span class="sc">*</span>data<span class="sc">$</span>Y)</span>
<span id="cb71-450"><a href="#cb71-450" aria-hidden="true" tabindex="-1"></a>IPW</span>
<span id="cb71-451"><a href="#cb71-451" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>( (wt1<span class="sc">-</span>wt0)<span class="sc">*</span>data<span class="sc">$</span>Y)</span>
<span id="cb71-452"><a href="#cb71-452" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-453"><a href="#cb71-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-454"><a href="#cb71-454" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Stabilized weights (optional but common in practice)</span></span>
<span id="cb71-455"><a href="#cb71-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-456"><a href="#cb71-456" aria-hidden="true" tabindex="-1"></a>Unstabilized weights can be variable in finite samples. A common alternative is to use stabilized weights, which multiply by the marginal probability of observed treatment:</span>
<span id="cb71-457"><a href="#cb71-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-458"><a href="#cb71-458" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb71-459"><a href="#cb71-459" aria-hidden="true" tabindex="-1"></a>SW_i =</span>
<span id="cb71-460"><a href="#cb71-460" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb71-461"><a href="#cb71-461" aria-hidden="true" tabindex="-1"></a>\frac{P(A=1)}{e(W_i)}, &amp; A_i=1 <span class="sc">\\</span></span>
<span id="cb71-462"><a href="#cb71-462" aria-hidden="true" tabindex="-1"></a>\frac{P(A=0)}{1-e(W_i)}, &amp; A_i=0.</span>
<span id="cb71-463"><a href="#cb71-463" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb71-464"><a href="#cb71-464" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb71-465"><a href="#cb71-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-466"><a href="#cb71-466" aria-hidden="true" tabindex="-1"></a>Stabilized weights often reduce variance and improve numerical stability without changing the large-sample target under correct specification.</span>
<span id="cb71-467"><a href="#cb71-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-470"><a href="#cb71-470" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb71-471"><a href="#cb71-471" aria-hidden="true" tabindex="-1"></a>pA <span class="ot">&lt;-</span> <span class="fu">mean</span>(data<span class="sc">$</span>A)</span>
<span id="cb71-472"><a href="#cb71-472" aria-hidden="true" tabindex="-1"></a>sw1 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(data<span class="sc">$</span>A<span class="sc">==</span><span class="dv">1</span>) <span class="sc">*</span> pA <span class="sc">/</span> predict.prob.A1</span>
<span id="cb71-473"><a href="#cb71-473" aria-hidden="true" tabindex="-1"></a>sw0 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(data<span class="sc">$</span>A<span class="sc">==</span><span class="dv">0</span>) <span class="sc">*</span> (<span class="dv">1</span><span class="sc">-</span>pA) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> predict.prob.A1)</span>
<span id="cb71-474"><a href="#cb71-474" aria-hidden="true" tabindex="-1"></a>sw  <span class="ot">&lt;-</span> sw1 <span class="sc">+</span> sw0</span>
<span id="cb71-475"><a href="#cb71-475" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(sw)</span>
<span id="cb71-476"><a href="#cb71-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-477"><a href="#cb71-477" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-478"><a href="#cb71-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-479"><a href="#cb71-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-480"><a href="#cb71-480" aria-hidden="true" tabindex="-1"></a>**Implementation note:** IPTW can be implemented either by directly computing weighted means of <span class="sc">\(</span>Y<span class="sc">\)</span> within treatment groups (as shown here) or by fitting a weighted regression of <span class="sc">\(</span>Y<span class="sc">\)</span> on <span class="sc">\(</span>A<span class="sc">\)</span> using robust standard errors. These approaches target the same marginal contrast when implemented consistently.</span>
<span id="cb71-481"><a href="#cb71-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-482"><a href="#cb71-482" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Diagnostics and practical tips (IPTW)</span></span>
<span id="cb71-483"><a href="#cb71-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-484"><a href="#cb71-484" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Overlap:** Inspect the distribution of <span class="sc">\(</span>e(W)<span class="sc">\)</span> by treatment group. Limited overlap indicates practical positivity problems and increases variance.</span>
<span id="cb71-485"><a href="#cb71-485" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Weight tails:** Summarize weights (mean, sd, extreme quantiles). A heavy right tail indicates instability and sensitivity to a small number of observations.</span>
<span id="cb71-486"><a href="#cb71-486" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Truncation:** Truncating weights (for example, at the 1st and 99th percentiles) can reduce variance at the cost of potential bias. In finite samples, truncation can improve mean squared error, but it should be reported transparently as a sensitivity analysis.</span>
<span id="cb71-487"><a href="#cb71-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-490"><a href="#cb71-490" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb71-491"><a href="#cb71-491" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> wt1 <span class="sc">+</span> wt0</span>
<span id="cb71-492"><a href="#cb71-492" aria-hidden="true" tabindex="-1"></a>lo <span class="ot">&lt;-</span> <span class="fu">quantile</span>(w, <span class="fl">0.01</span>)</span>
<span id="cb71-493"><a href="#cb71-493" aria-hidden="true" tabindex="-1"></a>hi <span class="ot">&lt;-</span> <span class="fu">quantile</span>(w, <span class="fl">0.99</span>)</span>
<span id="cb71-494"><a href="#cb71-494" aria-hidden="true" tabindex="-1"></a>w_trunc <span class="ot">&lt;-</span> <span class="fu">pmin</span>(<span class="fu">pmax</span>(w, lo), hi)</span>
<span id="cb71-495"><a href="#cb71-495" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(w_trunc)</span>
<span id="cb71-496"><a href="#cb71-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-497"><a href="#cb71-497" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-498"><a href="#cb71-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-499"><a href="#cb71-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-500"><a href="#cb71-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-501"><a href="#cb71-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-502"><a href="#cb71-502" aria-hidden="true" tabindex="-1"></a><span class="fu">### TMLE- targeted maximum likelihood estimation</span></span>
<span id="cb71-503"><a href="#cb71-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-504"><a href="#cb71-504" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Why doubly robust estimators?</span></span>
<span id="cb71-505"><a href="#cb71-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-506"><a href="#cb71-506" aria-hidden="true" tabindex="-1"></a>Both g-computation and IPTW rely on strong modeling assumptions: g-computation requires a correct outcome model, while IPTW requires a correct treatment model. Doubly robust estimators combine both approaches and are consistent if **either** the outcome model or the treatment model is correctly specified. This property is particularly valuable in real-world data settings, where all models are approximations.</span>
<span id="cb71-507"><a href="#cb71-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-508"><a href="#cb71-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-509"><a href="#cb71-509" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>For intuition here,  we again think of causal inference as a problem of missing information. </span>
<span id="cb71-510"><a href="#cb71-510" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We predict the outcomes for all units under both exposed and unexposed conditions. We use a flexible estimation approach e.g. Super Learner to avoid assuming regression models that are not known or we use parametric knowledge if known.</span>
<span id="cb71-511"><a href="#cb71-511" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We incorporate information on the covariate-exposure relation to ***improve*** the initial estimator. Why TMLE?</span>
<span id="cb71-512"><a href="#cb71-512" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Again here we use a flexible estimation approach or parameteric knowledge if available.</span>
<span id="cb71-513"><a href="#cb71-513" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>We have a second chance to control for confounding hence this method is doubly robust</span>
<span id="cb71-514"><a href="#cb71-514" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>We are able to hone our estimator towards the parameter of interest.</span>
<span id="cb71-515"><a href="#cb71-515" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>This estimator is asymptotically linear and therefore we can obtain normal curve inference</span>
<span id="cb71-516"><a href="#cb71-516" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Finally, we average and compare the targeted predictions under exposure and no exposure.</span>
<span id="cb71-517"><a href="#cb71-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-518"><a href="#cb71-518" aria-hidden="true" tabindex="-1"></a><span class="fu">#### What is Super Learner?</span></span>
<span id="cb71-519"><a href="#cb71-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-520"><a href="#cb71-520" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>This is a supervised machine learning algorithm that offers a flexible and data daptive approach to learn complex relationships from data. </span>
<span id="cb71-521"><a href="#cb71-521" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>This algorithm uses cross-validation(sample splitting) to evaluate the performance of a library of candidate estimators.</span>
<span id="cb71-522"><a href="#cb71-522" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>The library should be diverse including simple (e.g expert informed parametric regressions) and more adaptive algorithms (e.g penalized regressions, stepwise regression, adaptive splines)</span>
<span id="cb71-523"><a href="#cb71-523" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Performance is measured by a loss function e.g squared prediction error</span>
<span id="cb71-524"><a href="#cb71-524" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Cross-validation allows us to compare algorithms based on how they perform on independent data. Here we partition data in "folds", fit each algorithm on the training set and evaluate its performance (called "risk") on the validation set. We rotate through the folds and average the cross-validated risk estimates across the folds to obtain one measure of performance for each algorithm.</span>
<span id="cb71-525"><a href="#cb71-525" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We could choose the algorithm with the best performance (e.g the lowest cross-validated MSE)</span>
<span id="cb71-526"><a href="#cb71-526" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Instead, Super Learner builds the best combination of algorithm- specific predictions. We now illustrate below how to fit a Super Learner.</span>
<span id="cb71-527"><a href="#cb71-527" aria-hidden="true" tabindex="-1"></a><span class="in">```{r,message=FALSE}</span></span>
<span id="cb71-528"><a href="#cb71-528" aria-hidden="true" tabindex="-1"></a><span class="in">library('SuperLearner')</span></span>
<span id="cb71-529"><a href="#cb71-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-530"><a href="#cb71-530" aria-hidden="true" tabindex="-1"></a><span class="in">SL.library &lt;- c("SL.glm", "SL.step.interaction", "SL.gam")</span></span>
<span id="cb71-531"><a href="#cb71-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-532"><a href="#cb71-532" aria-hidden="true" tabindex="-1"></a><span class="in">X_Q &lt;- select(data, A, W1, W2, W3, W4)</span></span>
<span id="cb71-533"><a href="#cb71-533" aria-hidden="true" tabindex="-1"></a><span class="in">Y_Q &lt;- data$Y</span></span>
<span id="cb71-534"><a href="#cb71-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-535"><a href="#cb71-535" aria-hidden="true" tabindex="-1"></a><span class="in">SL.outcome.regression &lt;- suppressWarnings(</span></span>
<span id="cb71-536"><a href="#cb71-536" aria-hidden="true" tabindex="-1"></a><span class="in">  SuperLearner(Y = Y_Q, X = X_Q, SL.library = SL.library, family = binomial())</span></span>
<span id="cb71-537"><a href="#cb71-537" aria-hidden="true" tabindex="-1"></a><span class="in">)</span></span>
<span id="cb71-538"><a href="#cb71-538" aria-hidden="true" tabindex="-1"></a><span class="in">SL.outcome.regression</span></span>
<span id="cb71-539"><a href="#cb71-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-540"><a href="#cb71-540" aria-hidden="true" tabindex="-1"></a><span class="in">SL.predict.outcome &lt;- predict(SL.outcome.regression, </span></span>
<span id="cb71-541"><a href="#cb71-541" aria-hidden="true" tabindex="-1"></a><span class="in">                              newdata=subset(data, select=-Y))$pred</span></span>
<span id="cb71-542"><a href="#cb71-542" aria-hidden="true" tabindex="-1"></a><span class="in">head(SL.predict.outcome)</span></span>
<span id="cb71-543"><a href="#cb71-543" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-544"><a href="#cb71-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-545"><a href="#cb71-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-546"><a href="#cb71-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-547"><a href="#cb71-547" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Why do I need to target?</span></span>
<span id="cb71-548"><a href="#cb71-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-549"><a href="#cb71-549" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We could use Super Learner to predict the outcomes for each unit while "setting" the exposure to different levels and then average and contrast the predictions. </span>
<span id="cb71-552"><a href="#cb71-552" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb71-553"><a href="#cb71-553" aria-hidden="true" tabindex="-1"></a>SL.predict.outcome.A1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(SL.outcome.regression, </span>
<span id="cb71-554"><a href="#cb71-554" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">newdata=</span><span class="fu">subset</span>(data.A1, <span class="at">select=</span><span class="sc">-</span>Y))<span class="sc">$</span>pred</span>
<span id="cb71-555"><a href="#cb71-555" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(SL.predict.outcome.A1)</span>
<span id="cb71-556"><a href="#cb71-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-557"><a href="#cb71-557" aria-hidden="true" tabindex="-1"></a>SL.predict.outcome.A0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(SL.outcome.regression, <span class="at">newdata=</span><span class="fu">subset</span>(data.A0, <span class="at">select=</span><span class="sc">-</span>Y))<span class="sc">$</span>pred</span>
<span id="cb71-558"><a href="#cb71-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-559"><a href="#cb71-559" aria-hidden="true" tabindex="-1"></a><span class="co"># simple subst estimator</span></span>
<span id="cb71-560"><a href="#cb71-560" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(SL.predict.outcome.A1) <span class="sc">-</span> <span class="fu">mean</span>(SL.predict.outcome.A0)</span>
<span id="cb71-561"><a href="#cb71-561" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-562"><a href="#cb71-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-563"><a href="#cb71-563" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>But Super Learner is focused on $\mathbb{E}(Y\mid A,W)$ and not our parameter of interest. It makes the wrong bias-variance trade-off and specifically incurs too much bias. </span>
<span id="cb71-564"><a href="#cb71-564" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>There is also no reliable way to obtain statistical inference (i.e create 95% confidence intervals)</span>
<span id="cb71-565"><a href="#cb71-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-566"><a href="#cb71-566" aria-hidden="true" tabindex="-1"></a><span class="fu">#### What is targeting?</span></span>
<span id="cb71-567"><a href="#cb71-567" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Targeting involves using information in the estimated propensity score $\mathbb{P}(A=1\mid W)$ to update the initial (Super Learner) estimator of $\mathbb{E}(Y\mid A,W)$.</span>
<span id="cb71-568"><a href="#cb71-568" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>It involves running a univariate regression of the outcome Y on a clever covariate with offset the initial estimator. Why "clever"? It ensures that the targeting step moves the initial estimator in a direction that removes bias. </span>
<span id="cb71-569"><a href="#cb71-569" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We then use the estimated coefficient to update our initial predictions of the outcome under the exposure and no exposure.</span>
<span id="cb71-570"><a href="#cb71-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-571"><a href="#cb71-571" aria-hidden="true" tabindex="-1"></a><span class="fu">#### How do i target? (One approach)</span></span>
<span id="cb71-572"><a href="#cb71-572" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Use Super Learner to estimate the propensity score $\mathbb{P}(A=1\mid W)$</span>
<span id="cb71-575"><a href="#cb71-575" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb71-576"><a href="#cb71-576" aria-hidden="true" tabindex="-1"></a>SL.pscore <span class="ot">&lt;-</span> <span class="fu">SuperLearner</span>(<span class="at">Y=</span>data<span class="sc">$</span>A, <span class="at">X=</span><span class="fu">subset</span>(data, <span class="at">select=</span><span class="sc">-</span><span class="fu">c</span>(A,Y)),</span>
<span id="cb71-577"><a href="#cb71-577" aria-hidden="true" tabindex="-1"></a>                          <span class="at">SL.library=</span>SL.library, <span class="at">family=</span><span class="fu">binomial</span>())</span>
<span id="cb71-578"><a href="#cb71-578" aria-hidden="true" tabindex="-1"></a>SL.pscore</span>
<span id="cb71-579"><a href="#cb71-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-580"><a href="#cb71-580" aria-hidden="true" tabindex="-1"></a>SL.predict.prob.A1 <span class="ot">&lt;-</span> SL.pscore<span class="sc">$</span>SL.predict</span>
<span id="cb71-581"><a href="#cb71-581" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(SL.predict.prob.A1 <span class="sc">-</span> <span class="fu">predict</span>(SL.pscore, <span class="at">newdata=</span><span class="fu">subset</span>(data,<span class="at">select=</span><span class="sc">-</span><span class="fu">c</span>(A,Y)))<span class="sc">$</span>pred)</span>
<span id="cb71-582"><a href="#cb71-582" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(SL.predict.prob.A1)</span>
<span id="cb71-583"><a href="#cb71-583" aria-hidden="true" tabindex="-1"></a>SL.predict.prob.A0 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> SL.predict.prob.A1</span>
<span id="cb71-584"><a href="#cb71-584" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-585"><a href="#cb71-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-586"><a href="#cb71-586" aria-hidden="true" tabindex="-1"></a>***Note***: As you run this code you might encounter a warning "non-integer #successes in a binomial glm!". This simply means that our outcome Y is not binary much as it's bounded between 0 and 1. This is okay and can be ignored. </span>
<span id="cb71-587"><a href="#cb71-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-588"><a href="#cb71-588" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Calculate the "clever covariate"</span>
<span id="cb71-589"><a href="#cb71-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-590"><a href="#cb71-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-591"><a href="#cb71-591" aria-hidden="true" tabindex="-1"></a>$$H(A,W)= \frac{\mathbb{I}(A=1)}{\mathbb{P}(A=1\mid W)}- \frac{\mathbb{I}(A=0)}{\mathbb{P}(A=0\mid W)}$$</span>
<span id="cb71-592"><a href="#cb71-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-593"><a href="#cb71-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-594"><a href="#cb71-594" aria-hidden="true" tabindex="-1"></a>Here's code to evaluate the "clever covariate"</span>
<span id="cb71-597"><a href="#cb71-597" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb71-598"><a href="#cb71-598" aria-hidden="true" tabindex="-1"></a>H.AW <span class="ot">&lt;-</span> (data<span class="sc">$</span>A<span class="sc">==</span><span class="dv">1</span>)<span class="sc">/</span>SL.predict.prob.A1 <span class="sc">-</span> (data<span class="sc">$</span>A<span class="sc">==</span><span class="dv">0</span>)<span class="sc">/</span>SL.predict.prob.A0</span>
<span id="cb71-599"><a href="#cb71-599" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(H.AW)</span>
<span id="cb71-600"><a href="#cb71-600" aria-hidden="true" tabindex="-1"></a>H<span class="fl">.1</span>W <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>SL.predict.prob.A1</span>
<span id="cb71-601"><a href="#cb71-601" aria-hidden="true" tabindex="-1"></a>H<span class="fl">.0</span>W <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span>SL.predict.prob.A0</span>
<span id="cb71-602"><a href="#cb71-602" aria-hidden="true" tabindex="-1"></a><span class="fu">tail</span>(<span class="fu">data.frame</span>(<span class="at">A=</span>data<span class="sc">$</span>A, H.AW, H<span class="fl">.1</span>W, H<span class="fl">.0</span>W))</span>
<span id="cb71-603"><a href="#cb71-603" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-604"><a href="#cb71-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-605"><a href="#cb71-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-606"><a href="#cb71-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-607"><a href="#cb71-607" aria-hidden="true" tabindex="-1"></a>3.Run logistic regression of the outcome on this covariate using logit of the initial estimator $\mathbb{E}(Y\mid A,W)$  as offset where logit(x)= log<span class="co">[</span><span class="ot">x/(1-x)</span><span class="co">]</span></span>
<span id="cb71-608"><a href="#cb71-608" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb71-611"><a href="#cb71-611" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb71-612"><a href="#cb71-612" aria-hidden="true" tabindex="-1"></a>logitUpdate <span class="ot">&lt;-</span> <span class="fu">glm</span>( data<span class="sc">$</span>Y <span class="sc">~</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span><span class="fu">offset</span>( <span class="fu">qlogis</span>(SL.predict.outcome)) <span class="sc">+</span></span>
<span id="cb71-613"><a href="#cb71-613" aria-hidden="true" tabindex="-1"></a>                      H.AW, <span class="at">family=</span><span class="st">'binomial'</span>)</span>
<span id="cb71-614"><a href="#cb71-614" aria-hidden="true" tabindex="-1"></a>epsilon <span class="ot">&lt;-</span> logitUpdate<span class="sc">$</span>coef</span>
<span id="cb71-615"><a href="#cb71-615" aria-hidden="true" tabindex="-1"></a>epsilon</span>
<span id="cb71-616"><a href="#cb71-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-617"><a href="#cb71-617" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-618"><a href="#cb71-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-619"><a href="#cb71-619" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Plug in the estimated coefficient $\epsilon$ to yield our targeted estimator $\mathbb{E^*}(Y\mid A,W)$ and use the targeted estimator $\mathbb{E^*}(Y\mid A,W)$ to predict outcomes for all  under A=1 and A=0</span>
<span id="cb71-622"><a href="#cb71-622" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb71-623"><a href="#cb71-623" aria-hidden="true" tabindex="-1"></a>target.predict.outcome.A1 <span class="ot">&lt;-</span> <span class="fu">plogis</span>( <span class="fu">qlogis</span>(SL.predict.outcome.A1)<span class="sc">+</span></span>
<span id="cb71-624"><a href="#cb71-624" aria-hidden="true" tabindex="-1"></a>                                       epsilon<span class="sc">*</span>H<span class="fl">.1</span>W)</span>
<span id="cb71-625"><a href="#cb71-625" aria-hidden="true" tabindex="-1"></a>target.predict.outcome.A0 <span class="ot">&lt;-</span> <span class="fu">plogis</span>( <span class="fu">qlogis</span>(SL.predict.outcome.A0)<span class="sc">+</span></span>
<span id="cb71-626"><a href="#cb71-626" aria-hidden="true" tabindex="-1"></a>                                      epsilon<span class="sc">*</span>H<span class="fl">.0</span>W)</span>
<span id="cb71-627"><a href="#cb71-627" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-628"><a href="#cb71-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-629"><a href="#cb71-629" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Average the predictions to estimate the marginal risks in the population under exposure and no exposure. Compare the estimates by taking the difference. </span>
<span id="cb71-632"><a href="#cb71-632" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb71-633"><a href="#cb71-633" aria-hidden="true" tabindex="-1"></a>TMLE <span class="ot">&lt;-</span> <span class="fu">mean</span>( target.predict.outcome.A1 <span class="sc">-</span> target.predict.outcome.A0)</span>
<span id="cb71-634"><a href="#cb71-634" aria-hidden="true" tabindex="-1"></a>TMLE</span>
<span id="cb71-635"><a href="#cb71-635" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb71-636"><a href="#cb71-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-637"><a href="#cb71-637" aria-hidden="true" tabindex="-1"></a><span class="fu">### Estimator Properties</span></span>
<span id="cb71-638"><a href="#cb71-638" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We have discussed three estimators and gone through their implementation. We shall now go over the properties and each of them and points of consideration. </span>
<span id="cb71-639"><a href="#cb71-639" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Simple substitution estimator</span>
<span id="cb71-640"><a href="#cb71-640" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Relies on consistently estimating the mean outcome $\mathbb{E^*}(Y\mid A,W)$. Sometimes we have a lot of knowledge about how the relationship between the outcome Y and the exposure-covariates (A,W) but other times, our knowldege is limited and assuming a parametric regression model can result in bias and misleading inferences.</span>
<span id="cb71-641"><a href="#cb71-641" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>IPTW</span>
<span id="cb71-642"><a href="#cb71-642" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Relies on consistently estimating the propensity score $\mathbb{P}(A=1\mid W)$. While sometimes we have a lot of knowledge about how the exposure was assigned, other times our knowledge is limited and assuming a parametric regression model can result in bias and misleading inference. </span>
<span id="cb71-643"><a href="#cb71-643" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>This estimator is unstable under positivity violations. When covariate groups only have a few exposed or unexposed observations, weights can blow up!!. When there are covariate groups with 0 exposed or unexposed observations, weights will not blow up but the estimator will likely be biased and varaince will be underestimated. </span>
<span id="cb71-644"><a href="#cb71-644" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>TMLE</span>
<span id="cb71-645"><a href="#cb71-645" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>This estimator is doubly robust i.e. yields a consistent estimate if either the conditional mean  $\mathbb{E^*}(Y\mid A,W)$ or the propensity score $\mathbb{P}(A=1\mid W)$ is consistently estimated. We get two chances to get it right !!</span>
<span id="cb71-646"><a href="#cb71-646" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>It is also semi-parametric efficient which means it achieves the lowest asymptotic variance (most precision) among a large class of estimators if both the conditional mean and propensity score are consistently  estimated at reasonable rates.</span>
<span id="cb71-647"><a href="#cb71-647" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>This estimator has formal theory to support valid statistical inference under mild conditions even when using machine learning. </span>
<span id="cb71-648"><a href="#cb71-648" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Being a substitution estimator (plug-in), it is robust under positivity violations,strong confounding and rare outcomes.</span>
<span id="cb71-649"><a href="#cb71-649" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>There is readily available software to implement this estimator e.g. ltmle package, lmptp package in R among others</span>
<span id="cb71-650"><a href="#cb71-650" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We have now come to the end of our estimation exercise assuming we have selected an estimating approach and estimated our parameter of interest. We now move back to the general Roadmap.</span>
<span id="cb71-651"><a href="#cb71-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-652"><a href="#cb71-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-653"><a href="#cb71-653" aria-hidden="true" tabindex="-1"></a><span class="fu">## Step 6: Statistical Uncertainty</span></span>
<span id="cb71-654"><a href="#cb71-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-655"><a href="#cb71-655" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>To do statistical inference, we need to derive an estimate of the sampling distribution. </span>
<span id="cb71-656"><a href="#cb71-656" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We can consider doing a non-parametric bootstrap where we re-sample the observed data with replacement, apply the entire estimation process (including machine learning algorithms) to the re-sampled data, repeat X times and estimate the variance with the bootstrapped point estimates. </span>
<span id="cb71-657"><a href="#cb71-657" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Alternatively, we can use influence curve based inference. We shall not discuss this here but this form of inference is available in the R packages. </span>
<span id="cb71-658"><a href="#cb71-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-659"><a href="#cb71-659" aria-hidden="true" tabindex="-1"></a><span class="fu">## Step 7: Interpret findings</span></span>
<span id="cb71-660"><a href="#cb71-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-661"><a href="#cb71-661" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The final step of the Causal Roadmap is to interpret the findings. At this stage, we evaluate whether and to what extent  the underlying assumptions have been met in order to determine the strength of interpretation.</span>
<span id="cb71-662"><a href="#cb71-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-663"><a href="#cb71-663" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Findings support a statistical interpretation if (1) the statistical estimator has negligible bias and its variance is well estimated </span>
<span id="cb71-664"><a href="#cb71-664" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Findings support a causal interpretation if 1 holds and  (2) if the non testable identifiability assumptions hold.</span>
<span id="cb71-665"><a href="#cb71-665" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Can be interpreted as if implemented in the real-world if 1 and 2 hold and if (3) the intervention is feasible and applicable to the real world population. </span>
<span id="cb71-666"><a href="#cb71-666" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Findings can be interpreted as if we had emulated a randomized trial if 1-3 hold and the exposure could have been randomized to that population.</span>
<span id="cb71-667"><a href="#cb71-667" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>If there are concerns about causal assumptions (e.g. temporal odering is unclear, unmeasured confounding), the results can be interpreted as ***associational***.  In this case the estimand, $\mathbb{E}\big<span class="co">[</span><span class="ot">\mathbb{E}(Y\mid A=1,W)-\mathbb{E}(Y\mid A=0,W)</span><span class="co">]</span>$ can be interpreted as; </span>
<span id="cb71-668"><a href="#cb71-668" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>The marginal difference in the expected outcome associated with the exposure, after accounting for the measured confounders</span>
<span id="cb71-669"><a href="#cb71-669" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>The difference in the mean outcome between persons exposed versus unexposed but with the same values of the adjustment covariates (averaged with respect to the distribution of those covariates in the population).e.g The difference in the risk of cardiovascular disease with intervention A vs B is X, accounting for region,age,sex,SES etc</span>
<span id="cb71-670"><a href="#cb71-670" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Alternatively one can report that this is as close as we can get to the causal effet of A on Y given the limitations of the data detailing all limitations and including a causal graph to empower the reader to assess the plausibility of assumptions.</span>
<span id="cb71-671"><a href="#cb71-671" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>If the authors believe causal assumptions are met, the parameter can be interpreted as the population average treatment effect  $\mathbb{E}\big<span class="co">[</span><span class="ot">Y_1-Y_0\big</span><span class="co">]</span>$.</span>
<span id="cb71-672"><a href="#cb71-672" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>In words, this would be the difference in the expected outcome if everyone were exposed compared if everyone were unexposed. For example, there would be an X difference in the risk of cardiovascular disease if all patients in the population received intervention A vs B. </span>
<span id="cb71-673"><a href="#cb71-673" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb71-674"><a href="#cb71-674" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary and Discussion</span></span>
<span id="cb71-675"><a href="#cb71-675" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Congratulations!! You have successfully gone through the causal roadmap tutorial and successfully implemented the simple substitution, IPTW and TMLE estimators. </span>
<span id="cb71-676"><a href="#cb71-676" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Hopefully, you have increased your intuitive and technical understanding of these estimators.</span>
<span id="cb71-677"><a href="#cb71-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-678"><a href="#cb71-678" aria-hidden="true" tabindex="-1"></a><span class="fu">## Caution: Use your tools well. </span></span>
<span id="cb71-679"><a href="#cb71-679" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Use TMLE with Super Learner as part of a toolbox. Recall, fancy estimation tools cannot replace careful thinking throughout the rest of the Roadmap.</span>
<span id="cb71-680"><a href="#cb71-680" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Remember to formally derive adjustment sets and the statistical parameter. </span>
<span id="cb71-681"><a href="#cb71-681" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Avoid errors of "causal model neglect", occuring when estimating something differing meaningfully from any interpretable causal effect.</span>
<span id="cb71-682"><a href="#cb71-682" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb71-683"><a href="#cb71-683" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Doubly robust estimators (e.g TMLE or A-IPW) can incorporate machine learning while maintaining basis for valid statistical inference. This helps us avoid errors  of "statistical model neglect", occurring when relying on unsubstantiated (parametric) assumptions during estimation. However, not without conditions. </span>
<span id="cb71-684"><a href="#cb71-684" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Specify the Super Learner library with care.</span>
<span id="cb71-685"><a href="#cb71-685" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Diversity is key</span>
<span id="cb71-686"><a href="#cb71-686" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Avoid overfitting by using sample splitting</span>
<span id="cb71-687"><a href="#cb71-687" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Practical positivity violations can happen. This can result from poor support for exposures of interest and can lead to bias  and/or underestimates of variance. Some solutions to this include;</span>
<span id="cb71-688"><a href="#cb71-688" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Using a substitution estimator (G-comp,TMLE)</span>
<span id="cb71-689"><a href="#cb71-689" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Doing targeting in TMLE through weighted regression instead of a clever covariate</span>
<span id="cb71-690"><a href="#cb71-690" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Using a robust variance estimator e.g Tran et al.(2018), Benkeser et al. (2017)</span>
<span id="cb71-691"><a href="#cb71-691" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Bounding the estimated propensity score away from O</span>
<span id="cb71-692"><a href="#cb71-692" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Run a simulation study mimicking key patterns of the observed data for example sample size, confounding structure, missing data mechanisms, practical violations, sparsity of the exposure and/or outcome, dependence structure etc and use results to guide analyses.</span>
<span id="cb71-693"><a href="#cb71-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-694"><a href="#cb71-694" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>You have also survived a high speed tour through the Roadmap, and hopefully can appreciate some of its strengths.</span>
<span id="cb71-695"><a href="#cb71-695" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>It necessitates clearly defined research questions, and ensures the parameters estimated will match the questions posed.</span>
<span id="cb71-696"><a href="#cb71-696" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Elaborates what assumptions are necessary to interpret estimates as a causal effect</span>
<span id="cb71-697"><a href="#cb71-697" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>When assumptions are not met, the unmet assumptions provide clear guidance on how future research must be improved to increase the potential of causal interpretation.</span>
<span id="cb71-698"><a href="#cb71-698" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Working in this framework can improve interpretability and relevance of epidemiologic research.</span>
<span id="cb71-699"><a href="#cb71-699" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Despite focusing on the ATE, this framework is applicable to other causal questions and data structures such as estimating effects among treated/untreated, mediation, longitudinal interventions, dynamic regimes etc.</span>
<span id="cb71-700"><a href="#cb71-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-701"><a href="#cb71-701" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>If you are interested in learning about more advanced settings, here are some links to other resources. </span>
<span id="cb71-702"><a href="#cb71-702" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb71-703"><a href="#cb71-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-704"><a href="#cb71-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-705"><a href="#cb71-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-706"><a href="#cb71-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-707"><a href="#cb71-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-708"><a href="#cb71-708" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb71-709"><a href="#cb71-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-710"><a href="#cb71-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-711"><a href="#cb71-711" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>