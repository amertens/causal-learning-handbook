{
  "hash": "324a6274d983bb7b9b2525a5a28fb63b",
  "result": {
    "engine": "knitr",
    "markdown": "# Common Pitfalls and How to Avoid Them\n*A practical guide for avoiding frequent mistakes in causal inference and targeted learning*\n\nEven with a solid understanding of the Causal Roadmap and modern estimators, it is easy to make analytic choices that lead to biased, unstable, or misleading results. In real-world evidence (RWE), the stakes are higher: data are messy, treatment pathways are irregular, and credibility depends on careful alignment between the scientific question, identification conditions, and the estimator.\n\nThis chapter catalogs common pitfalls encountered in causal inference, especially in pharmacoepidemiologic and longitudinal RWE settings, and provides practical strategies to avoid them.\n\n---\n\n## 1. Pitfall: Confusing Association With Causation  \n### The regression coefficient problem\n\n**Mistake:**  \nFitting a multivariable regression and interpreting the treatment coefficient as a causal effect.\n\n**Why it matters:**  \nRegression coefficients are typically **conditional associations**, not causal contrasts. Unless the model corresponds to the identified statistical functional and is correctly specified, the result may not estimate the causal estimand.\n\n**Avoid by:**  \n- Defining a precise **causal question** and **estimand**  \n- Estimating the corresponding statistical functional using **g-computation**, **IPTW**, **AIPW**, or **TMLE**  \n- Using flexible nuisance estimation (for example, **SuperLearner**) where appropriate  \n\n---\n\n## 2. Pitfall: Adjusting for Post-Treatment Variables  \n### The mediator/collider trap\n\n**Mistake:**  \nIncluding variables measured after treatment initiation in outcome regression or propensity score models.\n\n**Why it matters:**  \n- Post-treatment variables may lie on the **causal pathway** (mediators), so adjustment can block part of the effect  \n- They may be **colliders**, inducing spurious associations  \n- Adjustment can invalidate the intervention being emulated\n\n**Avoid by:**  \n- Restricting adjustment to **baseline** confounders for baseline treatment effects  \n- Using longitudinal methods (for example, **LTMLE** or **LMTP**) when time-varying confounding affected by prior treatment is present  \n- Drawing DAGs to clarify temporal ordering and avoid collider bias  \n\n---\n\n## 3. Pitfall: Violated Positivity or Limited Overlap  \n### Treatment not comparable across covariate strata\n\n**Symptoms:**  \n- Propensity scores close to 0 or 1  \n- Large or highly variable IPTW weights  \n- Extreme clever covariate values in TMLE  \n\n**Why it matters:**  \nPositivity violations can lead to instability, high variance, and in finite samples, estimand drift toward extrapolation.\n\n**Avoid by:**  \n- Inspecting propensity score overlap and weight distributions  \n- Truncating or stabilizing weights when justified  \n- Restricting to **regions of common support**  \n- Considering **stochastic interventions** when static interventions are not feasible in the observed data  \n\n---\n\n## 4. Pitfall: Misspecified Outcome or Propensity Models  \n### Relying on simple models in complex settings\n\n**Mistake:**  \nAssuming linearity, additivity, or simple parametric relationships without support.\n\n**Why it matters:**  \nMisspecification of nuisance functions can create bias, especially for non-collapsible estimands or when overlap is limited.\n\n**Avoid by:**  \n- Using **SuperLearner** or other data-adaptive estimation with cross-validation  \n- Inspecting calibration and predictive performance (for example, cross-validated risk)  \n- Including domain-informed learners when strong structure is known  \n\n---\n\n## 5. Pitfall: Blindly Trusting Machine Learning  \n### Flexible models do not guarantee valid inference\n\n**Mistake:**  \nAssuming that a strong predictive model implies a correct causal estimate.\n\n**Why it matters:**  \nMachine learning can overfit, extrapolate, or yield poorly calibrated probabilities. Prediction quality alone does not ensure correct estimation of a causal functional.\n\n**Avoid by:**  \n- Using strict **cross-validation** and avoiding leakage  \n- Checking calibration (especially for propensity scores)  \n- Using TMLE or other doubly robust approaches to reduce sensitivity to nuisance estimation errors, subject to regularity conditions  \n\n---\n\n## 6. Pitfall: Ignoring Censoring and Informative Dropout  \n\n**Mistake:**  \nTreating censoring as non-informative without justification, or ignoring treatment discontinuation and switching when they affect the estimand.\n\n**Why it matters:**  \nInformative censoring can bias estimates of risk and survival functionals.\n\n**Avoid by:**  \n- Defining censoring relative to the estimand (administrative versus intercurrent event handling)  \n- Modeling censoring mechanisms (for example, with SuperLearner) and applying **IPCW** when appropriate  \n- Using TMLE/LTMLE with censoring nodes in longitudinal settings  \n- Conducting sensitivity analyses for violations of independent censoring  \n\n---\n\n## 7. Pitfall: Over-interpreting Heterogeneous Treatment Effects  \n### Subgroup and HTE analyses are fragile\n\n**Mistake:**  \nTreating exploratory subgroup findings as confirmatory evidence.\n\n**Why it matters:**  \nHTE estimates are often high variance, subject to multiple testing, and sensitive to modeling choices.\n\n**Avoid by:**  \n- Pre-specifying subgroups and hypotheses  \n- Reporting uncertainty and accounting for multiplicity where relevant  \n- Treating causal forest or related approaches as exploratory unless paired with confirmatory design  \n- Using targeted-learning-based approaches (for example, TMLE-based variable importance) when aligned with the scientific objective  \n\n---\n\n## 8. Pitfall: Using the Wrong Estimand  \n### Odds ratios and hazard ratios are commonly misinterpreted\n\n**Mistake:**  \nDefaulting to odds ratios or hazard ratios and interpreting them as causal effects without careful justification.\n\n**Why it matters:**  \n- Odds ratios are non-collapsible and may not correspond to the causal contrast of interest  \n- Hazard ratios are often difficult to interpret causally in the presence of time-varying hazards and selection into the risk set\n\n**Avoid by:**  \n- Targeting risk differences, risk ratios, survival curves, cumulative incidence, or RMST when scientifically appropriate  \n- Using methods designed for causal survival analysis (including targeted learning approaches) when time-to-event outcomes are primary  \n\n---\n\n## 9. Pitfall: Not Performing Diagnostics  \n### “The model ran” does not imply validity\n\n**Mistake:**  \nReporting results without checking whether key assumptions are approximately supported in the observed data.\n\n**Why it matters:**  \nMany failures in applied causal inference arise from detectable issues such as overlap problems, extreme weights, or unstable influence curves.\n\n**Avoid by:**  \n- Inspecting weight distributions and effective sample sizes  \n- Checking clever covariate ranges and outliers in targeted learning  \n- Examining influence curve stability and identifying influential observations  \n- Evaluating nuisance model calibration and cross-validated risk  \n\n---\n\n## 10. Pitfall: Neglecting Sensitivity Analyses  \n### Unmeasured confounding is not solved by optimism\n\n**Mistake:**  \nAssuming exchangeability holds without probing robustness.\n\n**Why it matters:**  \nIn observational settings, residual confounding is frequently plausible and may change qualitative conclusions.\n\n**Avoid by:**  \n- Quantitative bias analysis and sensitivity parameters  \n- Negative control outcomes or exposures when feasible  \n- E-values (where appropriate) as a screening tool  \n- Stochastic or simulation-based sensitivity analyses aligned with the causal model  \n\n---\n\n## 11. Pitfall: Poor Alignment Between Randomized and Real-World Data in Hybrid Designs  \n\n**Mistake:**  \nPooling or comparing RCT and RWD without harmonizing definitions and populations.\n\n**Why it matters:**  \nDifferences in eligibility, measurement, follow-up, and outcome definitions can dominate causal conclusions.\n\n**Avoid by:**  \n- Harmonizing inclusion criteria, covariates, endpoints, and follow-up windows  \n- Checking covariate balance and comparability across data sources  \n- Using principled external control / transportability approaches where applicable  \n- Conducting negative control checks in RWD components  \n\n---\n\n## 12. Pitfall: Reporting Without Context or Interpretation  \n\n**Mistake:**  \nReporting only a point estimate (or a single relative measure) without absolute risks, assumptions, or limitations.\n\n**Why it matters:**  \nCausal results are only meaningful relative to the estimand, assumptions, and the population.\n\n**Avoid by:**  \n- Reporting absolute risk estimates alongside contrasts  \n- Transparently stating identification assumptions and their plausibility  \n- Discussing limitations, diagnostics, and sensitivity analyses  \n- Framing results in terms of the hypothetical intervention and estimand  \n\n---\n\n## 13. Summary\n\nCommon pitfalls arise from misalignment between analytic choices and scientific questions, misspecification, unchecked assumptions, and overinterpretation. Avoiding them requires:\n\n- Explicit use of the Causal Roadmap  \n- Diagnostics aligned with identification risks (for example, overlap and censoring)  \n- Sensitivity analyses for plausible violations  \n- Careful communication of estimands and assumptions  \n\nThese practices improve credibility, reproducibility, and decision relevance.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}