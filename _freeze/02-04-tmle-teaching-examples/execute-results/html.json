{
  "hash": "1bd22d1c7be524c2eb993da92187113e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chapter 2.4: From Question to Estimate — TMLE in Practice\"\nformat: html\n---\n\n\n\n\n# Chapter 2.4: From Question to Estimate — TMLE in Practice\n*A progressive tutorial for pharmacoepidemiologists*\n\nThis chapter walks through a complete causal analysis from start to finish, building each estimator step-by-step so you can see exactly where bias enters, how each method addresses it, and why TMLE provides a principled solution.\n\nWe use a realistic post-marketing safety scenario: **evaluating the cardiovascular safety of a new diabetes drug**.\n\nBy the end of this chapter, you will have implemented:\n\n1. A naive (unadjusted) model\n2. G-computation (outcome modeling)\n3. IPTW (treatment modeling)\n4. AIPW (combining both)\n5. TMLE (targeting the estimate)\n\nEach method builds on what came before. Every step includes code, diagnostics, and interpretation.\n\n---\n\n# 1. Clinical Motivation\n\n## The Regulatory Question\n\nA new sodium-glucose co-transporter 2 (SGLT2) inhibitor, **dapagliflozin**, has been approved for type 2 diabetes. Post-marketing surveillance data from insurance claims suggest a potential cardiovascular safety signal. The FDA's Office of Surveillance and Epidemiology asks:\n\n> **Does initiation of dapagliflozin (vs. a sulfonylurea comparator) increase the 1-year risk of major adverse cardiovascular events (MACE) in adults with type 2 diabetes?**\n\nThis is a classic **active comparator, new user** design question.\n\n### Key elements\n\n- **Target population:** Adults aged 40-85 with type 2 diabetes initiating a new oral glucose-lowering agent\n- **Treatment strategies:** Initiate dapagliflozin (A = 1) vs. initiate sulfonylurea (A = 0)\n- **Outcome:** 1-year MACE (composite of MI, stroke, CV death), binary\n- **Intercurrent events:** Treatment discontinuation, switching, death from non-CV causes\n- **Decision:** Should the label carry a cardiovascular warning? Is a formal safety trial needed?\n\n### Why standard regression falls short\n\nA logistic regression of MACE on treatment will confound the effect with differences in baseline health. Patients prescribed newer, more expensive agents may differ systematically from those prescribed sulfonylureas — in age, comorbidity burden, prior cardiovascular history, renal function, and concomitant medications.\n\nWe need methods that explicitly separate confounding from causal effects.\n\n---\n\n# 2. The Causal Roadmap\n\nWe follow a five-step workflow that structures every causal analysis.\n\n:::{.callout-note}\n## Step 1: Define the Causal Question\n\n**In plain language:**\nWhat would happen to 1-year MACE risk if every eligible patient started dapagliflozin, compared to if every eligible patient started a sulfonylurea?\n\n**As a counterfactual estimand:**\n\nThe Average Treatment Effect (ATE) on the risk difference scale:\n\n$$\n\\psi = E[Y(1)] - E[Y(0)]\n$$\n\nwhere $Y(a)$ is the potential outcome under treatment strategy $a$.\n\n- $E[Y(1)]$ = population risk of MACE if everyone took dapagliflozin\n- $E[Y(0)]$ = population risk of MACE if everyone took sulfonylurea\n- A negative $\\psi$ means dapagliflozin is protective; a positive $\\psi$ means increased risk\n:::\n\n:::{.callout-note}\n## Step 2: Define the Causal Model\n\nWe posit the following causal structure. Confounders $W$ affect both treatment choice $A$ and the outcome $Y$. Treatment $A$ also affects $Y$ directly.\n\nThe confounders include:\n\n- **Age** — older patients have higher CV risk and may receive different prescriptions\n- **BMI** — obesity correlates with both drug choice and CV risk\n- **HbA1c** — glycemic control at baseline affects prescribing and outcomes\n- **Prior CVD** — history of cardiovascular disease is a strong confounder\n- **eGFR** — renal function influences both drug eligibility and CV risk\n- **Statin use** — a marker of CV risk management\n\nThe DAG (directed acyclic graph):\n\n```\n       W (age, BMI, HbA1c, prior CVD, eGFR, statin)\n      / \\\n     v   v\n     A --> Y\n```\n\nAll arrows from $W$ point to both $A$ and $Y$. There is a direct arrow from $A$ to $Y$. There are no arrows from $A$ back to $W$ (this is a point-treatment analysis at baseline).\n\nStructural equations:\n\n- $W$ is drawn from the population distribution\n- $A = f_A(W, U_A)$ — treatment depends on confounders and unmeasured factors\n- $Y = f_Y(A, W, U_Y)$ — outcome depends on treatment, confounders, and unmeasured factors\n:::\n\n:::{.callout-warning}\n## Step 3: Identify Assumptions\n\nFor the causal estimand $\\psi = E[Y(1)] - E[Y(0)]$ to be identified from observational data, we need three untestable assumptions:\n\n**Consistency:**\nThe observed outcome for a patient who received treatment $a$ equals their potential outcome $Y(a)$. This requires a well-defined intervention — \"initiate dapagliflozin\" must mean the same thing across patients. In practice, we define treatment as filling a new prescription.\n\n**Exchangeability (no unmeasured confounding):**\n$Y(a) \\perp\\!\\!\\!\\perp A \\mid W$ for all $a$. Conditional on measured baseline covariates, treatment assignment is as-good-as-random. This is the most vulnerable assumption. We cannot test it, but we can make it more plausible by adjusting for a rich set of confounders.\n\n**Positivity:**\n$0 < P(A = 1 \\mid W = w) < 1$ for all $w$ with $P(W = w) > 0$. Every patient type has some chance of receiving either drug. Violations occur when, for example, patients with severe renal impairment are never prescribed dapagliflozin.\n\nEach assumption is untestable but can be made more or less plausible by study design.\n:::\n\n:::{.callout-tip}\n## Step 4: Map to a Statistical Estimand\n\nUnder the three assumptions above, the causal estimand equals a statistical quantity we can estimate from data:\n\n$$\n\\psi = E_W\\big[E[Y \\mid A=1, W]\\big] - E_W\\big[E[Y \\mid A=0, W]\\big]\n$$\n\nThis is the **G-computation identification formula**. It says: fit a model for $E[Y \\mid A, W]$, predict under $A = 1$ and $A = 0$ for every patient, and average over the population distribution of $W$.\n\nEquivalently, using the propensity score $g(W) = P(A=1 \\mid W)$:\n\n$$\nE[Y(a)] = E\\left[\\frac{I(A=a) Y}{P(A=a \\mid W)}\\right]\n$$\n\nThis is the **IPTW identification formula**.\n\nBoth representations target the same quantity. They differ in which nuisance function they rely on.\n:::\n\n:::{.callout-important}\n## Step 5: Choose an Estimation Strategy\n:::\n\n| Method | Relies on | Robust to | Weakness |\n|--------|-----------|-----------|----------|\n| G-computation | Outcome model $E[Y \\mid A, W]$ | Treatment model misspecification | Sensitive to outcome model misspecification |\n| IPTW | Treatment model $P(A \\mid W)$ | Outcome model misspecification | Sensitive to positivity violations and weight instability |\n| AIPW | Both models | Misspecification of either one model | Not targeted; can produce out-of-bounds estimates |\n| TMLE | Both models | Misspecification of either one model | More complex to implement; requires understanding the targeting step |\n\nTMLE additionally:\n\n- Respects the natural bounds of the parameter space (probabilities stay between 0 and 1)\n- Achieves the semiparametric efficiency bound when both models are well-specified\n- Provides valid inference through the efficient influence curve\n- Integrates naturally with machine learning via Super Learner\n\nWe now implement each estimator progressively.\n\n---\n\n# 3. Data Simulation\n\nWe simulate a realistic claims-like dataset with multiple confounders, nonlinear effects, and treatment-confounder interactions.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'ggplot2' was built under R version 4.4.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'stringr' was built under R version 4.4.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.6.0\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nset.seed(2026)\nn <- 5000\n\n# --- Baseline confounders ---\nage    <- rnorm(n, mean = 62, sd = 10)\nbmi    <- rnorm(n, mean = 31, sd = 5)\nhba1c  <- rnorm(n, mean = 8.2, sd = 1.3)\n# Prior CVD: more likely with age and high BMI\ncvd    <- rbinom(n, 1, plogis(-3.5 + 0.04 * age + 0.03 * bmi))\n# eGFR: lower with age, higher with lower BMI\negfr   <- pmax(15, rnorm(n, mean = 95 - 0.5 * (age - 60) - 0.3 * bmi, sd = 15))\n# Statin use: more likely with CVD and age\nstatin <- rbinom(n, 1, plogis(-1.5 + 1.8 * cvd + 0.02 * age))\n\n# --- Treatment model (propensity score) ---\n# Dapagliflozin is preferentially prescribed to:\n# - younger patients, higher eGFR (renal eligibility), higher BMI, lower HbA1c\n# Includes nonlinear terms and interactions\nlp_trt <- -0.8 +\n  -0.03 * (age - 62) +\n  0.04 * (bmi - 31) +\n  -0.15 * (hba1c - 8.2) +\n  -0.6 * cvd +\n  0.02 * (egfr - 80) +\n  -0.3 * statin +\n  0.01 * (age - 62) * cvd +         # interaction\n  -0.002 * (age - 62)^2             # nonlinear age effect\n\nA <- rbinom(n, 1, plogis(lp_trt))\n\n# --- Outcome model ---\n# MACE risk depends on treatment, confounders, with nonlinearities\n# True treatment effect: dapagliflozin REDUCES MACE risk (protective)\nlp_out <- -3.2 +\n  -0.40 * A +                       # true causal effect (protective)\n  0.04 * (age - 62) +\n  0.02 * (bmi - 31) +\n  0.10 * (hba1c - 8.2) +\n  1.00 * cvd +\n  -0.01 * (egfr - 80) +\n  0.30 * statin +\n  0.015 * (age - 62) * cvd +        # interaction\n  0.0008 * (age - 62)^2 +           # nonlinear age effect\n  -0.10 * A * cvd                   # treatment-confounder interaction\n\nY <- rbinom(n, 1, plogis(lp_out))\n\ndat <- tibble(age, bmi, hba1c, cvd, egfr, statin, A, Y)\n```\n:::\n\n\n\n\n### True causal effect\n\nWe compute the true ATE from the data-generating process:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# True potential outcomes from the structural model\np1_true <- plogis(-3.2 + -0.40 * 1 + 0.04 * (age - 62) + 0.02 * (bmi - 31) +\n                    0.10 * (hba1c - 8.2) + 1.00 * cvd + -0.01 * (egfr - 80) +\n                    0.30 * statin + 0.015 * (age - 62) * cvd +\n                    0.0008 * (age - 62)^2 + -0.10 * 1 * cvd)\n\np0_true <- plogis(-3.2 + -0.40 * 0 + 0.04 * (age - 62) + 0.02 * (bmi - 31) +\n                    0.10 * (hba1c - 8.2) + 1.00 * cvd + -0.01 * (egfr - 80) +\n                    0.30 * statin + 0.015 * (age - 62) * cvd +\n                    0.0008 * (age - 62)^2 + -0.10 * 0 * cvd)\n\ntrue_ate <- mean(p1_true - p0_true)\ncat(\"True ATE (risk difference):\", round(true_ate, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTrue ATE (risk difference): -0.0338 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"True risk under dapagliflozin:\", round(mean(p1_true), 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTrue risk under dapagliflozin: 0.0691 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"True risk under sulfonylurea: \", round(mean(p0_true), 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTrue risk under sulfonylurea:  0.1029 \n```\n\n\n:::\n:::\n\n\n\n\n### Inspect the data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat %>%\n  group_by(A) %>%\n  summarise(\n    n          = n(),\n    mean_age   = mean(age),\n    mean_bmi   = mean(bmi),\n    mean_hba1c = mean(hba1c),\n    pct_cvd    = mean(cvd),\n    mean_egfr  = mean(egfr),\n    pct_statin = mean(statin),\n    mace_rate  = mean(Y),\n    .groups = \"drop\"\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 9\n      A     n mean_age mean_bmi mean_hba1c pct_cvd mean_egfr pct_statin\n  <int> <int>    <dbl>    <dbl>      <dbl>   <dbl>     <dbl>      <dbl>\n1     0  3828     62.6     30.9       8.27   0.532      83.7      0.653\n2     1  1172     59.7     31.7       8.01   0.334      89.1      0.515\n# ℹ 1 more variable: mace_rate <dbl>\n```\n\n\n:::\n:::\n\n\n\n\nNotice the imbalances: dapagliflozin patients are younger, have higher eGFR, and less prior CVD. These differences will bias a naive comparison.\n\n---\n\n# 4. Progressive Estimation\n\n:::{.callout-caution}\n## 4A. Naive (Unadjusted) Model — What Happens Without Adjustment?\n\nWe start with what many analysts would try first: a simple comparison of MACE rates by treatment group. This establishes the baseline from which all other methods improve.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Unadjusted risk difference\nrisk_A1 <- mean(dat$Y[dat$A == 1])\nrisk_A0 <- mean(dat$Y[dat$A == 0])\nnaive_rd <- risk_A1 - risk_A0\n\ncat(\"Naive risk (dapagliflozin):\", round(risk_A1, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNaive risk (dapagliflozin): 0.0444 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Naive risk (sulfonylurea): \", round(risk_A0, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNaive risk (sulfonylurea):  0.11 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Naive risk difference:     \", round(naive_rd, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNaive risk difference:      -0.0656 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"True ATE:                  \", round(true_ate, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTrue ATE:                   -0.0338 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Unadjusted logistic regression\nnaive_mod <- glm(Y ~ A, family = binomial, data = dat)\nsummary(naive_mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = Y ~ A, family = binomial, data = dat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -2.09095    0.05166 -40.475  < 2e-16 ***\nA           -0.97889    0.15095  -6.485 8.89e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 3130.5  on 4999  degrees of freedom\nResidual deviance: 3078.2  on 4998  degrees of freedom\nAIC: 3082.2\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-warning}\n## What Went Wrong?\n\nThe naive estimate is biased because dapagliflozin patients differ systematically from sulfonylurea patients. The treatment groups are not exchangeable. The naive estimate conflates the drug effect with the confounding by indication.\n\n**The lesson:** Never interpret unadjusted treatment comparisons as causal effects in observational data. The difference in MACE rates reflects both the drug's effect AND the differences in who gets each drug.\n:::\n\n---\n\n## 4B. G-Computation (Outcome Modeling)\n\nG-computation directly implements the identification formula by modeling $E[Y \\mid A, W]$, then standardizing.\n\n:::{.callout-note}\n## G-Computation Step 1: Fit the Outcome Model\n\nFit a model for $E[Y \\mid A, W]$ — the expected outcome given treatment and confounders. This model will be used to predict what would happen to each patient under each treatment scenario.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Parametric outcome model (logistic regression)\n# We include main effects and key interactions\nq_mod <- glm(Y ~ A + age + bmi + hba1c + cvd + egfr + statin +\n               A:cvd + I(age^2),\n             family = binomial, data = dat)\n```\n:::\n\n\n\n\n:::{.callout-tip}\n## G-Computation Step 2: Predict Counterfactual Outcomes\n\nAsk: \"What would this patient's outcome be if they received dapagliflozin? And if they received sulfonylurea?\" We generate these predictions for *every* patient, regardless of what they actually received.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create counterfactual datasets\ndat1 <- dat %>% mutate(A = 1)\ndat0 <- dat %>% mutate(A = 0)\n\n# Predict potential outcomes for each individual\nQ1 <- predict(q_mod, newdata = dat1, type = \"response\")\nQ0 <- predict(q_mod, newdata = dat0, type = \"response\")\n```\n:::\n\n\n\n\n:::{.callout-important}\n## G-Computation Step 3: Standardize (Average Over the Population)\n\nAverage the predicted outcomes across all patients. This implements the G-computation formula: $E_W[E[Y \\mid A=a, W]]$.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngcomp_risk1 <- mean(Q1)\ngcomp_risk0 <- mean(Q0)\ngcomp_ate   <- gcomp_risk1 - gcomp_risk0\n\ncat(\"G-comp risk (dapagliflozin):\", round(gcomp_risk1, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nG-comp risk (dapagliflozin): 0.0629 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"G-comp risk (sulfonylurea): \", round(gcomp_risk0, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nG-comp risk (sulfonylurea):  0.0996 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"G-comp ATE:                 \", round(gcomp_ate, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nG-comp ATE:                  -0.0367 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"True ATE:                   \", round(true_ate, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTrue ATE:                    -0.0338 \n```\n\n\n:::\n:::\n\n\n\n\n### Bootstrap confidence interval for G-computation\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nn_boot <- 500\nboot_ate <- numeric(n_boot)\n\nfor (b in 1:n_boot) {\n  idx <- sample(1:n, n, replace = TRUE)\n  dat_b <- dat[idx, ]\n  mod_b <- glm(Y ~ A + age + bmi + hba1c + cvd + egfr + statin +\n                  A:cvd + I(age^2),\n                family = binomial, data = dat_b)\n  Q1_b <- predict(mod_b, newdata = dat_b %>% mutate(A = 1), type = \"response\")\n  Q0_b <- predict(mod_b, newdata = dat_b %>% mutate(A = 0), type = \"response\")\n  boot_ate[b] <- mean(Q1_b - Q0_b)\n}\n\ngcomp_se <- sd(boot_ate)\ngcomp_ci <- quantile(boot_ate, c(0.025, 0.975))\n\ncat(\"G-comp ATE:\", round(gcomp_ate, 4),\n    \" SE:\", round(gcomp_se, 4),\n    \" 95% CI: [\", round(gcomp_ci[1], 4), \",\", round(gcomp_ci[2], 4), \"]\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nG-comp ATE: -0.0367  SE: 0.0098  95% CI: [ -0.0569 , -0.0191 ]\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-caution}\n## What Just Happened?\n\nG-computation gave a much better estimate than the naive approach by adjusting for confounders. It works by predicting what would happen to each patient under each treatment, then averaging.\n\n**But there is a catch:** G-computation depends entirely on the outcome model being correct. If we misspecified the functional form (missed interactions, nonlinearities), the estimate would be biased. And we would have no way to know.\n\n**This motivates IPTW** — which adjusts for confounding using the *treatment* model instead.\n:::\n\n---\n\n## 4C. IPTW (Treatment Modeling)\n\nIPTW takes a different approach: instead of modeling the outcome, it models treatment assignment and reweights the data to create a pseudo-population where confounders are balanced.\n\n:::{.callout-tip}\n## IPTW Step 1: Estimate the Propensity Score\n\nThe propensity score $g(W) = P(A = 1 \\mid W)$ answers: given a patient's covariates, how likely were they to receive dapagliflozin? We use this to reweight the data so that treatment looks \"as-if-randomized.\"\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Propensity score model\ng_mod <- glm(A ~ age + bmi + hba1c + cvd + egfr + statin +\n               I(age^2) + age:cvd,\n             family = binomial, data = dat)\n\ndat <- dat %>%\n  mutate(ps = predict(g_mod, type = \"response\"))\n\n# Summary of propensity scores\nsummary(dat$ps)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.002505 0.146338 0.220684 0.234400 0.314028 0.632319 \n```\n\n\n:::\n:::\n\n\n\n\n### Step 2: Assess propensity score overlap\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dat, aes(x = ps, fill = factor(A, labels = c(\"Sulfonylurea\", \"Dapagliflozin\")))) +\n  geom_density(alpha = 0.45) +\n  labs(\n    x = \"Estimated propensity score P(A=1 | W)\",\n    y = \"Density\",\n    fill = \"Treatment\",\n    title = \"Propensity Score Overlap\"\n  ) +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"#4477AA\", \"#EE6677\"))\n```\n\n::: {.cell-output-display}\n![](02-04-tmle-teaching-examples_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\nGood overlap means every type of patient has some chance of getting either drug. If the distributions barely overlap, IPTW will produce extreme weights and unstable estimates.\n\n### Step 3: Construct stabilized weights\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Marginal treatment probability\np_A <- mean(dat$A)\n\ndat <- dat %>%\n  mutate(\n    # Unstabilized weights\n    w_unstab = ifelse(A == 1, 1 / ps, 1 / (1 - ps)),\n    # Stabilized weights\n    sw = ifelse(A == 1, p_A / ps, (1 - p_A) / (1 - ps))\n  )\n```\n:::\n\n\n\n\n### Step 4: Diagnose weights\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Weight diagnostics\ndat %>%\n  group_by(A) %>%\n  summarise(\n    min_w  = min(sw),\n    p01_w  = quantile(sw, 0.01),\n    median = median(sw),\n    p99_w  = quantile(sw, 0.99),\n    max_w  = max(sw),\n    mean_w = mean(sw),\n    sd_w   = sd(sw),\n    .groups = \"drop\"\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 8\n      A min_w p01_w median p99_w max_w mean_w  sd_w\n  <int> <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl>\n1     0 0.768 0.784  0.960  1.50  2.08  1.00  0.161\n2     1 0.373 0.406  0.817  3.22  7.06  0.991 0.594\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Weight distribution plot\nggplot(dat, aes(x = sw, fill = factor(A, labels = c(\"Sulfonylurea\", \"Dapagliflozin\")))) +\n  geom_histogram(bins = 50, alpha = 0.6, position = \"identity\") +\n  labs(\n    x = \"Stabilized IPTW weight\",\n    y = \"Count\",\n    fill = \"Treatment\",\n    title = \"Distribution of Stabilized IPTW Weights\"\n  ) +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"#4477AA\", \"#EE6677\")) +\n  geom_vline(xintercept = 1, linetype = \"dashed\", color = \"grey40\")\n```\n\n::: {.cell-output-display}\n![](02-04-tmle-teaching-examples_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n\n**What to look for:**\n\n- Weights should be centered around 1 (for stabilized weights)\n- Very large weights (> 10) indicate positivity problems\n- The mean of stabilized weights should be approximately 1\n\n### Step 5: Check covariate balance after weighting\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Standardized mean differences: unweighted vs weighted\ncompute_smd <- function(data, var, trt, weights = NULL) {\n  if (is.null(weights)) weights <- rep(1, nrow(data))\n  d1 <- data[[var]][data[[trt]] == 1]\n  d0 <- data[[var]][data[[trt]] == 0]\n  w1 <- weights[data[[trt]] == 1]\n  w0 <- weights[data[[trt]] == 0]\n  m1 <- weighted.mean(d1, w1)\n  m0 <- weighted.mean(d0, w0)\n  s1 <- sqrt(sum(w1 * (d1 - m1)^2) / sum(w1))\n  s0 <- sqrt(sum(w0 * (d0 - m0)^2) / sum(w0))\n  pooled_sd <- sqrt((s1^2 + s0^2) / 2)\n  (m1 - m0) / pooled_sd\n}\n\ncovariates <- c(\"age\", \"bmi\", \"hba1c\", \"cvd\", \"egfr\", \"statin\")\n\nsmd_raw <- sapply(covariates, function(v) compute_smd(dat, v, \"A\"))\nsmd_wt  <- sapply(covariates, function(v) compute_smd(dat, v, \"A\", dat$sw))\n\nsmd_df <- tibble(\n  variable = covariates,\n  Unadjusted = abs(smd_raw),\n  Weighted   = abs(smd_wt)\n) %>%\n  pivot_longer(-variable, names_to = \"Method\", values_to = \"SMD\")\n\nggplot(smd_df, aes(x = SMD, y = reorder(variable, SMD), color = Method, shape = Method)) +\n  geom_point(size = 3) +\n  geom_vline(xintercept = 0.1, linetype = \"dashed\", color = \"grey50\") +\n  labs(\n    x = \"Absolute Standardized Mean Difference\",\n    y = \"\",\n    title = \"Covariate Balance: Before and After IPTW\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"#EE6677\", \"#228833\"))\n```\n\n::: {.cell-output-display}\n![](02-04-tmle-teaching-examples_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n\nThe dashed line at 0.1 is a common threshold. After weighting, all covariates should be below this line.\n\n### Step 6: Estimate the ATE\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Hajek (ratio) estimator with stabilized weights\nrisk1_iptw <- with(dat, sum(sw * Y * (A == 1)) / sum(sw * (A == 1)))\nrisk0_iptw <- with(dat, sum(sw * Y * (A == 0)) / sum(sw * (A == 0)))\niptw_ate   <- risk1_iptw - risk0_iptw\n\ncat(\"IPTW risk (dapagliflozin):\", round(risk1_iptw, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIPTW risk (dapagliflozin): 0.0559 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"IPTW risk (sulfonylurea): \", round(risk0_iptw, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIPTW risk (sulfonylurea):  0.0996 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"IPTW ATE:                 \", round(iptw_ate, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIPTW ATE:                  -0.0438 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"True ATE:                 \", round(true_ate, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTrue ATE:                  -0.0338 \n```\n\n\n:::\n:::\n\n\n\n\n### Weight truncation\n\nIf weights are extreme, truncation can improve stability at the cost of a small amount of bias:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Truncate at 1st and 99th percentiles\ntrunc_lower <- quantile(dat$sw, 0.01)\ntrunc_upper <- quantile(dat$sw, 0.99)\n\ndat <- dat %>%\n  mutate(sw_trunc = pmin(pmax(sw, trunc_lower), trunc_upper))\n\nrisk1_trunc <- with(dat, sum(sw_trunc * Y * (A == 1)) / sum(sw_trunc * (A == 1)))\nrisk0_trunc <- with(dat, sum(sw_trunc * Y * (A == 0)) / sum(sw_trunc * (A == 0)))\niptw_ate_trunc <- risk1_trunc - risk0_trunc\n\ncat(\"IPTW ATE (truncated weights):\", round(iptw_ate_trunc, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIPTW ATE (truncated weights): -0.0472 \n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-caution}\n## What Just Happened?\n\nIPTW adjusts for confounding through the treatment model alone. It does not use information about the outcome-confounder relationship.\n\n**The weakness:** If the propensity score model is wrong, IPTW is biased. If positivity is limited, weights become extreme and the estimate becomes unstable. And unlike G-computation, IPTW does not use the outcome model at all.\n\n**This motivates doubly robust methods** — which use BOTH the outcome model and the treatment model, so that if either one is correct, the estimate is consistent.\n:::\n\n---\n\n## 4D. AIPW (Augmented Inverse Probability Weighting)\n\n:::{.callout-tip}\n## The Doubly Robust Idea\n\nWhat if we could use BOTH the outcome model and the treatment model, and as long as EITHER one is correct, get a consistent estimate? This is exactly what AIPW (and TMLE) provide.\n:::\n\nAIPW combines the outcome model and the treatment model. It is **doubly robust**: consistent if either model is correct.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Using models from previous steps:\n# Q1, Q0 = predicted outcomes from g-computation\n# ps     = propensity scores from IPTW\n\n# AIPW components\nmu1_aipw <- with(dat, mean(\n  Q1 + A * (Y - Q1) / ps\n))\nmu0_aipw <- with(dat, mean(\n  Q0 + (1 - A) * (Y - Q0) / (1 - ps)\n))\naipw_ate <- mu1_aipw - mu0_aipw\n\ncat(\"AIPW risk (dapagliflozin):\", round(mu1_aipw, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAIPW risk (dapagliflozin): 0.0596 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"AIPW risk (sulfonylurea): \", round(mu0_aipw, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAIPW risk (sulfonylurea):  0.0995 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"AIPW ATE:                 \", round(aipw_ate, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAIPW ATE:                  -0.04 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"True ATE:                 \", round(true_ate, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTrue ATE:                  -0.0338 \n```\n\n\n:::\n:::\n\n\n\n\n### Influence curve and inference\n\nThe efficient influence curve (EIC) for the ATE gives us individual-level \"scores\" that measure each observation's contribution to the estimate. The variance of these scores provides valid standard errors.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Efficient influence curve for ATE\neic <- with(dat,\n  (A / ps) * (Y - Q1) + Q1 - mu1_aipw -\n  ((1 - A) / (1 - ps)) * (Y - Q0) - Q0 + mu0_aipw\n)\n\naipw_se <- sqrt(var(eic) / n)\naipw_ci <- aipw_ate + c(-1.96, 1.96) * aipw_se\n\ncat(\"AIPW ATE:\", round(aipw_ate, 4),\n    \" SE:\", round(aipw_se, 4),\n    \" 95% CI: [\", round(aipw_ci[1], 4), \",\", round(aipw_ci[2], 4), \"]\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAIPW ATE: -0.04  SE: 0.0101  95% CI: [ -0.0598 , -0.0201 ]\n```\n\n\n:::\n:::\n\n\n\n\n**Key insight:** AIPW improves on both g-computation and IPTW by using both models. However, AIPW does not \"target\" its initial estimates — it can produce predicted probabilities outside [0, 1], and it does not solve the efficient influence curve equation exactly when machine learning is used. TMLE addresses both issues.\n\n---\n\n## 4E. TMLE (Targeted Maximum Likelihood Estimation)\n\n:::{.callout-important}\n## Why TMLE?\n\nTMLE is the centerpiece of this chapter. It combines the best properties of all previous methods:\n\n- Uses both outcome and treatment models (**doubly robust**)\n- **Targets** the specific estimand of interest (not just fitting a good outcome model)\n- Respects natural parameter bounds (probabilities stay in [0, 1])\n- Solves the efficient influence curve equation, ensuring **valid inference**\n- Integrates naturally with machine learning (Super Learner)\n:::\n\n### Conceptual overview\n\n:::{.callout-note}\n## TMLE in Three Stages\n\n1. **Initial estimate:** Fit an outcome model $\\hat{Q}^0(A, W) = \\hat{E}[Y \\mid A, W]$ (like g-computation)\n2. **Targeting step:** Update $\\hat{Q}^0$ using information from the propensity score to reduce bias for the specific estimand\n3. **Substitution estimate:** Plug the updated $\\hat{Q}^*$ into the G-computation formula\n\nThe targeting step is what makes TMLE special. It uses the **clever covariate** — a function of the propensity score — to fluctuate the initial outcome model in the direction that solves the efficient influence curve equation.\n:::\n\n### Step-by-step implementation\n\n:::{.callout-note}\n#### Step 1: Initial Outcome Model\n\nThis is the same as G-computation — fit $E[Y \\mid A, W]$. Think of this as your \"first draft\" of the outcome model. It does not need to be perfect; the targeting step will correct it.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Same as g-computation — fit E[Y | A, W]\nq_init <- glm(Y ~ A + age + bmi + hba1c + cvd + egfr + statin +\n                A:cvd + I(age^2),\n              family = binomial, data = dat)\n\n# Initial predictions\nQ1_init <- predict(q_init, newdata = dat %>% mutate(A = 1), type = \"response\")\nQ0_init <- predict(q_init, newdata = dat %>% mutate(A = 0), type = \"response\")\nQA_init <- predict(q_init, type = \"response\")  # predictions at observed A\n```\n:::\n\n\n\n\n:::{.callout-tip}\n#### Step 2: Estimate the Propensity Score\n\nSame as IPTW — model the probability of treatment given confounders. We bound the scores away from 0 and 1 to prevent numerical instability.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Same model as IPTW\ng_fit <- glm(A ~ age + bmi + hba1c + cvd + egfr + statin +\n               I(age^2) + age:cvd,\n             family = binomial, data = dat)\n\nps_tmle <- predict(g_fit, type = \"response\")\n\n# Bound propensity scores away from 0 and 1 for stability\nps_tmle <- pmax(0.01, pmin(0.99, ps_tmle))\n```\n:::\n\n\n\n\n:::{.callout-important}\n#### Step 3: Compute the Clever Covariate\n\nThe clever covariate $H(A, W)$ is the bridge between the treatment model and the outcome model. It tells the targeting step *which observations are most informative* about the causal effect.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Clever covariate for each observation at their OBSERVED treatment\nH_A <- dat$A / ps_tmle - (1 - dat$A) / (1 - ps_tmle)\n\n# Clever covariate under A=1 and A=0 (for prediction)\nH_1 <- 1 / ps_tmle\nH_0 <- -1 / (1 - ps_tmle)\n```\n:::\n\n\n\n\nThe clever covariate is large when a patient's treatment was unlikely given their covariates — exactly the patients who are most informative about the causal effect.\n\n:::{.callout-warning}\n#### Step 4: Fluctuation (The Targeting Step)\n\nThis is **the key step** that makes TMLE different from every other estimator. We fit a logistic regression of $Y$ on $H(A, W)$ with the initial $\\hat{Q}^0$ as an offset. The coefficient $\\epsilon$ tells us how much to \"nudge\" the initial estimate toward solving the efficient influence curve equation.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogit <- function(p) log(p / (1 - p))\n\n# Fluctuation model: logit(Y) ~ offset(logit(Q_init)) + H\nfluc <- glm(Y ~ -1 + offset(logit(QA_init)) + H_A,\n            family = binomial, data = dat)\n\nepsilon <- coef(fluc)\ncat(\"Epsilon (fluctuation parameter):\", round(epsilon, 5), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEpsilon (fluctuation parameter): -0.00633 \n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-tip}\n## Interpreting Epsilon\n\nA small $\\epsilon$ means the initial model was already close to solving the EIC equation. A large $\\epsilon$ means the targeting step made a substantial correction.\n:::\n\n:::{.callout-note}\n#### Step 5: Update Predictions\n\nApply the fluctuation to get the **targeted** predictions. Because we use the inverse-logit function (`plogis`), predictions are guaranteed to stay in [0, 1] — the natural bounds for a probability.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Apply the fluctuation to counterfactual predictions\nQ1_star <- plogis(logit(Q1_init) + epsilon * H_1)\nQ0_star <- plogis(logit(Q0_init) + epsilon * H_0)\n```\n:::\n\n\n\n\n:::{.callout-tip}\n#### Step 6: Compute the TMLE Estimate\n\nAverage the targeted predictions across the population — just like the final step of G-computation, but now using the **updated** $\\hat{Q}^*$ that has been targeted for our specific estimand.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmle_risk1 <- mean(Q1_star)\ntmle_risk0 <- mean(Q0_star)\ntmle_ate   <- tmle_risk1 - tmle_risk0\n\ncat(\"TMLE risk (dapagliflozin):\", round(tmle_risk1, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTMLE risk (dapagliflozin): 0.0594 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"TMLE risk (sulfonylurea): \", round(tmle_risk0, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTMLE risk (sulfonylurea):  0.1002 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"TMLE ATE:                 \", round(tmle_ate, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTMLE ATE:                  -0.0409 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"True ATE:                 \", round(true_ate, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTrue ATE:                  -0.0338 \n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-important}\n#### Step 7: Inference via the Efficient Influence Curve\n\nThe EIC gives each observation a \"score\" measuring its contribution to the estimate. The variance of these scores provides asymptotically valid standard errors — no bootstrap needed.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# EIC evaluated at the TMLE estimates\neic_tmle <- with(dat,\n  (A / ps_tmle) * (Y - Q1_star) + Q1_star - tmle_risk1 -\n  ((1 - A) / (1 - ps_tmle)) * (Y - Q0_star) - Q0_star + tmle_risk0\n)\n\ntmle_se <- sqrt(var(eic_tmle) / n)\ntmle_ci <- tmle_ate + c(-1.96, 1.96) * tmle_se\n\ncat(\"TMLE ATE:\", round(tmle_ate, 4),\n    \" SE:\", round(tmle_se, 4),\n    \" 95% CI: [\", round(tmle_ci[1], 4), \",\", round(tmle_ci[2], 4), \"]\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTMLE ATE: -0.0409  SE: 0.0102  95% CI: [ -0.0608 , -0.021 ]\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-caution}\n### Verify: Is the EIC Mean Zero?\n\nA correctly implemented TMLE solves the efficient influence curve equation, meaning the sample mean of the EIC should be approximately zero. This is how you know the targeting step worked correctly.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"Mean of EIC:\", round(mean(eic_tmle), 8), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean of EIC: 0 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"(Should be very close to zero)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Should be very close to zero)\n```\n\n\n:::\n:::\n\n\n\n\n---\n\n:::{.callout-note}\n## Putting It All Together\n\nWe now have five estimators of the same causal quantity. Let's see how they compare. If our models are reasonable, the doubly robust methods (AIPW and TMLE) should be closest to the truth.\n:::\n\n# 5. Comparing All Estimators\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults <- tibble(\n  Method  = c(\"Naive\", \"G-computation\", \"IPTW\", \"IPTW (truncated)\", \"AIPW\", \"TMLE\"),\n  ATE     = c(naive_rd, gcomp_ate, iptw_ate, iptw_ate_trunc, aipw_ate, tmle_ate),\n  SE      = c(NA, gcomp_se, NA, NA, aipw_se, tmle_se),\n  CI_low  = c(NA, gcomp_ci[1], NA, NA, aipw_ci[1], tmle_ci[1]),\n  CI_high = c(NA, gcomp_ci[2], NA, NA, aipw_ci[2], tmle_ci[2])\n)\n\nresults %>%\n  mutate(across(where(is.numeric), ~round(., 4)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  Method               ATE      SE  CI_low CI_high\n  <chr>              <dbl>   <dbl>   <dbl>   <dbl>\n1 Naive            -0.0656 NA      NA      NA     \n2 G-computation    -0.0367  0.0098 -0.0569 -0.0191\n3 IPTW             -0.0438 NA      NA      NA     \n4 IPTW (truncated) -0.0472 NA      NA      NA     \n5 AIPW             -0.04    0.0101 -0.0598 -0.0201\n6 TMLE             -0.0409  0.0102 -0.0608 -0.021 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize the comparison\nplot_df <- results %>%\n  filter(!is.na(SE)) %>%\n  mutate(Method = factor(Method, levels = c(\"G-computation\", \"AIPW\", \"TMLE\")))\n\nggplot(plot_df, aes(x = ATE, y = Method)) +\n  geom_point(size = 3) +\n  geom_errorbarh(aes(xmin = CI_low, xmax = CI_high), height = 0.2) +\n  geom_vline(xintercept = true_ate, linetype = \"dashed\", color = \"red\") +\n  annotate(\"text\", x = true_ate, y = 0.5, label = \"True ATE\",\n           hjust = -0.1, color = \"red\", size = 3.5) +\n  labs(\n    x = \"Estimated ATE (Risk Difference)\",\n    y = \"\",\n    title = \"Comparison of Causal Estimators\",\n    subtitle = \"Red dashed line = true causal effect\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](02-04-tmle-teaching-examples_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\n\n\n---\n\n# 6. Diagnostics\n\n:::{.callout-warning}\n## Diagnostics Are Non-Negotiable\n\nGood estimation is nothing without good diagnostics. **Never report a causal estimate without checking these diagnostics.** They tell you whether your assumptions are plausible and whether the estimator is well-behaved.\n:::\n\n:::{.callout-note}\n## 6.1 Propensity Score Overlap\n\nIf the propensity score distributions for treated and untreated overlap well, the positivity assumption is plausible. **Gaps** indicate regions where one treatment is rarely or never prescribed — all methods will struggle there, but IPTW is especially vulnerable.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dat, aes(x = ps_tmle, fill = factor(A, labels = c(\"Sulfonylurea\", \"Dapagliflozin\")))) +\n  geom_histogram(bins = 40, alpha = 0.55, position = \"identity\") +\n  labs(\n    x = \"Propensity score\",\n    y = \"Count\",\n    fill = \"Treatment\",\n    title = \"Propensity Score Distribution by Treatment Group\"\n  ) +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"#4477AA\", \"#EE6677\"))\n```\n\n::: {.cell-output-display}\n![](02-04-tmle-teaching-examples_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\n\n\n:::{.callout-tip}\n## 6.2 Weight Distribution\n\nStabilized weights should center around 1. Very large weights (> 10) indicate **practical positivity violations** — patients who almost never receive their observed treatment. These patients dominate IPTW estimates and destabilize the clever covariate in TMLE.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"--- Unstabilized weight summary ---\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n--- Unstabilized weight summary ---\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(dat$w_unstab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.003   1.182   1.337   1.991   1.828  30.108 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\n--- Stabilized weight summary ---\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n--- Stabilized weight summary ---\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(dat$sw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.3727  0.8562  0.9480  0.9977  1.0891  7.0573 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nProportion of stabilized weights > 5:\", mean(dat$sw > 5), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nProportion of stabilized weights > 5: 6e-04 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Proportion of stabilized weights > 10:\", mean(dat$sw > 10), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nProportion of stabilized weights > 10: 0 \n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-important}\n## 6.3 Clever Covariate Diagnostics\n\nThe clever covariate drives the TMLE targeting step. Extreme values indicate potential instability — if $H(A, W)$ has heavy tails, the targeting step may overfit to a few influential observations.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclever_cov_df <- tibble(\n  H = H_A,\n  treatment = factor(dat$A, labels = c(\"Sulfonylurea\", \"Dapagliflozin\"))\n)\n\nggplot(clever_cov_df, aes(x = H, fill = treatment)) +\n  geom_histogram(bins = 50, alpha = 0.5, position = \"identity\") +\n  labs(\n    x = \"Clever covariate H(A, W)\",\n    y = \"Count\",\n    fill = \"Treatment\",\n    title = \"Distribution of the Clever Covariate\"\n  ) +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"#4477AA\", \"#EE6677\"))\n```\n\n::: {.cell-output-display}\n![](02-04-tmle-teaching-examples_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n\n\n:::{.callout-caution}\n## 6.4 Influence Curve Diagnostics\n\nThe EIC values reveal **influential observations**. A well-behaved TMLE has EIC values centered near zero with no extreme outliers. If you see long tails or a non-zero mean, something may be wrong with the targeting step or the propensity score model.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\neic_df <- tibble(eic = eic_tmle)\n\nggplot(eic_df, aes(x = eic)) +\n  geom_histogram(bins = 50, fill = \"#228833\", alpha = 0.7) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(\n    x = \"Efficient influence curve value\",\n    y = \"Count\",\n    title = \"Distribution of TMLE Influence Curve Values\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](02-04-tmle-teaching-examples_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncat(\"EIC summary:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEIC summary:\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(eic_tmle)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-4.80971 -0.02585  0.08820  0.00000  0.12378 24.86376 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"EIC mean:\", round(mean(eic_tmle), 6), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEIC mean: 0 \n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-note}\n## 6.5 Extreme Prediction Check\n\nOne of TMLE's advantages: because the targeting step uses a logistic fluctuation, predictions are guaranteed to stay in [0, 1]. Compare the initial and targeted ranges — the targeting step may shift predictions, but never outside the natural bounds.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"--- Predicted outcome range (initial model) ---\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n--- Predicted outcome range (initial model) ---\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Q1 range:\", round(range(Q1_init), 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nQ1 range: 0.0088 0.7715 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Q0 range:\", round(range(Q0_init), 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nQ0 range: 0.0091 0.877 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\n--- Predicted outcome range (after targeting) ---\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n--- Predicted outcome range (after targeting) ---\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Q1* range:\", round(range(Q1_star), 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nQ1* range: 0.0087 0.6419 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Q0* range:\", round(range(Q0_star), 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nQ0* range: 0.0092 0.8777 \n```\n\n\n:::\n:::\n\n\n\n\n---\n\n# 7. Interpretation\n\n:::{.callout-tip}\n## Translating to Regulatory Language\n\nBased on the TMLE analysis:\n:::\n\n- **Point estimate:** Dapagliflozin is estimated to reduce 1-year MACE risk by approximately 4.1 percentage points compared to sulfonylurea\n- **Confidence interval:** The 95% CI is [-6.1, -2.1] percentage points\n- **Risk difference vs. odds ratio:** We report on the risk difference scale because it is directly interpretable. An odds ratio would obscure the magnitude of absolute risk change, which is what matters for labeling and clinical decisions.\n\n:::{.callout-note}\n## Regulatory Decision\n\nIf the confidence interval excludes zero and the point estimate is negative (protective), the data do not support adding a cardiovascular warning. If the CI includes zero, the evidence is inconclusive and further monitoring or a dedicated outcomes trial may be warranted.\n:::\n\n:::{.callout-warning}\n## Sensitivity to Assumptions — Which Are Most Fragile?\n\n1. **No unmeasured confounding (exchangeability):** This is always the weakest link in observational data. Lifestyle factors (diet, exercise, smoking) may confound and are poorly captured in claims data.\n\n2. **Positivity:** If some patient types never receive one drug (e.g., patients with very low eGFR are ineligible for SGLT2 inhibitors), the ATE is not identifiable for the full population. Consider restricting to a subpopulation where positivity holds.\n\n3. **Consistency:** If treatment initiation is not well-defined (e.g., varying doses), the potential outcomes are ambiguous.\n\n**What if unmeasured confounding exists?** A sensitivity analysis (E-value or bias analysis) can quantify how strong unmeasured confounding would need to be to explain away the observed effect.\n:::\n\n---\n\n# 8. Why Super Learner Improves Nuisance Estimation\n\n:::{.callout-tip}\n## The Problem With Parametric Models\n\nIn the examples above, we used parametric logistic regression for both the outcome and treatment models. In practice, these models may be misspecified — missing interactions, wrong functional forms, or overly rigid assumptions. **Super Learner** eliminates the need to guess the right model.\n:::\n\n:::{.callout-note}\n## What Is Super Learner?\n\nSuper Learner is an ensemble machine learning method that:\n\n1. Takes a **library of candidate learners** (logistic regression, LASSO, random forest, etc.)\n2. Uses **cross-validation** to evaluate each learner's performance\n3. Combines them using **optimally weighted stacking**\n4. Guarantees performance at least as good as the best individual learner (asymptotically)\n:::\n\n:::{.callout-important}\n## Why This Matters for TMLE\n\n- TMLE is doubly robust: consistent if either the outcome or treatment model is correct\n- But TMLE is **efficient** when both models are consistent at reasonable rates\n- Super Learner reduces the risk of misspecifying either model\n- Cross-validation within Super Learner protects against overfitting\n\n**Bottom line:** Super Learner + TMLE = data-adaptive, doubly robust, efficient estimation with valid inference.\n:::\n\n### Conceptual demonstration\n\nThe following shows how Super Learner would be integrated (this requires the SuperLearner package, which may not run in all webR environments):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(SuperLearner)\n\n# Define learner library\nSL_lib <- c(\"SL.glm\", \"SL.glmnet\", \"SL.gam\", \"SL.mean\")\n\n# Outcome model via Super Learner\nQ_SL <- SuperLearner(\n  Y = dat$Y,\n  X = dat %>% select(A, age, bmi, hba1c, cvd, egfr, statin),\n  family = binomial(),\n  SL.library = SL_lib\n)\n\n# Treatment model via Super Learner\ng_SL <- SuperLearner(\n  Y = dat$A,\n  X = dat %>% select(age, bmi, hba1c, cvd, egfr, statin),\n  family = binomial(),\n  SL.library = SL_lib\n)\n\n# View the cross-validated weights\nQ_SL$coef  # how much each learner contributes to the outcome model\ng_SL$coef  # how much each learner contributes to the treatment model\n```\n:::\n\n\n\n\nThe Super Learner automatically determines which learners are most useful and how to combine them — no manual model selection required.\n\n---\n\n:::{.callout-note}\n# 9. Summary of Estimator Trade-offs\n\nThe table below summarizes the key properties of each estimator. TMLE stands out as the only method that is doubly robust, respects parameter bounds, solves the EIC, and integrates naturally with machine learning.\n:::\n\n| Property | G-comp | IPTW | AIPW | TMLE |\n|----------|--------|------|------|------|\n| Uses outcome model | Yes | No | Yes | Yes |\n| Uses treatment model | No | Yes | Yes | Yes |\n| Doubly robust | No | No | Yes | Yes |\n| Respects bounds | Depends | N/A | No | Yes |\n| Efficient (solves EIC) | No | No | Asymptotically | Yes |\n| Works with ML | Partially | Partially | Needs cross-fitting | Naturally |\n| Inference method | Bootstrap | Sandwich | Influence curve | Influence curve |\n\n---\n\n:::{.callout-tip}\n# Key Takeaways\n\n1. **The naive estimate is biased** because treatment groups differ in baseline characteristics. Never interpret unadjusted comparisons as causal effects.\n\n2. **G-computation is intuitive** but depends on correctly modeling the outcome. It implements the identification formula directly.\n\n3. **IPTW tackles confounding through reweighting** but is sensitive to positivity violations and propensity score misspecification. Always check weight distributions.\n\n4. **AIPW is doubly robust** — consistent if either the outcome or treatment model is correct. But it does not target the parameter of interest and can produce out-of-bounds predictions.\n\n5. **TMLE combines the strengths of all methods.** It starts with an outcome model, targets it using the propensity score, respects parameter bounds, and provides efficient inference through the influence curve.\n\n6. **Super Learner** reduces the risk of model misspecification by ensembling multiple learners with cross-validated weights. It pairs naturally with TMLE.\n\n7. **Diagnostics are non-negotiable.** Always inspect propensity score overlap, weight distributions, covariate balance, and influence curve behavior before trusting any estimate.\n\n8. **Every step of the causal roadmap matters.** The estimate is only as valid as the assumptions that identify the causal effect from observational data.\n:::\n\n---\n\n:::{.callout-note}\n# 10. Where to Go Next\n\nThe framework in this chapter extends to several important settings — each covered in subsequent chapters:\n\n- **Dynamic treatment regimes:** Treatment rules that depend on patient characteristics (e.g., \"prescribe dapagliflozin if eGFR > 45, else sulfonylurea\")\n- **Stochastic interventions:** Shift the probability of treatment rather than forcing a deterministic assignment — useful when positivity is limited\n- **Mediation analysis:** Decompose the total effect into direct and indirect pathways (see Chapter 3.10)\n- **Longitudinal TMLE (LTMLE):** Handle time-varying treatments and confounders (see Chapters 3.7 and 3.9)\n- **Clean-room TMLE:** Pre-specified, locked, auditable analysis for regulatory submissions (see Chapter 3.8)\n- **Conditional average treatment effects (CATE):** Estimate how the treatment effect varies across subgroups\n- **Variable importance:** Identify which confounders matter most for the treatment effect\n\nEach extension follows the same causal roadmap: define the question, specify the causal model, verify assumptions, identify the statistical estimand, and choose an appropriate estimator.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26200)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.3 forcats_1.0.0   stringr_1.6.0   dplyr_1.1.4    \n [5] purrr_1.0.2     readr_2.1.5     tidyr_1.3.1     tibble_3.2.1   \n [9] ggplot2_3.5.2   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6      jsonlite_2.0.0    compiler_4.4.2    tidyselect_1.2.1 \n [5] scales_1.3.0      yaml_2.3.10       fastmap_1.2.0     R6_2.6.1         \n [9] labeling_0.4.3    generics_0.1.3    knitr_1.49        htmlwidgets_1.6.4\n[13] munsell_0.5.1     pillar_1.9.0      tzdb_0.4.0        rlang_1.1.6      \n[17] utf8_1.2.4        stringi_1.8.7     xfun_0.49         timechange_0.3.0 \n[21] cli_3.6.5         withr_3.0.2       magrittr_2.0.3    digest_0.6.37    \n[25] grid_4.4.2        rstudioapi_0.17.1 hms_1.1.3         lifecycle_1.0.4  \n[29] vctrs_0.6.5       evaluate_1.0.5    glue_1.8.0        farver_2.1.2     \n[33] fansi_1.0.6       colorspace_2.1-1  rmarkdown_2.29    tools_4.4.2      \n[37] pkgconfig_2.0.3   htmltools_0.5.8.1\n```\n\n\n:::\n:::\n\n\n\n\n---\n\n## Software Implementation (R)\n\nThis example brings together the progressive estimation sequence from this chapter (naive → g-computation → IPTW → TMLE) using the `tmle` package with Super Learner.\n\n- Simulate a pharmacoepi-style dataset with multiple confounders\n- Run the `tmle()` function with a diverse Super Learner library\n- Extract and interpret: ATE, risk difference, confidence interval, and influence curve diagnostics\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\nn <- 800\nW1 <- rnorm(n)                                      # age (standardized)\nW2 <- rbinom(n, 1, 0.3)                             # diabetes indicator\nW3 <- rnorm(n, mean = 0.5 * W1)                     # BMI (standardized)\nA  <- rbinom(n, 1, plogis(-0.3 + 0.4 * W1 + 0.5 * W2 - 0.2 * W3))\nY  <- rbinom(n, 1, plogis(-2 + 0.6 * A + 0.5 * W1 + 0.8 * W2 + 0.3 * W3))\n\nif (requireNamespace(\"tmle\", quietly = TRUE)) {\n  library(tmle)\n  W <- data.frame(W1 = W1, W2 = W2, W3 = W3)\n\n  tmle_fit <- tmle(\n    Y = Y, A = A, W = W,\n    family = \"binomial\",\n    Q.SL.library = c(\"SL.glm\", \"SL.step\", \"SL.mean\"),\n    g.SL.library  = c(\"SL.glm\", \"SL.step\", \"SL.mean\")\n  )\n\n  cat(\"── TMLE results ─────────────────────\\n\")\n  cat(\"ATE (risk difference):\", round(tmle_fit$estimates$ATE$psi, 4), \"\\n\")\n  cat(\"95% CI:\", round(tmle_fit$estimates$ATE$CI, 4), \"\\n\")\n  cat(\"p-value:\", format.pval(tmle_fit$estimates$ATE$pvalue, digits = 3), \"\\n\")\n\n  ## Influence curve diagnostic (mean should be ≈ 0)\n  ic <- tmle_fit$estimates$ATE$IC\n  cat(\"\\nInfluence curve mean:\", round(mean(ic), 6),\n      \" (should be ≈ 0)\\n\")\n} else {\n  message(\"Install the 'tmle' package:  install.packages('tmle')\")\n}\n```\n:::\n",
    "supporting": [
      "02-04-tmle-teaching-examples_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}