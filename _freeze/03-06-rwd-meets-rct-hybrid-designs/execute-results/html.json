{
  "hash": "011c2ff15347d10772e70033b907ddde",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chapter 3.6: When RWD Meets RCT – Hybrid Designs\"\nformat: html\n---\n\n\n\n\n# Chapter 3.6  \n## When RWD Meets RCT – Hybrid Designs for Causal Inference  \n*Combining randomized and observational data to improve precision and generalizability*\n\nRandomized controlled trials (RCTs) are the gold standard for causal inference.  \nBut they are:\n\n- Expensive and slow  \n- Often underpowered for rare events and subgroup effects  \n- Conducted in selective populations  \n- Not always feasible or ethical  \n\nReal-world data (RWD) — registries, EHR, claims — provide:\n\n- Large, diverse populations  \n- Naturalistic treatment patterns  \n- Long-term safety follow-up  \n\n**Hybrid RCT–RWD designs** aim to combine:\n\n- The *internal validity* of RCTs  \n- The *external validity* and scale of RWD  \n\nThis chapter introduces:\n\n1. Why hybrid designs are needed  \n2. Types of hybrid designs with external controls  \n3. Transportability and generalizability concepts  \n4. ES-CV-TMLE (External Supervised Cross-Validated TMLE)  \n5. A-TMLE (Adaptive TMLE) for integrating multiple data sources  \n6. Practical considerations and diagnostics  \n\n---\n\n## 1. Why Combine RCT and RWD?\n\n:::{.callout-important}\n## Three Key Motivations for Hybrid RCT-RWD Designs\n\nAs epidemiologists, we know that no single data source is perfect. RCTs give us internal validity but are often too small, too narrow, or too slow. RWD gives us scale and diversity but lacks randomization. Hybrid designs try to get the best of both worlds. There are three core reasons to combine them:\n\n### 1.1 Precision\n\nTrials may be underpowered for:\n\n- Rare safety endpoints\n- Important subgroups\n- Long-term secondary endpoints\n\nExternal RWD can add information and boost precision without enrolling more randomized patients.\n\n### 1.2 Generalizability\n\nRCT participants tend to:\n\n- Be younger and healthier\n- Have fewer comorbidities\n- Be more adherent and monitored\n\nThus, trial results may not fully apply to routine-care populations. Think of the typical phase III oncology trial -- the enrolled patients are often younger and have better performance status than those you would see in a community oncology clinic.\n\n### 1.3 Feasibility and ethics\n\nHybrid designs are useful when:\n\n- Placebo or standard randomized controls are unethical\n- Only a single-arm trial is feasible\n- Rapid evidence is needed (e.g., post-marketing surveillance, rare diseases)\n:::\n\n---\n\n## 2. Basic Hybrid Designs\n\nSeveral design patterns are commonly used.\n\n---\n\n:::{.callout-note}\n## External Control Arms\n\nIn plain language, an **external control arm** means: instead of randomizing some patients to a control group within your trial, you borrow the control group from outside the trial -- typically from a registry, EHR database, or historical trial data.\n\nA **single-arm trial** (all patients get experimental treatment) may be compared against an **external control** arm from RWD.\n\nUse cases:\n\n- Oncology (historical controls)\n- Rare diseases\n- When standard-of-care is well characterized\n:::\n\n:::{.callout-warning}\n## Challenges of External Controls\n\nExternal controls introduce serious methodological risks that every epidemiologist should scrutinize:\n\n- **Confounding by indication**: Patients in the RWD were not randomized. The reasons they received (or did not receive) a treatment are entangled with their prognosis.\n- **Differences in data capture**: The trial measures outcomes with protocol-specified visits, imaging schedules, and adjudication committees. The RWD may rely on billing codes, free-text notes, or inconsistent follow-up.\n- **Eligibility misalignment**: Trial patients passed strict inclusion/exclusion criteria. RWD patients may differ systematically.\n- **Calendar time and secular trends**: Changes in supportive care, diagnostic coding (e.g., ICD-9 to ICD-10 transitions), or standard-of-care over time can create spurious differences.\n\nAlways ask: \"Would the external controls have been eligible for the trial, and are their outcomes measured comparably?\"\n:::\n\n---\n\n:::{.callout-tip}\n## Augmented Control Arms\n\nUnlike a fully external control, an **augmented control arm** retains randomization within the trial -- you still have a concurrent randomized control group. The external RWD supplements it rather than replacing it entirely. Think of it as \"topping up\" your control arm with additional data.\n\nAn RCT randomizes patients to:\n\n- Experimental treatment vs trial control (e.g., 2:1 randomization)\n\nBut the trial control arm is **augmented** with external RWD controls to:\n\n- Improve precision\n- Reduce required randomized control sample size\n- Support safety and rare-event evaluation\n\nBorrowing can be:\n\n- **Fixed (pre-specified)**: You decide before unblinding how much external data to incorporate.\n- **Dynamic / adaptive (data-driven)**: The degree of borrowing depends on how similar the RWD control outcomes are to the trial control outcomes (e.g., power prior, commensurate prior approaches).\n\nThis is generally safer than a pure external control design because the concurrent randomized control arm serves as a built-in validity check.\n:::\n\n---\n\n:::{.callout-important}\n## Transportability and Generalizability\n\n**In plain language**: “Transporting” a trial result means taking the causal effect estimated in the trial's selected population and asking, “What would this effect be in a different, broader population?” For example, if a trial enrolled mostly younger patients with good kidney function, transportability methods let you estimate what the treatment effect would be in the full population of Medicare beneficiaries -- including older, sicker patients who were excluded from the trial.\n\n- **Generalizability** = extending results from the trial sample to the full population the trial was sampled from.\n- **Transportability** = extending results to an entirely different target population.\n\nYou may have:\n\n- An RCT effect estimate in a selected population\n- A target population in RWD\n\nGoal:\n\n> *Transport* or *generalize* the trial effect to the RWD population.\n\nRequires:\n\n- Modeling the difference between trial and target populations\n- Adjusting for “sampling bias” (who joins the trial)\n\nTechniques:\n\n- Inverse odds of sampling weights (IOSW)\n- Transport / generalizability TMLE\n- Doubly robust methods combining outcome and sampling models\n:::\n\n---\n\n## 3. Identification: Assumptions in Hybrid Settings\n\nBeyond usual RCT assumptions, hybrid designs require:\n\n:::{.callout-warning}\n## Assumption 3.1: No Unmeasured Confounding (for External / Observational Arms)\n\nWithin the external data:\n\n- Treatment-outcome confounding must be controlled using available covariates\n- Residual confounding may bias the hybrid estimate\n\nIn epi terms, this is the same exchangeability assumption you are familiar with from observational studies -- but now it applies specifically to the RWD component of your hybrid design. The RCT component is protected by randomization; the RWD component is not.\n:::\n\n:::{.callout-warning}\n## Assumption 3.2: Common Support (Overlap)\n\nThe joint covariate space of:\n\n- RCT participants\n- RWD patients\n\nmust overlap, especially when:\n\n- Using RWD to estimate control outcomes\n- Transporting effects across populations\n\nThis is the positivity assumption applied across data sources. If trial participants are systematically different from RWD patients in ways that matter for the outcome, you cannot borrow information reliably. Check covariate distributions carefully before proceeding.\n:::\n\n:::{.callout-warning}\n## Assumption 3.3: Consistency Across Sources\n\nMedical coding, endpoint definitions, and measurement schemes should be compatible (or harmonized).\n\nFor example, \"progression-free survival\" measured by central radiology review in a trial is not the same as \"progression-free survival\" inferred from claims data or chart review. If outcome definitions differ between the RCT and RWD, the hybrid estimator conflates apples and oranges.\n:::\n\n---\n\n## 4. ES-CV-TMLE: External Supervised Cross-Validated TMLE\n\n**ES-CV-TMLE (External Supervised Cross-Validated TMLE)** is a targeted learning approach that:\n\n- Uses **external data (RWD)** to help train nuisance models (e.g., outcome regressions)  \n- Validates and selects among them using **cross-validation in the RCT only**  \n- Ensures external data do not degrade the validity of RCT-based estimation  \n\n:::{.callout-note}\n## ES-CV-TMLE: The Core Insight\n\nHere is the key idea in plain language: **External data help you train better prediction models, but the RCT is the judge.** Think of it like studying for an exam with extra textbooks (the RWD), but the exam itself (cross-validation) is graded only on RCT data. If the external textbooks helped you learn real patterns, great -- your exam score improves. If they taught you spurious associations driven by confounding, the exam catches that and those models get down-weighted.\n\nWe may have poor precision in the RCT alone for nuisance functions \\(Q\\) and \\(g\\).\nExternal data can improve the *learning* of these functions, but confounding in the RWD could distort:\n\n- Outcome relationships\n- Treatment assignment mechanisms\n\nES-CV-TMLE protects against this by:\n\n1. Proposing multiple candidate nuisance models, some learned on:\n   - RCT only\n   - RWD only\n   - Combined data\n\n2. Using **cross-validation on the RCT** to evaluate each model’s performance (e.g., via log-likelihood loss).\n3. Choosing the best-performing nuisance model (or an ensemble of them) for TMLE.\n\nExternal data are “supervisors” but do not override the RCT.\n:::\n\n:::{.callout-tip}\n## ES-CV-TMLE Algorithm (Step by Step)\n\n1. **Train candidate models** by pooling RCT and RWD data in different ways:\n   - \\(Q_{\text{RCT}}\\): trained only on RCT\n   - \\(Q_{\text{RWD}}\\): trained only on RWD\n   - \\(Q_{\text{pool}}\\): trained on combined RCT+RWD\n\n2. **Evaluate each candidate** using RCT data only:\n   - Run cross-validated evaluation (e.g., deviance, negative log-likelihood)\n\n3. **Select or weight candidates** via SuperLearner-style metalearning.\n\n4. **Run TMLE** using the chosen Q (and similarly chosen g, if desired) on the RCT data.\n\nThis preserves the RCT-based identification and uses RWD as an auxiliary data source for better prediction. The bottom line: even if the RWD is confounded, this procedure can only help (or do no harm) relative to using the RCT alone.\n:::\n\n---\n\n## 5. A-TMLE: Adaptive Targeted Maximum Likelihood Estimation\n\n:::{.callout-note}\n## A-TMLE: Adaptive Combination in Plain Language\n\nThink of A-TMLE as a \"meta-analysis machine\" that does not just combine study results, but adaptively learns the best way to blend multiple estimators from different data sources. Where ES-CV-TMLE selects among candidate prediction models (a step inside the estimator), A-TMLE operates one level up: it selects among or blends entire estimators, each of which may use different data sources or modeling strategies. The data themselves decide how much to trust each source.\n:::\n\n**Adaptive TMLE (A-TMLE)** generalizes ES-CV-TMLE to the estimator level.\n\nInstead of combining candidate **nuisance models**, A-TMLE combines candidate **estimators** (e.g., separate hybrid analyses):\n\n- TMLE using RCT only\n- TMLE using RWD only (carefully adjusted)\n- TMLE using both RCT + RWD in a joint model\n- Other candidate estimators\n\nIt then uses a SuperLearner-style convex combination of these estimators to:\n\n> Minimize cross-validated risk, yielding an adaptive, doubly robust final estimate.\n\n### 5.1 Why A-TMLE?\n\nMultiple data sources can provide:\n\n- High internal validity (RCT)  \n- High external validity (RWD)  \n- Different types of bias and variance  \n\nA-TMLE lets the data decide the optimal combination, subject to:\n\n- Constraints (e.g., RCT estimator always included)  \n- Hierarchical preferences (e.g., more weight on RCT when conflict arises)\n\n### 5.2 Mathematical structure\n\nLet \\( \\hat\\Psi_1, \\dots, \\hat\\Psi_K\\) be candidate estimators of the same target parameter \\(\\Psi\\).\n\nA-TMLE constructs:\n\n\\[\n\\hat\\Psi_{\text{A-TMLE}} = \\sum_{k=1}^K \u0007lpha_k \\hat\\Psi_k\n\\]\n\nwith\n\n- \\(\u0007lpha_k \\ge 0\\)  \n- \\(\\sum_k \u0007lpha_k = 1\\)\n\nWeights \\(\u0007lpha\\) are chosen to minimize cross-validated loss (e.g., squared error of influence curves).\n\n---\n\n## 6. Example Hybrid Workflow (Conceptual)\n\nConsider:\n\n- RCT: experimental vs placebo  \n- RWD: observational comparison between experimental drug and standard-of-care  \n\n### 6.1 TMLE using RCT only\n\n```r\ntmle_rct <- tmle(\n  Y = Y_rct,\n  A = A_rct,\n  W = W_rct,\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\")\n)\npsi_rct <- tmle_rct$estimates$ATE$psi\n```\n\n### 6.2 TMLE using RWD (careful confounding control)\n\n```r\ntmle_rwd <- tmle(\n  Y = Y_rwd,\n  A = A_rwd,\n  W = W_rwd,\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\")\n)\npsi_rwd <- tmle_rwd$estimates$ATE$psi\n```\n\n### 6.3 Pooled-source TMLE\n\n```r\nY_pool <- c(Y_rct, Y_rwd)\nA_pool <- c(A_rct, A_rwd)\nW_pool <- rbind(W_rct, W_rwd)\n\ntmle_pool <- tmle(\n  Y = Y_pool,\n  A = A_pool,\n  W = W_pool,\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\")\n)\npsi_pool <- tmle_pool$estimates$ATE$psi\n```\n\n### 6.4 Adaptive combination (A-TMLE style idea)\n\n```r\ncandidates <- c(psi_rct, psi_rwd, psi_pool)\n\n# Placeholder: in practice, you would build a loss function based on influence curves\n# and use constrained optimization (e.g., nnls) with cross-validation to find weights.\n\nweights <- c(0.6, 0.0, 0.4)  # e.g., chosen by cross-validation\nweights <- weights / sum(weights)\n\npsi_atmle <- sum(weights * candidates)\npsi_atmle\n```\n\nIn a true A-TMLE implementation, the weights would be:\n\n- Estimated based on CV risk  \n- Possibly constrained to ensure heavier emphasis on RCT-based estimators  \n\n---\n\n## 7. Practical Considerations and Diagnostics for Hybrid Designs\n\n:::{.callout-important}\n## 7.1 Harmonization\n\nBefore attempting hybrid estimation, you must ensure that the two data sources are speaking the same language. This is often the most labor-intensive step.\n\n- Align endpoint definitions and censoring rules\n- Harmonize covariates (coding, units, ranges)\n- Confirm consistent definition of “treatment” across sources\n:::\n\n:::{.callout-tip}\n## 7.2 Assess Similarity Between RCT and RWD\n\nCheck covariate distributions before you borrow. Visualization is your first line of defense:\n\n```r\nbind_rows(\n  W_rct %>% mutate(source = “RCT”),\n  W_rwd %>% mutate(source = “RWD”)\n) %>%\n  pivot_longer(cols = -source) %>%\n  ggplot(aes(x = value, fill = source)) +\n  geom_density(alpha = 0.4) +\n  facet_wrap(~ name, scales = “free”)\n```\n\nLook for:\n\n- Large discrepancies --> may require transportability modeling\n- Non-overlapping regions --> positivity issues\n:::\n\n:::{.callout-warning}\n## 7.3 Sensitivity Analyses Are Not Optional\n\nEvery hybrid analysis should include sensitivity checks that quantify how much the result depends on the external data:\n\n- Re-estimate using RCT-only TMLE (your “no-borrowing” benchmark)\n- Vary the degree of borrowing (e.g., by up-weighting/down-weighting RWD in hybrid estimators)\n- Use E-values or quantitative bias analysis (QBA) to examine the impact of unmeasured confounding in the RWD component\n- Apply negative control analyses in the RWD part\n\nIf your conclusions change dramatically depending on how much RWD you include, that is a signal that the external data may be introducing bias rather than reducing variance.\n:::\n\n---\n\n## 8. When to Use Hybrid Designs (and When Not To)\n\nHybrid designs are **appropriate** when:\n\n- RWD is of reasonable quality  \n- Key confounders in RWD are measured  \n- Outcome definitions are compatible  \n- There is substantial overlap in covariate distributions  \n- The trial alone is underpowered or narrow in scope  \n\n:::{.callout-caution}\n## When Hybrid Designs Are Inappropriate\n\nThey may be **inappropriate** when:\n\n- **RWD is subject to severe unmeasured confounding**: If the observational data lack key confounders (e.g., disease severity, performance status), borrowing from RWD can introduce more bias than it resolves.\n- **Data sources are poorly harmonized**: If outcome definitions, covariate coding, or follow-up schedules differ substantially and cannot be reconciled, the hybrid estimator is comparing incompatible quantities.\n- **There is little overlap in covariate or treatment patterns**: If the trial population and RWD population occupy different regions of the covariate space, extrapolation replaces estimation.\n- **The trial is already well-powered for the primary endpoint**: In this case, the marginal precision gain from RWD may not justify the additional assumptions and complexity.\n\nIn those cases, a pure RCT analysis with careful interpretation may be preferable. Adding RWD is not always better -- it is better only when the assumptions hold and the data quality warrants it.\n:::\n\n---\n\n## 9. Summary\n\n:::{.callout-tip}\n## Chapter Takeaways\n\nHybrid RCT-RWD designs extend the causal roadmap to a richer evidence ecosystem:\n\n- **External controls** can augment sparse trial control arms\n- **Transport and generalizability methods** can extend findings to broader populations\n- **ES-CV-TMLE** leverages RWD for nuisance modeling while preserving internal validity\n- **A-TMLE** adaptively combines estimators from multiple sources using targeted learning and cross-validation\n\nUsed carefully, these tools can:\n\n- Improve precision\n- Enhance generalizability\n- Provide robust, transparent evidence that respects the strengths and limitations of both RCT and RWD\n\nThe overarching principle for MPH-trained epidemiologists: hybrid designs do not weaken the RCT -- they extend it. But the extension is only as trustworthy as the assumptions and data quality behind the RWD component. Always report the RCT-only result alongside the hybrid result so readers can judge for themselves.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26200)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.2    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.4.2       htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10      \n [9] rmarkdown_2.29    knitr_1.49        jsonlite_2.0.0    xfun_0.49        \n[13] digest_0.6.37     rlang_1.1.6       evaluate_1.0.5   \n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}