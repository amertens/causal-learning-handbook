{
  "hash": "c6e1686a66953c88b1242b0784fb0994",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chapter 2.2: Inverse Probability of Treatment Weighting (IPTW)\"\nformat: html\n---\n\n\n\n\n# Chapter 2.2: Inverse Probability of Treatment Weighting  \n\nInverse probability of treatment weighting (IPTW) is a core method in modern causal inference. Instead of modeling the outcome directly as in g computation, IPTW uses a model for **treatment assignment** to create a pseudo population where treatment is independent of confounders.  \n\nIn this chapter we will\n\n- Build intuition for IPTW\n- Derive the weights and connect them to the causal estimand\n- Show how to estimate and diagnose propensity scores\n- Implement IPTW in R with tidyverse style\n- Discuss stabilized weights and truncation\n- Compare IPTW to g computation on the same simulated data\n\nThis is still point treatment only. Longitudinal extensions come later.\n\n---\n\n# 1. Intuition: Reweighting to Mimic a Trial\n\n:::{.callout-tip}\n## Key Insight: IPTW Creates a Pseudo-Population That Mimics a Randomized Trial\n\nIn observational data, some types of patients are more likely to receive one treatment than another. This creates **confounding by indication**. Think of it this way: if sicker patients are preferentially given a new drug, a naive comparison of outcomes between treated and untreated groups will be biased.\n\nIPTW tackles this by\n\n> Giving more weight to underrepresented patients and less weight to overrepresented ones, so that in the weighted sample, treatment looks as if it were randomized given the measured covariates.\n\nThe result is a **pseudo-population** --- a reweighted version of your study sample where the distribution of confounders is the same across treatment groups, just as it would be in a well-conducted randomized trial. This is the core idea that makes IPTW so powerful for epidemiologic research.\n\n- Patients who got a treatment that was unlikely for their covariate pattern receive a large weight (they are \"surprising\" and therefore informative)\n- Patients who got the most expected treatment get a small weight (they are \"predictable\" and already well-represented)\n\nIn the weighted pseudo-population, confounders are balanced between treatment groups (if the propensity score model is correctly specified).\n:::\n\n:::{.callout-note}\n## Definition: The Propensity Score\n\nThe **propensity score** is the probability of receiving treatment given measured covariates:\n\n$$\ne(W) = P(A = 1 \\mid W)\n$$\n\nIPTW weights are constructed from the propensity score:\n\n- For treated:  \\( \\displaystyle w_i = \\frac{1}{e(W_i)} \\)\n- For control: \\( \\displaystyle w_i = \\frac{1}{1 - e(W_i)} \\)\n\nThe propensity score is a **balancing score**: conditioning on it is sufficient to remove confounding by all measured covariates $W$. This is why a single scalar summary can replace adjustment for many covariates.\n:::\n\n---\n\n# 2. Identification Using IPTW\n\n:::{.callout-important}\n## The IPTW Identification Result and the Horvitz-Thompson Connection\n\nUnder the same causal assumptions as before\n\n- **Consistency**: the observed outcome equals the potential outcome under the treatment actually received\n- **Exchangeability**: \\( Y(a) \\perp A \\mid W \\) --- no unmeasured confounding\n- **Positivity**: every covariate stratum has a non-zero probability of receiving each treatment\n\nthe average potential outcome under treatment can be expressed as\n\n$$\nE[Y(1)] = E\\left[ \\frac{I(A = 1) Y}{e(W)} \\right]\n$$\n\nand under control\n\n$$\nE[Y(0)] = E\\left[ \\frac{I(A = 0) Y}{1 - e(W)} \\right]\n$$\n\nThe IPTW estimator replaces the expectation with the sample average and replaces the true \\( e(W) \\) with an estimated one.\n\nThis is called a **Horvitz-Thompson type** estimator because it has the same structure as the survey sampling estimator that reweights observations by the inverse of their selection probability. In our setting, \"selection\" is selection into a treatment group. Just as survey statisticians upweight undersampled populations, we upweight patients whose treatment assignment was unlikely given their covariates.\n:::\n\n---\n\n# 3. Simulated Example\n\nWe reuse a familiar setup: an osteoporosis like population with confounding by age and cardiovascular history.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'ggplot2' was built under R version 4.4.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'stringr' was built under R version 4.4.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.6.0\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nset.seed(2025)\nn <- 4000\n\nage <- rnorm(n, 75, 6)\ncvd <- rbinom(n, 1, plogis(0.12 * (age - 70)))\n\n# Treatment assignment with strong confounding\nA <- rbinom(n, 1, plogis(-1 + 0.09 * (age - 70) + 1.5 * cvd))\n\n# Outcome model\nY <- rbinom(n, 1, plogis(-2 + 0.5*A + 0.10*(age - 70) + 1.0*cvd))\n\ndat <- tibble(age, cvd, A, Y)\ndat %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n    age   cvd     A     Y\n  <dbl> <int> <int> <int>\n1  78.7     1     1     1\n2  75.2     1     0     1\n3  79.6     0     1     0\n4  82.6     1     0     0\n5  77.2     0     1     0\n6  74.0     1     1     1\n```\n\n\n:::\n:::\n\n\n\n\nFor simplicity\n\n- A = 1 can be thought of as denosumab\n- A = 0 can be thought of as zoledronic acid\n- Y = 1 indicates occurrence of a cardiovascular outcome\n\n---\n\n# 4. Estimating the Propensity Score\n\nWe model the probability of receiving treatment given covariates.\n\nIn practice, one might use logistic regression, SuperLearner, or other ML. Here we start with logistic regression for clarity.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nps_mod <- glm(A ~ age + cvd, family = binomial, data = dat)\nsummary(ps_mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = A ~ age + cvd, family = binomial, data = dat)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -7.186635   0.486406  -14.78   <2e-16 ***\nage          0.088177   0.006572   13.42   <2e-16 ***\ncvd          1.478441   0.073676   20.07   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 5459  on 3999  degrees of freedom\nResidual deviance: 4634  on 3997  degrees of freedom\nAIC: 4640\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\ndat <- dat %>%\n  mutate(\n    ps = predict(ps_mod, type = \"response\")\n  )\n\ndat %>% \n  summarize(\n    min_ps = min(ps),\n    max_ps = max(ps)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  min_ps max_ps\n   <dbl>  <dbl>\n1 0.0987  0.950\n```\n\n\n:::\n:::\n\n\n\n\nWe can visualize the propensity score distribution.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dat, aes(x = ps, fill = factor(A))) +\n  geom_density(alpha = 0.4) +\n  labs(\n    x = \"Estimated propensity score P(A=1 | W)\",\n    fill = \"Treatment\",\n    title = \"Propensity score overlap\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](02-02-iptw_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n:::{.callout-tip}\n## Reading the Propensity Score Overlap Plot\n\n**Good overlap** looks like two density curves that cover mostly the same range of propensity scores, even if their peaks differ. This means that for most covariate patterns, there are both treated and untreated patients --- exactly what positivity requires.\n\n**Bad overlap** looks like two density curves that barely touch, with the treated group concentrated at high propensity scores and the untreated group concentrated at low ones. When this happens:\n\n- IPTW produces extreme weights for patients in the non-overlapping tails\n- Estimates become highly variable and unreliable\n- You may need to restrict your target population to the region of overlap (trimming) or reconsider your study design\n\nAs a rule of thumb, be concerned if propensity scores for either group pile up near 0 or 1.\n:::\n\n---\n\n# 5. Constructing IPTW Weights\n\n:::{.callout-note}\n## Unstabilized Weights\n\nUnstabilized weights are the simplest form of IPTW weights. For each individual, the weight is the inverse of the probability of receiving the treatment they actually received:\n\n- Treated ($A = 1$): $w_i = 1 / e(W_i)$\n- Untreated ($A = 0$): $w_i = 1 / (1 - e(W_i))$\n\nThese weights create a pseudo-population where treatment is independent of measured confounders. However, they can be highly variable --- especially when some propensity scores are close to 0 or 1.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- dat %>%\n  mutate(\n    w_ipw = if_else(A == 1, 1 / ps, 1 / (1 - ps))\n  )\n\nsummary(dat$w_ipw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.052   1.297   1.487   1.998   2.327  15.717 \n```\n\n\n:::\n\n```{.r .cell-code}\nquantile(dat$w_ipw, probs = c(0.01, 0.99))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      1%      99% \n1.118912 6.063346 \n```\n\n\n:::\n:::\n\n\n\n\nKeep an eye on\n\n- Very large weights (suggest near-violations of positivity)\n- Range and extreme quantiles (the 99th percentile should not be orders of magnitude larger than the median)\n\n:::{.callout-tip}\n## Why Stabilized Weights Are Preferred in Practice\n\nStabilized weights multiply the standard IPTW weights by the **marginal probability of treatment**, which brings the weights closer to 1 on average and reduces their variance without introducing bias for the marginal causal effect.\n\nFor a binary treatment:\n\n$$\nSW_i = \\frac{P(A_i)}{e(W_i)} \\text{ if } A_i = 1\n$$\n\nand\n\n$$\nSW_i = \\frac{P(A_i)}{1 - e(W_i)} \\text{ if } A_i = 0\n$$\n\nHere \\( P(A_i) \\) is the marginal probability of treatment (estimated as the sample proportion treated).\n\n**Why this helps:** Unstabilized weights create a pseudo-population that is larger than the original sample, which inflates standard errors. Stabilized weights preserve the original sample size in expectation, leading to:\n\n- Narrower confidence intervals\n- More stable point estimates\n- Better finite-sample performance\n\nIn epidemiologic practice, **always prefer stabilized weights** unless you have a specific reason to use unstabilized ones.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npA <- mean(dat$A)\n\ndat <- dat %>%\n  mutate(\n    sw_ipw = case_when(\n      A == 1 ~ pA / ps,\n      A == 0 ~ (1 - pA) / (1 - ps)\n    )\n  )\n\nsummary(dat$sw_ipw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.4735  0.6846  0.7863  0.9992  1.1240  6.7071 \n```\n\n\n:::\n\n```{.r .cell-code}\nquantile(dat$sw_ipw, probs = c(0.01, 0.99))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       1%       99% \n0.5029079 2.9252532 \n```\n\n\n:::\n:::\n\n\n\n\n---\n\n# 6. Estimating the ATE via IPTW\n\nThere are several equivalent ways to use the weights.\n\n## 6.1 Direct weighted mean of outcomes\n\nEstimated risk under treatment\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrisk1_ipw <- with(dat, sum(sw_ipw * Y * (A == 1)) / sum(sw_ipw * (A == 1)))\nrisk0_ipw <- with(dat, sum(sw_ipw * Y * (A == 0)) / sum(sw_ipw * (A == 0)))\n\nate_ipw <- risk1_ipw - risk0_ipw\nc(risk1 = risk1_ipw, risk0 = risk0_ipw, ate = ate_ipw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    risk1     risk0       ate \n0.4109454 0.2991691 0.1117762 \n```\n\n\n:::\n:::\n\n\n\n\nThis matches the formula\n\n$$\n\\hat E[Y(1)] = \\frac{\\sum_i SW_i Y_i I(A_i = 1)}{\\sum_i SW_i I(A_i = 1)}\n$$\n\n## 6.2 Weighted regression model\n\nWe can also fit a weighted regression with treatment as the only predictor.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sandwich)\nlibrary(lmtest)\n\n# Fit a simple weighted model\nfit_ipw <- glm(Y ~ A, family = binomial, weights = sw_ipw, data = dat)\n\n# Robust standard errors\ncov_ipw <- vcovHC(fit_ipw, type = \"HC0\")\ncoeftest(fit_ipw, cov_ipw)\n```\n:::\n\n\n\n\nInterpretation\n\n- The coefficient of A (on the log odds scale) now estimates a marginal effect in the pseudo population\n- You can compute marginal risk differences or ratios by predicting from the model at A=1 and A=0 and standardizing\n\n---\n\n# 7. Comparing IPTW and G Computation\n\nWe can compare the IPTW ATE to the g computation ATE from the previous chapter.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# g computation\ng_mod <- glm(Y ~ A + age + cvd, family = binomial, data = dat)\np1_g <- predict(g_mod, newdata = dat %>% mutate(A = 1), type = \"response\")\np0_g <- predict(g_mod, newdata = dat %>% mutate(A = 0), type = \"response\")\nate_g <- mean(p1_g - p0_g)\n\nc(ate_gcomp = ate_g, ate_iptw = ate_ipw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nate_gcomp  ate_iptw \n0.1064902 0.1117762 \n```\n\n\n:::\n:::\n\n\n\n\nUnder correct models and adequate positivity, these methods should converge to similar estimates as sample size grows.\n\n:::{.callout-important}\n## Critical Takeaway: IPTW and G-Computation Depend on Different Models\n\nThis is one of the most important conceptual points in causal inference methodology:\n\n- **G-computation** depends on correctly specifying the **outcome model** $E[Y \\mid A, W]$\n- **IPTW** depends on correctly specifying the **treatment model** $P(A \\mid W)$\n- **Neither uses both models at once**\n\nIn practice, you rarely know which model is correct. This motivates **doubly robust** methods (next chapter), which combine both approaches and provide consistent estimates if *either* the treatment model *or* the outcome model is correctly specified --- giving you two chances to get it right.\n\nFor MPH epidemiologists: when you present IPTW results, always show propensity score diagnostics (overlap, balance) alongside your estimates. When you present g-computation results, discuss outcome model fit. When the two approaches give very different answers, that is a signal that at least one model may be misspecified.\n:::\n\n---\n\n# 8. Diagnostics and Practical Tips\n\nIPTW is powerful but fragile if diagnostics are ignored.\n\n:::{.callout-important}\n## Diagnostic Checklist: Never Report IPTW Without These Checks\n\nEvery IPTW analysis should include diagnostics. Reviewers and readers should expect to see them. Omitting diagnostics is a red flag in any manuscript.\n:::\n\n### 8.1 Check propensity score overlap\n\n:::{.callout-note}\n## Assessing Positivity via Overlap\n\n- Plot propensity score densities by treatment group (as we did in Section 4)\n- Flag regions where one group is missing or sparse\n- If the treated and untreated distributions do not overlap, the ATE may not be identifiable in that region\n- Consider restricting inference to the overlap population or reporting the ATT instead\n:::\n\n### 8.2 Check weights\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat %>%\n  summarize(\n    min_w = min(sw_ipw),\n    max_w = max(sw_ipw),\n    mean_w = mean(sw_ipw),\n    sd_w = sd(sw_ipw)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  min_w max_w mean_w  sd_w\n  <dbl> <dbl>  <dbl> <dbl>\n1 0.474  6.71  0.999 0.544\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-warning}\n## When Extreme Weights Signal Trouble\n\nLarge extreme weights are a red flag. Watch for these warning signs:\n\n- **Maximum weight > 10--20**: a single observation is being counted as 10--20 people. Your estimate may be driven by one or two individuals.\n- **Mean of stabilized weights far from 1**: stabilized weights should average approximately 1. Deviations suggest model misspecification.\n- **Ratio of max to median weight > 20**: indicates near-violation of positivity for some covariate patterns.\n\nWhen you see extreme weights, consider: (1) improving your propensity score model, (2) checking for data errors in the extreme-weight observations, and (3) applying weight truncation (see below).\n:::\n\n### 8.3 Consider truncation\n\nYou can truncate weights at a chosen percentile, for example the 1st and 99th percentiles.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlower <- quantile(dat$sw_ipw, 0.01)\nupper <- quantile(dat$sw_ipw, 0.99)\n\ndat <- dat %>%\n  mutate(\n    sw_trunc = pmin(pmax(sw_ipw, lower), upper)\n  )\n\n# recompute ATE with truncated weights\nrisk1_trunc <- with(dat, sum(sw_trunc * Y * (A == 1)) / sum(sw_trunc * (A == 1)))\nrisk0_trunc <- with(dat, sum(sw_trunc * Y * (A == 0)) / sum(sw_trunc * (A == 0)))\nate_trunc   <- risk1_trunc - risk0_trunc\n\nc(ate_truncated = ate_trunc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nate_truncated \n    0.1168119 \n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-caution}\n## The Truncation Trade-Off: Bias vs. Variance\n\nTruncation (also called \"winsorizing\") reduces variance at the cost of introducing some bias. By capping extreme weights, you are effectively saying: \"I am willing to accept a small amount of bias in exchange for a much more stable estimate.\"\n\n**The trade-off in practice:**\n\n- **Without truncation**: unbiased (if the propensity model is correct) but potentially high variance, with confidence intervals that may be uninformatively wide\n- **With truncation**: slightly biased but often lower mean squared error, producing more useful estimates\n\n**Common approaches:**\n\n- Truncate at the 1st and 99th percentiles (as shown above)\n- Truncate at fixed values (e.g., cap weights at 10 or 20)\n- Report results with and without truncation as a sensitivity analysis\n\nThere is no single \"right\" truncation threshold. In your manuscripts, always report which threshold you used and show sensitivity to this choice.\n:::\n\n---\n\n# 9. Summary\n\n:::{.callout-tip}\n## Chapter Takeaways and Limitations\n\n**What we covered:**\n\n- The intuition for IPTW as a method that reweights observational data to mimic a randomized trial\n- The key role of the propensity score in computing weights, and its connection to the Horvitz-Thompson estimator from survey sampling\n- How to construct unstabilized and stabilized IPTW weights (prefer stabilized in practice)\n- How to estimate ATEs via weighted means or weighted regression\n- How to diagnose propensity score overlap and extreme weights --- never skip these diagnostics\n- How IPTW compares to g-computation, and why each depends on a different model\n\n**Limitations to keep in mind:**\n\n- Depends entirely on a correctly specified treatment model --- if you miss a confounder or misspecify the functional form, your weights will not balance the confounders\n- Sensitive to violations of positivity --- extreme weights can dominate your estimates\n- Does not use information from the outcome model, which motivates doubly robust approaches\n- For rare exposures or outcomes, IPTW can be particularly unstable\n\n**Looking ahead:** In the next chapter, we will introduce **doubly robust estimators** and **Targeted Maximum Likelihood Estimation (TMLE)**, which combine the strengths of g-computation and IPTW and allow the use of machine learning for both nuisance models.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26200)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.3 forcats_1.0.0   stringr_1.6.0   dplyr_1.1.4    \n [5] purrr_1.0.2     readr_2.1.5     tidyr_1.3.1     tibble_3.2.1   \n [9] ggplot2_3.5.2   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6      jsonlite_2.0.0    compiler_4.4.2    tidyselect_1.2.1 \n [5] scales_1.3.0      yaml_2.3.10       fastmap_1.2.0     R6_2.6.1         \n [9] labeling_0.4.3    generics_0.1.3    knitr_1.49        htmlwidgets_1.6.4\n[13] munsell_0.5.1     pillar_1.9.0      tzdb_0.4.0        rlang_1.1.6      \n[17] utf8_1.2.4        stringi_1.8.7     xfun_0.49         timechange_0.3.0 \n[21] cli_3.6.5         withr_3.0.2       magrittr_2.0.3    digest_0.6.37    \n[25] grid_4.4.2        rstudioapi_0.17.1 hms_1.1.3         lifecycle_1.0.4  \n[29] vctrs_0.6.5       evaluate_1.0.5    glue_1.8.0        farver_2.1.2     \n[33] fansi_1.0.6       colorspace_2.1-1  rmarkdown_2.29    tools_4.4.2      \n[37] pkgconfig_2.0.3   htmltools_0.5.8.1\n```\n\n\n:::\n:::\n",
    "supporting": [
      "02-02-iptw_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}