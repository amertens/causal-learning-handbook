{
  "hash": "730cc75712f21326e482c445e84e701c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chapter 1.2: The Causal Roadmap\"\nformat: html\n---\n\n\n\n\nIn this chapter, we introduce the **Causal Roadmap**, a structured approach for asking and answering causal questions with observational data. The roadmap helps researchers define their scientific question, translate it into a formal causal model, assess whether the causal effect is identifiable from data, and choose appropriate estimators to answer that question.\n\n:::{.callout-important}\n## Why Use a Causal Roadmap?\n\nIn epidemiology, it is tempting to jump straight to fitting a model---\"Let’s run a regression and see what we find.\" But this approach conflates the scientific question with the statistical procedure, making it difficult to evaluate whether the analysis actually answers the question you care about. Modern causal inference begins by asking: **What is the causal question we are trying to answer?**\n\nA causal roadmap ensures:\n- Transparency in how evidence is generated\n- Separation of scientific questions from statistical methods\n- Clear articulation of assumptions and their implications\n- Structured thinking in both trial and non-randomized settings\n\nStarting with a well-defined question---before touching data or code---is the single most important step in any causal analysis. Every choice downstream (confounders to adjust for, estimator to use, how to interpret results) flows from this starting point.\n\nWe’ll walk step-by-step through each part of the roadmap, with illustrative examples.\n:::\n\n:::{.callout-note}\n## Step 1: Define the Causal Question\n\nThis includes:\n- **Population**: Who are we studying?\n- **Intervention**: What exposure or treatment are we manipulating?\n- **Outcome**: What effect are we interested in?\n- **Timeframe**: Over what duration?\n\nExample:\n\n> What is the 3-year risk of cardiovascular events if all postmenopausal women with osteoporosis initiated **denosumab** compared to if all initiated **zoledronic acid**?\n\nThis PICO-style framing is the foundation of causal inference.\n:::\n\n:::{.callout-note}\n## Step 2: Specify the Causal Model\n\nWe now draw out how we believe the data were generated. This includes:\n\n- **Variables**: Treatment (A), outcome (Y), and covariates (W)\n- **DAGs**: Directed acyclic graphs to encode assumptions\n- **Potential Outcomes**: $Y(1)$ and $Y(0)$ for each individual\n\nWe are making an implicit **Structural Causal Model (SCM)**:\n\n**In plain language:** A Structural Causal Model is simply a formal way of writing down your story about how the world works. Think of it as a set of equations that say: \"This variable is caused by these other variables, plus some factors we cannot measure.\" For MPH students, the SCM is the mathematical version of the causal DAG you draw on a whiteboard---each arrow in the DAG corresponds to one of these equations. The key advantage is that it forces you to be explicit about every assumption you are making about what causes what.\n\n$$\nW = f_W(U_W),\\\nA = f_A(W, U_A),\\\nY = f_Y(W, A, U_Y)\n$$\n\nWhere $U$ terms represent unmeasured variables.\n\nA simple DAG:\n\n```\nW → A → Y\n \\    ↘\n  →────→\n```\n\nThis DAG implies:\n- W (confounders) affect both A and Y\n- A (treatment) affects Y\n- No unmeasured confounding (U nodes omitted for simplicity)\n:::\n\n:::{.callout-tip}\n## Step 3: Define the Target Causal Estimand\n\nWe often want the **Average Treatment Effect (ATE)**:\n\n$$\nATE = E[Y(1) - Y(0)]\n$$\n\nOr equivalently, **Risk Difference**:\n\n$$\nE[Y | do(A=1)] - E[Y | do(A=0)]\n$$\n\n**Why prefer risk differences over odds ratios?** In applied epidemiology, the risk difference (RD) is often the most interpretable effect measure. It directly tells you: \"Treatment changes the probability of the outcome by X percentage points.\" Odds ratios, by contrast, are non-collapsible (they change when you marginalize over covariates even without confounding), do not have a straightforward causal interpretation on the population level, and are frequently misinterpreted as risk ratios by clinicians and policymakers. When your goal is to inform a public health decision---\"How many cases would we prevent if everyone received treatment?\"---the risk difference answers that question directly.\n\nWe might also want:\n- Risk ratios\n- Hazard ratios (with caveats)\n- Median survival differences\n- Effects in subgroups (CATEs)\n:::\n\n:::{.callout-warning}\n## Step 4: Link the Causal Estimand to the Observed Data\n\nThis is the **identification step**. It answers the question: *Can we estimate the causal effect from the data we have?*\n\n**This is the most critical step in the entire roadmap.** The assumptions below cannot be tested with data alone---they are fundamentally untestable. No statistical diagnostic, no balance table, and no sensitivity analysis can prove they hold. They must be justified by subject-matter knowledge. If these assumptions fail, your estimate may be biased no matter how sophisticated your statistical method is.\n\nRequires three assumptions:\n\n- **Exchangeability (No unmeasured confounding)**: $Y(a) \\perp A | W$ --- This means that, within levels of the measured covariates W, the treated and untreated groups are comparable. In practice, this requires that you have measured and adjusted for *every* common cause of treatment and outcome. There is no way to verify this from the data.\n- **Positivity**: Everyone has a nonzero probability of receiving each treatment, given W --- If certain covariate strata always receive one treatment, you cannot estimate effects for those groups.\n- **Consistency**: The observed outcome equals the potential outcome under the received treatment --- This requires a well-defined intervention with no hidden variations in how treatment is delivered.\n\nIf satisfied, we can identify:\n\n$$\nE[Y(1) - Y(0)] = E_W[ E[Y | A = 1, W] - E[Y | A = 0, W] ]\n$$\n:::\n\n:::{.callout-tip}\n## Step 5: Choose a Statistical Estimator\n\nThis step translates the identified quantity into an algorithm we can apply to data.\n\nOptions include:\n- **G-computation**: Predict outcomes under each treatment, average over W\n- **IPTW**: Weight observations by inverse probability of treatment\n- **TMLE**: Targeted learning that combines outcome and treatment models\n\nWe’ll explore these in later chapters. The choice depends on:\n- Assumptions you’re willing to make\n- Sample size\n- Tolerance for model misspecification\n:::\n\n:::{.callout-caution}\n## Step 6: Evaluate and Interpret\n\nOnce you've estimated your parameter, interpretation is **not automatic**.\n\n- Are your assumptions plausible?\n- What does your estimate mean for real-world decisions?\n- Can you generalize to other populations?\n\nTools for evaluation:\n- Sensitivity analyses\n- Negative control outcomes\n- Covariate balance checks\n- Expert consultation\n:::\n\n## A Simple Simulated Example\n\nWe'll simulate a small dataset to show how steps 1-5 look in practice.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nn <- 1000\nage <- rnorm(n, 75, 6)\ncvd_history <- rbinom(n, 1, plogis(0.1 * (age - 70)))\nW <- data.frame(age, cvd_history)\nA <- rbinom(n, 1, plogis(-1 + 0.05 * (age - 70) + 1.5 * cvd_history))\nY <- rbinom(n, 1, plogis(-2 + 0.4 * A + 0.1 * (age - 70) + 1 * cvd_history))\ndata <- data.frame(W, A, Y)\n```\n:::\n\n\n\n\nEstimate ATE using g-computation:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- glm(Y ~ A + age + cvd_history, family = binomial, data = data)\nnewdata1 <- transform(data, A = 1)\nnewdata0 <- transform(data, A = 0)\np1 <- predict(model, newdata = newdata1, type = \"response\")\np0 <- predict(model, newdata = newdata0, type = \"response\")\nmean(p1 - p0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1206902\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-tip}\n## Interpreting the G-Computation Result\n\nThe number produced by `mean(p1 - p0)` is the estimated **average causal risk difference**. In plain language: it tells you how much the probability of the outcome (e.g., a cardiovascular event) would change, on average, if everyone in the study population had received treatment (A = 1) compared to if everyone had received no treatment (A = 0). For example, a value of 0.07 means that treatment is estimated to increase the risk of the outcome by 7 percentage points on average across the population, after adjusting for age and CVD history. This is the core quantity that g-computation targets---a population-level \"what if\" comparison.\n:::\n\n---\n\n:::{.callout-note}\n## Summary\n\nThe Causal Roadmap gives a rigorous framework for designing and evaluating real-world effect estimates. Before choosing a statistical method, start with the science:\n- Define your causal question\n- Specify your model and assumptions\n- Decide how to express the effect\n- Choose a transparent, defensible method\n\nIn the next chapter, we’ll explore different estimation strategies in detail.\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}