{
  "hash": "2e25cfd8e5be8a920640505e8f8a11fa",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chapter X: Common Pitfalls and How to Avoid Them\"\nformat: html\n---\n\n\n\n\n# Chapter X  \n## Common Pitfalls and How to Avoid Them  \n*A practical guide for avoiding frequent mistakes in causal inference and targeted learning*\n\nEven with a solid understanding of the causal roadmap and modern estimators, it is remarkably easy to make analytic choices that lead to biased, unstable, or misleading results. In real-world evidence (RWE), the stakes are even higher: data are messy, treatment pathways are irregular, and clinical validity depends on careful execution.\n\nThis chapter catalogs **the most common pitfalls** analysts encounter in causal inference—especially in pharmacoepidemiologic and longitudinal RWE settings—and provides **concrete strategies** to avoid them.\n\n---\n\n## 1. Pitfall: Confusing Association With Causation  \n### The regression coefficient problem\n\n**Mistake:**  \nRunning multivariable regression and interpreting the treatment coefficient as a causal effect.\n\n**Why it matters:**  \nRegression coefficients estimate **conditional associations**, not causal contrasts. Unless the regression exactly corresponds to the identification formula and correctly specifies the functional forms, the estimate is biased.\n\n**Avoid by:**  \n- Defining a precise **causal question** and **estimand**  \n- Using **G-computation**, **IPTW**, **AIPW**, or **TMLE** instead of regression coefficients  \n- Using flexible nuisance estimation (SuperLearner)  \n\n---\n\n## 2. Pitfall: Adjusting for Post-Treatment Variables  \n### The mediator/collider trap\n\n**Mistake:** Including variables measured after treatment assignment in regression or propensity score models.\n\n**Why it matters:**  \n- These variables often lie on **causal pathways** → adjusting blocks part of the effect  \n- They may be **colliders** → inducing bias  \n- Breaks the hypothetical intervention definition\n\n**Avoid by:**  \n- Adjusting only for **baseline** confounders  \n- Using **LMTP/LTMLE** when post-treatment confounding exists  \n- Drawing DAGs to clarify temporal structure  \n\n---\n\n## 3. Pitfall: Violated Positivity / Lack of Overlap  \n### Treatment not comparable across covariate strata\n\n**Symptoms:**  \n- Propensity scores near 0 or 1  \n- Large IPTW weights  \n- Extreme clever covariates in TMLE  \n\n**Avoid by:**  \n- Checking PS overlap  \n- Truncating weights  \n- Restricting to **regions of support**  \n- Using **stochastic interventions** when static interventions are not feasible  \n\n---\n\n## 4. Pitfall: Misspecified Outcome or Propensity Models  \n### Relying on simple models when relationships are nonlinear\n\n**Avoid by:**  \n- Using **SuperLearner**  \n- Evaluating cross-validated risk  \n- Inspecting calibration  \n\n---\n\n## 5. Pitfall: Blindly Trusting Machine Learning  \n### Flexible models ≠ correct models\n\n**Avoid by:**  \n- Always using **cross-validation**  \n- Checking calibration and residual diagnostics  \n- Using TMLE to protect inference from ML instability  \n\n---\n\n## 6. Pitfall: Ignoring Censoring and Informative Dropout  \n\n**Avoid by:**  \n- Modeling censoring with SL  \n- Using TMLE/LMTP with censoring nodes  \n- Conducting sensitivity analyses  \n\n---\n\n## 7. Pitfall: Over-interpreting Heterogeneous Treatment Effects  \n### HTE estimates are high variance and easy to misinterpret\n\n**Avoid by:**  \n- Prespecifying subgroups  \n- Reporting uncertainty  \n- Treating causal forest results as **exploratory**  \n- Using TMLE-based variable-importance for confirmatory analyses  \n\n---\n\n## 8. Pitfall: Using the Wrong Estimand  \n### Hazard ratios and odds ratios are not causal effects\n\n**Avoid by:**  \n- Targeting risk differences, risk ratios, survival curves, or RMST  \n- Using LMTP/TMLE for causal survival analysis  \n\n---\n\n## 9. Pitfall: Not Performing Diagnostics  \n### “The model ran” ≠ “The result is valid”\n\n**Avoid by:**  \n- Inspecting weight distributions  \n- Checking clever covariate ranges  \n- Examining influence curve stability  \n- Running calibration checks for Q/g  \n\n---\n\n## 10. Pitfall: Neglecting Sensitivity Analyses  \n### Assuming away unmeasured confounding\n\n**Avoid by:**  \n- E-values  \n- Quantitative bias analysis  \n- Negative control outcomes/exposures  \n- Stochastic sensitivity analyses  \n\n---\n\n## 11. Pitfall: Poor Alignment Between RCT and RWD in Hybrid Designs  \n\n**Avoid by:**  \n- Harmonizing definitions  \n- Checking covariate balance across datasets  \n- Applying ES-CV-TMLE or A-TMLE  \n- Conducting negative controls in RWD  \n\n---\n\n## 12. Pitfall: Reporting Without Context or Interpretation  \n\n**Avoid by:**  \n- Including absolute risk estimates  \n- Transparently stating assumptions  \n- Discussing limitations and robustness  \n- Framing the estimand in scientific terms  \n\n---\n\n## 13. Summary\n\nCommon pitfalls arise from misalignment between analytic choices and scientific questions, misspecification, unchecked assumptions, and overinterpretation. Avoiding them requires:\n\n- The causal roadmap  \n- Diagnostics  \n- Sensitivity analyses  \n- Careful communication  \n\nThese principles yield causal evidence that is credible, reproducible, and actionable.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 26200)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.2    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.4.2       htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10      \n [9] rmarkdown_2.29    knitr_1.49        jsonlite_2.0.0    xfun_0.49        \n[13] digest_0.6.37     rlang_1.1.6       evaluate_1.0.5   \n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}