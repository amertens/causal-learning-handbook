{
  "hash": "30c103a1d864b23200c7930757a677df",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chapter 2.4: SuperLearner and Machine Learning for Causal Inference\"\nformat: html\n---\n\n\n\n\n# Chapter 2.4: SuperLearner and Machine Learning for Causal Inference  \n*Flexible prediction to strengthen causal effect estimation*\n\nModern causal inference relies on estimating **nuisance functions** (outcome regressions and treatment / censoring mechanisms) that are as accurate as possible. If these models are mis-specified, even sophisticated causal estimators can be biased.\n\nRather than gambling on a single model (e.g., logistic regression), we can **stack** many candidate learners and let the data decide how to combine them. This is what **SuperLearner** does.\n\nIn this chapter you will learn:\n\n- The intuition behind SuperLearner (SL) and stacking  \n- How cross-validation is used to avoid overfitting  \n- How to build and interpret SuperLearner models in R  \n- When and why to choose different **loss functions** (MSE, log-likelihood, AUC)  \n- How to customize SL libraries and tune algorithms  \n- How SL integrates with TMLE and other causal estimators  \n\nThis chapter leans heavily on the excellent visual tutorial by Katherine Hoffman and the SuperLearner demo by David Benkeser (both provided as PDFs), and recasts them in a causal-inference focused Quarto format.\n\n---\n\n## 1. Why Use SuperLearner in Causal Inference?\n\nCausal estimators such as g-computation, IPTW, AIPW, and TMLE rely on estimating:\n\n- The **outcome regression**:  \n  \\( Q(W, A) = E[Y \\mid W, A] \\)\n\n- The **treatment (or censoring) mechanism**:  \n  \\( g(W) = P(A = 1 \\mid W) \\)\n\nIn traditional practice, both are often modeled with simple GLMs. This is dangerous when:\n\n- Relationships are nonlinear\n- Interactions are present\n- There are many covariates\n- We are unsure about which variables to include or in what functional form\n\nSuperLearner helps by:\n\n- Combining multiple algorithms (GLM, random forests, LASSO, boosted trees, etc.)\n- Using **K-fold cross-validation** to evaluate and weight each algorithm\n- Producing an ensemble predictor with theoretical guarantees (an “oracle inequality”): asymptotically, SL performs nearly as well as the best algorithm in the library\n\nIn causal inference, we rarely care about prediction for its own sake, but good prediction of nuisance functions leads to **better causal effect estimation**.\n\n---\n\n## 2. Conceptual Overview of SuperLearner\n\nAt a high level, SuperLearner does the following:\n\n1. Pick a **set of candidate learners** (the library).\n2. Split the data into **K folds**.\n3. For each learner:\n   - Fit on K-1 folds (training data),\n   - Predict on the held-out fold (validation data).\n4. Collect **cross-validated predictions** for every observation and every learner.\n5. Fit a **metalearner** (often a linear regression) that finds the optimal weighted combination of the learners’ predictions to minimize a chosen **loss function** (e.g., mean squared error, negative log-likelihood).\n6. Refit each base learner on the full dataset.\n7. Use the metalearner and the refit base learners to form the final ensemble and obtain predictions for new data.\n\nThis is exactly the workflow illustrated in the “VISUAL GUIDE TO SUPERLEARNING” figure in the KHstats tutorial.\n\n---\n\n## 3. A Minimal Working Example\n\nWe’ll start with a simple prediction problem, then connect it back to causal inference later.\n\n### 3.1 Simulated data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'ggplot2' was built under R version 4.4.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'stringr' was built under R version 4.4.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.6.0\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(SuperLearner)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: nnls\nLoading required package: gam\nLoading required package: splines\nLoading required package: foreach\n\nAttaching package: 'foreach'\n\nThe following objects are masked from 'package:purrr':\n\n    accumulate, when\n\nLoaded gam 1.22-5\n\nSuper Learner\nVersion: 2.0-29\nPackage created on 2024-02-06\n```\n\n\n:::\n\n```{.r .cell-code}\nset.seed(7)\nn <- 2000\n\nobs <- tibble(\n  id = 1:n,\n  x1 = rnorm(n),\n  x2 = rbinom(n, 1, plogis(10 * x1)),\n  x3 = rbinom(n, 1, plogis(x1 * x2 + 0.5 * x2)),\n  x4 = rnorm(n, mean = x1 * x2, sd = 0.5 * x3),\n  y  = x1 + x2 + x2 * x3 + sin(x4) + rnorm(n, sd = 0.2)\n)\n\nglimpse(obs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 2,000\nColumns: 6\n$ id <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, …\n$ x1 <dbl> 2.287247161, -1.196771682, -0.694292510, -0.412292951, -0.970673341…\n$ x2 <int> 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1…\n$ x3 <int> 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1…\n$ x4 <dbl> 1.50283924, 0.04260947, 0.00000000, 0.00000000, 0.00000000, 1.07555…\n$ y  <dbl> 5.03669124, -1.13306036, -0.38284042, -0.28671230, -0.87539307, -0.…\n```\n\n\n:::\n:::\n\n\n\n\nThe outcome `y` is a nonlinear function of the covariates, with interactions and a sine term. GLMs will struggle here.\n\n---\n\n## 4. Using the `SuperLearner` Package\n\n### 4.1 Basic call\n\nWe’ll start with a small library for illustration.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n\nX <- obs %>% select(x1:x4) %>% as.data.frame()\nY <- obs$y\n\nSL.lib <- c(\"SL.glm\",      # simple GLM\n            \"SL.mean\",     # intercept-only\n            \"SL.earth\",    # multivariate adaptive regression splines (MARS)\n            \"SL.ranger\")   # random forest\n\nsl_fit <- SuperLearner(\n  Y = Y,\n  X = X,\n  newX = NULL,\n  family = gaussian(),\n  SL.library = SL.lib,\n  method = \"method.NNLS\",  # non-negative least squares metalearner\n  cvControl = list(V = 10L)\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required namespace: earth\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required namespace: ranger\n```\n\n\n:::\n\n```{.r .cell-code}\nsl_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  \nSuperLearner(Y = Y, X = X, newX = NULL, family = gaussian(), SL.library = SL.lib,  \n    method = \"method.NNLS\", cvControl = list(V = 10L)) \n\n                    Risk      Coef\nSL.glm_All    0.15038334 0.0000000\nSL.mean_All   4.52716718 0.0000000\nSL.earth_All  0.04408952 0.8593302\nSL.ranger_All 0.05735981 0.1406698\n```\n\n\n:::\n:::\n\n\n\n\nKey outputs:\n\n- `Risk`: cross-validated risk (e.g., MSE) for each learner\n- `Coef`: weight given to each learner in the ensemble\n\nThe learner with the smallest CV-risk often gets the largest weight, but SL can combine learners.\n\nWe can access the **ensemble predictions**:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(sl_fit$SL.predict)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]\n1  5.36960217\n2 -1.15651994\n3 -0.66557910\n4 -0.39653932\n5 -0.94879355\n6 -0.04451723\n```\n\n\n:::\n:::\n\n\n\n\nand predictions from individual learners:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(sl_fit$library.predict)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  SL.glm_All SL.mean_All SL.earth_All SL.ranger_All\n1  4.9119003    1.145784   5.44169210     4.9292158\n2 -0.9619611    1.145784  -1.14585410    -1.2216759\n3 -0.8907976    1.145784  -0.67326080    -0.6186528\n4 -0.6300543    1.145784  -0.40211488    -0.3624791\n5 -1.1463457    1.145784  -0.94947428    -0.9446351\n6 -0.1673960    1.145784  -0.01723667    -0.2111701\n```\n\n\n:::\n:::\n\n\n\n\n---\n\n## 5. Choosing a Loss Function: MSE vs Log-Likelihood vs AUC\n\nSuperLearner allows different **loss functions**, which define what we mean by “best” prediction.\n\n### 5.1 Mean Squared Error (MSE)\n\n- Default for `family = gaussian()`\n- Appropriate for **continuous outcomes** when we care about squared error:\n  $$ L(y, \\hat{y}) = (y - \\hat{y})^2 $$\n- Good when we want well-calibrated mean predictions\n\nExample (already used above): `method = \"method.NNLS\"` with `family = gaussian()`\n\n### 5.2 Negative Log-Likelihood (Binomial deviance)\n\n- Natural choice for **binary outcomes** when we care about probability calibration:\n  $$ L(y, \\hat{p}) = -[y \\log(\\hat{p}) + (1-y) \\log(1-\\hat{p})] $$\n- Strongly penalizes confident but wrong predictions\n- Recommended for:\n  - Outcome models (`Y` binary)\n  - Treatment models (`A` binary) in causal inference\n\nUse `method = \"method.NNloglik\"` with `family = binomial()`.\n\nExample:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# suppose Y is binary\nY_bin <- rbinom(n, 1, plogis(X$x1 + X$x2))\n\nsl_loglik <- SuperLearner(\n  Y = Y_bin,\n  X = X,\n  family = binomial(),\n  SL.library = c(\"SL.glm\", \"SL.mean\", \"SL.ranger\"),\n  method = \"method.NNloglik\"\n)\n\nsl_loglik\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  \nSuperLearner(Y = Y_bin, X = X, family = binomial(), SL.library = c(\"SL.glm\",  \n    \"SL.mean\", \"SL.ranger\"), method = \"method.NNloglik\") \n\n                   Risk      Coef\nSL.glm_All    0.5286216 0.8914129\nSL.mean_All   0.6818619 0.0000000\nSL.ranger_All 0.5537130 0.1085871\n```\n\n\n:::\n:::\n\n\n\n\n### 5.3 AUC / Rank Loss\n\n- For classification problems where the **ranking** of probabilities matters more than calibration\n- Common when choosing a threshold later (e.g., risk stratification)\n- SuperLearner implementation: `method = \"method.AUC\"`\n- Particularly useful when interested in discriminatory ability (e.g., disease risk scores)\n\nExample:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(cvAUC)   # required by method.AUC\n\nsl_auc <- SuperLearner(\n  Y = Y_bin,\n  X = X,\n  family = binomial(),\n  SL.library = c(\"SL.glm\", \"SL.mean\", \"SL.ranger\"),\n  method = \"method.AUC\"\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames, :\noptim didn't converge when estimating the super learner coefficients, reason\n(see ?optim): 52 optim message: ERROR: ABNORMAL_TERMINATION_IN_LNSRCH\n```\n\n\n:::\n\n```{.r .cell-code}\nsl_auc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  \nSuperLearner(Y = Y_bin, X = X, family = binomial(), SL.library = c(\"SL.glm\",  \n    \"SL.mean\", \"SL.ranger\"), method = \"method.AUC\") \n\n                   Risk         Coef\nSL.glm_All    0.1938743 0.9988292700\nSL.mean_All   0.5268196 0.0006672332\nSL.ranger_All 0.2104779 0.0005034968\n```\n\n\n:::\n:::\n\n\n\n\n### 5.4 Which loss should I choose?\n\n- **For outcome models in TMLE/AIPW:**  \n  - If binary → log-likelihood (binomial deviance)  \n  - If continuous → MSE or other appropriate distribution-based loss  \n- **For treatment / censoring models in causal inference:**  \n  - Typically log-likelihood (because we want accurate estimates of `P(A | W)`)\n- **For pure classification (no causal estimation):**  \n  - Consider AUC loss (`method.AUC`) if ranking is the priority\n\n---\n\n## 6. Interpreting CV-Risk and Coefficient Weights\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsl_fit$cvRisk\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   SL.glm_All   SL.mean_All  SL.earth_All SL.ranger_All \n   0.15038334    4.52716718    0.04408952    0.05735981 \n```\n\n\n:::\n\n```{.r .cell-code}\nsl_fit$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   SL.glm_All   SL.mean_All  SL.earth_All SL.ranger_All \n    0.0000000     0.0000000     0.8593302     0.1406698 \n```\n\n\n:::\n:::\n\n\n\n\n- `cvRisk` shows cross-validated risk for each algorithm\n- `coef` gives the ensemble weights (metalearner solution)\n\nAn algorithm might have:\n\n- Low risk → high weight  \n- High risk → weight near zero (effectively excluded)\n\nThis matches the demonstration in the Benkeser notes where GLM dominates mean-only models when predicting MI.  \n\n---\n\n## 7. Customizing the Library and Tuning Learners\n\n### 7.1 Adding tuned versions of a learner (e.g., Random Forest)\n\nWe can define bounded random forest variants with different hyperparameters.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSL.ranger_mtry3 <- function(..., mtry = 3) {\n  SL.ranger(..., mtry = mtry)\n}\n\nSL.ranger_mtry5 <- function(..., mtry = 5) {\n  SL.ranger(..., mtry = mtry)\n}\n\nSL.lib_tuned <- c(\"SL.glm\",\n                  \"SL.earth\",\n                  \"SL.ranger_mtry3\",\n                  \"SL.ranger_mtry5\")\n```\n:::\n\n\n\n\nThen run:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nsl_tuned <- SuperLearner(\n  Y = Y,\n  X = X,\n  family = gaussian(),\n  SL.library = SL.lib_tuned,\n  method = \"method.NNLS\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5 \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nError in ranger::ranger(`_Y` ~ ., data = cbind(`_Y` = Y, X), num.trees = num.trees,  : \n  User interrupt or internal error.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in FUN(X[[i]], ...): Error in algorithm SL.ranger_mtry5  on full data \n  The Algorithm will be removed from the Super Learner (i.e. given weight 0) \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in SuperLearner(Y = Y, X = X, family = gaussian(), SL.library =\nSL.lib_tuned, : Coefficients already 0 for all failed algorithm(s)\n```\n\n\n:::\n\n```{.r .cell-code}\nsl_tuned$cvRisk\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         SL.glm_All        SL.earth_All SL.ranger_mtry3_All SL.ranger_mtry5_All \n          0.1506218           0.0440174           0.0505784                  NA \n```\n\n\n:::\n\n```{.r .cell-code}\nsl_tuned$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         SL.glm_All        SL.earth_All SL.ranger_mtry3_All SL.ranger_mtry5_All \n            0.00000             0.73464             0.26536             0.00000 \n```\n\n\n:::\n:::\n\n\n\n\nSuperLearner automatically picks which tuned version (or combination) works best.\n\n---\n\n## 8. Cross-Validated SuperLearner (`CV.SuperLearner`)\n\n`CV.SuperLearner` adds an **outer layer** of cross-validation to evaluate SL versus its components objectively.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\ncv_sl <- CV.SuperLearner(\n  Y = Y,\n  X = X,\n  V = 5,\n  family = gaussian(),\n  SL.library = SL.lib\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required namespace: earth\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required namespace: ranger\n```\n\n\n:::\n\n```{.r .cell-code}\ncv_sl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  \nCV.SuperLearner(Y = Y, X = X, V = 5, family = gaussian(), SL.library = SL.lib) \n\n\n\nCross-validated predictions from the SuperLearner:  SL.predict \n\nCross-validated predictions from the discrete super learner (cross-validation selector):  discreteSL.predict \n\nWhich library algorithm was the discrete super learner:  whichDiscreteSL \n\nCross-validated prediction for all algorithms in the library:  library.predict\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(cv_sl)\n```\n\n::: {.cell-output-display}\n![](02-04-superlearner_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\nThe plot shows:\n\n- Cross-validated risks and confidence intervals for each learner\n- Performance of the discrete and continuous SuperLearner\n\nThis step is particularly helpful when you want to justify using SL rather than a single, simpler algorithm.\n\n---\n\n## 9. Integrating SuperLearner into Causal Inference\n\nSo far we focused on prediction. How does this relate to causal inference?\n\nFor a point-treatment ATE, a TMLE analysis might look like:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example skeleton (you will flesh this out later with your own data)\nlibrary(tmle)\n\ntmle_fit <- tmle(\n  Y = Y_bin,          # binary outcome\n  A = A,              # treatment\n  W = X,              # covariates\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\", \"SL.earth\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\", \"SL.mean\")\n)\n\ntmle_fit$estimates$ATE\n```\n:::\n\n\n\n\nHere:\n\n- `Q.SL.library` is used to estimate outcome regression `E[Y|A,W]`\n- `g.SL.library` is used to estimate propensity scores `P(A|W)`\n- TMLE combines these with targeting to produce an efficient, doubly robust estimate\n\nKey advantages:\n\n- You no longer need to guess the “right” model for Y or A  \n- You can include many flexible learners without overfitting (thanks to SL + CV)  \n- Your causal inference relies less on arbitrary parametric modeling choices  \n\n---\n\n## 10. Practical Tips for Using SuperLearner\n\n1. **Start with a modest but diverse library**  \n   - GLM (`SL.glm`)  \n   - Random forest (`SL.ranger` or `SL.randomForest`)  \n   - MARS (`SL.earth`)  \n   - Penalized regression (`SL.glmnet`)  \n\n2. **Pick loss functions that match your problem**  \n   - Binary → log-likelihood (for calibration) or AUC (for ranking)  \n   - Continuous → MSE  \n\n3. **Watch computation time**  \n   - SL is more expensive than a single GLM, especially with many learners and CV folds.\n\n4. **Use SL primarily on nuisance functions**  \n   - Don’t use SL to directly estimate the causal effect; instead, use SL to estimate `Q` and `g` and feed these into TMLE, AIPW, etc.\n\n5. **Inspect SL outputs**  \n   - Which learners are getting weight?  \n   - Are any learners consistently poor performers?  \n   - Do you need to adjust your library?  \n\n---\n\n## 11. Summary\n\nIn this chapter you learned\n\n- How SuperLearner combines multiple algorithms using cross-validation and a metalearner  \n- The role of loss functions (MSE, log-likelihood, AUC) and when to choose each  \n- How to implement SuperLearner in R, inspect CV-risk and weights, and customize the library  \n- How SuperLearner supports reliable causal inference by improving nuisance function estimation and integrating seamlessly with TMLE and other estimators  \n\nNext, we move to **Module 3**, where we tackle longitudinal data, dynamic treatment regimes, and modified treatment policies, often using SuperLearner as a core building block.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}