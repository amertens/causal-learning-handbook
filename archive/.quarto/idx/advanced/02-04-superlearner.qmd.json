{"title":"Chapter 2.4: SuperLearner and Machine Learning for Causal Inference","markdown":{"yaml":{"title":"Chapter 2.4: SuperLearner and Machine Learning for Causal Inference","format":"html"},"headingText":"Chapter 2.4: SuperLearner and Machine Learning for Causal Inference","containsRefs":false,"markdown":"\n\n*Flexible prediction to strengthen causal effect estimation*\n\nModern causal inference relies on estimating **nuisance functions** (outcome regressions and treatment / censoring mechanisms) that are as accurate as possible. If these models are mis-specified, even sophisticated causal estimators can be biased.\n\nRather than gambling on a single model (e.g., logistic regression), we can **stack** many candidate learners and let the data decide how to combine them. This is what **SuperLearner** does.\n\nIn this chapter you will learn:\n\n- The intuition behind SuperLearner (SL) and stacking  \n- How cross-validation is used to avoid overfitting  \n- How to build and interpret SuperLearner models in R  \n- When and why to choose different **loss functions** (MSE, log-likelihood, AUC)  \n- How to customize SL libraries and tune algorithms  \n- How SL integrates with TMLE and other causal estimators  \n\nThis chapter leans heavily on the excellent visual tutorial by Katherine Hoffman and the SuperLearner demo by David Benkeser (both provided as PDFs), and recasts them in a causal-inference focused Quarto format.\n\n---\n\n## 1. Why Use SuperLearner in Causal Inference?\n\nCausal estimators such as g-computation, IPTW, AIPW, and TMLE rely on estimating:\n\n- The **outcome regression**:  \n  \\( Q(W, A) = E[Y \\mid W, A] \\)\n\n- The **treatment (or censoring) mechanism**:  \n  \\( g(W) = P(A = 1 \\mid W) \\)\n\nIn traditional practice, both are often modeled with simple GLMs. This is dangerous when:\n\n- Relationships are nonlinear\n- Interactions are present\n- There are many covariates\n- We are unsure about which variables to include or in what functional form\n\nSuperLearner helps by:\n\n- Combining multiple algorithms (GLM, random forests, LASSO, boosted trees, etc.)\n- Using **K-fold cross-validation** to evaluate and weight each algorithm\n- Producing an ensemble predictor with theoretical guarantees (an “oracle inequality”): asymptotically, SL performs nearly as well as the best algorithm in the library\n\nIn causal inference, we rarely care about prediction for its own sake, but good prediction of nuisance functions leads to **better causal effect estimation**.\n\n---\n\n## 2. Conceptual Overview of SuperLearner\n\nAt a high level, SuperLearner does the following:\n\n1. Pick a **set of candidate learners** (the library).\n2. Split the data into **K folds**.\n3. For each learner:\n   - Fit on K-1 folds (training data),\n   - Predict on the held-out fold (validation data).\n4. Collect **cross-validated predictions** for every observation and every learner.\n5. Fit a **metalearner** (often a linear regression) that finds the optimal weighted combination of the learners’ predictions to minimize a chosen **loss function** (e.g., mean squared error, negative log-likelihood).\n6. Refit each base learner on the full dataset.\n7. Use the metalearner and the refit base learners to form the final ensemble and obtain predictions for new data.\n\nThis is exactly the workflow illustrated in the “VISUAL GUIDE TO SUPERLEARNING” figure in the KHstats tutorial.\n\n---\n\n## 3. A Minimal Working Example\n\nWe’ll start with a simple prediction problem, then connect it back to causal inference later.\n\n### 3.1 Simulated data\n\n```{r, cache=TRUE}\nlibrary(tidyverse)\nlibrary(SuperLearner)\n\nset.seed(7)\nn <- 2000\n\nobs <- tibble(\n  id = 1:n,\n  x1 = rnorm(n),\n  x2 = rbinom(n, 1, plogis(10 * x1)),\n  x3 = rbinom(n, 1, plogis(x1 * x2 + 0.5 * x2)),\n  x4 = rnorm(n, mean = x1 * x2, sd = 0.5 * x3),\n  y  = x1 + x2 + x2 * x3 + sin(x4) + rnorm(n, sd = 0.2)\n)\n\nglimpse(obs)\n```\n\nThe outcome `y` is a nonlinear function of the covariates, with interactions and a sine term. GLMs will struggle here.\n\n---\n\n## 4. Using the `SuperLearner` Package\n\n### 4.1 Basic call\n\nWe’ll start with a small library for illustration.\n\n```{r, cache=TRUE}\nset.seed(1234)\n\nX <- obs %>% select(x1:x4) %>% as.data.frame()\nY <- obs$y\n\nSL.lib <- c(\"SL.glm\",      # simple GLM\n            \"SL.mean\",     # intercept-only\n            \"SL.earth\",    # multivariate adaptive regression splines (MARS)\n            \"SL.ranger\")   # random forest\n\nsl_fit <- SuperLearner(\n  Y = Y,\n  X = X,\n  newX = NULL,\n  family = gaussian(),\n  SL.library = SL.lib,\n  method = \"method.NNLS\",  # non-negative least squares metalearner\n  cvControl = list(V = 10L)\n)\n\nsl_fit\n```\n\nKey outputs:\n\n- `Risk`: cross-validated risk (e.g., MSE) for each learner\n- `Coef`: weight given to each learner in the ensemble\n\nThe learner with the smallest CV-risk often gets the largest weight, but SL can combine learners.\n\nWe can access the **ensemble predictions**:\n\n```{r, cache=TRUE}\nhead(sl_fit$SL.predict)\n```\n\nand predictions from individual learners:\n\n```{r, cache=TRUE}\nhead(sl_fit$library.predict)\n```\n\n---\n\n## 5. Choosing a Loss Function: MSE vs Log-Likelihood vs AUC\n\nSuperLearner allows different **loss functions**, which define what we mean by “best” prediction.\n\n### 5.1 Mean Squared Error (MSE)\n\n- Default for `family = gaussian()`\n- Appropriate for **continuous outcomes** when we care about squared error:\n  $$ L(y, \\hat{y}) = (y - \\hat{y})^2 $$\n- Good when we want well-calibrated mean predictions\n\nExample (already used above): `method = \"method.NNLS\"` with `family = gaussian()`\n\n### 5.2 Negative Log-Likelihood (Binomial deviance)\n\n- Natural choice for **binary outcomes** when we care about probability calibration:\n  $$ L(y, \\hat{p}) = -[y \\log(\\hat{p}) + (1-y) \\log(1-\\hat{p})] $$\n- Strongly penalizes confident but wrong predictions\n- Recommended for:\n  - Outcome models (`Y` binary)\n  - Treatment models (`A` binary) in causal inference\n\nUse `method = \"method.NNloglik\"` with `family = binomial()`.\n\nExample:\n\n```{r, cache=TRUE}\n# suppose Y is binary\nY_bin <- rbinom(n, 1, plogis(X$x1 + X$x2))\n\nsl_loglik <- SuperLearner(\n  Y = Y_bin,\n  X = X,\n  family = binomial(),\n  SL.library = c(\"SL.glm\", \"SL.mean\", \"SL.ranger\"),\n  method = \"method.NNloglik\"\n)\n\nsl_loglik\n```\n\n### 5.3 AUC / Rank Loss\n\n- For classification problems where the **ranking** of probabilities matters more than calibration\n- Common when choosing a threshold later (e.g., risk stratification)\n- SuperLearner implementation: `method = \"method.AUC\"`\n- Particularly useful when interested in discriminatory ability (e.g., disease risk scores)\n\nExample:\n\n```{r, cache=TRUE}\nlibrary(cvAUC)   # required by method.AUC\n\nsl_auc <- SuperLearner(\n  Y = Y_bin,\n  X = X,\n  family = binomial(),\n  SL.library = c(\"SL.glm\", \"SL.mean\", \"SL.ranger\"),\n  method = \"method.AUC\"\n)\n\nsl_auc\n```\n\n### 5.4 Which loss should I choose?\n\n- **For outcome models in TMLE/AIPW:**  \n  - If binary → log-likelihood (binomial deviance)  \n  - If continuous → MSE or other appropriate distribution-based loss  \n- **For treatment / censoring models in causal inference:**  \n  - Typically log-likelihood (because we want accurate estimates of `P(A | W)`)\n- **For pure classification (no causal estimation):**  \n  - Consider AUC loss (`method.AUC`) if ranking is the priority\n\n---\n\n## 6. Interpreting CV-Risk and Coefficient Weights\n\n```{r, cache=TRUE}\nsl_fit$cvRisk\nsl_fit$coef\n```\n\n- `cvRisk` shows cross-validated risk for each algorithm\n- `coef` gives the ensemble weights (metalearner solution)\n\nAn algorithm might have:\n\n- Low risk → high weight  \n- High risk → weight near zero (effectively excluded)\n\nThis matches the demonstration in the Benkeser notes where GLM dominates mean-only models when predicting MI.  \n\n---\n\n## 7. Customizing the Library and Tuning Learners\n\n### 7.1 Adding tuned versions of a learner (e.g., Random Forest)\n\nWe can define bounded random forest variants with different hyperparameters.\n\n```{r, cache=TRUE}\nSL.ranger_mtry3 <- function(..., mtry = 3) {\n  SL.ranger(..., mtry = mtry)\n}\n\nSL.ranger_mtry5 <- function(..., mtry = 5) {\n  SL.ranger(..., mtry = mtry)\n}\n\nSL.lib_tuned <- c(\"SL.glm\",\n                  \"SL.earth\",\n                  \"SL.ranger_mtry3\",\n                  \"SL.ranger_mtry5\")\n```\n\nThen run:\n\n```{r, cache=TRUE}\nset.seed(123)\nsl_tuned <- SuperLearner(\n  Y = Y,\n  X = X,\n  family = gaussian(),\n  SL.library = SL.lib_tuned,\n  method = \"method.NNLS\"\n)\n\nsl_tuned$cvRisk\nsl_tuned$coef\n```\n\nSuperLearner automatically picks which tuned version (or combination) works best.\n\n---\n\n## 8. Cross-Validated SuperLearner (`CV.SuperLearner`)\n\n`CV.SuperLearner` adds an **outer layer** of cross-validation to evaluate SL versus its components objectively.\n\n```{r, cache=TRUE}\nset.seed(123)\ncv_sl <- CV.SuperLearner(\n  Y = Y,\n  X = X,\n  V = 5,\n  family = gaussian(),\n  SL.library = SL.lib\n)\n\ncv_sl\nplot(cv_sl)\n```\n\nThe plot shows:\n\n- Cross-validated risks and confidence intervals for each learner\n- Performance of the discrete and continuous SuperLearner\n\nThis step is particularly helpful when you want to justify using SL rather than a single, simpler algorithm.\n\n---\n\n## 9. Integrating SuperLearner into Causal Inference\n\nSo far we focused on prediction. How does this relate to causal inference?\n\nFor a point-treatment ATE, a TMLE analysis might look like:\n\n```{r, cache=TRUE, eval=F}\n# Example skeleton (you will flesh this out later with your own data)\nlibrary(tmle)\n\ntmle_fit <- tmle(\n  Y = Y_bin,          # binary outcome\n  A = A,              # treatment\n  W = X,              # covariates\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\", \"SL.earth\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\", \"SL.mean\")\n)\n\ntmle_fit$estimates$ATE\n```\n\nHere:\n\n- `Q.SL.library` is used to estimate outcome regression `E[Y|A,W]`\n- `g.SL.library` is used to estimate propensity scores `P(A|W)`\n- TMLE combines these with targeting to produce an efficient, doubly robust estimate\n\nKey advantages:\n\n- You no longer need to guess the “right” model for Y or A  \n- You can include many flexible learners without overfitting (thanks to SL + CV)  \n- Your causal inference relies less on arbitrary parametric modeling choices  \n\n---\n\n## 10. Practical Tips for Using SuperLearner\n\n1. **Start with a modest but diverse library**  \n   - GLM (`SL.glm`)  \n   - Random forest (`SL.ranger` or `SL.randomForest`)  \n   - MARS (`SL.earth`)  \n   - Penalized regression (`SL.glmnet`)  \n\n2. **Pick loss functions that match your problem**  \n   - Binary → log-likelihood (for calibration) or AUC (for ranking)  \n   - Continuous → MSE  \n\n3. **Watch computation time**  \n   - SL is more expensive than a single GLM, especially with many learners and CV folds.\n\n4. **Use SL primarily on nuisance functions**  \n   - Don’t use SL to directly estimate the causal effect; instead, use SL to estimate `Q` and `g` and feed these into TMLE, AIPW, etc.\n\n5. **Inspect SL outputs**  \n   - Which learners are getting weight?  \n   - Are any learners consistently poor performers?  \n   - Do you need to adjust your library?  \n\n---\n\n## 11. Summary\n\nIn this chapter you learned\n\n- How SuperLearner combines multiple algorithms using cross-validation and a metalearner  \n- The role of loss functions (MSE, log-likelihood, AUC) and when to choose each  \n- How to implement SuperLearner in R, inspect CV-risk and weights, and customize the library  \n- How SuperLearner supports reliable causal inference by improving nuisance function estimation and integrating seamlessly with TMLE and other estimators  \n\nNext, we move to **Module 3**, where we tackle longitudinal data, dynamic treatment regimes, and modified treatment policies, often using SuperLearner as a core building block.\n","srcMarkdownNoYaml":"\n\n# Chapter 2.4: SuperLearner and Machine Learning for Causal Inference  \n*Flexible prediction to strengthen causal effect estimation*\n\nModern causal inference relies on estimating **nuisance functions** (outcome regressions and treatment / censoring mechanisms) that are as accurate as possible. If these models are mis-specified, even sophisticated causal estimators can be biased.\n\nRather than gambling on a single model (e.g., logistic regression), we can **stack** many candidate learners and let the data decide how to combine them. This is what **SuperLearner** does.\n\nIn this chapter you will learn:\n\n- The intuition behind SuperLearner (SL) and stacking  \n- How cross-validation is used to avoid overfitting  \n- How to build and interpret SuperLearner models in R  \n- When and why to choose different **loss functions** (MSE, log-likelihood, AUC)  \n- How to customize SL libraries and tune algorithms  \n- How SL integrates with TMLE and other causal estimators  \n\nThis chapter leans heavily on the excellent visual tutorial by Katherine Hoffman and the SuperLearner demo by David Benkeser (both provided as PDFs), and recasts them in a causal-inference focused Quarto format.\n\n---\n\n## 1. Why Use SuperLearner in Causal Inference?\n\nCausal estimators such as g-computation, IPTW, AIPW, and TMLE rely on estimating:\n\n- The **outcome regression**:  \n  \\( Q(W, A) = E[Y \\mid W, A] \\)\n\n- The **treatment (or censoring) mechanism**:  \n  \\( g(W) = P(A = 1 \\mid W) \\)\n\nIn traditional practice, both are often modeled with simple GLMs. This is dangerous when:\n\n- Relationships are nonlinear\n- Interactions are present\n- There are many covariates\n- We are unsure about which variables to include or in what functional form\n\nSuperLearner helps by:\n\n- Combining multiple algorithms (GLM, random forests, LASSO, boosted trees, etc.)\n- Using **K-fold cross-validation** to evaluate and weight each algorithm\n- Producing an ensemble predictor with theoretical guarantees (an “oracle inequality”): asymptotically, SL performs nearly as well as the best algorithm in the library\n\nIn causal inference, we rarely care about prediction for its own sake, but good prediction of nuisance functions leads to **better causal effect estimation**.\n\n---\n\n## 2. Conceptual Overview of SuperLearner\n\nAt a high level, SuperLearner does the following:\n\n1. Pick a **set of candidate learners** (the library).\n2. Split the data into **K folds**.\n3. For each learner:\n   - Fit on K-1 folds (training data),\n   - Predict on the held-out fold (validation data).\n4. Collect **cross-validated predictions** for every observation and every learner.\n5. Fit a **metalearner** (often a linear regression) that finds the optimal weighted combination of the learners’ predictions to minimize a chosen **loss function** (e.g., mean squared error, negative log-likelihood).\n6. Refit each base learner on the full dataset.\n7. Use the metalearner and the refit base learners to form the final ensemble and obtain predictions for new data.\n\nThis is exactly the workflow illustrated in the “VISUAL GUIDE TO SUPERLEARNING” figure in the KHstats tutorial.\n\n---\n\n## 3. A Minimal Working Example\n\nWe’ll start with a simple prediction problem, then connect it back to causal inference later.\n\n### 3.1 Simulated data\n\n```{r, cache=TRUE}\nlibrary(tidyverse)\nlibrary(SuperLearner)\n\nset.seed(7)\nn <- 2000\n\nobs <- tibble(\n  id = 1:n,\n  x1 = rnorm(n),\n  x2 = rbinom(n, 1, plogis(10 * x1)),\n  x3 = rbinom(n, 1, plogis(x1 * x2 + 0.5 * x2)),\n  x4 = rnorm(n, mean = x1 * x2, sd = 0.5 * x3),\n  y  = x1 + x2 + x2 * x3 + sin(x4) + rnorm(n, sd = 0.2)\n)\n\nglimpse(obs)\n```\n\nThe outcome `y` is a nonlinear function of the covariates, with interactions and a sine term. GLMs will struggle here.\n\n---\n\n## 4. Using the `SuperLearner` Package\n\n### 4.1 Basic call\n\nWe’ll start with a small library for illustration.\n\n```{r, cache=TRUE}\nset.seed(1234)\n\nX <- obs %>% select(x1:x4) %>% as.data.frame()\nY <- obs$y\n\nSL.lib <- c(\"SL.glm\",      # simple GLM\n            \"SL.mean\",     # intercept-only\n            \"SL.earth\",    # multivariate adaptive regression splines (MARS)\n            \"SL.ranger\")   # random forest\n\nsl_fit <- SuperLearner(\n  Y = Y,\n  X = X,\n  newX = NULL,\n  family = gaussian(),\n  SL.library = SL.lib,\n  method = \"method.NNLS\",  # non-negative least squares metalearner\n  cvControl = list(V = 10L)\n)\n\nsl_fit\n```\n\nKey outputs:\n\n- `Risk`: cross-validated risk (e.g., MSE) for each learner\n- `Coef`: weight given to each learner in the ensemble\n\nThe learner with the smallest CV-risk often gets the largest weight, but SL can combine learners.\n\nWe can access the **ensemble predictions**:\n\n```{r, cache=TRUE}\nhead(sl_fit$SL.predict)\n```\n\nand predictions from individual learners:\n\n```{r, cache=TRUE}\nhead(sl_fit$library.predict)\n```\n\n---\n\n## 5. Choosing a Loss Function: MSE vs Log-Likelihood vs AUC\n\nSuperLearner allows different **loss functions**, which define what we mean by “best” prediction.\n\n### 5.1 Mean Squared Error (MSE)\n\n- Default for `family = gaussian()`\n- Appropriate for **continuous outcomes** when we care about squared error:\n  $$ L(y, \\hat{y}) = (y - \\hat{y})^2 $$\n- Good when we want well-calibrated mean predictions\n\nExample (already used above): `method = \"method.NNLS\"` with `family = gaussian()`\n\n### 5.2 Negative Log-Likelihood (Binomial deviance)\n\n- Natural choice for **binary outcomes** when we care about probability calibration:\n  $$ L(y, \\hat{p}) = -[y \\log(\\hat{p}) + (1-y) \\log(1-\\hat{p})] $$\n- Strongly penalizes confident but wrong predictions\n- Recommended for:\n  - Outcome models (`Y` binary)\n  - Treatment models (`A` binary) in causal inference\n\nUse `method = \"method.NNloglik\"` with `family = binomial()`.\n\nExample:\n\n```{r, cache=TRUE}\n# suppose Y is binary\nY_bin <- rbinom(n, 1, plogis(X$x1 + X$x2))\n\nsl_loglik <- SuperLearner(\n  Y = Y_bin,\n  X = X,\n  family = binomial(),\n  SL.library = c(\"SL.glm\", \"SL.mean\", \"SL.ranger\"),\n  method = \"method.NNloglik\"\n)\n\nsl_loglik\n```\n\n### 5.3 AUC / Rank Loss\n\n- For classification problems where the **ranking** of probabilities matters more than calibration\n- Common when choosing a threshold later (e.g., risk stratification)\n- SuperLearner implementation: `method = \"method.AUC\"`\n- Particularly useful when interested in discriminatory ability (e.g., disease risk scores)\n\nExample:\n\n```{r, cache=TRUE}\nlibrary(cvAUC)   # required by method.AUC\n\nsl_auc <- SuperLearner(\n  Y = Y_bin,\n  X = X,\n  family = binomial(),\n  SL.library = c(\"SL.glm\", \"SL.mean\", \"SL.ranger\"),\n  method = \"method.AUC\"\n)\n\nsl_auc\n```\n\n### 5.4 Which loss should I choose?\n\n- **For outcome models in TMLE/AIPW:**  \n  - If binary → log-likelihood (binomial deviance)  \n  - If continuous → MSE or other appropriate distribution-based loss  \n- **For treatment / censoring models in causal inference:**  \n  - Typically log-likelihood (because we want accurate estimates of `P(A | W)`)\n- **For pure classification (no causal estimation):**  \n  - Consider AUC loss (`method.AUC`) if ranking is the priority\n\n---\n\n## 6. Interpreting CV-Risk and Coefficient Weights\n\n```{r, cache=TRUE}\nsl_fit$cvRisk\nsl_fit$coef\n```\n\n- `cvRisk` shows cross-validated risk for each algorithm\n- `coef` gives the ensemble weights (metalearner solution)\n\nAn algorithm might have:\n\n- Low risk → high weight  \n- High risk → weight near zero (effectively excluded)\n\nThis matches the demonstration in the Benkeser notes where GLM dominates mean-only models when predicting MI.  \n\n---\n\n## 7. Customizing the Library and Tuning Learners\n\n### 7.1 Adding tuned versions of a learner (e.g., Random Forest)\n\nWe can define bounded random forest variants with different hyperparameters.\n\n```{r, cache=TRUE}\nSL.ranger_mtry3 <- function(..., mtry = 3) {\n  SL.ranger(..., mtry = mtry)\n}\n\nSL.ranger_mtry5 <- function(..., mtry = 5) {\n  SL.ranger(..., mtry = mtry)\n}\n\nSL.lib_tuned <- c(\"SL.glm\",\n                  \"SL.earth\",\n                  \"SL.ranger_mtry3\",\n                  \"SL.ranger_mtry5\")\n```\n\nThen run:\n\n```{r, cache=TRUE}\nset.seed(123)\nsl_tuned <- SuperLearner(\n  Y = Y,\n  X = X,\n  family = gaussian(),\n  SL.library = SL.lib_tuned,\n  method = \"method.NNLS\"\n)\n\nsl_tuned$cvRisk\nsl_tuned$coef\n```\n\nSuperLearner automatically picks which tuned version (or combination) works best.\n\n---\n\n## 8. Cross-Validated SuperLearner (`CV.SuperLearner`)\n\n`CV.SuperLearner` adds an **outer layer** of cross-validation to evaluate SL versus its components objectively.\n\n```{r, cache=TRUE}\nset.seed(123)\ncv_sl <- CV.SuperLearner(\n  Y = Y,\n  X = X,\n  V = 5,\n  family = gaussian(),\n  SL.library = SL.lib\n)\n\ncv_sl\nplot(cv_sl)\n```\n\nThe plot shows:\n\n- Cross-validated risks and confidence intervals for each learner\n- Performance of the discrete and continuous SuperLearner\n\nThis step is particularly helpful when you want to justify using SL rather than a single, simpler algorithm.\n\n---\n\n## 9. Integrating SuperLearner into Causal Inference\n\nSo far we focused on prediction. How does this relate to causal inference?\n\nFor a point-treatment ATE, a TMLE analysis might look like:\n\n```{r, cache=TRUE, eval=F}\n# Example skeleton (you will flesh this out later with your own data)\nlibrary(tmle)\n\ntmle_fit <- tmle(\n  Y = Y_bin,          # binary outcome\n  A = A,              # treatment\n  W = X,              # covariates\n  family = \"binomial\",\n  Q.SL.library = c(\"SL.glm\", \"SL.ranger\", \"SL.earth\"),\n  g.SL.library = c(\"SL.glm\", \"SL.ranger\", \"SL.mean\")\n)\n\ntmle_fit$estimates$ATE\n```\n\nHere:\n\n- `Q.SL.library` is used to estimate outcome regression `E[Y|A,W]`\n- `g.SL.library` is used to estimate propensity scores `P(A|W)`\n- TMLE combines these with targeting to produce an efficient, doubly robust estimate\n\nKey advantages:\n\n- You no longer need to guess the “right” model for Y or A  \n- You can include many flexible learners without overfitting (thanks to SL + CV)  \n- Your causal inference relies less on arbitrary parametric modeling choices  \n\n---\n\n## 10. Practical Tips for Using SuperLearner\n\n1. **Start with a modest but diverse library**  \n   - GLM (`SL.glm`)  \n   - Random forest (`SL.ranger` or `SL.randomForest`)  \n   - MARS (`SL.earth`)  \n   - Penalized regression (`SL.glmnet`)  \n\n2. **Pick loss functions that match your problem**  \n   - Binary → log-likelihood (for calibration) or AUC (for ranking)  \n   - Continuous → MSE  \n\n3. **Watch computation time**  \n   - SL is more expensive than a single GLM, especially with many learners and CV folds.\n\n4. **Use SL primarily on nuisance functions**  \n   - Don’t use SL to directly estimate the causal effect; instead, use SL to estimate `Q` and `g` and feed these into TMLE, AIPW, etc.\n\n5. **Inspect SL outputs**  \n   - Which learners are getting weight?  \n   - Are any learners consistently poor performers?  \n   - Do you need to adjust your library?  \n\n---\n\n## 11. Summary\n\nIn this chapter you learned\n\n- How SuperLearner combines multiple algorithms using cross-validation and a metalearner  \n- The role of loss functions (MSE, log-likelihood, AUC) and when to choose each  \n- How to implement SuperLearner in R, inspect CV-risk and weights, and customize the library  \n- How SuperLearner supports reliable causal inference by improving nuisance function estimation and integrating seamlessly with TMLE and other estimators  \n\nNext, we move to **Module 3**, where we tackle longitudinal data, dynamic treatment regimes, and modified treatment policies, often using SuperLearner as a core building block.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"02-04-superlearner.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","theme":"cosmo","smooth-scroll":true,"title":"Chapter 2.4: SuperLearner and Machine Learning for Causal Inference","sidebar":{"style":"docked","search":true,"contents":[{"text":"Overview","href":"index.qmd"},{"section":"Advanced topics","contents":[{"text":"1.1 Regression vs Causal Inference","href":"01-01-regression-vs-causal.qmd"},{"text":"1.2 The Causal Roadmap in detail","href":"01-02-causal-roadmap.qmd"},{"text":"1.3 Identification and Estimands","href":"01-03-identification-estimands.qmd"},{"text":"2.1 G-computation","href":"02-01-gcomputation.qmd"},{"text":"2.2 Inverse Probability of Treatment Weighting (IPTW)","href":"02-02-iptw.qmd"},{"text":"2.3 Doubly Robust Estimation and Targeted Maximum Likelihood Estimation (TMLE)","href":"02-03-doubly-robust-tmle.qmd"},{"text":"2.4 Super Learner","href":"02-04-superlearner.qmd"},{"text":"3.3 Longitudinal Case Study","href":"03-03-longitudinal-case-study.qmd"},{"text":"3.4 Effect Modification","href":"03-04-effect-modification.qmd"},{"text":"3.5 Advanced Diagnostics","href":"03-05-advanced-diagnostics.qmd"},{"text":"3.6 RWD meets RCT: Hybrid Designs","href":"03-06-rwd-meets-rct-hybrid-designs.qmd"},{"text":"3.7 Longitudinal Time-Dependent Confounding","href":"03-07-longitudinal-td-confounding.qmd"},{"text":"3.8 TMLE in the Clean Room Design","href":"03-08-tmle-clean-room.qmd"},{"text":"Covariate Adjustment IN RCTs using TMLE","href":"chapter_covariate_adjustment_tmle.qmd"},{"text":"Common Pitfalls in Causal Inference","href":"common-pitfalls.qmd"}]}]}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}