
@book{van_der_laan_targeted_2011,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Targeted {Learning}: {Causal} {Inference} for {Observational} and {Experimental} {Data}},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-1-4419-9781-4 978-1-4419-9782-1},
	shorttitle = {Targeted {Learning}},
	url = {https://link.springer.com/10.1007/978-1-4419-9782-1},
	language = {en},
	urldate = {2024-05-10},
	publisher = {Springer},
	author = {Van Der Laan, Mark J. and Rose, Sherri},
	year = {2011},
	doi = {10.1007/978-1-4419-9782-1},
	keywords = {Causal inference, High-dimensional and complex data, Nonparametric and semiparametric statistics, Observational studies, Prediction, Randomized controlled trials, Super (machine) learning, Targeted maximum likelihood estimation, Time-dependent confounding},
	file = {Full Text PDF:/Users/zoranakato/Zotero/storage/LJNNDSM6/Van Der Laan and Rose - 2011 - Targeted Learning Causal Inference for Observatio.pdf:application/pdf},
}

@article{dang_causal_2022,
	title = {A causal roadmap for generating high-quality real-world evidence},
	volume = {7},
	issn = {2059-8661},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC10603361/},
	doi = {10.1017/cts.2023.635},
	abstract = {Increasing emphasis on the use of real-world evidence (RWE) to support clinical policy and regulatory decision-making has led to a proliferation of guidance, advice, and frameworks from regulatory agencies, academia, professional societies, and industry. A broad spectrum of studies use real-world data (RWD) to produce RWE, ranging from randomized trials with outcomes assessed using RWD to fully observational studies. Yet, many proposals for generating RWE lack sufficient detail, and many analyses of RWD suffer from implausible assumptions, other methodological flaws, or inappropriate interpretations. The Causal Roadmap is an explicit, itemized, iterative process that guides investigators to prespecify study design and analysis plans; it addresses a wide range of guidance within a single framework. By supporting the transparent evaluation of causal assumptions and facilitating objective comparisons of design and analysis choices based on prespecified criteria, the Roadmap can help investigators to evaluate the quality of evidence that a given study is likely to produce, specify a study to generate high-quality RWE, and communicate effectively with regulatory agencies and other stakeholders. This paper aims to disseminate and extend the Causal Roadmap framework for use by clinical and translational researchers; three companion papers demonstrate applications of the Causal Roadmap for specific use cases.},
	number = {1},
	urldate = {2025-12-14},
	journal = {Journal of Clinical and Translational Science},
	author = {Dang, Lauren E. and Gruber, Susan and Lee, Hana and Dahabreh, Issa J. and Stuart, Elizabeth A. and Williamson, Brian D. and Wyss, Richard and Díaz, Iván and Ghosh, Debashis and Kıcıman, Emre and Alemayehu, Demissie and Hoffman, Katherine L. and Vossen, Carla Y. and Huml, Raymond A. and Ravn, Henrik and Kvist, Kajsa and Pratley, Richard and Shih, Mei-Chiung and Pennello, Gene and Martin, David and Waddy, Salina P. and Barr, Charles E. and Akacha, Mouna and Buse, John B. and van der Laan, Mark and Petersen, Maya},
	pmid = {37900353},
	pmcid = {PMC10603361},
	pages = {e212},
	file = {Full Text:/Users/zoranakato/Zotero/storage/GIC2FYZX/Dang et al. - A causal roadmap for generating high-quality real-.pdf:application/pdf},
}

@misc{ich_e9r1_2021,
	title = {E9({R1}) {Statistical} {Principles} for {Clinical} {Trials}: {Addendum}: {Estimands} and {Sensitivity} {Analysis} in {Clinical} {Trials}},
	shorttitle = {E9({R1}) {Statistical} {Principles} for {Clinical} {Trials}},
	url = {https://www.fda.gov/regulatory-information/search-fda-guidance-documents/e9r1-statistical-principles-clinical-trials-addendum-estimands-and-sensitivity-analysis-clinical},
	abstract = {International Conference on Harmonisation - Efficacy},
	language = {en},
	urldate = {2025-12-15},
	author = {Research, Center for Drug Evaluation and},
	month = may,
	year = {2021},
	note = {Publisher: FDA},
	file = {Snapshot:/Users/zoranakato/Zotero/storage/W9JS98PB/e9r1-statistical-principles-clinical-trials-addendum-estimands-and-sensitivity-analysis-clinica.html:text/html},
}

@article{phillips_practical_2023,
	title = {Practical considerations for specifying a super learner},
	volume = {52},
	issn = {1464-3685},
	doi = {10.1093/ije/dyad023},
	abstract = {Common tasks encountered in epidemiology, including disease incidence estimation and causal inference, rely on predictive modelling. Constructing a predictive model can be thought of as learning a prediction function (a function that takes as input covariate data and outputs a predicted value). Many strategies for learning prediction functions from data (learners) are available, from parametric regressions to machine learning algorithms. It can be challenging to choose a learner, as it is impossible to know in advance which one is the most suitable for a particular dataset and prediction task. The super learner (SL) is an algorithm that alleviates concerns over selecting the one 'right' learner by providing the freedom to consider many, such as those recommended by collaborators, used in related research or specified by subject-matter experts. Also known as stacking, SL is an entirely prespecified and flexible approach for predictive modelling. To ensure the SL is well specified for learning the desired prediction function, the analyst does need to make a few important choices. In this educational article, we provide step-by-step guidelines for making these decisions, walking the reader through each of them and providing intuition along the way. In doing so, we aim to empower the analyst to tailor the SL specification to their prediction task, thereby ensuring their SL performs as well as possible. A flowchart provides a concise, easy-to-follow summary of key suggestions and heuristics, based on our accumulated experience and guided by SL optimality theory.},
	language = {eng},
	number = {4},
	journal = {International Journal of Epidemiology},
	author = {Phillips, Rachael V. and van der Laan, Mark J. and Lee, Hana and Gruber, Susan},
	month = aug,
	year = {2023},
	pmid = {36905602},
	keywords = {Algorithms, causal inference, disease epidemiology, ensemble machine learning, health outcomes, Humans, Machine Learning, model validation, prediction, risk assessment, stacking, statistical data analysis, Super learner},
	pages = {1276--1285},
	file = {Full Text:/Users/zoranakato/Zotero/storage/QD8BHPV7/Phillips et al. - 2023 - Practical considerations for specifying a super le.pdf:application/pdf},
}

@article{van_der_laan_super_2007,
	title = {Super learner},
	volume = {6},
	issn = {1544-6115},
	doi = {10.2202/1544-6115.1309},
	abstract = {When trying to learn a model for the prediction of an outcome given a set of covariates, a statistician has many estimation procedures in their toolbox. A few examples of these candidate learners are: least squares, least angle regression, random forests, and spline regression. Previous articles (van der Laan and Dudoit (2003); van der Laan et al. (2006); Sinisi et al. (2007)) theoretically validated the use of cross validation to select an optimal learner among many candidate learners. Motivated by this use of cross validation, we propose a new prediction method for creating a weighted combination of many candidate learners to build the super learner. This article proposes a fast algorithm for constructing a super learner in prediction which uses V-fold cross-validation to select weights to combine an initial set of candidate learners. In addition, this paper contains a practical demonstration of the adaptivity of this so called super learner to various true data generating distributions. This approach for construction of a super learner generalizes to any parameter which can be defined as a minimizer of a loss function.},
	language = {eng},
	journal = {Statistical Applications in Genetics and Molecular Biology},
	author = {van der Laan, Mark J. and Polley, Eric C. and Hubbard, Alan E.},
	year = {2007},
	pmid = {17910531},
	keywords = {Algorithms, Artificial Intelligence, Models, Statistical},
	pages = {Article25},
}

@article{hernan_using_2016,
	title = {Using {Big} {Data} to {Emulate} a {Target} {Trial} {When} a {Randomized} {Trial} {Is} {Not} {Available}},
	volume = {183},
	issn = {0002-9262},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC4832051/},
	doi = {10.1093/aje/kwv254},
	abstract = {Ideally, questions about comparative effectiveness or safety would be answered using an appropriately designed and conducted randomized experiment. When we cannot conduct a randomized experiment, we analyze observational data. Causal inference from large observational databases (big data) can be viewed as an attempt to emulate a randomized experiment—the target experiment or target trial—that would answer the question of interest. When the goal is to guide decisions among several strategies, causal analyses of observational data need to be evaluated with respect to how well they emulate a particular target trial. We outline a framework for comparative effectiveness research using big data that makes the target trial explicit. This framework channels counterfactual theory for comparing the effects of sustained treatment strategies, organizes analytic approaches, provides a structured process for the criticism of observational studies, and helps avoid common methodologic pitfalls.},
	number = {8},
	urldate = {2025-12-15},
	journal = {American Journal of Epidemiology},
	author = {Hernán, Miguel A. and Robins, James M.},
	month = apr,
	year = {2016},
	pmid = {26994063},
	pmcid = {PMC4832051},
	pages = {758--764},
	file = {Full Text:/Users/zoranakato/Zotero/storage/WKTHBXKG/Hernán and Robins - 2016 - Using Big Data to Emulate a Target Trial When a Ra.pdf:application/pdf},
}
