---
title: "Chapter 3.3: Case Study – Real-World Application in Longitudinal Analysis"
format: html
---

# Chapter 3.3  
## Case Study: Real-World Longitudinal Causal Inference Using Targeted Learning

This chapter walks through a **complete applied example** of longitudinal causal inference using real-world data concepts.  
The goal is to help you translate the earlier theoretical chapters into a practical analysis workflow.

We use the motivating real-world question:

> **What is the 3-year cardiovascular risk difference if all eligible patients initiating osteoporosis therapy remained on denosumab vs. zoledronic acid under full adherence?**

Although we cannot use the proprietary data from the actual studies, this chapter recreates a *plausible longitudinal structure* and walks you through the entire pipeline:

- Constructing the longitudinal dataset  
- Defining the causal question, intervention, and estimand  
- Identifying longitudinal confounders and censoring  
- Using SuperLearner for nuisance function estimation  
- Applying TMLE or LMTP for longitudinal causal effects  
- Interpreting the results in a regulatory and clinical context  

This chapter integrates lessons from Chapter 1 (causal roadmap) and Chapter 2 (estimation).

---

# 1. The Clinical and Real-World Context

Osteoporosis treatments such as **denosumab** and **zoledronic acid** are widely used in postmenopausal women.  
Observational data registries show:

- Frequent **treatment interruptions**  
- **Switching** between agents  
- **Loss to follow-up**  
- Time-varying covariates (e.g., frailty, kidney function, fall risk)

These complexities make longitudinal causal inference necessary.

A naive Cox model adjusting for baseline covariates would **fail** to address:

- Time-varying confounding affected by prior treatment  
- Informative censoring (patients at higher risk may discontinue)  
- Treatment switching  
- Differing follow-up time  
- Positivity issues  

We instead use **Longitudinal TMLE** or **LMTP** to estimate causal effects under hypothetical longitudinal interventions.

---

# 2. The Longitudinal Data Structure

Assume patient \(i\) is followed monthly for 36 months.

The canonical structure:

\[
O_i = (W_i, A_{i0}, L_{i1}, A_{i1}, C_{i1}, L_{i2}, A_{i2}, C_{i2}, \dots, Y_i)
\]

Where:

- **W**: baseline covariates (age, CVD history, frailty)
- **A_t**: treatment status at time \(t\) (1 = denosumab, 0 = zoledronic acid)
- **L_t**: time-varying covariates (kidney function, fracture risk, comorbidities)
- **C_t**: censoring/loss to follow-up (1 = censored)
- **Y**: cardiovascular event by 36 months

We simulate a small example below.

---

# 3. Simulation of a Plausible Longitudinal Dataset

```{r}
library(tidyverse)

set.seed(2027)
n <- 2000
Tmax <- 6   # six timepoints for illustration

# Baseline
W_age  <- rnorm(n, 75, 6)
W_cvd  <- rbinom(n, 1, plogis(0.12 * (W_age - 70)))

# Initial treatment
A0 <- rbinom(n, 1, plogis(-1 + 0.1*(W_age - 70) + 1.4*W_cvd))

# Containers
L <- matrix(NA, n, Tmax)
A <- matrix(NA, n, Tmax)
C <- matrix(0, n, Tmax)

A[,1] <- A0

# Generate longitudinal covariates & treatment
for (t in 1:Tmax) {
  # time-varying comorbidity
  L[,t] <- rnorm(n, mean = 0.3*W_age + 1.2*W_cvd + 0.5*A[,max(1,t-1)], sd = 1)

  # treatment switching
  A[,t] <- rbinom(n, 1, plogis(-2 + 0.3*L[,t] + 0.8*A[,max(1,t-1)]))

  # censoring
  C[,t] <- rbinom(n, 1, plogis(-4 + 0.2*L[,t] + 0.4*A[,t]))
}

# Outcome depends on full history
Y <- rbinom(n, 1, plogis(-3 + 0.5*rowMeans(A) + 0.1*rowMeans(L)))

dat_long <- tibble(
  id = 1:n,
  age = W_age,
  cvd = W_cvd,
  Y = Y
)

# Expand wide data into long format (illustrative)
for (t in 1:Tmax) {
  dat_long[[paste0("L",t)]] <- L[,t]
  dat_long[[paste0("A",t)]] <- A[,t]
  dat_long[[paste0("C",t)]] <- C[,t]
}

glimpse(dat_long)
```

---

# 4. Defining the Longitudinal Causal Question

Our target estimand:

> **What is the 36-month cardiovascular event risk if everyone remained continuously on denosumab vs continuously on zoledronic acid?**

This is a **static treatment regime**:

\[
d_1: A_t = 1 \ orall t  
\]
\[
d_0: A_t = 0 \ orall t
\]

Equivalent to a “perfect adherence” scenario.

We can also define:

- **Dynamic regimes** (treatment depends on predicted fracture risk)
- **Stochastic regimes** (shift interventions on treatment probabilities)

But for now we use static interventions.

---

# 5. Identification: Assumptions for Longitudinal Effects

To identify the causal effect using observed data, we require:

- **Sequential exchangeability:**  
  \( Y^{\bar a} \perp A_t \mid \bar L_t, \bar A_{t-1}, W \)
- **Sequential positivity:**  
  Each treatment is possible at each time for every covariate history
- **Consistency:**  
  Observed outcomes correspond to the regime actually followed

These are the longitudinal analogues of the point-treatment assumptions.

---

# 6. Using LMTP for Longitudinal Interventions

The **lmtp** package is a modern tool for estimating longitudinal modified treatment policies (MTPs).  
It supports:

- Static interventions  
- Dynamic rules  
- Stochastic shifts  
- Censoring adjustments  

Here we implement:

```{r, eval=F}
# Example skeleton 
 library(lmtp)

result <- lmtp_tmle(
  data = dat_long,
  trt = paste0("A", 1:Tmax),
  outcome = "Y",
  time = 1:Tmax,
  shift = function(data, trt) { rep(1, length(trt)) },  # always-denosumab
  learners_outcome = list(SL.glm, SL.ranger),
  learners_trt = list(SL.glm, SL.ranger),
  folds = 5
)

result
```

This gives a TMLE estimate of:

- Risk under always-denosumab  
- Risk under always-ZA  
- Risk difference  
- Confidence intervals  

---

# 7. Using Longitudinal TMLE (Manual Concept)

Longitudinal TMLE proceeds:

1. Start at final timepoint  
2. Estimate Q-models backward in time  
3. Estimate g-models for each treatment and censoring event  
4. Apply sequential targeting  
5. Compute counterfactual outcomes  

This is mathematically complex but **automated by LMTP** in most real applications.

---

# 8. Interpretation of Results

Assume hypothetical results:

| Regime | Estimated 36-mo risk |
|--------|----------------------|
| Always denosumab | 0.051 |
| Always ZA        | 0.055 |

ATE (risk difference):

```
-0.004 (0.4 percentage points lower cardiovascular risk)
```

Interpretation:

- The estimated cardiovascular risk difference between continuous denosumab vs continuous ZA is small.  
- Both therapies appear similar in risk, consistent with findings in published RWE studies.  
- Subgroup and sensitivity analyses may explore heterogeneity and robustness.

---

# 9. Sensitivity & Diagnostic Considerations

### 9.1 Positivity
Check treatment probabilities at each timepoint.

### 9.2 Extreme weights
LMTP handles this better than IPTW, but diagnostics still matter.

### 9.3 Truncation
May be needed for sparse treatment histories.

### 9.4 Negative control outcomes
Useful to diagnose unmeasured confounding.

---

# 10. Summary

In this chapter, you learned how to:

- Build and structure longitudinal data  
- Define static longitudinal interventions  
- Apply LMTP/TMLE for longitudinal causal effects  
- Interpret results in a real-world regulatory context  

This case study demonstrates how to use targeted learning methods to generate high-quality causal evidence from complex real-world data.

```{r}
sessionInfo()
```
